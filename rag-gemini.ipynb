{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13947559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"all-of-statistics.pdf\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8501a686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 0, 'page_label': '1'}, page_content='To Isa'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 1, 'page_label': '2'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 2, 'page_label': '3'}, page_content='Preface\\nTaken literally, the title “All of Statistics” is an exaggeration. But in spirit,\\nthe title is apt, as the book does cover a much broader range of topics than a\\ntypical introductory book on mathematical statistics.\\nThis book is for people who want to learn probability and statistics quickly.\\nIt is suitable for graduate or advanced undergraduate students in computer\\nscience, mathematics, statistics, and related disciplines. The book includes\\nmodern topics like nonparametric curve estimation, bootstrapping, and clas-\\nsiﬁcation, topics that are usually relegated to follow-up courses. The reader is\\npresumed to know calculus and a littlelinear algebra. No previous knowledge\\nof probability and statistics is required.\\nStatistics, data mining,a n dmachine learning are all concerned with\\ncollecting and analyzing data. For some time, statistics research was con-\\nducted in statistics departments while data mining and machine learning re-\\nsearch was conducted in computer science departments. Statisticians thought\\nthat computer scientists were reinventing the wheel. Computer scientists\\nthought that statistical theory didn’t apply to their problems.\\nThings are changing. Statisticians now recognize that computer scientists\\nare making novel contributions while computer scientists now recognize the\\ngenerality of statistical theory and methodology. Clever data mining algo-\\nrithms are more scalable than statisticians ever thought possible. Formal sta-\\ntistical theory is more pervasive than computer scientists had realized.\\nStudents who analyze data, or who aspire to develop new methods for\\nanalyzing data, should be well grounded in basic probability and mathematical\\nstatistics. Using fancy tools like neural nets, boosting, and support vector'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 3, 'page_label': '4'}, page_content='viii Preface\\nmachines without understanding basic statistics is like doing brain surgery\\nbefore knowing how to use a band-aid.\\nBut where can students learn basic probability and statistics quickly? Nowhere.\\nAt least, that was my conclusion when my computer science colleagues kept\\nasking me: “Where can I send my students to get a good understanding of\\nmodern statistics quickly?” The typical mathematical statistics course spends\\ntoo much time on tedious and uninspiring topics (counting methods, two di-\\nmensional integrals, etc.) at the expense of covering modern concepts (boot-\\nstrapping, curve estimation, graphical models, etc.). So I set out to redesign\\nour undergraduate honors course on probability and mathematical statistics.\\nThis book arose from that course. Here is a summary of the main features of\\nthis book.\\n1. The book is suitable for graduate students in computer science and\\nhonors undergraduates in math, statistics, and computer science. It is\\nalso useful for students beginning graduate work in statistics who need\\nto ﬁll in their background on mathematical statistics.\\n2. I cover advanced topics that are traditionally not taught in a ﬁrst course.\\nFor example, nonparametric regression, bootstrapping, density estima-\\ntion, and graphical models.\\n3. I have omitted topics in probability that do not play a central role in\\nstatistical inference. For example, counting methods are virtually ab-\\nsent.\\n4. Whenever possible, I avoid tedious calculations in favor of emphasizing\\nconcepts.\\n5. I cover nonparametric inference before parametric inference.\\n6. I abandon the usual “First Term = Probability” and “Second Term\\n= Statistics” approach. Some students only take the ﬁrst half and it\\nwould be a crime if they did not see any statistical theory. Furthermore,\\nprobability is more engaging when students can see it put to work in the\\ncontext of statistics. An exception is the topic of stochastic processes\\nwhich is included in the later material.\\n7. The course moves very quickly and covers much material. My colleagues\\njoke that I cover all of statistics in this course and hence the title. The\\ncourse is demanding but I have worked hard to make the material as\\nintuitive as possible so that the material is very understandable despite\\nthe fast pace.\\n8. Rigor and clarity are not synonymous. I have tried to strike a good\\nbalance. To avoid getting bogged down in uninteresting technical details,\\nmany results are stated without proof. The bibliographic references at\\nthe end of each chapter point the student to appropriate sources.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 4, 'page_label': '5'}, page_content='Preface ix\\nData generating process Observed data\\nProbability\\nInference and Data Mining\\nFIGURE 1. Probability and inference.\\n9. On my website are ﬁles with R code which students can use for doing\\nall the computing. The website is:\\nhttp://www.stat.cmu.edu/∼larry/all-of-statistics\\nHowever, the book is not tied to R and any computing language can be\\nused.\\nPart I of the text is concerned with probability theory, the formal language\\nof uncertainty which is the basis of statistical inference. The basic problem\\nthat we study in probability is:\\nGiven a data generating process, what are the properties of the out-\\ncomes?\\nPart II is about statistical inference and its close cousins, data mining and\\nmachine learning. The basic problem of statistical inference is the inverse of\\nprobability:\\nGiven the outcomes, what can we say about the process that gener-\\nated the data?\\nThese ideas are illustrated in Figure 1. Prediction, classiﬁcation, clustering,\\nand estimation are all special cases of statistical inference. Data analysis,\\nmachine learning and data mining are various names given to the practice of\\nstatistical inference, depending on the context.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 5, 'page_label': '6'}, page_content='xP r e f a c e\\nPart III applies the ideas from Part II to speciﬁc problems such as regres-\\nsion, graphical models, causation, density estimation, smoothing, classiﬁca-\\ntion, and simulation. Part III contains one more chapter on probability that\\ncovers stochastic processes including Markov chains.\\nI have drawn on other books in many places. Most chapters contain a section\\ncalled Bibliographic Remarks which serves both to acknowledge my debt to\\nother authors and to point readers to other useful references. I would especially\\nlike to mention the books by DeGroot and Schervish (2002) and Grimmett\\nand Stirzaker (1982) from which I adapted many examples and exercises.\\nAs one develops a book over several years it is easy to lose track of where pre-\\nsentation ideas and, especially, homework problems originated. Some I made\\nup. Some I remembered from my education. Some I borrowed from other\\nbooks. I hope I do not oﬀend anyone if I have used a problem from their book\\nand failed to give proper credit. As my colleague Mark Schervish wrote in his\\nbook (Schervish (1995)),\\n“ ...t h ep r o b l e m sa tt h ee n d so fe a c hc h a p t e rh a v ec o m ef r o mm a n y\\ns o u r c e s . ...T h e s e p r o b l e m s , i n t u r n , c a m e f r o m v a r i o u s s o u r c e s\\nu n k n o w nt om e...I fIh a v eu s e dap r o b l e mw i t h o u tg i v i n gp r o pe r\\ncredit, please take it as a compliment.”\\nI am indebted to many people without whose help I could not have written\\nthis book. First and foremost, the many students who used earlier versions\\nof this text and provided much feedback. In particular, Liz Prather and Jen-\\nnifer Bakal read the book carefully. Rob Reeder valiantly read through the\\nentire book in excruciating detail and gave me countless suggestions for im-\\nprovements. Chris Genovese deserves special mention. He not only provided\\nhelpful ideas about intellectual content, but also spent many, many hours\\nwriting L\\nATEXcode for the book. The best aspects of the book’s layout are due\\nto his hard work; any stylistic deﬁcien cies are due to my lack of expertise.\\nDavid Hand, Sam Roweis, and David Scott read the book very carefully and\\nmade numerous suggestions that greatly improved the book. John Laﬀerty\\nand Peter Spirtes also provided helpful feedback. John Kimmel has been sup-\\nportive and helpful throughout the writing process. Finally, my wife Isabella\\nVerdinelli has been an invaluable source of love, support, and inspiration.\\nLarry Wasserman\\nPittsburgh, Pennsylvania\\nJuly 2003'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 6, 'page_label': '7'}, page_content='Preface xi\\nStatistics/Data Mining Dictionary\\nStatisticians and computer scientists often use diﬀerent language for the\\nsame thing. Here is a dictionary that the reader may want to return to\\nthroughout the course.\\nStatistics\\nComputer Science Meaning\\nestimation learning using data to estimate\\nan unknown quantity\\nclassiﬁcation supervised learning predicting a discrete Y\\nfrom X\\nclustering unsupervised learning putting data into groups\\ndata training sample ( X\\n1,Y1),..., (Xn,Yn)\\ncovariates features the Xi’s\\nclassiﬁer hypothesis a map from covariates\\nto outcomes\\nhypothesis — subset of a parameter\\nspace Θ\\nconﬁdence interval — interval that contains an\\nunknown quantity\\nwith given frequency\\ndirected acyclic graph Bayes net multivariate distribution\\nwith given conditional\\nindependence relations\\nBayesian inference Bayesian inference statistical methods for\\nusing data to\\nupdate beliefs\\nfrequentist inference — statistical methods\\nwith guaranteed\\nfrequency behavior\\nlarge deviation bounds PAC learning uniform bounds on\\nprobability of errors'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 7, 'page_label': '8'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 8, 'page_label': '9'}, page_content='Contents\\nI Probability\\n1 Probability 3\\n1.1 Introduction ............................. 3\\n1.2 Sample Spaces and Events ..................... 3\\n1.3 Probability ............................. 5\\n1.4 Probability on Finite Sample Spaces ............... 7\\n1.5 Independent Events ........................ 8\\n1.6 Conditional Probability ...................... 1 0\\n1.7 Bayes’ Theorem ........................... 1 2\\n1.8 Bibliographic Remarks ....................... 1 3\\n1.9 Appendix .............................. 1 3\\n1.10 Exercises .............................. 1 3\\n2 Random Variables 19\\n2.1 Introduction ............................. 1 9\\n2.2 Distribution Functions and Probability Functions ........ 2 0\\n2.3 Some Important Discrete Random Variables ........... 2 5\\n2.4 Some Important Continuous Random Variables ......... 2 7\\n2.5 Bivariate Distributions ....................... 3 1\\n2.6 Marginal Distributions ....................... 3 3\\n2.7 Independent Random Variables .................. 3 4\\n2.8 Conditional Distributions ..................... 3 6'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 9, 'page_label': '10'}, page_content='xiv Contents\\n2.9 Multivariate Distributions and iid Samples ........... 3 8\\n2.10 Two Important Multivariate Distributions ............ 3 9\\n2.11 Transformations of Random Variables .............. 4 1\\n2.12 Transformations of Several Random Variables .......... 4 2\\n2.13 Appendix .............................. 4 3\\n2.14 Exercises .............................. 4 3\\n3 Expectation 47\\n3.1 Expectation of a Random Variable ................ 4 7\\n3.2 Properties of Expectations ..................... 5 0\\n3.3 Variance and Covariance ...................... 5 0\\n3.4 Expectation and Variance of Important Random Variables . . . 52\\n3.5 Conditional Expectation ...................... 5 4\\n3.6 Moment Generating Functions .................. 5 6\\n3.7 Appendix .............................. 5 8\\n3.8 Exercises .............................. 5 8\\n4 Inequalities 63\\n4.1 Probability Inequalities ...................... 6 3\\n4.2 Inequalities For Expectations ................... 6 6\\n4.3 Bibliographic Remarks ....................... 6 6\\n4.4 Appendix .............................. 6 7\\n4.5 Exercises .............................. 6 8\\n5 Convergence of Random Variables 71\\n5.1 Introduction ............................. 7 1\\n5.2 Types of Convergence ....................... 7 2\\n5.3 The Law of Large Numbers .................... 7 6\\n5.4 The Central Limit Theorem .................... 7 7\\n5.5 The Delta Method ......................... 7 9\\n5.6 Bibliographic Remarks ....................... 8 0\\n5.7 Appendix .............................. 8 1\\n5.7.1 Almost Sure and L\\n1 Convergence ............. 8 1\\n5.7.2 Proof of the Central Limit Theorem ........... 8 1\\n5.8 Exercises .............................. 8 2\\nII Statistical Inference\\n6 Models, Statistical Inference and Learning 87\\n6.1 Introduction ............................. 8 7\\n6.2 Parametric and Nonparametric Models .............. 8 7\\n6.3 Fundamental Concepts in Inference ................ 9 0\\n6.3.1 Point Estimation ...................... 9 0\\n6.3.2 Conﬁdence Sets ....................... 9 2'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 10, 'page_label': '11'}, page_content='Contents xv\\n6.3.3 Hypothesis Testing ..................... 9 4\\n6.4 Bibliographic Remarks ....................... 9 5\\n6.5 Appendix .............................. 9 5\\n6.6 Exercises .............................. 9 5\\n7 Estimating the cdf and Statistical Functionals 97\\n7.1 The Empirical Distribution Function ............... 9 7\\n7.2 Statistical Functionals ....................... 9 9\\n7.3 Bibliographic Remarks .......................1 0 4\\n7.4 Exercises ..............................1 0 4\\n8 The Bootstrap 107\\n8.1 Simulation ..............................1 0 8\\n8.2 Bootstrap Variance Estimation ..................1 0 8\\n8.3 Bootstrap Conﬁdence Intervals ..................1 1 0\\n8.4 Bibliographic Remarks .......................1 1 5\\n8.5 Appendix ..............................1 1 5\\n8.5.1 The Jackknife ........................1 1 5\\n8.5.2 Justiﬁcation For The Percentile Interval .........1 1 6\\n8.6 Exercises ..............................1 1 6\\n9 Parametric Inference 119\\n9.1 Parameter of Interest ........................1 2 0\\n9.2 The Method of Moments ......................1 2 0\\n9.3 Maximum Likelihood ........................1 2 2\\n9.4 Properties of Maximum Likelihood Estimators .........1 2 4\\n9.5 Consistency of Maximum Likelihood Estimators .........1 2 6\\n9.6 Equivariance of the mle ......................1 2 7\\n9.7 Asymptotic Normality .......................1 2 8\\n9.8 Optimality .............................1 3 0\\n9.9 The Delta Method .........................1 3 1\\n9.10 Multiparameter Models ......................1 3 3\\n9.11 The Parametric Bootstrap .....................1 3 4\\n9.12 Checking Assumptions .......................1 3 5\\n9.13 Appendix ..............................1 3 5\\n9.13.1 Proofs ............................1 3 5\\n9.13.2 Suﬃciency ..........................1 3 7\\n9.13.3 Exponential Families ....................1 4 0\\n9.13.4 Computing Maximum Likelihood Estimates .......1 4 2\\n9.14 Exercises ..............................1 4 6\\n10 Hypothesis Testing and p-values 149\\n10.1 The Wald Test ...........................1 5 2\\n10.2 p-values ...............................1 5 6\\n10.3 The χ2 Distribution ........................1 5 9'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 11, 'page_label': '12'}, page_content='xvi Contents\\n10.4 Pearson’s χ2 Test For Multinomial Data .............1 6 0\\n10.5 The Permutation Test .......................1 6 1\\n10.6 The Likelihood Ratio Test .....................1 6 4\\n10.7 Multiple Testing ..........................1 6 5\\n10.8 Goodness-of-ﬁt Tests ........................1 6 8\\n10.9 Bibliographic Remarks .......................1 6 9\\n10.10Appendix ..............................1 7 0\\n10.10.1The Neyman-Pearson Lemma ...............1 7 0\\n10.10.2The t-test ..........................1 7 0\\n10.11Exercises ..............................1 7 0\\n11 Bayesian Inference 175\\n11.1 The Bayesian Philosophy .....................1 7 5\\n11.2 The Bayesian Method .......................1 7 6\\n11.3 Functions of Parameters ......................1 8 0\\n11.4 Simulation ..............................1 8 0\\n11.5 Large Sample Properties of Bayes’ Procedures ..........1 8 1\\n11.6 Flat Priors, Improper Priors, and “Noninformative” Priors . . . 181\\n11.7 Multiparameter Problems .....................1 8 3\\n11.8 Bayesian Testing ..........................1 8 4\\n11.9 Strengths and Weaknesses of Bayesian Inference ........1 8 5\\n11.10Bibliographic Remarks .......................1 8 9\\n11.11Appendix ..............................1 9 0\\n11.12Exercises ..............................1 9 0\\n12 Statistical Decision Theory 193\\n12.1 Preliminaries ............................1 9 3\\n12.2 Comparing Risk Functions .....................1 9 4\\n12.3 Bayes Estimators ..........................1 9 7\\n12.4 Minimax Rules ...........................1 9 8\\n12.5 Maximum Likelihood, Minimax, and Bayes ...........2 0 1\\n12.6 Admissibility ............................2 0 2\\n12.7 Stein’s Paradox ...........................2 0 4\\n12.8 Bibliographic Remarks .......................2 0 4\\n12.9 Exercises ..............................2 0 4\\nIII Statistical Models and Methods\\n13 Linear and Logistic Regression 209\\n13.1 Simple Linear Regression .....................2 0 9\\n13.2 Least Squares and Maximum Likelihood .............2 1 2\\n13.3 Properties of the Least Squares Estimators ...........2 1 4\\n13.4 Prediction ..............................2 1 5\\n13.5 Multiple Regression ........................2 1 6'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 12, 'page_label': '13'}, page_content='Contents xvii\\n13.6 Model Selection ...........................2 1 8\\n13.7 Logistic Regression .........................2 2 3\\n13.8 Bibliographic Remarks .......................2 2 5\\n13.9 Appendix ..............................2 2 5\\n13.10Exercises ..............................2 2 6\\n14 Multivariate Models 231\\n14.1 Random Vectors ..........................2 3 2\\n14.2 Estimating the Correlation ....................2 3 3\\n14.3 Multivariate Normal ........................2 3 4\\n14.4 Multinomial .............................2 3 5\\n14.5 Bibliographic Remarks .......................2 3 7\\n14.6 Appendix ..............................2 3 7\\n14.7 Exercises ..............................2 3 8\\n15 Inference About Independence 239\\n15.1 Two Binary Variables .......................2 3 9\\n15.2 Two Discrete Variables .......................2 4 3\\n15.3 Two Continuous Variables .....................2 4 4\\n15.4 One Continuous Variable and One Discrete ...........2 4 4\\n15.5 Appendix ..............................2 4 5\\n15.6 Exercises ..............................2 4 8\\n16 Causal Inference 251\\n16.1 The Counterfactual Model .....................2 5 1\\n16.2 Beyond Binary Treatments ....................2 5 5\\n16.3 Observational Studies and Confounding .............2 5 7\\n16.4 Simpson’s Paradox .........................2 5 9\\n16.5 Bibliographic Remarks .......................2 6 1\\n16.6 Exercises ..............................2 6 1\\n17 Directed Graphs and Conditional Independence 263\\n17.1 Introduction .............................2 6 3\\n17.2 Conditional Independence .....................2 6 4\\n17.3 DAGs ................................2 6 4\\n17.4 Probability and DAGs .......................2 6 6\\n17.5 More Independence Relations ...................2 6 7\\n17.6 Estimation for DAGs ........................2 7 2\\n17.7 Bibliographic Remarks .......................2 7 2\\n17.8 Appendix ..............................2 7 2\\n17.9 Exercises ..............................2 7 6\\n18 Undirected Graphs 281\\n18.1 Undirected Graphs .........................2 8 1\\n18.2 Probability and Graphs ......................2 8 2'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 13, 'page_label': '14'}, page_content='xviii Contents\\n18.3 Cliques and Potentials .......................2 8 5\\n18.4 Fitting Graphs to Data ......................2 8 6\\n18.5 Bibliographic Remarks .......................2 8 6\\n18.6 Exercises ..............................2 8 6\\n19 Log-Linear Models 291\\n19.1 The Log-Linear Model .......................2 9 1\\n19.2 Graphical Log-Linear Models ...................2 9 4\\n19.3 Hierarchical Log-Linear Models ..................2 9 6\\n19.4 Model Generators ..........................2 9 7\\n19.5 Fitting Log-Linear Models to Data ................2 9 8\\n19.6 Bibliographic Remarks .......................3 0 0\\n19.7 Exercises ..............................3 0 1\\n20 Nonparametric Curve Estimation 303\\n20.1 The Bias-Variance Tradeoﬀ ....................3 0 4\\n20.2 Histograms .............................3 0 5\\n20.3 Kernel Density Estimation .....................3 1 2\\n20.4 Nonparametric Regression .....................3 1 9\\n20.5 Appendix ..............................3 2 4\\n20.6 Bibliographic Remarks .......................3 2 5\\n20.7 Exercises ..............................3 2 5\\n21 Smoothing Using Orthogonal Functions 327\\n21.1 Orthogonal Functions and L2 Spaces ...............3 2 7\\n21.2 Density Estimation .........................3 3 1\\n21.3 Regression ..............................3 3 5\\n21.4 Wavelets ...............................3 4 0\\n21.5 Appendix ..............................3 4 5\\n21.6 Bibliographic Remarks .......................3 4 6\\n21.7 Exercises ..............................3 4 6\\n22 Classiﬁcation 349\\n22.1 Introduction ............................3 4 9\\n22.2 Error Rates and the Bayes Classiﬁer ...............3 5 0\\n22.3 Gaussian and Linear Classiﬁers ..................3 5 3\\n22.4 Linear Regression and Logistic Regression ...........3 5 6\\n22.5 Relationship Between Logistic Regression and LDA ......3 5 8\\n22.6 Density Estimation and Naive Bayes ...............3 5 9\\n22.7 Trees ................................3 6 0\\n22.8 Assessing Error Rates and Choosing a Good Classiﬁer .....3 6 2\\n22.9 Support Vector Machines .....................3 6 8\\n22.10 Kernelization ............................3 7 1\\n22.11 Other Classiﬁers ..........................3 7 5\\n22.12 Bibliographic Remarks ......................3 7 7'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 14, 'page_label': '15'}, page_content='Contents xix\\n22.13 Exercises ..............................3 7 7\\n23 Probability Redux: Stochastic Processes 381\\n23.1 Introduction .............................3 8 1\\n23.2 Markov Chains ...........................3 8 3\\n23.3 Poisson Processes ..........................3 9 4\\n23.4 Bibliographic Remarks .......................3 9 7\\n23.5 Exercises ..............................3 9 8\\n24 Simulation Methods 403\\n24.1 Bayesian Inference Revisited ....................4 0 3\\n24.2 Basic Monte Carlo Integration ..................4 0 4\\n24.3 Importance Sampling ........................4 0 8\\n24.4 MCMC Part I: The Metropolis–Hastings Algorithm ......4 1 1\\n24.5 MCMC Part II: Diﬀerent Flavors .................4 1 5\\n24.6 Bibliographic Remarks .......................4 2 0\\n24.7 Exercises ..............................4 2 0\\nIndex 434'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 15, 'page_label': '16'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 16, 'page_label': '17'}, page_content='Part I\\nProbability'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 17, 'page_label': '18'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 18, 'page_label': '19'}, page_content='1\\nProbability\\n1.1 Introduction\\nProbability is a mathematical language for quantifying uncertainty. In this\\nChapter we introduce the basic concepts underlying probability theory. We\\nbegin with the sample space, which is the set of possible outcomes.\\n1.2 Sample Spaces and Events\\nThe sample space Ω is the set of possible outcomes of an experiment. Points\\nω in Ω are called sample outcomes, realizations,o r elements. Subsets of\\nΩ are called Events.\\n1.1 Example. If we toss a coin twice then Ω ={HH,HT,TH,TT }. The event\\nthat the ﬁrst toss is heads is A = {HH,HT }. ■\\n1.2 Example. Let ω be the outcome of a measurement of some physical quan-\\ntity, for example, temperature. Then Ω =R =( −∞,∞). One could argue that\\ntaking Ω = R is not accurate since temperature has a lower bound. But there\\nis usually no harm in taking the sample space to be larger than needed. The\\nevent that the measurement is larger than 10 but less than or equal to 23 is\\nA = (10,23].\\n■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 19, 'page_label': '20'}, page_content='4 1. Probability\\n1.3 Example. If we toss a coin forever, then the sample space is the inﬁnite\\nset\\nΩ=\\n{\\nω =( ω1,ω 2,ω 3,..., ): ωi ∈{ H,T }\\n}\\n.\\nLet E be the event that the ﬁrst head appears on the third toss. Then\\nE =\\n{\\n(ω1,ω 2,ω 3,..., ): ω1 = T,ω 2 = T,ω 3 = H, ω i ∈{ H,T } for i> 3\\n}\\n. ■\\nGiven an event A, let Ac = {ω ∈ Ω: ω/∈ A} denote the complement of\\nA. Informally, Ac can be read as “not A.” The complement of Ω is the empty\\nset ∅. The union of events A and B is deﬁned\\nA\\n⋃\\nB = {ω ∈ Ω: ω ∈ A or ω ∈ B or ω ∈ both}\\nwhich can be thought of as “A or B.” If A1,A2,... is a sequence of sets then\\n∞⋃\\ni=1\\nAi =\\n{\\nω ∈ Ω: ω ∈ Ai for at least one i\\n}\\n.\\nThe intersection of A and B is\\nA\\n⋂\\nB = {ω ∈ Ω: ω ∈ A and ω ∈ B}\\nread “A and B.” Sometimes we write A ⋂ B as AB or (A, B). If A1,A2,... is\\na sequence of sets then\\n∞⋂\\ni=1\\nAi =\\n{\\nω ∈ Ω: ω ∈ Ai for all i\\n}\\n.\\nThe set diﬀerence is deﬁned byA−B = {ω : ω ∈ A, ω /∈ B}. If every element\\nof A is also contained in B we write A ⊂ B or, equivalently,B ⊃ A.I f A is a\\nﬁnite set, let |A| denote the number of elements in A. See the following table\\nfor a summary.\\nSummary of Terminology\\nΩ sample space\\nω outcome (point or element)\\nA event (subset of Ω)\\nAc complement of A (not A)\\nA ⋃ B union (A or B)\\nA ⋂ B or AB intersection (A and B)\\nA − B set diﬀerence (ω in A but not in B)\\nA ⊂ B set inclusion\\n∅ null event (always false)\\nΩ true event (always true)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 20, 'page_label': '21'}, page_content='1.3 Probability 5\\nWe say thatA1,A2,... are disjointor aremutually exclusiveif Ai\\n⋂ Aj =\\n∅ whenever i ̸= j. For example, A1 =[ 0,1),A2 =[ 1,2),A3 =[ 2,3),... are\\ndisjoint. A partition of Ω is a sequence of disjoint sets A1,A2,... such that⋃∞\\ni=1 Ai = Ω. Given an event A, deﬁne the indicator function of A by\\nIA(ω)= I(ω ∈ A)=\\n{\\n1i f ω ∈ A\\n0i f ω/∈ A.\\nA sequence of sets A1,A2,... is monotone increasing if A1 ⊂ A2 ⊂\\n··· and we deﬁne lim n→∞ An = ⋃∞\\ni=1 Ai. A sequence of sets A1,A2,... is\\nmonotone decreasing if A1 ⊃ A2 ⊃ ··· and then we deﬁne limn→∞ An =⋂∞\\ni=1 Ai. In either case, we will write An → A.\\n1.4 Example. Let Ω =R and letAi =[ 0,1/i) fori =1 ,2,... . Then⋃∞\\ni=1 Ai =\\n[0,1) and ⋂∞\\ni=1 Ai = {0}. If instead we deﬁne Ai =( 0,1/i) then ⋃∞\\ni=1 Ai =\\n(0,1) and ⋂∞\\ni=1 Ai = ∅. ■\\n1.3 Probability\\nWe will assign a real numberP(A) to every eventA, called theprobability of\\nA. 1 We also callP a probability distribution or a probability measure.\\nTo qualify as a probability,P must satisfy three axioms:\\n1.5 Deﬁnition. A function P that assigns a real number P(A) to each\\nevent A is a probability distribution or a probability measure if it\\nsatisﬁes the following three axioms:\\nAxiom 1: P(A) ≥ 0 for every A\\nAxiom 2: P( Ω )=1\\nAxiom 3:I f A\\n1,A2,... are disjoint then\\nP\\n\\uf8f6∞⋃\\ni=1\\nAi\\n\\uf8f7\\n=\\n∞∑\\ni=1\\nP(Ai).\\n1It is not always possible to assign a probability to every eventA if the sample space is large,\\nsuch as the whole real line. Instead, we assign probabilities to a limited class of set called a\\nσ-ﬁeld. See the appendix for details.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 21, 'page_label': '22'}, page_content='6 1. Probability\\nThere are many interpretations of P(A). The two common interpretations\\nare frequencies and degrees of beliefs. In the frequency interpretation, P(A)\\nis the long run proportion of times thatA is true in repetitions. For example,\\nif we say that the probability of heads is 1/2, we mean that if we ﬂip the\\ncoin many times then the proportion of times we get heads tends to 1/2 as\\nthe number of tosses increases. An inﬁnitely long, unpredictable sequence of\\ntosses whose limiting proportion tends to a constant is an idealization, much\\nlike the idea of a straight line in geometry. The degree-of-belief interpretation\\nis that P(A) measures an observer’s strength of belief thatA is true. In either\\ninterpretation, we require that Axioms 1 to 3 hold. The diﬀerence in inter-\\npretation will not matter much until we deal with statistical inference. There,\\nthe diﬀering interpretations lead to two schools of inference: the frequentist\\nand the Bayesian schools. We defer discussion until Chapter 11.\\nOne can derive many properties of P from the axioms, such as:\\nP(∅)=0\\nA ⊂ B =⇒ P(A) ≤ P(B)\\n0 ≤ P(A) ≤ 1\\nP(A\\nc)=1 − P(A)\\nA\\n⋂\\nB = ∅ =⇒ P\\n\\uf8f6\\nA\\n⋃\\nB\\n\\uf8f7\\n= P(A)+ P(B). (1.1)\\nA less obvious property is given in the following Lemma.\\n1.6 Lemma. For any events A and B,\\nP\\n\\uf8f6\\nA\\n⋃\\nB\\n\\uf8f7\\n= P(A)+ P(B) − P(AB).\\nProof. Write A ⋃ B =( ABc) ⋃(AB) ⋃(AcB) and note that these events\\nare disjoint. Hence, making repeated use of the fact that P is additive for\\ndisjoint events, we see that\\nP\\n\\uf8f6\\nA\\n⋃\\nB\\n\\uf8f7\\n= P\\n\\uf8f6\\n(ABc)\\n⋃\\n(AB)\\n⋃\\n(AcB)\\n\\uf8f7\\n= P(ABc)+ P(AB)+ P(AcB)\\n= P(ABc)+ P(AB)+ P(AcB)+ P(AB) − P(AB)\\n= P\\n\\uf8f6\\n(ABc)\\n⋃\\n(AB)\\n\\uf8f7\\n+ P\\n\\uf8f6\\n(AcB)\\n⋃\\n(AB)\\n\\uf8f7\\n− P(AB)\\n= P(A)+ P(B) − P(AB). ■\\n1.7 Example. Two coin tosses. Let H1 be the event that heads occurs on\\ntoss 1 and let H2 be the event that heads occurs on toss 2. If all outcomes are'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 22, 'page_label': '23'}, page_content='1.4 Probability on Finite Sample Spaces 7\\nequally likely, thenP(H1\\n⋃ H2)= P(H1)+P(H2)−P(H1H2)= 1\\n2 +1\\n2 −1\\n4 =3 /4.\\n■\\n1.8 Theorem (Continuity of Probabilities). If An → A then\\nP(An) → P(A)\\nas n →∞ .\\nProof. Suppose that An is monotone increasing so that A1 ⊂ A2 ⊂ ··· .\\nLet A = limn→∞ An = ⋃∞\\ni=1 Ai. Deﬁne B1 = A1, B2 = {ω ∈ Ω: ω ∈\\nA2,ω /∈ A1}, B3 = {ω ∈ Ω: ω ∈ A3,ω /∈ A2,ω /∈ A1},... It can be\\nshown that B1,B2,... are disjoint, An = ⋃n\\ni=1 Ai = ⋃n\\ni=1 Bi for each n and⋃∞\\ni=1 Bi = ⋃∞\\ni=1 Ai. (See exercise 1.) From Axiom 3,\\nP(An)= P\\n\\uf8f6 n⋃\\ni=1\\nBi\\n\\uf8f7\\n=\\nn∑\\ni=1\\nP(Bi)\\nand hence, using Axiom 3 again,\\nlim\\nn→∞\\nP(An) = lim\\nn→∞\\nn∑\\ni=1\\nP(Bi)=\\n∞∑\\ni=1\\nP(Bi)= P\\n\\uf8f6∞⋃\\ni=1\\nBi\\n\\uf8f7\\n= P(A). ■\\n1.4 Probability on Finite Sample Spaces\\nSuppose that the sample space Ω = {ω1,...,ω n} is ﬁnite. For example, if we\\ntoss a die twice, then Ω has 36 elements: Ω ={(i, j); i, j ∈{ 1,... 6}}. If each\\noutcome is equally likely, then P(A)= |A|/36 where |A| denotes the number\\nof elements in A. The probability that the sum of the dice is 11 is 2/36 since\\nthere are two outcomes that correspond to this event.\\nIf Ω is ﬁnite and if each outcome is equally likely, then\\nP(A)= |A|\\n|Ω|,\\nwhich is called the uniform probability distribution. To compute prob-\\nabilities, we need to count the number of points in an event A. Methods for\\ncounting points are called combinatorial methods. We needn’t delve into these\\nin any great detail. We will, however, need a few facts from counting theory\\nthat will be useful later. Given n objects, the number of ways of ordering'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 23, 'page_label': '24'}, page_content='8 1. Probability\\nthese objects is n!= n(n − 1)(n − 2) ··· 3 · 2 · 1. For convenience, we deﬁne\\n0! = 1. We also deﬁne \\uf8f6n\\nk\\n\\uf8f7\\n= n!\\nk!(n − k)!, (1.2)\\nread “n choose k”, which is the number of distinct ways of choosingk objects\\nfrom n. For example, if we have a class of 20 people and we want to select a\\ncommittee of 3 students, then there are\\n\\uf8f620\\n3\\n\\uf8f7\\n= 20!\\n3!17! = 20 × 19 × 18\\n3 × 2 × 1 = 1140\\npossible committees. We note the following properties:\\n\\uf8f6n\\n0\\n\\uf8f7\\n=\\n\\uf8f6n\\nn\\n\\uf8f7\\n= 1 and\\n\\uf8f6n\\nk\\n\\uf8f7\\n=\\n\\uf8f6 n\\nn − k\\n\\uf8f7\\n.\\n1.5 Independent Events\\nIf we ﬂip a fair coin twice, then the probability of two heads is 1\\n2 × 1\\n2.W e\\nmultiply the probabilities because we regard the two tosses as independent.\\nThe formal deﬁnition of independence is as follows:\\n1.9 Deﬁnition. Two events A and B are independent if\\nP(AB)= P(A)P(B) (1.3)\\nand we write A ⨿ B. A set of events {Ai : i ∈ I} is independent if\\nP\\n\\uf8f6⋂\\ni∈J\\nAi\\n\\uf8f7\\n=\\n∏\\ni∈J\\nP(Ai)\\nfor every ﬁnite subset J of I.I f A and B are not independent, we write\\nA /gluonbelement/gluonelement/gluonelement/gluonelement/gluonelement/gluoneelementB\\nIndependence can arise in two distinct ways. Sometimes, we explicitly as-\\nsume that two events are independent. For example, in tossing a coin twice,\\nwe usually assume the tosses are independent which reﬂects the fact that the\\ncoin has no memory of the ﬁrst toss. In other instances, we derive indepen-\\ndence by verifying that P(AB)= P(A)P(B) holds. For example, in tossing\\na fair die, let A = {2,4,6} and let B = {1,2,3,4}. Then, A ⋂ B = {2,4},'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 24, 'page_label': '25'}, page_content='1.5 Independent Events 9\\nP(AB)=2 /6= P(A)P(B)=( 1 /2) × (2/3) and so A and B are independent.\\nIn this case, we didn’t assume thatA and B are independent — it just turned\\nout that they were.\\nSuppose that A and B are disjoint events, each with positive probability.\\nCan they be independent? No. This follows sinceP(A)P(B) > 0y e tP(AB)=\\nP(∅) = 0. Except in this special case, there is no way to judge independence\\nby looking at the sets in a Venn diagram.\\n1.10 Example. Toss a fair coin 10 times. LetA =“at least one head.” Let Tj\\nbe the event that tails occurs on the jth toss. Then\\nP(A)=1 − P(Ac)\\n=1 − P(all tails)\\n=1 − P(T1T2 ··· T10)\\n=1 − P(T1)P(T2) ··· P(T10) using independence\\n=1 −\\n\\uf8f61\\n2\\n\\uf8f710\\n≈ .999. ■\\n1.11 Example. Two people take turns trying to sink a basketball into a net.\\nPerson 1 succeeds with probability 1/3 while person 2 succeeds with proba-\\nbility 1/4. What is the probability that person 1 succeeds before person 2?\\nLet E denote the event of interest. Let A\\nj be the event that the ﬁrst success\\nis by person 1 and that it occurs on trial number j. Note that A1,A2,... are\\ndisjoint and that E = ⋃∞\\nj=1 Aj. Hence,\\nP(E)=\\n∞∑\\nj=1\\nP(Aj).\\nNow, P(A1)=1 /3. A2 occurs if we have the sequence person 1 misses, person\\n2 misses, person 1 succeeds. This has probability P(A2)=( 2 /3)(3/4)(1/3) =\\n(1/2)(1/3). Following this logic we see that P(Aj)=( 1 /2)j−1(1/3). Hence,\\nP(E)=\\n∞∑\\nj=1\\n1\\n3\\n\\uf8f61\\n2\\n\\uf8f7j−1\\n= 1\\n3\\n∞∑\\nj=1\\n\\uf8f61\\n2\\n\\uf8f7j−1\\n= 2\\n3.\\nHere we used that fact that, if 0 <r< 1 then ∑ ∞\\nj=k rj = rk/(1 − r). ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 25, 'page_label': '26'}, page_content='10 1. Probability\\nSummary of Independence\\n1. A and B are independent if and only if P(AB)= P(A)P(B).\\n2. Independence is sometimes assumed and sometimes derived.\\n3. Disjoint events with positive probability are not independent.\\n1.6 Conditional Probability\\nAssuming that P(B) > 0, we deﬁne the conditional probability of A given\\nthat B has occurred as follows:\\n1.12 Deﬁnition. If P(B) > 0 then the conditional probability of A\\ngiven B is\\nP(A|B)= P(AB)\\nP(B) . (1.4)\\nThink of P(A|B) as the fraction of times A occurs among those in which\\nB occurs. For any ﬁxed B such that P(B) > 0, P(·|B) is a probability (i.e., it\\nsatisﬁes the three axioms of probability). In particular,P(A|B) ≥ 0, P(Ω|B)=\\n1 and if A1,A2,... are disjoint then P(⋃∞\\ni=1 Ai|B)= ∑ ∞\\ni=1 P(Ai|B). But it\\nis in general not true that P(A|B ⋃ C)= P(A|B)+ P(A|C). The rules of\\nprobability apply to events on the left of the bar. In general it isnot the case\\nthat P(A|B)= P(B|A). People get this confused all the time. For example,\\nthe probability of spots given you have measles is 1 but the probability that\\nyou have measles given that you have spots is not 1. In this case, the diﬀerence\\nbetween P(A|B) and P(B|A) is obvious but there are cases where it is less\\nobvious. This mistake is made often enough in legal cases that it is sometimes\\ncalled the prosecutor’s fallacy.\\n1.13 Example. A medical test for a disease D has outcomes + and −. The\\nprobabilities are:\\nDD c\\n+ .009 .099\\n− .001 .891'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 26, 'page_label': '27'}, page_content='1.6 Conditional Probability 11\\nFrom the deﬁnition of conditional probability,\\nP(+|D)= P(+⋂ D)\\nP(D) = .009\\n.009 +.001 = .9\\nand\\nP(−|Dc)= P(− ⋂ Dc)\\nP(Dc) = .891\\n.891 +.099 ≈ .9.\\nApparently, the test is fairly accurate. Sick people yield a positive 90 percent\\nof the time and healthy people yield a negative about 90 percent of the time.\\nSuppose you go for a test and get a positive. What is the probability you have\\nthe disease? Most people answer .90. The correct answer is\\nP(D|+) = P(+⋂ D)\\nP(+) = .009\\n.009 +.099 ≈ .08.\\nThe lesson here is that you need to compute the answer numerically. Don’t\\ntrust your intuition. ■\\nThe results in the next lemma follow directly from the deﬁnition of condi-\\ntional probability.\\n1.14 Lemma. If A and B are independent events thenP(A|B)= P(A). Also,\\nfor any pair of events A and B,\\nP(AB)= P(A|B)P(B)= P(B|A)P(A).\\nFrom the last lemma, we see that another interpretation of independence is\\nthat knowing B doesn’t change the probability of A. The formula P(AB)=\\nP(A)P(B|A) is sometimes helpful for calculating probabilities.\\n1.15 Example. Draw two cards from a deck, without replacement. Let A be\\nthe event that the ﬁrst draw is the Ace of Clubs and let B be the event that\\nthe second draw is the Queen of Diamonds. Then P(AB)= P(A)P(B|A)=\\n(1/52) × (1/51). ■\\nSummary of Conditional Probability\\n1. If P(B) > 0, then\\nP(A|B)= P(AB)\\nP(B) .\\n2. P(·|B) satisﬁes the axioms of probability, for ﬁxed B. In general,\\nP(A|·) does not satisfy the axioms of probability, for ﬁxed A.\\n3. In general, P(A|B) ̸= P(B|A).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 27, 'page_label': '28'}, page_content='12 1. Probability\\n4. A and B are independent if and only if P(A|B)= P(A).\\n1.7 Bayes’ Theorem\\nBayes’ theorem is the basis of “expert systems” and “Bayes’ nets,” which are\\ndiscussed in Chapter 17. First, we need a preliminary result.\\n1.16 Theorem (The Law of Total Probability). Let A1,...,A k be a partition\\nof Ω. Then, for any event B,\\nP(B)=\\nk∑\\ni=1\\nP(B|Ai)P(Ai).\\nProof. Deﬁne Cj = BAj and note that C1,...,C k are disjoint and that\\nB = ⋃k\\nj=1 Cj. Hence,\\nP(B)=\\n∑\\nj\\nP(Cj)=\\n∑\\nj\\nP(BAj)=\\n∑\\nj\\nP(B|Aj)P(Aj)\\nsince P(BAj)= P(B|Aj)P(Aj) from the deﬁnition of conditional probability.\\n■\\n1.17 Theorem (Bayes’ Theorem). Let A1,...,A k be a partition of Ω such\\nthat P(Ai) > 0 for each i.I f P(B) > 0 then, for each i =1 ,...,k ,\\nP(Ai|B)= P(B|Ai)P(Ai)∑\\nj P(B|Aj)P(Aj). (1.5)\\n1.18 Remark. We call P(Ai) the prior probability of A and P(Ai|B) the\\nposterior probability of A.\\nProof. We apply the deﬁnition of conditional probability twice, followed\\nby the law of total probability:\\nP(Ai|B)= P(AiB)\\nP(B) = P(B|Ai)P(Ai)\\nP(B) = P(B|Ai)P(Ai)∑\\nj P(B|Aj)P(Aj). ■\\n1.19 Example. I divide my email into three categories: A1 = “spam,” A2 =\\n“low priority” andA3 = “high priority.” From previous experience I ﬁnd that'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 28, 'page_label': '29'}, page_content='1.8 Bibliographic Remarks 13\\nP(A1)= .7, P(A2)= .2 and P(A3)= .1. Of course, .7+ .2+ .1=1 .L e t B be\\nthe event that the email contains the word “free.” From previous experience,\\nP(B|A\\n1)= .9, P(B|A2)= .01, P(B|A1)= .01. (Note: .9+ .01 + .01 ̸= 1.) I\\nreceive an email with the word “free.” What is the probability that it is spam?\\nBayes’ theorem yields,\\nP(A\\n1|B)= .9 × .7\\n(.9 × .7 )+(.01 × .2 )+(.01 × .1) = .995. ■\\n1.8 Bibliographic Remarks\\nThe material in this chapter is standard. Details can be found in any number\\nof books. At the introductory level, there is DeGroot and Schervish (2002);\\nat the intermediate level, Grimmett and Stirzaker (1982) and Karr (1993); at\\nthe advanced level there are Billingsley (1979) and Breiman (1992). I adapted\\nmany examples and exercises from DeGroot and Schervish (2002) and Grim-\\nmett and Stirzaker (1982).\\n1.9 Appendix\\nGenerally, it is not feasible to assign probabilities to all subsets of a sample\\nspace Ω. Instead, one restricts attention to a set of events called aσ-algebra\\nor a σ-ﬁeld which is a class A that satisﬁes:\\n(i) ∅∈A ,\\n(ii) if A\\n1,A2,..., ∈A then ⋃∞\\ni=1 Ai ∈A and\\n(iii) A ∈A implies that Ac ∈A .\\nThe sets in A are said to be measurable. We call (Ω ,A)a measurable\\nspace. If P is a probability measure deﬁned on A, then (Ω,A,P) is called a\\nprobability space. When Ω is the real line, we take A to be the smallest\\nσ-ﬁeld that contains all the open subsets, which is called the Borel σ-ﬁeld.\\n1.10 Exercises\\n1. Fill in the details of the proof of Theorem 1.8. Also, prove the monotone\\ndecreasing case.\\n2. Prove the statements in equation (1.1).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 29, 'page_label': '30'}, page_content='14 1. Probability\\n3. Let Ω be a sample space and let A1,A2,..., be events. Deﬁne Bn =⋃∞\\ni=n Ai and Cn = ⋂∞\\ni=n Ai.\\n(a) Show that B1 ⊃ B2 ⊃··· and that C1 ⊂ C2 ⊂··· .\\n(b) Show that ω ∈ ⋂∞\\nn=1 Bn if and only if ω belongs to an inﬁnite\\nnumber of the events A1,A2,... .\\n(c) Show that ω ∈ ⋃∞\\nn=1 Cn if and only if ω belongs to all the events\\nA1,A2,... except possibly a ﬁnite number of those events.\\n4. Let {Ai : i ∈ I} be a collection of events where I is an arbitrary index\\nset. Show that\\n\\uf8f6⋃\\ni∈I\\nAi\\n\\uf8f7c\\n=\\n⋂\\ni∈I\\nAc\\ni and\\n\\uf8f6⋂\\ni∈I\\nAi\\n\\uf8f7c\\n=\\n⋃\\ni∈I\\nAc\\ni\\nHint: First prove this for I = {1,...,n }.\\n5. Suppose we toss a fair coin until we get exactly two heads. Describe\\nthe sample space S. What is the probability that exactly k tosses are\\nrequired?\\n6. Let Ω = {0,1,..., }. Prove that there does not exist a uniform distri-\\nbution on Ω (i.e., if P(A)= P(B) whenever |A| = |B|, then P cannot\\nsatisfy the axioms of probability).\\n7. Let A1,A2,... be events. Show that\\nP\\n\\uf8f6 ∞⋃\\nn=1\\nAn\\n\\uf8f7\\n≤\\n∞∑\\nn=1\\nP (An) .\\nHint: Deﬁne Bn = An − ⋃n−1\\ni=1 Ai. Then show that the Bn are disjoint\\nand that ⋃∞\\nn=1 An = ⋃∞\\nn=1 Bn.\\n8. Suppose that P(Ai) = 1 for each i. Prove that\\nP\\n\\uf8f6∞⋂\\ni=1\\nAi\\n\\uf8f7\\n=1 .\\n9. For ﬁxed B such that P(B) > 0, show that P(·|B) satisﬁes the axioms\\nof probability.\\n10. You have probably heard it before. Now you can solve it rigorously.\\nIt is called the “Monty Hall Problem.” A prize is placed at random'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 30, 'page_label': '31'}, page_content='1.10 Exercises 15\\nbehind one of three doors. You pick a door. To be concrete, let’s suppose\\nyou always pick door 1. Now Monty Hall chooses one of the other two\\ndoors, opens it and shows you that it is empty. He then gives you the\\nopportunity to keep your door or switch to the other unopened door.\\nShould you stay or switch? Intuition suggests it doesn’t matter. The\\ncorrect answer is that you should switch. Prove it. It will help to specify\\nthe sample space and the relevant events carefully. Thus write Ω =\\n{(ω\\n1,ω 2): ωi ∈{ 1,2,3}} where ω1 is where the prize is and ω2 is the\\ndoor Monty opens.\\n11. Suppose that A and B are independent events. Show that Ac and Bc\\nare independent events.\\n12. There are three cards. The ﬁrst is green on both sides, the second is red\\non both sides and the third is green on one side and red on the other. We\\nchoose a card at random and we see one side (also chosen at random).\\nIf the side we see is green, what is the probability that the other side is\\nalso green? Many people intuitively answer 1/2. Show that the correct\\nanswer is 2/3.\\n13. Suppose that a fair coin is tossed repeatedly until both a head and tail\\nhave appeared at least once.\\n(a) Describe the sample space Ω.\\n(b) What is the probability that three tosses will be required?\\n14. Show that if P(A)=0o r P(A) = 1 thenA is independent of every other\\nevent. Show that if A is independent of itself then P(A) is either 0 or 1.\\n15. The probability that a child has blue eyes is 1/4. Assume independence\\nbetween children. Consider a family with 3 children.\\n(a) If it is known that at least one child has blue eyes, what is the\\nprobability that at least two children have blue eyes?\\n(b) If it is known that the youngest child has blue eyes, what is the\\nprobability that at least two children have blue eyes?\\n16. Prove Lemma 1.14.\\n17. Show that\\nP(ABC)= P(A|BC)P(B|C)P(C).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 31, 'page_label': '32'}, page_content='16 1. Probability\\n18. Suppose k events form a partition of the sample space Ω, i.e., they\\nare disjoint and ⋃k\\ni=1 Ai = Ω. Assume that P(B) > 0. Prove that if\\nP(A1|B) < P(A1) then P(Ai|B) > P(Ai) for some i =2 ,...,k .\\n19. Suppose that 30 percent of computer owners use a Macintosh, 50 percent\\nuse Windows, and 20 percent use Linux. Suppose that 65 percent of\\nthe Mac users have succumbed to a computer virus, 82 percent of the\\nWindows users get the virus, and 50 percent of the Linux users get\\nthe virus. We select a person at random and learn that her system was\\ninfected with the virus. What is the probability that she is a Windows\\nuser?\\n20. A box contains 5 coins and each has a diﬀerent probability of show-\\ning heads. Let p\\n1,...,p 5 denote the probability of heads on each coin.\\nSuppose that\\np1 =0 ,p 2 =1 /4,p 3 =1 /2,p 4 =3 /4 and p5 =1 .\\nLet H denote “heads is obtained” and letCi denote the event that coin\\ni is selected.\\n(a) Select a coin at random and toss it. Suppose a head is obtained.\\nWhat is the posterior probability that coini was selected (i =1 ,..., 5)?\\nIn other words, ﬁnd P(Ci|H) for i =1 ,..., 5.\\n(b) Toss the coin again. What is the probability of another head? In\\nother words ﬁnd P(H2|H1) where Hj = “heads on toss j.”\\nNow suppose that the experiment was carried out as follows: We select\\na coin at random and toss it until a head is obtained.\\n(c) Find P(Ci|B4) where B4 = “ﬁrst head is obtained on toss 4.”\\n21. ( Computer Experiment.) Suppose a coin has probabilityp of falling heads\\nup. If we ﬂip the coin many times, we would expect the proportion of\\nheads to be near p. We will make this formal later. Take p = .3 and\\nn =1 ,000 and simulate n coin ﬂips. Plot the proportion of heads as a\\nfunction of n. Repeat for p = .03.\\n22. ( Computer Experiment.) Suppose we ﬂip a coin n times and let p denote\\nthe probability of heads. Let X be the number of heads. We call X\\na binomial random variable, which is discussed in the next chapter.\\nIntuition suggests that X will be close to np . To see if this is true, we\\ncan repeat this experiment many times and average theX values. Carry'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 32, 'page_label': '33'}, page_content='1.10 Exercises 17\\nout a simulation and compare the average of theX’s to np . Try this for\\np = .3 and n = 10, n = 100, and n =1 ,000.\\n23. ( Computer Experiment .) Here we will get some experience simulating\\nconditional probabilities. Consider tossing a fair die. Let A = {2,4,6}\\nand B = {1,2,3,4}. Then, P(A)=1 /2, P(B)=2 /3 and P(AB)=1 /3.\\nSince P(AB)= P(A)P(B), the events A and B are independent. Simu-\\nlate draws from the sample space and verify that ˆP(AB)= ˆP(A)ˆP(B)\\nwhere ˆP(A) is the proportion of times A occurred in the simulation and\\nsimilarly for ˆP(AB) and ˆP(B). Now ﬁnd two eventsA and B that are not\\nindependent. Compute ˆP(A), ˆP(B) and ˆP(AB). Compare the calculated\\nvalues to their theoretical values. Report your results and interpret.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 33, 'page_label': '34'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 34, 'page_label': '35'}, page_content='2\\nRandom Variables\\n2.1 Introduction\\nStatistics and data mining are concerned with data. How do we link sample\\nspaces and events to data? The link is provided by the concept of a random\\nvariable.\\n2.1 Deﬁnition. A random variable is a mapping1\\nX :Ω → R\\nthat assigns a real number X(ω) to each outcome ω.\\nAt a certain point in most probability courses, the sample space is rarely\\nmentioned anymore and we work directly with random variables. But you\\nshould keep in mind that the sample space is really there, lurking in the\\nbackground.\\n2.2 Example. Flip a coin ten times. Let X(ω) be the number of heads in the\\nsequence ω. For example, if ω = HHTHHTHHTT , then X(ω)=6 .\\n■\\n1Technically, a random variable must be measurable. See the appendix for details.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 35, 'page_label': '36'}, page_content='20 2. Random Variables\\n2.3 Example. Let Ω =\\n{\\n(x, y); x2 + y2 ≤ 1\\n}\\nbe the unit disk. Consider\\ndrawing a point at random from Ω. (We will make this idea more precise\\nlater.) A typical outcome is of the formω =( x, y). Some examples of random\\nvariables are X(ω)= x, Y (ω)= y, Z(ω)= x + y, and W(ω)=\\n√\\nx2 + y2. ■\\nGiven a random variableX and a subsetA of the real line, deﬁneX−1(A)=\\n{ω ∈ Ω: X(ω) ∈ A} and let\\nP(X ∈ A)= P(X−1(A)) = P({ω ∈ Ω; X(ω) ∈ A})\\nP(X = x)= P(X−1(x)) = P({ω ∈ Ω; X(ω)= x}).\\nNotice that X denotes the random variable and x denotes a particular value\\nof X.\\n2.4 Example. Flip a coin twice and let X be the number of heads. Then,\\nP(X =0 )= P({TT })=1 /4, P(X =1 )= P({HT,TH })=1 /2 and\\nP(X =2 )= P({HH})=1 /4. The random variable and its distribution\\ncan be summarized as follows:\\nω P({ω}) X(ω)\\nTT 1/4 0\\nTH 1/4 1\\nHT 1/4 1\\nHH 1/4 2\\nx P(X = x)\\n0 1/4\\n1 1/2\\n2 1/4\\nTry generalizing this to n ﬂips. ■\\n2.2 Distribution Functions and Probability Functions\\nGiven a random variable X, we deﬁne the cumulative distribution function\\n(or distribution function) as follows.\\n2.5 Deﬁnition. The cumulative distribution function,o r cdf,i st h e\\nfunction FX : R → [0,1] deﬁned by\\nFX(x)= P(X ≤ x). (2.1)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 36, 'page_label': '37'}, page_content='2.2 Distribution Functions and Probability Functions 21\\n012\\n1\\n/Bullet\\n/Bullet\\n/Bullet\\nFX(x)\\nx\\n.25\\n.50\\n.75\\nFIGURE 2.1. cdf for ﬂipping a coin twice (Example 2.6.)\\nWe will see later that thecdf eﬀectively contains all the information about\\nthe random variable. Sometimes we write the cdf as F instead of FX.\\n2.6 Example. Flip a fair coin twice and let X be the number of heads. Then\\nP(X =0 )= P(X =2 )=1 /4 and P(X =1 )=1 /2. The distribution function\\nis\\nFX(x)=\\n\\uf8f1\\n\\uf8f4\\uf8f4\\n\\uf8f2\\n\\uf8f4\\uf8f4\\n\\uf8f3\\n0 x< 0\\n1/40 ≤ x< 1\\n3/41 ≤ x< 2\\n1 x ≥ 2.\\nThe cdf is shown in Figure 2.1. Although this example is simple, study it\\ncarefully. cdf’s can be very confusing. Notice that the function is right contin-\\nuous, non-decreasing, and that it is deﬁned for allx, even though the random\\nvariable only takes values 0,1, and 2. Do you see why F\\nX(1.4) = .75? ■\\nThe following result shows that the cdf completely determines the distri-\\nbution of a random variable.\\n2.7 Theorem. Let X have cdf F and let Y have cdf G.I f F(x)= G(x) for\\nall x, then P(X ∈ A)= P(Y ∈ A) for all A. 2\\n2.8 Theorem. A function F mapping the real line to[0,1] is a cdf for some\\nprobability P if and only if F satisﬁes the following three conditions:\\n(i) F is non-decreasing: x1 <x 2 implies that F(x1) ≤ F(x2).\\n(ii) F is normalized:\\nlim\\nx→−∞\\nF(x)=0\\n2Technically, we only have thatP(X ∈ A)= P(Y ∈ A) for every measurable event A.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 37, 'page_label': '38'}, page_content='22 2. Random Variables\\nand\\nlim\\nx→∞\\nF(x)=1 .\\n(iii) F is right-continuous: F(x)= F(x+) for all x, where\\nF(x+) = lim\\ny→x\\ny>x\\nF(y).\\nProof. Suppose that F is a cdf. Let us show that (iii) holds. Let x be\\na real number and let y1,y 2,... be a sequence of real numbers such that\\ny1 >y 2 > ··· and limi yi = x. Let Ai =( −∞,y i] and let A =( −∞,x]. Note\\nthat A = ⋂∞\\ni=1 Ai and also note that A1 ⊃ A2 ⊃··· . Because the events are\\nmonotone, limi P(Ai)= P(⋂\\ni Ai). Thus,\\nF(x)= P(A)= P\\n\\uf8f6⋂\\ni\\nAi\\n\\uf8f7\\n= lim\\ni\\nP(Ai) = lim\\ni\\nF(yi)= F(x+).\\nShowing (i) and (ii) is similar. Proving the other direction — namely, that if\\nF satisﬁes (i), (ii), and (iii) then it is acdf for some random variable — uses\\nsome deep tools in analysis. ■\\n2.9 Deﬁnition. X is discrete if it takes countably3many values\\n{x1,x2,... }. We deﬁne the probability function or probability mass\\nfunction for X by fX(x)= P(X = x).\\nThus, fX(x) ≥ 0 for all x ∈ R and ∑\\ni fX(xi) = 1. Sometimes we write f\\ninstead of fX. The cdf of X is related to fX by\\nFX(x)= P(X ≤ x)=\\n∑\\nxi≤x\\nfX(xi).\\n2.10 Example. The probability function for Example 2.6 is\\nfX(x)=\\n\\uf8f1\\n\\uf8f4\\uf8f4\\n\\uf8f2\\n\\uf8f4\\uf8f4\\n\\uf8f3\\n1/4 x =0\\n1/2 x =1\\n1/4 x =2\\n0 otherwise .\\nSee Figure 2.2.\\n■\\n3A set is countable if it is ﬁnite or it can be put in a one-to-one correspondence with the\\nintegers. The even numbers, the odd numbers, and the rationals are countable; the set of real\\nnumbers between 0 and 1 is not countable.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 38, 'page_label': '39'}, page_content='2.2 Distribution Functions and Probability Functions 23\\n012\\n1\\n/Bullet\\n/Bullet\\n/Bullet\\nfX(x)\\nx\\n.25\\n.5\\n.75\\nFIGURE 2.2. Probability function for ﬂipping a coin twice (Example 2.6).\\n2.11 Deﬁnition. A random variable X is continuous if there exists a\\nfunction fX such that fX(x) ≥ 0 for all x,\\n∫∞\\n−∞ fX(x)dx =1 and for\\nevery a ≤ b,\\nP(a<X<b )=\\n∫ b\\na\\nfX(x)dx. (2.2)\\nThe function fX is called the probability density function (pdf). We\\nhave that\\nFX(x)=\\n∫ x\\n−∞\\nfX(t)dt\\nand fX(x)= F′\\nX(x) at all points x at which FX is diﬀerentiable.\\nSometimes we write\\n∫\\nf(x)dx or\\n∫\\nf to mean\\n∫∞\\n−∞ f(x)dx.\\n2.12 Example. Suppose that X has pdf\\nfX(x)=\\n{ 1 for 0 ≤ x ≤ 1\\n0 otherwise .\\nClearly, fX(x) ≥ 0 and\\n∫\\nfX(x)dx = 1. A random variable with this density\\nis said to have a Uniform (0,1) distribution. This is meant to capture the idea\\nof choosing a point at random between 0 and 1. The cdf is given by\\nF\\nX(x)=\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n0 x< 0\\nx 0 ≤ x ≤ 1\\n1 x> 1.\\nSee Figure 2.3. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 39, 'page_label': '40'}, page_content='24 2. Random Variables\\n01\\n1\\nFX(x)\\nx\\nFIGURE 2.3. cdf for Uniform (0,1).\\n2.13 Example. Suppose that X has pdf\\nf(x)=\\n{ 0 for x< 0\\n1\\n(1+x)2 otherwise.\\nSince\\n∫\\nf(x)dx = 1, this is a well-deﬁned pdf. ■\\nWarning! Continuous random variables can lead to confusion. First, note\\nthat if X is continuous then P(X = x) = 0 for every x. Don’t try to think\\nof f(x)a s P(X = x). This only holds for discrete random variables. We get\\nprobabilities from a pdf by integrating. A pdf can be bigger than 1 (unlike\\na mass function). For example, if f(x)=5f o r x ∈ [0,1/5] and 0 otherwise,\\nthen f(x) ≥ 0 and\\n∫\\nf(x)dx = 1 so this is a well-deﬁned pdf even though\\nf(x) = 5 in some places. In fact, a pdf can be unbounded. For example, if\\nf(x)=( 2 /3)x−1/3 for 0 <x< 1 and f(x) = 0 otherwise, then\\n∫\\nf(x)dx =1\\neven though f is not bounded.\\n2.14 Example. Let\\nf(x)=\\n{ 0 for x< 0\\n1\\n(1+x) otherwise.\\nThis is not apdf since\\n∫\\nf(x)dx =\\n∫∞\\n0 dx/(1+ x)=\\n∫∞\\n1 du/u = log(∞)= ∞.\\n■\\n2.15 Lemma. Let F be the cdf for a random variable X. Then:\\n1. P(X = x)= F(x) − F(x−) where F(x−) = limy↑x F(y);'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 40, 'page_label': '41'}, page_content='2.3 Some Important Discrete Random Variables 25\\n2. P(x<X ≤ y)= F(y) − F(x);\\n3. P(X>x )=1 − F(x);\\n4. If X is continuous then\\nF(b) − F(a)= P(a<X<b )= P(a ≤ X<b )\\n= P(a<X ≤ b)= P(a ≤ X ≤ b).\\nIt is also useful to deﬁne the inverse cdf (or quantile function).\\n2.16 Deﬁnition. Let X be a random variable with cdf F. The inverse\\nCDF or quantile function is deﬁned by4\\nF−1(q) = inf\\n{\\nx : F(x) >q\\n}\\nfor q ∈ [0,1].I f F is strictly increasing and continuous then F−1(q) is the\\nunique real number x such that F(x)= q.\\nWe call F−1(1/4) the ﬁrst quartile, F−1(1/2) the median (or second\\nquartile), and F−1(3/4) the third quartile.\\nTwo random variables X and Y are equal in distribution — written\\nX\\nd\\n= Y —i f FX(x)= FY (x) for all x. This does not mean that X and Y are\\nequal. Rather, it means that all probability statements about X and Y will\\nbe the same. For example, suppose that P(X =1 )= P(X = −1 )=1 /2. Let\\nY = −X. Then P(Y =1 )= P(Y = −1 )=1 /2 and so X\\nd\\n= Y . But X and Y\\nare not equal. In fact, P(X = Y )=0 .\\n2.3 Some Important Discrete Random Variables\\nWarning About Notation! It is traditional to write X ∼ F to indicate\\nthat X has distribution F. This is unfortunate notation since the symbol ∼\\nis also used to denote an approximation. The notation X ∼ F is so pervasive\\nthat we are stuck with it. ReadX ∼ F as “X has distribution F” not as “X\\nis approximately F”.\\n4If you are unfamiliar with “inf”, just think of it as the minimum.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 41, 'page_label': '42'}, page_content='26 2. Random Variables\\nThe Point Mass Distribution. X has a point mass distribution at a,\\nwritten X ∼ δa,i f P(X = a) = 1 in which case\\nF(x)=\\n{\\n0 x<a\\n1 x ≥ a.\\nThe probability mass function is f(x)=1f o r x = a and 0 otherwise.\\nThe Discrete Uniform Distribution. Let k> 1 be a given integer.\\nSuppose that X has probability mass function given by\\nf(x)=\\n{\\n1/k for x =1 ,...,k\\n0 otherwise .\\nWe say that X has a uniform distribution on {1,...,k }.\\nThe Bernoulli Distribution. Let X represent a binary coin ﬂip. Then\\nP(X =1 )= p and P(X =0 )=1 − p for some p ∈ [0,1]. We say that X has a\\nBernoulli distribution written X ∼ Bernoulli(p). The probability function is\\nf(x)= px(1 − p)1−x for x ∈{ 0,1}.\\nThe Binomial Distribution. Suppose we have a coin which falls heads\\nup with probability p for some 0 ≤ p ≤ 1. Flip the coin n times and let\\nX be the number of heads. Assume that the tosses are independent. Let\\nf(x)= P(X = x) be the mass function. It can be shown that\\nf(x)=\\n{ \\uf8f6n\\nx\\n\\uf8f7\\npx(1 − p)n−x for x =0 ,...,n\\n0 otherwise .\\nA random variable with this mass function is called a Binomial random\\nvariable and we write X ∼ Binomial(n, p). If X1 ∼ Binomial(n1,p ) and\\nX2 ∼ Binomial(n2,p ) then X1 + X2 ∼ Binomial(n1 + n2,p ).\\nWarning! Let us take this opportunity to prevent some confusion. X is a\\nrandom variable; x denotes a particular value of the random variable;n and p\\nare parameters, that is, ﬁxed real numbers. The parameter p is usually un-\\nknown and must be estimated from data; that’s what statistical inference is all\\nabout. In most statistical models, there are random variables and parameters:\\ndon’t confuse them.\\nThe Geometric Distribution. X has a geometric distribution with\\nparameter p ∈ (0,1), written X ∼ Geom(p), if\\nP(X = k)= p(1 − p)\\nk−1,k ≥ 1.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 42, 'page_label': '43'}, page_content='2.4 Some Important Continuous Random Variables 27\\nWe have that\\n∞∑\\nk=1\\nP(X = k)= p\\n∞∑\\nk=1\\n(1 − p)k = p\\n1 − (1 − p) =1 .\\nThink of X as the number of ﬂips needed until the ﬁrst head when ﬂipping a\\ncoin.\\nThe Poisson Distribution.X has a Poisson distribution with parameter\\nλ, written X ∼ Poisson(λ)i f\\nf(x)= e−λ λx\\nx! x ≥ 0.\\nNote that ∞∑\\nx=0\\nf(x)= e−λ\\n∞∑\\nx=0\\nλx\\nx! = e−λeλ =1 .\\nThe Poisson is often used as a model for counts of rare events like radioactive\\ndecay and traﬃc accidents. If X1 ∼ Poisson(λ1) and X2 ∼ Poisson(λ2) then\\nX1 + X2 ∼ Poisson(λ1 + λ2).\\nWarning! We deﬁned random variables to be mappings from a sample\\nspace Ω to R but we did not mention the sample space in any of the distri-\\nbutions above. As I mentioned earlier, the sample space often “disappears”\\nbut it is really there in the background. Let’s construct a sample space ex-\\nplicitly for a Bernoulli random variable. Let Ω = [0,1] and deﬁne P to satisfy\\nP([a, b]) = b − a for 0 ≤ a ≤ b ≤ 1. Fix p ∈ [0,1] and deﬁne\\nX(ω)=\\n{ 1 ω ≤ p\\n0 ω>p .\\nThen P(X =1 )= P(ω ≤ p)= P([0,p ]) = p and P(X =0 )=1 − p. Thus,\\nX ∼ Bernoulli(p). We could do this for all the distributions deﬁned above. In\\npractice, we think of a random variable like a random number but formally it\\nis a mapping deﬁned on some sample space.\\n2.4 Some Important Continuous Random Variables\\nThe Uniform Distribution. X has a Uniform(a, b) distribution, written\\nX ∼ Uniform(a, b), if\\nf(x)=\\n{ 1\\nb−a for x ∈ [a, b]\\n0 otherwise'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 43, 'page_label': '44'}, page_content='28 2. Random Variables\\nwhere a<b . The distribution function is\\nF(x)=\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n0 x<a\\nx−a\\nb−a x ∈ [a, b]\\n1 x>b .\\nNormal (Gaussian). X has a Normal (or Gaussian) distribution with\\nparameters µ and σ, denoted by X ∼ N(µ, σ2), if\\nf(x)= 1\\nσ\\n√\\n2π exp\\n{\\n− 1\\n2σ2 (x − µ)2\\n}\\n,x ∈ R (2.3)\\nwhere µ ∈ R and σ> 0. The parameter µ is the “center” (or mean) of the\\ndistribution and σ is the “spread” (or standard deviation) of the distribu-\\ntion. (The mean and standard deviation will be formally deﬁned in the next\\nchapter.) The Normal plays an important role in probability and statistics.\\nMany phenomena in nature have approximately Normal distributions. Later,\\nwe shall study the Central Limit Theorem which says that the distribution of\\na sum of random variables can be approximated by a Normal distribution.\\nWe say thatX has a standard Normal distribution if µ = 0 and σ =1 .\\nTradition dictates that a standard Normal random variable is denoted by Z.\\nThe pdf and cdf of a standard Normal are denoted by φ(z) and Φ(z). The\\npdf is plotted in Figure 2.4. There is no closed-form expression for Φ. Here\\nare some useful facts:\\n(i) If X ∼ N(µ, σ\\n2), then Z =( X − µ)/σ ∼ N(0,1).\\n(ii) If Z ∼ N(0,1), then X = µ + σZ ∼ N(µ, σ2).\\n(iii) If Xi ∼ N(µi,σ 2\\ni ), i =1 ,...,n are independent, then\\nn∑\\ni=1\\nXi ∼ N\\n\\uf8f6 n∑\\ni=1\\nµi,\\nn∑\\ni=1\\nσ2\\ni\\n\\uf8f7\\n.\\nIt follows from (i) that if X ∼ N(µ, σ2), then\\nP (a<X<b )= P\\n\\uf8f6a − µ\\nσ <Z< b − µ\\nσ\\n\\uf8f7\\n=Φ\\n\\uf8f6b − µ\\nσ\\n\\uf8f7\\n− Φ\\n\\uf8f6a − µ\\nσ\\n\\uf8f7\\n.\\nThus we can compute any probabilities we want as long as we can compute\\nthe cdf Φ(z) of a standard Normal. All statistical computing packages will'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 44, 'page_label': '45'}, page_content='2.4 Some Important Continuous Random Variables 29\\n012−1−2\\nzFIGURE 2.4. Density of a standard Normal.\\ncompute Φ(z) and Φ−1(q). Most statistics texts, including this one, have a\\ntable of values of Φ(z).\\n2.17 Example. Suppose that X ∼ N(3,5). Find P(X> 1). The solution is\\nP(X> 1 )=1 − P(X< 1 )=1 − P\\n\\uf8f6\\nZ< 1 − 3√\\n5\\n\\uf8f7\\n=1 − Φ(−0.8944) = 0.81.\\nNow ﬁnd q =Φ −1(0.2). This means we have to ﬁnd q such that P(X<q )=\\n0.2. We solve this by writing\\n0.2= P(X<q )= P\\n\\uf8f6\\nZ< q − µ\\nσ\\n\\uf8f7\\n=Φ\\n\\uf8f6q − µ\\nσ\\n\\uf8f7\\n.\\nFrom the Normal table, Φ(−0.8416) = 0.2. Therefore,\\n−0.8416 = q − µ\\nσ = q − 3√\\n5\\nand hence q =3 − 0.8416\\n√\\n5=1 .1181. ■\\nExponential Distribution. X has an Exponential distribution with\\nparameter β, denoted by X ∼ Exp(β), if\\nf(x)= 1\\nβ e−x/β,x > 0\\nwhere β> 0. The exponential distribution is used to model the lifetimes of\\nelectronic components and the waiting times between rare events.\\nGamma Distribution. For α> 0, the Gamma function is deﬁned by\\nΓ(α)=\\n∫∞\\n0 yα−1e−ydy. X has a Gamma distribution with parameters α and'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 45, 'page_label': '46'}, page_content='30 2. Random Variables\\nβ, denoted by X ∼ Gamma(α, β), if\\nf(x)= 1\\nβαΓ(α)xα−1e−x/β,x > 0\\nwhere α, β >0. The exponential distribution is just a Gamma(1,β ) distribu-\\ntion. IfXi ∼ Gamma(αi,β ) are independent, then∑ n\\ni=1 Xi ∼ Gamma(∑ n\\ni=1 αi,β ).\\nThe Beta Distribution. X has a Beta distribution with parameters\\nα> 0 and β> 0, denoted by X ∼ Beta(α, β), if\\nf(x)= Γ(α + β)\\nΓ(α)Γ(β)xα−1(1 − x)β−1, 0 <x< 1.\\nt and Cauchy Distribution. X has a t distribution with ν degrees of\\nfreedom — written X ∼ tν —i f\\nf(x)= Γ\\n\\uf8f6ν+1\\n2\\n\\uf8f7\\nΓ\\n\\uf8f6ν\\n2\\n\\uf8f7 1\\n\\uf8f6\\n1+ x2\\nν\\n\\uf8f7(ν+1)/2 .\\nThe t distribution is similar to a Normal but it has thicker tails. In fact, the\\nNormal corresponds to a t with ν = ∞. The Cauchy distribution is a special\\ncase of the t distribution corresponding to ν = 1. The density is\\nf(x)= 1\\nπ(1 +x2).\\nTo see that this is indeed a density:\\n∫ ∞\\n−∞\\nf(x)dx = 1\\nπ\\n∫ ∞\\n−∞\\ndx\\n1+ x2 = 1\\nπ\\n∫ ∞\\n−∞\\nd tan−1(x)\\ndx\\n= 1\\nπ\\n[\\ntan−1(∞) − tan−1(−∞)\\n]\\n= 1\\nπ\\n[π\\n2 −\\n\\uf8f6\\n−π\\n2\\n\\uf8f7]\\n=1 .\\nThe χ2 distribution. X has a χ2 distribution with p degrees of freedom\\n— written X ∼ χ2\\np —i f\\nf(x)= 1\\nΓ(p/2)2p/2 x(p/2)−1e−x/2,x > 0.\\nIf Z1,...,Z p are independent standard Normal random variables then∑ p\\ni=1 Z2\\ni ∼\\nχ2\\np.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 46, 'page_label': '47'}, page_content='2.5 Bivariate Distributions 31\\n2.5 Bivariate Distributions\\nGiven a pair of discrete random variables X and Y , deﬁne the joint mass\\nfunction by f(x, y)= P(X = x and Y = y). From now on, we write P(X =\\nx and Y = y)a s P(X = x, Y = y). We write f as fX,Y when we want to be\\nmore explicit.\\n2.18 Example. Here is a bivariate distribution for two random variables X\\nand Y each taking values 0 or 1:\\nY =0 Y =1\\nX=0 1/9 2/9 1/3\\nX=1 2/9 4/9 2/3\\n1/3 2/3 1\\nThus, f(1,1) = P(X =1 ,Y =1 )=4 /9. ■\\n2.19 Deﬁnition. In the continuous case, we call a function f(x, y) a pdf\\nfor the random variables (X,Y ) if\\n(i) f(x, y) ≥ 0 for all (x, y),\\n(ii)\\n∫∞\\n−∞\\n∫∞\\n−∞ f(x, y)dxdy =1 and,\\n(iii) for any set A ⊂ R × R, P((X,Y ) ∈ A)=\\n∫∫\\nA f(x, y)dxdy.\\nIn the discrete or continuous case we deﬁne the joint cdf as FX,Y (x, y)=\\nP(X ≤ x, Y ≤ y).\\n2.20 Example. Let (X,Y ) be uniform on the unit square. Then,\\nf(x, y)=\\n{ 1i f 0 ≤ x ≤ 1, 0 ≤ y ≤ 1\\n0 otherwise .\\nFind P(X< 1/2,Y < 1/2). The event A = {X< 1/2,Y < 1/2} corresponds\\nto a subset of the unit square. Integrating f over this subset corresponds, in\\nthis case, to computing the area of the setA which is 1/4. So,P(X< 1/2,Y <\\n1/2 )=1 /4. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 47, 'page_label': '48'}, page_content='32 2. Random Variables\\n2.21 Example. Let (X,Y ) have density\\nf(x, y)=\\n{\\nx + y if 0 ≤ x ≤ 1, 0 ≤ y ≤ 1\\n0 otherwise .\\nThen\\n∫ 1\\n0\\n∫ 1\\n0\\n(x + y)dxdy =\\n∫ 1\\n0\\n[∫ 1\\n0\\nxd x\\n]\\ndy +\\n∫ 1\\n0\\n[∫ 1\\n0\\nyd x\\n]\\ndy\\n=\\n∫ 1\\n0\\n1\\n2dy +\\n∫ 1\\n0\\nyd y = 1\\n2 + 1\\n2 =1\\nwhich veriﬁes that this is a pdf ■\\n2.22 Example. If the distribution is deﬁned over a non-rectangular region,\\nthen the calculations are a bit more complicated. Here is an example which I\\nborrowed from DeGroot and Schervish (2002). Let (X,Y ) have density\\nf(x, y)=\\n{ cx\\n2y if x2 ≤ y ≤ 1\\n0 otherwise .\\nNote ﬁrst that −1 ≤ x ≤ 1. Now let us ﬁnd the value of c. The trick here is\\nto be careful about the range of integration. We pick one variable,x say, and\\nlet it range over its values. Then, for each ﬁxed value ofx,w el e ty vary over\\nits range, which is x2 ≤ y ≤ 1. It may help if you look at Figure 2.5. Thus,\\n1=\\n∫∫\\nf(x, y)dydx = c\\n∫ 1\\n−1\\n∫ 1\\nx2\\nx2yd yd x\\n= c\\n∫ 1\\n−1\\nx2\\n[∫ 1\\nx2\\nyd y\\n]\\ndx = c\\n∫ 1\\n−1\\nx2 1 − x4\\n2 dx = 4c\\n21.\\nHence, c =2 1/4. Now let us compute P(X ≥ Y ). This corresponds to the set\\nA = {(x, y); 0≤ x ≤ 1,x2 ≤ y ≤ x}. (You can see this by drawing a diagram.)\\nSo,\\nP(X ≥ Y )= 21\\n4\\n∫ 1\\n0\\n∫ x\\nx2\\nx2 yd yd x= 21\\n4\\n∫ 1\\n0\\nx2\\n[∫ x\\nx2\\nyd y\\n]\\ndx\\n= 21\\n4\\n∫ 1\\n0\\nx2\\n\\uf8f6x2 − x4\\n2\\n\\uf8f7\\ndx = 3\\n20. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 48, 'page_label': '49'}, page_content='2.6 Marginal Distributions 33\\n01\\n1\\ny = x2\\ny = x\\nx\\ny\\nFIGURE 2.5. The light shaded region is x2 ≤ y ≤ 1. The density is positive over\\nthis region. The hatched region is the event X ≥ Y intersected with x2 ≤ y ≤ 1.\\n2.6 Marginal Distributions\\n2.23 Deﬁnition. If (X,Y ) have joint distribution with mass function\\nfX,Y , then the marginal mass function for X is deﬁned by\\nfX(x)= P(X = x)=\\n∑\\ny\\nP(X = x, Y = y)=\\n∑\\ny\\nf(x, y) (2.4)\\nand the marginal mass function for Y is deﬁned by\\nfY (y)= P(Y = y)=\\n∑\\nx\\nP(X = x, Y = y)=\\n∑\\nx\\nf(x, y). (2.5)\\n2.24 Example. Suppose that fX,Y is given in the table that follows. The\\nmarginal distribution for X corresponds to the row totals and the marginal\\ndistribution for Y corresponds to the columns totals.\\nY =0 Y =1\\nX=0 1/10 2/10 3/10\\nX=1 3/10 4/10 7/10\\n4/10 6/10 1\\nFor example, fX( 0 )=3/10 and fX( 1 )=7/10. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 49, 'page_label': '50'}, page_content='34 2. Random Variables\\n2.25 Deﬁnition. For continuous random variables, the marginal densities\\nare\\nfX(x)=\\n∫\\nf(x, y)dy, and fY (y)=\\n∫\\nf(x, y)dx. (2.6)\\nThe corresponding marginal distribution functions are denoted byFX and\\nFY .\\n2.26 Example. Suppose that\\nfX,Y (x, y)= e−(x+y)\\nfor x, y≥ 0. Then fX(x)= e−x ∫∞\\n0 e−ydy = e−x. ■\\n2.27 Example. Suppose that\\nf(x, y)=\\n{ x + y if 0 ≤ x ≤ 1, 0 ≤ y ≤ 1\\n0 otherwise .\\nThen\\nfY (y)=\\n∫ 1\\n0\\n(x + y) dx =\\n∫ 1\\n0\\nxd x+\\n∫ 1\\n0\\nyd x= 1\\n2 + y. ■\\n2.28 Example. Let (X,Y ) have density\\nf(x, y)=\\n{ 21\\n4 x2y if x2 ≤ y ≤ 1\\n0 otherwise .\\nThus,\\nfX(x)=\\n∫\\nf(x, y)dy = 21\\n4 x2\\n∫ 1\\nx2\\nyd y = 21\\n8 x2(1 − x4)\\nfor −1 ≤ x ≤ 1 and fX(x) = 0 otherwise. ■\\n2.7 Independent Random Variables\\n2.29 Deﬁnition. Two random variables X and Y are independent if,\\nfor every A and B,\\nP(X ∈ A, Y ∈ B)= P(X ∈ A)P(Y ∈ B) (2.7)\\nand we write X ⨿ Y . Otherwise we say that X and Y are dependent\\nand we write X /gluonbelement/gluonelement/gluonelement/gluonelement/gluonelement/gluoneelementY .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 50, 'page_label': '51'}, page_content='2.7 Independent Random Variables 35\\nIn principle, to check whether X and Y are independent we need to check\\nequation (2.7) for all subsets A and B. Fortunately, we have the following\\nresult which we state for continuous random variables though it is true for\\ndiscrete random variables too.\\n2.30 Theorem. Let X and Y have joint pdf f\\nX,Y . Then X ⨿ Y if and only\\nif fX,Y (x, y)= fX(x)fY (y) for all values x and y. 5\\n2.31 Example. Let X and Y have the following distribution:\\nY =0 Y =1\\nX=0 1/4 1/4 1/2\\nX=1 1/4 1/4 1/2\\n1/2 1/2 1\\nThen, fX(0) = fX( 1 )=1/2 and fY (0) = fY ( 1 )=1/2. X and Y are inde-\\npendent because fX(0)fY (0) = f(0,0), fX(0)fY (1) = f(0,1), fX(1)fY (0) =\\nf(1,0), fX(1)fY (1) = f(1,1). Suppose instead that X and Y have the follow-\\ning distribution:\\nY =0 Y =1\\nX=0 1/2 0 1/2\\nX=1 0 1/2 1/2\\n1/2 1/2 1\\nThese are not independent because fX(0)fY ( 1 )=( 1 /2)(1/2 )=1 /4y e t\\nf(0,1 )=0 . ■\\n2.32 Example. Suppose that X and Y are independent and both have the\\nsame density\\nf(x)=\\n{ 2x if 0 ≤ x ≤ 1\\n0 otherwise .\\nLet us ﬁnd P(X + Y ≤ 1). Using independence, the joint density is\\nf(x, y)= fX(x)fY (y)=\\n{ 4xy if 0 ≤ x ≤ 1, 0 ≤ y ≤ 1\\n0 otherwise .\\n5The statement is not rigorous because the density is deﬁned only up to sets of\\nmeasure 0.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 51, 'page_label': '52'}, page_content='36 2. Random Variables\\nNow,\\nP(X + Y ≤ 1) =\\n∫∫\\nx+y≤1\\nf(x, y)dydx\\n=4\\n∫ 1\\n0\\nx\\n[∫ 1−x\\n0\\nydy\\n]\\ndx\\n=4\\n∫ 1\\n0\\nx(1 − x)2\\n2 dx = 1\\n6. ■\\nThe following result is helpful for verifying independence.\\n2.33 Theorem. Suppose that the range of X and Y is a (possibly inﬁnite)\\nrectangle. If f(x, y)= g(x)h(y) for some functions g and h (not necessarily\\nprobability density functions) then X and Y are independent.\\n2.34 Example. Let X and Y have density\\nf(x, y)=\\n{\\n2e−(x+2y) if x> 0 and y> 0\\n0 otherwise .\\nThe range ofX and Y is the rectangle (0,∞)×(0,∞). We can writef(x, y)=\\ng(x)h(y) where g(x)=2 e−x and h(y)= e−2y. Thus, X ⨿ Y . ■\\n2.8 Conditional Distributions\\nIf X and Y are discrete, then we can compute the conditional distribution of\\nX given that we have observedY = y. Speciﬁcally,P(X = x|Y = y)= P(X =\\nx, Y = y)/P(Y = y). This leads us to deﬁne the conditional probability mass\\nfunction as follows.\\n2.35 Deﬁnition. The conditional probability mass function is\\nfX|Y (x|y)= P(X = x|Y = y)= P(X = x, Y = y)\\nP(Y = y) = fX,Y (x, y)\\nfY (y)\\nif fY (y) > 0.\\nFor continuous distributions we use the same deﬁnitions. 6 The interpre-\\ntation diﬀers: in the discrete case, fX|Y (x|y)i s P(X = x|Y = y), but in the\\ncontinuous case, we must integrate to get a probability.\\n6We are treading in deep water here. When we compute P(X ∈ A|Y = y) in the\\ncontinuous case we are conditioning on the event{Y = y} which has probability 0. We'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 52, 'page_label': '53'}, page_content='2.8 Conditional Distributions 37\\n2.36 Deﬁnition. For continuous random variables, theconditional\\nprobability density function is\\nfX|Y (x|y)= fX,Y (x, y)\\nfY (y)\\nassuming that fY (y) > 0. Then,\\nP(X ∈ A|Y = y)=\\n∫\\nA\\nfX|Y (x|y)dx.\\n2.37 Example. Let X and Y have a joint uniform distribution on the unit\\nsquare. Thus, fX|Y (x|y) = 1 for 0 ≤ x ≤ 1 and 0 otherwise. Given Y = y, X\\nis Uniform(0,1). We can write this as X|Y = y ∼ Uniform(0,1). ■\\nFrom the deﬁnition of the conditional density, we see that fX,Y (x, y)=\\nfX|Y (x|y)fY (y)= fY |X(y|x)fX(x). This can sometimes be useful as in exam-\\nple 2.39.\\n2.38 Example. Let\\nf(x, y)=\\n{ x + y if 0 ≤ x ≤ 1, 0 ≤ y ≤ 1\\n0 otherwise .\\nLet us ﬁnd P(X< 1/4|Y =1 /3). In example 2.27 we saw that fY (y)=\\ny +( 1/2). Hence,\\nfX|Y (x|y)= fX,Y (x, y)\\nfY (y) = x + y\\ny + 1\\n2\\n.\\nSo,\\nP\\n\\uf8f6\\nX< 1\\n4\\n⏐⏐\\n⏐\\n⏐\\n⏐Y = 1\\n3\\n\\uf8f7\\n=\\n∫ 1/4\\n0\\nfX|Y\\n\\uf8f6\\nx\\n⏐⏐\\n⏐\\n⏐\\n⏐\\n1\\n3\\n\\uf8f7\\ndx\\n=\\n∫ 1/4\\n0\\nx + 1\\n3\\n1\\n3 + 1\\n2\\ndx =\\n1\\n32 + 1\\n12\\n1\\n3 + 1\\n2\\n= 11\\n80. ■\\n2.39 Example. Suppose that X ∼ Uniform(0,1). After obtaining a value of\\nX we generate Y |X = x ∼ Uniform(x,1). What is the marginal distribution\\navoid this problem by deﬁning things in terms of the pdf. The fact that this leads to\\na well-deﬁned theory is proved in more advanced courses. Here, we simply take it as a\\ndeﬁnition.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 53, 'page_label': '54'}, page_content='38 2. Random Variables\\nof Y ? First note that,\\nfX(x)=\\n{\\n1i f 0 ≤ x ≤ 1\\n0 otherwise\\nand\\nfY |X(y|x)=\\n{ 1\\n1−x if 0 <x<y< 1\\n0 otherwise .\\nSo,\\nfX,Y (x, y)= fY |X(y|x)fX(x)=\\n{ 1\\n1−x if 0 <x<y< 1\\n0 otherwise .\\nThe marginal for Y is\\nfY (y)=\\n∫ y\\n0\\nfX,Y (x, y)dx =\\n∫ y\\n0\\ndx\\n1 − x = −\\n∫ 1−y\\n1\\ndu\\nu = −log(1 − y)\\nfor 0 <y< 1. ■\\n2.40 Example. Consider the density in Example 2.28. Let’s ﬁnd fY |X(y|x).\\nWhen X = x, y must satisfy x2 ≤ y ≤ 1. Earlier, we saw that fX(x)=\\n(21/8)x2(1 − x4). Hence, for x2 ≤ y ≤ 1,\\nfY |X(y|x)= f(x, y)\\nfX(x) =\\n21\\n4 x2y\\n21\\n8 x2(1 − x4) = 2y\\n1 − x4 .\\nNow let us compute P(Y ≥ 3/4|X =1 /2). This can be done by ﬁrst noting\\nthat fY |X(y|1/2 )=3 2y/15. Thus,\\nP(Y ≥ 3/4|X =1 /2) =\\n∫ 1\\n3/4\\nf(y|1/2)dy =\\n∫ 1\\n3/4\\n32y\\n15 dy = 7\\n15. ■\\n2.9 Multivariate Distributions and iid Samples\\nLet X =( X1,...,X n) where X1,...,X n are random variables. We call X a\\nrandom vector. Let f(x1,...,x n) denote the pdf. It is possible to deﬁne\\ntheir marginals, conditionals etc. much the same way as in the bivariate case.\\nWe say that X\\n1,...,X n are independent if, for every A1,...,A n,\\nP(X1 ∈ A1,...,X n ∈ An)=\\nn∏\\ni=1\\nP(Xi ∈ Ai). (2.8)\\nIt suﬃces to check that f(x1,...,x n)= ∏n\\ni=1 fXi (xi).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 54, 'page_label': '55'}, page_content='2.10 Two Important Multivariate Distributions 39\\n2.41 Deﬁnition. If X1,...,X n are independent and each has the same\\nmarginal distribution with cdf F, we say that X1,...,X n are iid\\n(independent and identically distributed) and we write\\nX1,...X n ∼ F.\\nIf F has density f we also write X1,...X n ∼ f. We also call X1,...,X n\\na random sample of size n from F.\\nMuch of statistical theory and practice begins withiid observations and we\\nshall study this case in detail when we discuss statistics.\\n2.10 Two Important Multivariate Distributions\\nMultinomial. The multivariate version of a Binomial is called a Multino-\\nmial. Consider drawing a ball from an urn which has balls with k diﬀerent\\ncolors labeled “color 1, color 2, ..., color k.” Let p =( p1,...,p k) where\\npj ≥ 0 and ∑ k\\nj=1 pj = 1 and suppose that pj is the probability of drawing\\na ball of color j. Draw n times (independent draws with replacement) and\\nlet X =( X1,...,X k) where Xj is the number of times that color j appears.\\nHence, n = ∑ k\\nj=1 Xj. We say that X has a Multinomial ( n,p) distribution\\nwritten X ∼ Multinomial(n, p). The probability function is\\nf(x)=\\n\\uf8f6 n\\nx1 ...x k\\n\\uf8f7\\npx1\\n1 ··· pxk\\nk (2.9)\\nwhere \\uf8f6 n\\nx1 ...x k\\n\\uf8f7\\n= n!\\nx1!··· xk!.\\n2.42 Lemma. Suppose that X ∼ Multinomial(n, p) where X =( X1,...,X k)\\nand p =( p1,...,p k). The marginal distribution of Xj is Binomial (n,pj).\\nMultivariate Normal. The univariate Normal has two parameters, µ\\nand σ. In the multivariate version,µ is a vector andσ is replaced by a matrix\\nΣ. To begin, let\\nZ =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\nZ1\\n..\\n.\\nZ\\nk\\n\\uf8f6\\n\\uf8f7\\uf8f8'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 55, 'page_label': '56'}, page_content='40 2. Random Variables\\nwhere Z1,...,Z k ∼ N(0,1) are independent. The density of Z is 7\\nf(z)=\\nk∏\\ni=1\\nf(zi)= 1\\n(2π)k/2 exp\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3−1\\n2\\nk∑\\nj=1\\nz2\\nj\\n\\uf8fc\\n\\uf8fd\\n\\uf8fe\\n= 1\\n(2π)k/2 exp\\n{\\n−1\\n2zT z\\n}\\n.\\nWe say that Z has a standard multivariate Normal distribution written Z ∼\\nN(0,I ) where it is understood that 0 represents a vector of k zeroes and I is\\nthe k × k identity matrix.\\nMore generally, a vectorX has a multivariate Normal distribution, denoted\\nby X ∼ N(µ,Σ), if it has density 8\\nf(x; µ,Σ) = 1\\n(2π)k/2|(Σ)|1/2 exp\\n{\\n−1\\n2(x − µ)T Σ−1(x − µ)\\n}\\n(2.10)\\nwhere |Σ| denotes the determinant of Σ, µ is a vector of length k a n dΣi sa\\nk × k symmetric, positive deﬁnite matrix. 9 Setting µ =0a n dΣ= I gives\\nback the standard Normal.\\nSince Σ is symmetric and positive deﬁnite, it can be shown that there exists\\na matrix Σ1/2 — called the square root of Σ — with the following properties:\\n(i) Σ1/2 is symmetric, (ii) Σ = Σ1/2Σ1/2 and (iii) Σ1/2Σ−1/2 =Σ −1/2Σ1/2 = I\\nwhere Σ−1/2 =( Σ1/2)−1.\\n2.43 Theorem. If Z ∼ N(0,I ) and X = µ +Σ 1/2Z then X ∼ N(µ,Σ).\\nConversely, if X ∼ N(µ,Σ), then Σ−1/2(X − µ) ∼ N(0,I ).\\nSuppose we partition a random Normal vector X as X =( Xa,X b)W ec a n\\nsimilarly partition µ =( µa,µb) and\\nΣ=\\n\\uf8f6 Σaa Σab\\nΣba Σbb\\n\\uf8f7\\n.\\n2.44 Theorem. Let X ∼ N(µ,Σ). Then:\\n(1) The marginal distribution of Xa is Xa ∼ N(µa,Σaa).\\n(2) The conditional distribution of Xb given Xa = xa is\\nXb|Xa = xa ∼ N\\n\\uf8f6\\nµb +Σ baΣ−1\\naa (xa − µa), Σbb − ΣbaΣ−1\\naa Σab\\n\\uf8f7\\n.\\n(3) If a is a vector then aT X ∼ N(aT µ, aT Σa).\\n(4) V =( X − µ)T Σ−1(X − µ) ∼ χ2\\nk.\\n7If a and b are vectors then aT b = ∑ k\\ni=1 aibi.\\n8Σ−1 is the inverse of the matrix Σ.\\n9A matrix Σ is positive deﬁnite if, for all nonzero vectors x, xT Σx> 0.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 56, 'page_label': '57'}, page_content='2.11 Transformations of Random Variables 41\\n2.11 Transformations of Random Variables\\nSuppose that X is a random variable withpdf fX and cdf FX. Let Y = r(X)\\nbe a function of X, for example, Y = X2 or Y = eX. We call Y = r(X)a\\ntransformation of X. How do we compute the pdf and cdf of Y ?I nt h e\\ndiscrete case, the answer is easy. The mass function of Y is given by\\nfY (y)= P(Y = y)= P(r(X)= y)\\n= P({x; r(x)= y})= P(X ∈ r−1(y)).\\n2.45 Example. Suppose that P(X = −1) = P(X =1 )=1 /4 and P(X =0 )=\\n1/2. Let Y = X2. Then, P(Y =0 )= P(X =0 )=1 /2 and P(Y =1 )= P(X =\\n1) +P(X = −1 )=1 /2. Summarizing:\\nxf X(x)\\n-1 1/4\\n0 1/2\\n1 1/4\\nyf\\nY (y)\\n0 1/2\\n1 1/2\\nY takes fewer values than X because the transformation is not one-to-one. ■\\nThe continuous case is harder. There are three steps for ﬁnding fY :\\nThree Steps for Transformations\\n1. For each y, ﬁnd the set Ay = {x : r(x) ≤ y}.\\n2. Find the cdf\\nFY (y)= P(Y ≤ y)= P(r(X) ≤ y)\\n= P({x; r(x) ≤ y})\\n=\\n∫\\nAy\\nfX(x)dx. (2.11)\\n3. The pdf is fY (y)= F′\\nY (y).\\n2.46 Example. Let fX(x)= e−x for x> 0. Hence, FX(x)=\\n∫x\\n0 fX(s)ds =\\n1 − e−x. Let Y = r(X) = logX. Then, Ay = {x : x ≤ ey} and\\nFY (y)= P(Y ≤ y)= P(log X ≤ y)\\n= P(X ≤ ey)= FX(ey)=1 − e−ey\\n.\\nTherefore, fY (y)= eye−ey\\nfor y ∈ R. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 57, 'page_label': '58'}, page_content='42 2. Random Variables\\n2.47 Example. Let X ∼ Uniform(−1,3). Find the pdf of Y = X2. The\\ndensity of X is\\nfX(x)=\\n{\\n1/4i f − 1 <x< 3\\n0 otherwise .\\nY can only take values in (0,9). Consider two cases: (i) 0<y< 1 and (ii) 1≤\\ny< 9. For case (i), Ay =[ −√y, √y] and FY (y)=\\n∫\\nAy\\nfX(x)dx =( 1/2)√y.\\nFor case (ii), Ay =[ −1,√y] and FY (y)=\\n∫\\nAy\\nfX(x)dx =( 1/4)(√y + 1).\\nDiﬀerentiating F we get\\nfY (y)=\\n\\uf8f1\\n\\uf8f4\\uf8f4\\n\\uf8f2\\n\\uf8f4\\uf8f4\\n\\uf8f3\\n1\\n4√y if 0 <y< 1\\n1\\n8√y if 1 <y< 9\\n0 otherwise . ■\\nWhen r is strictly monotone increasing or strictly monotone decreasing then\\nr has an inverse s = r−1 and in this case one can show that\\nfY (y)= fX(s(y))\\n⏐⏐\\n⏐\\n⏐\\nds(y)\\ndy\\n⏐⏐\\n⏐\\n⏐. (2.12)\\n2.12 Transformations of Several Random Variables\\nIn some cases we are interested in transformations of several random variables.\\nFor example, if X and Y are given random variables, we might want to know\\nthe distribution of X/Y , X + Y , max{X,Y } or min{X,Y }. Let Z = r(X,Y )\\nbe the function of interest. The steps for ﬁnding fZ are the same as before:\\nThree Steps for Transformations\\n1. For each z, ﬁnd the set Az = {(x, y): r(x, y) ≤ z}.\\n2. Find the cdf\\nFZ(z)= P(Z ≤ z)= P(r(X,Y ) ≤ z)\\n= P({(x, y); r(x, y) ≤ z})=\\n∫∫\\nAz\\nfX,Y (x, y) dx dy.\\n3. Then fZ(z)= F′\\nZ(z).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 58, 'page_label': '59'}, page_content='2.13 Appendix 43\\n2.48 Example. Let X1,X 2 ∼ Uniform(0,1) be independent. Find the density\\nof Y = X1 + X2. The joint density of (X1,X 2)i s\\nf(x1,x2)=\\n{\\n10 <x 1 < 1, 0 <x 2 < 1\\n0 otherwise .\\nLet r(x1,x2)= x1 + x2.N o w ,\\nFY (y)= P(Y ≤ y)= P(r(X1,X 2) ≤ y)\\n= P({(x1,x2): r(x1,x2) ≤ y})=\\n∫∫\\nAy\\nf(x1,x2)dx1dx2.\\nNow comes the hard part: ﬁndingAy. First suppose that 0 <y ≤ 1. Then Ay\\nis the triangle with vertices (0,0),(y, 0) and (0,y ). See Figure 2.6. In this case,∫∫\\nAy\\nf(x1,x2)dx1dx2 is the area of this triangle which is y2/2. If 1 <y< 2,\\nthen Ay is everything in the unit square except the triangle with vertices\\n(1,y − 1),(1,1),(y − 1,1). This set has area 1 − (2 − y)2/2. Therefore,\\nFY (y)=\\n\\uf8f1\\n\\uf8f4\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f2\\n\\uf8f4\\uf8f4\\n\\uf8f4\\n\\uf8f4\\n\\uf8f3\\n0 y< 0\\ny2\\n2 0 ≤ y< 1\\n1 − (2−y)2\\n2 1 ≤ y< 2\\n1 y ≥ 2.\\nBy diﬀerentiation, the pdf is\\nfY (y)=\\n\\uf8f1\\n\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f3\\ny 0 ≤ y ≤ 1\\n2 − y 1 ≤ y ≤ 2\\n0 otherwise . ■\\n2.13 Appendix\\nRecall that a probability measure P is deﬁned on a σ-ﬁeld A of a sample\\nspace Ω. A random variableX is a measurable map X :Ω → R. Measurable\\nmeans that, for every x, {ω : X(ω) ≤ x}∈A .\\n2.14 Exercises\\n1. Show that\\nP(X = x)= F(x+) − F(x−).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 59, 'page_label': '60'}, page_content='44 2. Random Variables\\n01\\n0\\n1\\n(0,y )\\n(y, 0)\\n/Bullet\\n/Bullet\\nThis is the case 0 ≤ y< 1.\\n01\\n0\\n1\\n(1,y − 1)\\n(y − 1,1)\\n/Bullet\\n/Bullet\\nThis is the case 1 ≤ y ≤ 2.\\nFIGURE 2.6. The set Ay for example 2.48. Ay consists of all points (x1,x 2)i nt h e\\nsquare below the line x2 = y − x1.\\n2. Let X be such thatP(X =2 )= P(X =3 )=1 /10 andP(X =5 )=8 /10.\\nPlot the cdf F. Use F to ﬁnd P(2 <X ≤ 4.8) and P(2 ≤ X ≤ 4.8).\\n3. Prove Lemma 2.15.\\n4. Let X have probability density function\\nf\\nX(x)=\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1/40 <x< 1\\n3/83 <x< 5\\n0 otherwise .\\n(a) Find the cumulative distribution function of X.\\n(b) Let Y =1 /X. Find the probability density function fY (y) for Y .\\nHint: Consider three cases: 1\\n5 ≤ y ≤ 1\\n3, 1\\n3 ≤ y ≤ 1, and y ≥ 1.\\n5. Let X and Y be discrete random variables. Show that X and Y are\\nindependent if and only if fX,Y (x, y)= fX(x)fY (y) for all x and y.\\n6. Let X have distribution F and density function f and let A be a subset\\nof the real line. Let IA(x) be the indicator function for A:\\nIA(x)=\\n{ 1 x ∈ A\\n0 x/∈ A.\\nLet Y = IA(X). Find an expression for the cumulative distribution of\\nY . (Hint: ﬁrst ﬁnd the probability mass function for Y .)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 60, 'page_label': '61'}, page_content='2.14 Exercises 45\\n7. Let X and Y be independent and suppose that each has a Uniform(0,1)\\ndistribution. Let Z = min{X,Y }. Find the density fZ(z) for Z. Hint:\\nIt might be easier to ﬁrst ﬁnd P(Z>z ).\\n8. Let X have cdf F. Find the cdf of X+ = max{0,X }.\\n9. Let X ∼ Exp(β). Find F(x) and F−1(q).\\n10. Let X and Y be independent. Show that g(X) is independent of h(Y )\\nwhere g and h are functions.\\n11. Suppose we toss a coin once and let p be the probability of heads. Let\\nX denote the number of heads and let Y denote the number of tails.\\n(a) Prove that X and Y are dependent.\\n(b) Let N ∼ Poisson(λ) and suppose we toss a coinN times. Let X and\\nY be the number of heads and tails. Show thatX and Y are independent.\\n12. Prove Theorem 2.33.\\n13. Let X ∼ N(0,1) and let Y = e\\nX.\\n(a) Find the pdf for Y . Plot it.\\n(b) (Computer Experiment.) Generate a vector x =( x1,...,x 10,000) con-\\nsisting of 10,000 random standard Normals. Let y =( y1,...,y 10,000)\\nwhere yi = exi . Draw a histogram of y and compare it to the pdf you\\nfound in part (a).\\n14. Let (X,Y ) be uniformly distributed on the unit disk{(x, y): x2 +y2 ≤\\n1}. Let R =\\n√\\nX2 + Y 2. Find the cdf and pdf of R.\\n15. ( A universal random number generator.) Let X have a continuous, strictly\\nincreasing cdf F. Let Y = F(X). Find the density of Y . This is called\\nthe probability integral transform. Now let U ∼ Uniform(0,1) and let\\nX = F−1(U). Show that X ∼ F. Now write a program that takes\\nUniform (0,1) random variables and generates random variables from\\nan Exponential (β) distribution.\\n16. Let X ∼ Poisson(λ) and Y ∼ Poisson(µ) and assume that X and Y are\\nindependent. Show that the distribution of X given that X + Y = n is\\nBinomial(n, π) where π = λ/(λ + µ).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 61, 'page_label': '62'}, page_content='46 2. Random Variables\\nHint 1: You may use the following fact: If X ∼ Poisson(λ) and Y ∼\\nPoisson(µ), andX and Y are independent, thenX+Y ∼ Poisson(µ+λ).\\nHint 2: Note that {X = x, X + Y = n} = {X = x, Y = n − x}.\\n17. Let\\nfX,Y (x, y)=\\n{\\nc(x + y2)0 ≤ x ≤ 1 and 0 ≤ y ≤ 1\\n0 otherwise .\\nFind P\\n\\uf8f6\\nX< 1\\n2 | Y = 1\\n2\\n\\uf8f7\\n.\\n18. Let X ∼ N(3,16). Solve the following using the Normal table and using\\na computer package.\\n(a) Find P(X< 7).\\n(b) Find P(X> −2).\\n(c) Find x such that P(X>x )= .05.\\n(d) Find P(0 ≤ X< 4).\\n(e) Find x such that P(|X| > |x|)= .05.\\n19. Prove formula (2.12).\\n20. Let X,Y ∼ Uniform(0,1) be independent. Find the pdf for X − Y and\\nX/Y .\\n21. Let X\\n1,...,X n ∼ Exp(β)b e iid. Let Y = max{X1,...,X n}. Find the\\npdf of Y . Hint: Y ≤ y if and only if Xi ≤ y for i =1 ,...,n .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 62, 'page_label': '63'}, page_content='3\\nExpectation\\n3.1 Expectation of a Random Variable\\nThe mean, or expectation, of a random variable X is the average value ofX.\\n3.1 Deﬁnition. The expected value,o r mean,o r ﬁrst moment,o f\\nX is deﬁned to be\\nE(X)=\\n∫\\nxd F(x)=\\n{ ∑\\nx xf(x)i f X is discrete∫\\nxf(x)dx if X is continuous (3.1)\\nassuming that the sum (or integral) is well deﬁned. We use the following\\nnotation to denote the expected value of X:\\nE(X)= EX =\\n∫\\nxd F(x)= µ = µX. (3.2)\\nThe expectation is a one-number summary of the distribution. Think of\\nE(X) as the average ∑ n\\ni=1 Xi/n of a large number of iid draws X1,...,X n.\\nThe fact that E(X) ≈ ∑ n\\ni=1\\nXi/n is actually more than a heuristic; it is a\\ntheorem called the law of large numbers that we will discuss in Chapter 5.\\nThe notation\\n∫\\nxd F(x) deserves some comment. We use it merely as a\\nconvenient unifying notation so we don’t have to write∑\\nx xf(x) for discrete'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 63, 'page_label': '64'}, page_content='48 3. Expectation\\nrandom variables and\\n∫\\nxf(x)dx for continuous random variables, but you\\nshould be aware that\\n∫\\nxd F(x) has a precise meaning that is discussed in real\\nanalysis courses.\\nTo ensure thatE(X) is well deﬁned, we say thatE(X) exists if\\n∫\\nx |x|dFX(x) <\\n∞. Otherwise we say that the expectation does not exist.\\n3.2 Example. Let X ∼ Bernoulli(p). Then E(X)= ∑ 1\\nx=0 xf(x)=( 0 × (1 −\\np) )+( 1× p)= p. ■\\n3.3 Example. Flip a fair coin two times. LetX be the number of heads. Then,\\nE(X)=\\n∫\\nxdFX(x)= ∑\\nx xfX(x)=( 0 × f(0)) + (1× f(1)) + (2× f(2)) =\\n(0 × (1/4 ) )+( 1× (1/2 ) )+( 2× (1/4 ) )=1. ■\\n3.4 Example. Let X ∼ Uniform(−1,3). Then,E(X)=\\n∫\\nxd FX(x)=\\n∫\\nxfX(x)dx =\\n1\\n4\\n∫3\\n−1 xd x=1 . ■\\n3.5 Example. Recall that a random variable has a Cauchy distribution if it\\nhas density fX(x)= {π(1 + x2)}−1. Using integration by parts, (set u = x\\nand v = tan−1 x),\\n∫\\n|x|dF(x)= 2\\nπ\\n∫ ∞\\n0\\nxd x\\n1+ x2 =\\n[\\nx tan−1(x)\\n]∞\\n0 −\\n∫ ∞\\n0\\ntan−1 xd x= ∞\\nso the mean does not exist. If you simulate a Cauchy distribution many times\\nand take the average, you will see that the average never settles down. This\\nis because the Cauchy has thick tails and hence extreme observations are\\ncommon.\\n■\\nFrom now on, whenever we discuss expectations, we implicitly assume that\\nthey exist.\\nLet Y = r(X). How do we compute E(Y )? One way is to ﬁnd fY (y) and\\nthen compute E(Y )=\\n∫\\nyfY (y)dy. But there is an easier way.\\n3.6 Theorem (The Rule of the Lazy Statistician). Let Y = r(X). Then\\nE(Y )= E(r(X)) =\\n∫\\nr(x)dFX(x). (3.3)\\nThis result makes intuitive sense. Think of playing a game where we draw\\nX at random and then I pay youY = r(X). Your average income isr(x) times\\nthe chance that X = x, summed (or integrated) over all values of x. Here is'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 64, 'page_label': '65'}, page_content='3.1 Expectation of a Random Variable 49\\na special case. Let A be an event and let r(x)= IA(x) where IA(x)=1i f\\nx ∈ A and IA(x)=0i f x/∈ A. Then\\nE(IA(X)) =\\n∫\\nIA(x)fX(x)dx =\\n∫\\nA\\nfX(x)dx = P(X ∈ A).\\nIn other words, probability is a special case of expectation.\\n3.7 Example. Let X ∼ Unif(0,1). Let Y = r(X)= eX. Then,\\nE(Y )=\\n∫ 1\\n0\\nexf(x)dx =\\n∫ 1\\n0\\nexdx = e − 1.\\nAlternatively, you could ﬁnd fY (y) which turns out to be fY (y)=1 /y for\\n1 <y<e . Then, E(Y )=\\n∫e\\n1 yf (y)dy = e − 1. ■\\n3.8 Example. Take a stick of unit length and break it at random. Let Y be\\nthe length of the longer piece. What is the mean ofY ?I f X is the break point\\nthen X ∼ Unif(0,1) and Y = r(X) = max{X, 1 − X}. Thus, r(x)=1 − x\\nwhen 0 <x< 1/2 and r(x)= x when 1/2 ≤ x< 1. Hence,\\nE(Y )=\\n∫\\nr(x)dF(x)=\\n∫ 1/2\\n0\\n(1 − x)dx +\\n∫ 1\\n1/2\\nxd x= 3\\n4. ■\\nFunctions of several variables are handled in a similar way. IfZ = r(X,Y )\\nthen\\nE(Z)= E(r(X,Y )) =\\n∫∫\\nr(x, y)dF(x, y). (3.4)\\n3.9 Example. Let ( X,Y ) have a jointly uniform distribution on the unit\\nsquare. Let Z = r(X,Y )= X2 + Y 2. Then,\\nE(Z)=\\n∫∫\\nr(x, y)dF(x, y)=\\n∫ 1\\n0\\n∫ 1\\n0\\n(x2 + y2) dxdy\\n=\\n∫ 1\\n0\\nx2 dx +\\n∫ 1\\n0\\ny2 dy = 2\\n3. ■\\nThe kth moment of X is deﬁned to beE(Xk) assuming thatE(|X|k) < ∞.\\n3.10 Theorem. If the kth moment exists and if j<k then the jth moment\\nexists.\\nProof. We have\\nE|X|j =\\n∫ ∞\\n−∞\\n|x|jfX(x)dx'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 65, 'page_label': '66'}, page_content='50 3. Expectation\\n=\\n∫\\n|x|≤1\\n|x|jfX(x)dx +\\n∫\\n|x|>1\\n|x|jfX(x)dx\\n≤\\n∫\\n|x|≤1\\nfX(x)dx +\\n∫\\n|x|>1\\n|x|kfX(x)dx\\n≤ 1+ E(|X|k) < ∞. ■\\nThe kth central moment is deﬁned to be E((X − µ)k).\\n3.2 Properties of Expectations\\n3.11 Theorem. If X1,...,X n are random variables and a1,...,a n are con-\\nstants, then\\nE\\n\\uf8f6∑\\ni\\naiXi\\n\\uf8f7\\n=\\n∑\\ni\\naiE(Xi). (3.5)\\n3.12 Example. Let X ∼ Binomial(n, p). What is the mean of X? We could\\ntry to appeal to the deﬁnition:\\nE(X)=\\n∫\\nxd FX(x)=\\n∑\\nx\\nxfX(x)=\\nn∑\\nx=0\\nx\\n\\uf8f6n\\nx\\n\\uf8f7\\npx(1 − p)n−x\\nbut this is not an easy sum to evaluate. Instead, note that X = ∑ n\\ni=1 Xi\\nwhere Xi = 1 if the ith toss is heads and Xi = 0 otherwise. Then E(Xi)=\\n(p × 1) + ((1− p) × 0) = p and E(X)= E(∑\\ni Xi)= ∑\\ni E(Xi)= np. ■\\n3.13 Theorem. Let X1,...,X n be independent random variables. Then,\\nE\\n\\uf8f6 n∏\\ni=1\\nXi\\n\\uf8f7\\n=\\n∏\\ni\\nE(Xi). (3.6)\\nNotice that the summation rule does not require independence but the\\nmultiplication rule does.\\n3.3 Variance and Covariance\\nThe variance measures the “spread” of a distribution. 1\\n1We can’t use E(X − µ) as a measure of spread since E(X − µ)= E(X) − µ = µ − µ =0 .\\nWe can and sometimes do use E|X − µ| as a measure of spread but more often we use the\\nvariance.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 66, 'page_label': '67'}, page_content='3.3 Variance and Covariance 51\\n3.14 Deﬁnition. Let X be a random variable with mean µ. The variance\\nof X — denoted by σ2 or σ2\\nX or V(X) or VX — is deﬁned by\\nσ2 = E(X − µ)2 =\\n∫\\n(x − µ)2dF(x) (3.7)\\nassuming this expectation exists. The standard deviation is\\nsd(X)=\\n√\\nV(X) and is also denoted by σ and σX.\\n3.15 Theorem. Assuming the variance is well deﬁned, it has the following\\nproperties:\\n1. V(X)= E(X2) − µ2.\\n2. If a and b are constants then V(aX + b)= a2V(X).\\n3. If X1,...,X n are independent and a1,...,a n are constants, then\\nV\\n\\uf8f6 n∑\\ni=1\\naiXi\\n\\uf8f7\\n=\\nn∑\\ni=1\\na2\\ni V(Xi). (3.8)\\n3.16 Example. Let X ∼ Binomial(n, p). We write X = ∑\\ni Xi where Xi =1\\nif toss i is heads and Xi = 0 otherwise. Then X = ∑\\ni Xi and the random\\nvariables are independent. Also,P(Xi =1 )= p and P(Xi =0 )=1 −p. Recall\\nthat\\nE(Xi)=\\n\\uf8f6\\np × 1\\n\\uf8f7\\n+\\n\\uf8f6\\n(1 − p) × 0\\n\\uf8f7\\n= p.\\nNow,\\nE(X2\\ni )=\\n\\uf8f6\\np × 12\\n\\uf8f7\\n+\\n\\uf8f6\\n(1 − p) × 02\\n\\uf8f7\\n= p.\\nTherefore, V(Xi)= E(X2\\ni ) − p2 = p − p2 = p(1 − p). Finally, V(X)=\\nV(∑\\ni Xi)= ∑\\ni V(Xi)= ∑\\ni p(1 − p)= np(1 − p). Notice that V(X)=0\\nif p =1o r p = 0. Make sure you see why this makes intuitive sense.■\\nIf X1,...,X n are random variables then we deﬁne thesample mean to be\\nXn = 1\\nn\\nn∑\\ni=1\\nXi (3.9)\\nand the sample variance to be\\nS2\\nn = 1\\nn − 1\\nn∑\\ni=1\\n\\uf8f6\\nXi − Xn\\n\\uf8f72\\n. (3.10)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 67, 'page_label': '68'}, page_content='52 3. Expectation\\n3.17 Theorem. Let X1,...,X n be iid and let µ = E(Xi), σ2 = V(Xi). Then\\nE(Xn)= µ, V(Xn)= σ2\\nn and E(S2\\nn)= σ2.\\nIf X and Y are random variables, then the covariance and correlation be-\\ntween X and Y measure how strong the linear relationship is betweenX and\\nY .\\n3.18 Deﬁnition. Let X and Y be random variables with means µX and\\nµY and standard deviations σX and σY . Deﬁne the covariance between\\nX and Y by\\nCov(X,Y )= E\\n\\uf8f6\\n(X − µX)(Y − µY )\\n\\uf8f7\\n(3.11)\\nand the correlation by\\nρ = ρX,Y = ρ(X,Y )= Cov(X,Y )\\nσXσY\\n. (3.12)\\n3.19 Theorem. The covariance satisﬁes:\\nCov(X,Y )= E(XY ) − E(X)E(Y ).\\nThe correlation satisﬁes:\\n−1 ≤ ρ(X,Y ) ≤ 1.\\nIf Y = aX + b for some constants a and b then ρ(X,Y )=1 if a> 0 and\\nρ(X,Y )= −1 if a< 0.I f X and Y are independent, thenCov(X,Y )= ρ =0 .\\nThe converse is not true in general.\\n3.20 Theorem. V(X + Y )= V(X)+ V(Y )+2 Cov(X,Y ) and V(X − Y )=\\nV(X)+ V(Y )−2Cov(X,Y ). More generally, for random variablesX1,...,X n,\\nV\\n\\uf8f6∑\\ni\\naiXi\\n\\uf8f7\\n=\\n∑\\ni\\na2\\ni V(Xi)+2\\n∑∑\\ni<j\\naiajCov(Xi,X j).\\n3.4 Expectation and Variance of Important Random\\nVariables\\nHere we record the expectation of some important random variables:'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 68, 'page_label': '69'}, page_content='3.4 Expectation and Variance of Important Random Variables 53\\nDistribution Mean Variance\\nPoint mass at aa 0\\nBernoulli(p) pp (1 − p)\\nBinomial(n, p) np np (1 − p)\\nGeometric(p)1 /p (1 − p)/p2\\nPoisson(λ) λλ\\nUniform(a, b)( a + b)/2( b − a)2/12\\nNormal(µ, σ2) µσ 2\\nExponential(β) ββ 2\\nGamma(α, β) αβ αβ 2\\nBeta(α, β) α/(α + β) αβ/((α + β)2(α + β + 1))\\ntν 0 (if ν> 1) ν/(ν − 2) (if ν> 2)\\nχ2\\np p 2p\\nMultinomial(n, p) np see below\\nMultivariate Normal(µ,Σ) µ Σ\\nWe derived E(X) and V(X) for the Binomial in the previous section. The\\ncalculations for some of the others are in the exercises.\\nThe last two entries in the table are multivariate models which involve a\\nrandom vector X of the form\\nX =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\nX1\\n..\\n.\\nX\\nk\\n\\uf8f6\\n\\uf8f7\\uf8f8.\\nThe mean of a random vector X is deﬁned by\\nµ =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\nµ1\\n..\\n.\\nµ\\nk\\n\\uf8f6\\n\\uf8f7\\uf8f8 =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\nE(X1)\\n..\\n.\\nE(X\\nk)\\n\\uf8f6\\n\\uf8f7\\uf8f8.\\nThe variance-covariance matrixΣ is deﬁned to be\\nV(X)=\\n\\uf8ee\\n\\uf8ef\\uf8ef\\n\\uf8ef\\uf8f0\\nV(X\\n1) Cov(X1,X 2) ··· Cov(X1,X k)\\nCov(X2,X 1) V(X2) ··· Cov(X2,X k)\\n..\\n. ..\\n. ..\\n. ..\\n.\\nCov(X\\nk,X 1) Cov(Xk,X 2) ··· V(Xk)\\n\\uf8f9\\n\\uf8fa\\uf8fa\\n\\uf8fa\\uf8fb.\\nIf X ∼ Multinomial(n, p) then E(X)= np = n(p\\n1,...,p k) and\\nV(X)=\\n\\uf8eb\\n\\uf8ec\\uf8ec\\n\\uf8ec\\uf8ed\\nnp\\n1(1 − p1) −np1p2 ··· − np1pk\\n−np2p1 np2(1 − p2) ··· − np2pk\\n..\\n. ..\\n. ..\\n.\\n..\\n.\\n−np\\nkp1 −npkp2 ··· npk(1 − pk)\\n\\uf8f6\\n\\uf8f7\\uf8f7\\n\\uf8f7\\uf8f8.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 69, 'page_label': '70'}, page_content='54 3. Expectation\\nTo see this, note that the marginal distribution of any one component of the\\nvector Xi ∼ Binomial(n, pi). Thus, E(Xi)= npi and V(Xi)= npi(1 − pi).\\nNote also that Xi + Xj ∼ Binomial(n, pi + pj). Thus, V(Xi + Xj)= n(pi +\\npj)(1 − [pi + pj]). On the other hand, using the formula for the variance\\nof a sum, we have that V(Xi + Xj)= V(Xi)+ V(Xj)+2 Cov(Xi,X j)=\\nnpi(1 − pi)+ npj(1 − pj)+2 Cov(Xi,X j). If we equate this formula with\\nn(pi + pj)(1 − [pi + pj]) and solve, we get Cov(Xi,X j)= −npipj.\\nFinally, here is a lemma that can be useful for ﬁnding means and variances\\nof linear combinations of multivariate random vectors.\\n3.21 Lemma. If a is a vector and X is a random vector with mean µ and\\nvariance Σ, then E(aT X)= aT µ and V(aT X)= aT Σa.I f A is a matrix then\\nE(AX)= Aµ and V(AX)= AΣAT .\\n3.5 Conditional Expectation\\nSuppose that X and Y are random variables. What is the mean of X among\\nthose times when Y = y? The answer is that we compute the mean of X as\\nbefore but we substitute fX|Y (x|y) for fX(x) in the deﬁnition of expectation.\\n3.22 Deﬁnition. The conditional expectation of X given Y = y is\\nE(X|Y = y)=\\n{ ∑ xfX|Y (x|y) dx discrete case∫\\nxfX|Y (x|y) dx continuous case. (3.13)\\nIf r(x, y) is a function of x and y then\\nE(r(X,Y )|Y = y)=\\n{ ∑ r(x, y) fX|Y (x|y) dx discrete case∫\\nr(x, y) fX|Y (x|y) dx continuous case.\\n(3.14)\\nWarning! Here is a subtle point. Whereas E(X)i san u m b e r ,E(X|Y = y)\\nis a function ofy. Before we observeY , we don’t know the value ofE(X|Y = y)\\nso it is a random variable which we denote E(X|Y ). In other words, E(X|Y )\\nis the random variable whose value is E(X|Y = y) when Y = y. Similarly,\\nE(r(X,Y )|Y ) is the random variable whose value is E(r(X,Y )|Y = y) when\\nY = y. This is a very confusing point so let us look at an example.\\n3.23 Example. Suppose we draw X ∼ Unif(0,1). After we observe X = x,\\nwe draw Y |X = x ∼ Unif(x,1). Intuitively, we expect that E(Y |X = x)='),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 70, 'page_label': '71'}, page_content='3.5 Conditional Expectation 55\\n(1 +x)/2. In fact, fY |X(y|x)=1 /(1 − x) for x<y< 1 and\\nE(Y |X = x)=\\n∫ 1\\nx\\nyf Y |X(y|x)dy = 1\\n1 − x\\n∫ 1\\nx\\nyd y = 1+ x\\n2\\nas expected. Thus, E(Y |X)=( 1+ X)/2. Notice that E(Y |X)=( 1+ X)/2i s\\na random variable whose value is the number E(Y |X = x) = (1 +x)/2 once\\nX = x is observed. ■\\n3.24 Theorem (The Rule of Iterated Expectations). For random variables X\\nand Y , assuming the expectations exist, we have that\\nE [E(Y |X)] = E(Y ) and E [E(X|Y )] = E(X). (3.15)\\nMore generally, for any function r(x, y) we have\\nE [E(r(X,Y )|X)] = E(r(X,Y )). (3.16)\\nProof. We’ll prove the ﬁrst equation. Using the deﬁnition of conditional\\nexpectation and the fact that f(x, y)= f(x)f(y|x),\\nE [E(Y |X)] =\\n∫\\nE(Y |X = x)fX(x)dx =\\n∫∫\\nyf(y|x)dyf(x)dx\\n=\\n∫∫\\nyf(y|x)f(x)dxdy =\\n∫∫\\nyf(x, y)dxdy = E(Y ). ■\\n3.25 Example. Consider example 3.23. How can we compute E(Y )? One\\nmethod is to ﬁnd the joint densityf(x, y) and then computeE(Y )=\\n∫∫\\nyf(x, y)dxdy.\\nAn easier way is to do this in two steps. First, we already know thatE(Y |X)=\\n(1 +X)/2. Thus,\\nE(Y )= EE(Y |X)= E\\n\\uf8f6(1 +X)\\n2\\n\\uf8f7\\n= (1 +E(X))\\n2 = ( 1+( 1/2))\\n2 =3 /4. ■\\n3.26 Deﬁnition. The conditional variance is deﬁned as\\nV(Y |X = x)=\\n∫\\n(y − µ(x))2f(y|x)dy (3.17)\\nwhere µ(x)= E(Y |X = x).\\n3.27 Theorem. For random variables X and Y ,\\nV(Y )= EV(Y |X)+ VE(Y |X).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 71, 'page_label': '72'}, page_content='56 3. Expectation\\n3.28 Example. Draw a county at random from the United States. Then draw\\nn people at random from the county. Let X be the number of those people\\nwho have a certain disease. If Q denotes the proportion of people in that\\ncounty with the disease, then Q is also a random variable since it varies from\\ncounty to county. Given Q = q, we have that X ∼ Binomial(n, q). Thus,\\nE(X|Q = q)= nq and V(X|Q = q)= nq(1 − q). Suppose that the random\\nvariable Q has a Uniform (0,1) distribution. A distribution that is constructed\\nin stages like this is called a hierarchical model and can be written as\\nQ ∼ Uniform(0,1)\\nX|Q = q ∼ Binomial(n, q).\\nNow, E(X)= EE(X|Q)= E(nQ)= nE(Q)= n/2. Let us compute the\\nvariance of X.N o w ,V(X)= EV(X|Q)+ VE(X|Q). Let’s compute these\\ntwo terms. First, EV(X|Q)= E[nQ(1 − Q)] = nE(Q(1 − Q)) = n\\n∫\\nq(1 −\\nq)f(q)dq = n\\n∫1\\n0 q(1 − q)dq = n/6. Next, VE(X|Q)= V(nQ)= n2V(Q)=\\nn2 ∫\\n(q − (1/2))2dq = n2/12. Hence, V(X)=( n/6 )+(n2/12). ■\\n3.6 Moment Generating Functions\\nNow we will deﬁne the moment generating function which is used for ﬁnding\\nmoments, for ﬁnding the distribution of sums of random variables and which\\nis also used in the proofs of some theorems.\\n3.29 Deﬁnition. The moment generating function mgf,o r Laplace\\ntransform,o f X is deﬁned by\\nψX(t)= E(etX)=\\n∫\\netxdF(x)\\nwhere t varies over the real numbers.\\nIn what follows, we assume that the mgf is well deﬁned for all t in some\\nopen interval around t =0 . 2\\nWhen the mgf is well deﬁned, it can be shown that we can interchange the\\noperations of diﬀerentiation and “taking expectation.” This leads to\\nψ′(0) =\\n[d\\ndtEetX\\n]\\nt=0\\n= E\\n[d\\ndtetX\\n]\\nt=0\\n= E\\n[\\nXetX]\\nt=0 = E(X).\\n2A related function is the characteristic function, deﬁned by E(eitX ) where i = √−1. This\\nfunction is always well deﬁned for all t.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 72, 'page_label': '73'}, page_content='3.6 Moment Generating Functions 57\\nBy taking k derivatives we conclude that ψ(k)(0) = E(Xk). This gives us a\\nmethod for computing the moments of a distribution.\\n3.30 Example. Let X ∼ Exp(1). For any t< 1,\\nψX(t)= EetX =\\n∫ ∞\\n0\\netxe−xdx =\\n∫ ∞\\n0\\ne(t−1)xdx = 1\\n1 − t.\\nThe integral is divergent if t ≥ 1. So, ψX(t)=1 /(1 − t) for all t< 1. Now,\\nψ′(0) = 1 andψ′′(0) = 2. Hence,E(X)=1a n d V(X)= E(X2)−µ2 =2 −1=\\n1. ■\\n3.31 Lemma. Properties of the mgf.\\n(1) If Y = aX + b, then ψY (t)= ebtψX(at).\\n(2) If X1,...,X n are independent and Y = ∑\\ni Xi, then ψY (t)= ∏\\ni ψi(t)\\nwhere ψi is the mgf of Xi.\\n3.32 Example. Let X ∼ Binomial(n, p). We know that X = ∑ n\\ni=1 Xi where\\nP(Xi =1 )= p and P(Xi =0 )=1 − p.N o wψi(t)= EeXit =( p × et) + ((1−\\np)) = pet + q where q =1 − p. Thus, ψX(t)= ∏\\ni ψi(t)=( pet + q)n. ■\\nRecall that X and Y are equal in distribution if they have the same distri-\\nbution function and we write X\\nd\\n= Y .\\n3.33 Theorem. Let X and Y be random variables. IfψX(t)= ψY (t) for all t\\nin an open interval around 0, then X\\nd\\n= Y .\\n3.34 Example. Let X1 ∼ Binomial(n1,p ) and X2 ∼ Binomial(n2,p ) be inde-\\npendent. Let Y = X1 + X2. Then,\\nψY (t)= ψ1(t)ψ2(t)=( pet + q)n1 (pet + q)n2 =( pet + q)n1+n2\\nand we recognize the latter as the mgf of a Binomial( n1 + n2,p ) distribu-\\ntion. Since the mgf characterizes the distribution (i.e., there can’t be an-\\nother random variable which has the same mgf) we conclude that Y ∼\\nBinomial(n1 + n2,p ). ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 73, 'page_label': '74'}, page_content='58 3. Expectation\\nMoment Generating Functions for Some Common Distributions\\nDistribution MGF ψ(t)\\nBernoulli(p) pet +( 1− p)\\nBinomial(n, p)( pet +( 1− p))n\\nPoisson(λ) eλ(et−1)\\nNormal(µ,σ) exp\\n{\\nµt + σ2t2\\n2\\n}\\nGamma(α,β)\\n\\uf8f6\\n1\\n1−βt\\n\\uf8f7α\\nfor t< 1/β\\n3.35 Example. Let Y1 ∼ Poisson(λ1) and Y2 ∼ Poisson(λ2) be independent.\\nThe moment generating function ofY = Y1 +Y +2 is ψY (t)= ψY1 (t)ψY2 (t)=\\neλ1(et−1)eλ2(et−1) = e(λ1+λ2)(et−1) which is the moment generating function\\nof a Poisson(λ1 + λ2). We have thus proved that the sum of two independent\\nPoisson random variables has a Poisson distribution. ■\\n3.7 Appendix\\nExpectation as an Integral. The integral of a measurable function r(x)\\nis deﬁned as follows. First suppose that r is simple, meaning that it takes\\nﬁnitely many values a1,...,a k over a partition A1,...,A k. Then deﬁne\\n∫\\nr(x)dF(x)=\\nk∑\\ni=1\\nai P(r(X) ∈ Ai).\\nThe integral of a positive measurable function r is deﬁned by\\n∫\\nr(x)dF(x)=\\nlimi\\n∫\\nri(x)dF(x) where ri is a sequence of simple functions such thatri(x) ≤\\nr(x) and ri(x) → r(x)a s i →∞ . This does not depend on the particular se-\\nquence. The integral of a measurable functionr is deﬁned to be\\n∫\\nr(x)dF(x)=∫\\nr+(x)dF(x)−\\n∫\\nr−(x)dF(x) assuming both integrals are ﬁnite, wherer+(x)=\\nmax{r(x),0} and r−(x)= −min{r(x),0}.\\n3.8 Exercises\\n1. Suppose we play a game where we start with c dollars. On each play of\\nthe game you either double or halve your money, with equal probability.\\nWhat is your expected fortune after n trials?'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 74, 'page_label': '75'}, page_content='3.8 Exercises 59\\n2. Show that V(X) = 0 if and only if there is a constant c such that\\nP(X = c)=1 .\\n3. Let X1,...,X n ∼ Uniform(0,1) and let Yn = max{X1,...,X n}. Find\\nE(Yn).\\n4. A particle starts at the origin of the real line and moves along the line in\\njumps of one unit. For each jump the probability is p that the particle\\nwill jump one unit to the left and the probability is 1−p that the particle\\nwill jump one unit to the right. Let Xn be the position of the particle\\nafter n units. Find E(Xn) and V(Xn). (This is known as a random\\nwalk.)\\n5. A fair coin is tossed until a head is obtained. What is the expected\\nnumber of tosses that will be required?\\n6. Prove Theorem 3.6 for discrete random variables.\\n7. Let X be a continuous random variable with cdf F. Suppose that\\nP(X> 0) = 1 and that E(X) exists. Show that E(X)=\\n∫\\n∞\\n0 P(X>\\nx)dx.\\nHint: Consider integrating by parts. The following fact is helpful: ifE(X)\\nexists then limx→∞ x[1 − F(x) ]=0 .\\n8. Prove Theorem 3.17.\\n9. ( Computer Experiment.) Let X\\n1,X 2,...,X n be N(0,1) random variables\\nand let Xn = n−1 ∑ n\\ni=1 Xi. Plot Xn versus n for n =1 ,..., 10,000.\\nRepeat for X1,X 2,...,X n ∼ Cauchy. Explain why there is such a dif-\\nference.\\n10. Let X ∼ N(0,1) and let Y = eX. Find E(Y ) and V(Y ).\\n11. ( Computer Experiment: Simulating the Stock Market .) Let Y1,Y2,... be\\nindependent random variables such that P(Yi =1 )= P(Yi = −1) =\\n1/2. Let Xn = ∑ n\\ni=1 Yi. Think of Yi = 1 as “the stock price increased\\nby one dollar”, Yi = −1 as “the stock price decreased by one dollar”,\\nand Xn as the value of the stock on day n.\\n(a) Find E(Xn) and V(Xn).\\n(b) Simulate Xn and plot Xn versus n for n =1 ,2,..., 10,000. Repeat\\nthe whole simulation several times. Notice two things. First, it’s easy\\nto “see” patterns in the sequence even though it is random. Second,'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 75, 'page_label': '76'}, page_content='60 3. Expectation\\nyou will ﬁnd that the four runs look very diﬀerent even though they\\nwere generated the same way. How do the calculations in (a) explain\\nthe second observation?\\n12. Prove the formulas given in the table at the beginning of Section 3.4\\nfor the Bernoulli, Poisson, Uniform, Exponential, Gamma, and Beta.\\nHere are some hints. For the mean of the Poisson, use the fact that\\ne\\na = ∑ ∞\\nx=0 ax/x!. To compute the variance, ﬁrst computeE(X(X −1)).\\nFor the mean of the Gamma, it will help to multiply and divide by\\nΓ(α +1 )/β\\nα+1 and use the fact that a Gamma density integrates to 1.\\nFor the Beta, multiply and divide by Γ(α + 1)Γ(β)/Γ(α + β + 1).\\n13. Suppose we generate a random variable X in the following way. First\\nwe ﬂip a fair coin. If the coin is heads, take X to have a Unif(0,1)\\ndistribution. If the coin is tails, take X to have a Unif(3,4) distribution.\\n(a) Find the mean of X.\\n(b) Find the standard deviation of X.\\n14. Let X\\n1,...,X m and Y1,...,Y n be random variables and let a1,...,a m\\nand b1,...,b n be constants. Show that\\nCov\\n\\uf8eb\\n\\uf8ed\\nm∑\\ni=1\\naiXi,\\nn∑\\nj=1\\nbjYj\\n\\uf8f6\\n\\uf8f8 =\\nm∑\\ni=1\\nn∑\\nj=1\\naibjCov(Xi,Yj).\\n15. Let\\nfX,Y (x, y)=\\n{ 1\\n3(x + y)0 ≤ x ≤ 1, 0 ≤ y ≤ 2\\n0 otherwise .\\nFind V(2X − 3Y + 8).\\n16. Let r(x) be a function of x and let s(y) be a function of y. Show that\\nE(r(X)s(Y )|X)= r(X)E(s(Y )|X).\\nAlso, show that E(r(X)|X)= r(X).\\n17. Prove that\\nV(Y )= EV (Y | X)+ VE (Y | X).\\nHint: Let m = E(Y ) and let b(x)= E(Y |X = x). Note that E(b(X)) =\\nEE(Y |X)= E(Y )= m. Bear in mind that b is a function of x.N o w\\nwrite V(Y )= E(Y − m)2 = E((Y − b(X) )+(b(X) − m))2. Expand the'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 76, 'page_label': '77'}, page_content='3.8 Exercises 61\\nsquare and take the expectation. You then have to take the expectation\\nof three terms. In each case, use the rule of the iterated expectation:\\nE(stuﬀ) = E(E(stuﬀ|X)).\\n18. Show that if E(X|Y = y)= c for some constant c, then X and Y are\\nuncorrelated.\\n19. This question is to help you understand the idea of a sampling dis-\\ntribution. Let X\\n1,...,X n be iid with mean µ and variance σ2. Let\\nXn = n−1 ∑ n\\ni=1 Xi. Then Xn is a statistic, that is, a function of the\\ndata. Since Xn is a random variable, it has a distribution. This distri-\\nbution is called the sampling distribution of the statistic. Recall from\\nTheorem 3.17 that E(Xn)= µ and V(Xn)= σ2/n. Don’t confuse the\\ndistribution of the data fX and the distribution of the statisticfXn\\n.T o\\nmake this clear, let X1,...,X n ∼ Uniform(0,1). Let fX be the density\\nof the Uniform(0,1). Plot fX. Now let Xn = n−1 ∑ n\\ni=1 Xi. Find E(Xn)\\nand V(Xn). Plot them as a function of n. Interpret. Now simulate the\\ndistribution of Xn for n =1 ,5,25,100. Check that the simulated values\\nof E(Xn) and V(Xn) agree with your theoretical calculations. What do\\nyou notice about the sampling distribution of Xn as n increases?\\n20. Prove Lemma 3.21.\\n21. Let X and Y be random variables. Suppose that E(Y |X)= X. Show\\nthat Cov(X,Y )= V(X).\\n22. Let X ∼ Uniform(0,1). Let 0 <a<b< 1. Let\\nY =\\n{ 10 <x<b\\n0 otherwise\\nand let\\nZ =\\n{ 1 a<x< 1\\n0 otherwise\\n(a) Are Y and Z independent? Why/Why not?\\n(b) FindE(Y |Z). Hint: What valuesz can Z take? Now ﬁndE(Y |Z = z).\\n23. Find the moment generating function for the Poisson, Normal, and\\nGamma distributions.\\n24. Let X\\n1,...,X n ∼ Exp(β). Find the moment generating function of Xi.\\nProve that ∑ n\\ni=1 Xi ∼ Gamma(n, β).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 77, 'page_label': '78'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 78, 'page_label': '79'}, page_content='4\\nInequalities\\n4.1 Probability Inequalities\\nInequalities are useful for bounding quantities that might otherwise be hard\\nto compute. They will also be used in the theory of convergence which is\\ndiscussed in the next chapter. Our ﬁrst inequality is Markov’s inequality.\\n4.1 Theorem (Markov’s inequality). Let X be a non-negative random\\nvariable and suppose that E(X) exists. For any t> 0,\\nP(X>t ) ≤ E(X)\\nt . (4.1)\\nProof. Since X> 0,\\nE(X)=\\n∫ ∞\\n0\\nxf(x)dx =\\n∫ t\\n0\\nxf(x)dx +\\n∫ ∞\\nt\\nxf(x)dx\\n≥\\n∫ ∞\\nt\\nxf(x)dx ≥ t\\n∫ ∞\\nt\\nf(x)dx = t P(X>t ) ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 79, 'page_label': '80'}, page_content='64 4. Inequalities\\n4.2 Theorem (Chebyshev’s inequality). Let µ = E(X) and σ2 = V(X).\\nThen,\\nP(|X − µ|≥ t) ≤ σ2\\nt2 and P(|Z|≥ k) ≤ 1\\nk2 (4.2)\\nwhere Z =( X − µ)/σ. In particular, P(|Z| > 2) ≤ 1/4 and\\nP(|Z| > 3) ≤ 1/9.\\nProof. We use Markov’s inequality to conclude that\\nP(|X − µ|≥ t)= P(|X − µ|2 ≥ t2) ≤ E(X − µ)2\\nt2 = σ2\\nt2 .\\nThe second part follows by setting t = kσ. ■\\n4.3 Example. Suppose we test a prediction method, a neural net for example,\\non a set of n new test cases. Let Xi = 1 if the predictor is wrong and Xi =0\\nif the predictor is right. Then Xn = n−1 ∑ n\\ni=1 Xi is the observed error rate.\\nEach Xi may be regarded as a Bernoulli with unknown mean p. We would\\nlike to know the true — but unknown — error rate p. Intuitively, we expect\\nthat Xn should be close to p. How likely is Xn to not be within ϵ of p?W e\\nhave that V(Xn)= V(X1)/n = p(1 − p)/n and\\nP(|Xn − p| >ϵ ) ≤ V(Xn)\\nϵ2 = p(1 − p)\\nnϵ2 ≤ 1\\n4nϵ2\\nsince p(1 − p) ≤ 1\\n4 for all p.F o rϵ = .2 and n = 100 the bound is .0625. ■\\nHoeﬀding’s inequality is similar in spirit to Markov’s inequality but it is a\\nsharper inequality. We present the result here in two parts.\\n4.4 Theorem (Hoeﬀding’s Inequality). Let Y1,...,Y n be independent\\nobservations such that\\nE(Y\\ni)=0 and ai ≤ Yi ≤ bi.L e tϵ> 0. Then, for any t> 0,\\nP\\n\\uf8f6 n∑\\ni=1\\nYi ≥ ϵ\\n\\uf8f7\\n≤ e−tϵ\\nn∏\\ni=1\\net2(bi−ai)2/8. (4.3)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 80, 'page_label': '81'}, page_content='4.1 Probability Inequalities 65\\n4.5 Theorem. Let X1,...,X n ∼ Bernoulli(p). Then, for any ϵ> 0,\\nP\\n\\uf8f6\\n|Xn − p| >ϵ\\n\\uf8f7\\n≤ 2e−2nϵ2\\n(4.4)\\nwhere Xn = n−1 ∑ n\\ni=1 Xi.\\n4.6 Example. Let X1,...,X n ∼ Bernoulli(p). Let n = 100 and ϵ = .2. We\\nsaw that Chebyshev’s inequality yielded\\nP(|Xn − p| >ϵ ) ≤ .0625.\\nAccording to Hoeﬀding’s inequality,\\nP(|Xn − p| >. 2) ≤ 2e−2(100)(.2)2\\n= .00067\\nwhich is much smaller than .0625. ■\\nHoeﬀding’s inequality gives us a simple way to create aconﬁdence inter-\\nval for a binomial parameter p. We will discuss conﬁdence intervals in detail\\nlater (see Chapter 6) but here is the basic idea. Fix α> 0 and let\\nϵn =\\n√\\n1\\n2n log\\n\\uf8f62\\nα\\n\\uf8f7\\n.\\nBy Hoeﬀding’s inequality,\\nP\\n\\uf8f6\\n|Xn − p| >ϵ n\\n\\uf8f7\\n≤ 2e−2nϵ2\\nn = α.\\nLet C =( Xn −ϵn,Xn +ϵn). Then, P(p/∈ C)= P(|Xn −p| >ϵ n) ≤ α. Hence,\\nP(p ∈ C) ≥ 1 − α, that is, the random interval C traps the true parameter\\nvalue p with probability 1− α; we call C a1 − α conﬁdence interval. More on\\nthis later.\\nThe following inequality is useful for bounding probability statements about\\nNormal random variables.\\n4.7 Theorem (Mill’s Inequality). Let Z ∼ N(0,1). Then,\\nP(|Z| >t ) ≤\\n√\\n2\\nπ\\ne−t2/2\\nt .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 81, 'page_label': '82'}, page_content='66 4. Inequalities\\n4.2 Inequalities For Expectations\\nThis section contains two inequalities on expected values.\\n4.8 Theorem (Cauchy-Schwartz inequality). If X and Y have ﬁnite\\nvariances then\\nE |XY |≤\\n√\\nE(X2)E(Y 2). (4.5)\\nRecall that a function g is convex if for each x, y and each α ∈ [0,1],\\ng(αx +( 1− α)y) ≤ αg(x)+( 1 − α)g(y).\\nIf g is twice diﬀerentiable and g′′(x) ≥ 0 for all x, then g is convex. It can\\nbe shown that if g is convex, then g lies above any line that touches g at\\nsome point, called a tangent line. A function g is concave if −g is convex.\\nExamples of convex functions are g(x)= x2 and g(x)= ex. Examples of\\nconcave functions are g(x)= −x2 and g(x) = logx.\\n4.9 Theorem (Jensen’s inequality). If g is convex, then\\nEg(X) ≥ g(EX). (4.6)\\nIf g is concave, then\\nEg(X) ≤ g(EX). (4.7)\\nProof. Let L(x)= a + bx be a line, tangent to g(x) at the point E(X).\\nSince g is convex, it lies above the line L(x). So,\\nEg(X) ≥ EL(X)= E(a + bX)= a + bE(X)= L(E(X)) = g(EX). ■\\nFrom Jensen’s inequality we see that E(X2) ≥ (EX)2 and if X is positive,\\nthen E(1/X) ≥ 1/E(X). Since log is concave, E(log X) ≤ log E(X).\\n4.3 Bibliographic Remarks\\nDevroye et al. (1996) is a good reference on probability inequalities and their\\nuse in statistics and pattern recognition. The following proof of Hoeﬀding’s\\ninequality is from that text.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 82, 'page_label': '83'}, page_content='4.4 Appendix 67\\n4.4 Appendix\\nProof of Hoeffding’s Inequality.We will make use of the exact form of\\nTaylor’s theorem: if g is a smooth function, then there is a number ξ ∈ (0,u )\\nsuch that g(u)= g(0) +ug′(0) + u2\\n2 g\\n′′\\n(ξ).\\nProof of Theorem 4.4. For any t> 0, we have, from Markov’s inequality,\\nthat\\nP\\n\\uf8f6 n∑\\ni=1\\nYi ≥ ϵ\\n\\uf8f7\\n= P\\n\\uf8f6\\nt\\nn∑\\ni=1\\nYi ≥ tϵ\\n\\uf8f7\\n= P\\n\\uf8f6\\net ∑ n\\ni=1 Yi ≥ etϵ\\n\\uf8f7\\n≤ e−tϵE\\n\\uf8f6\\net ∑ n\\ni=1 Yi\\n\\uf8f7\\n= e−tϵ ∏\\ni\\nE(etYi ). (4.8)\\nSince ai ≤ Yi ≤ bi, we can write Yi as a convex combination of ai and bi,\\nnamely, Yi = αbi +( 1 − α)ai where α =( Yi − ai)/(bi − ai). So, by the\\nconvexity of ety we have\\netYi ≤ Yi − ai\\nbi − ai\\netbi + bi − Yi\\nbi − ai\\netai .\\nTake expectations of both sides and use the fact that E(Yi) = 0 to get\\nEetYi ≤− ai\\nbi − ai\\netbi + bi\\nbi − ai\\netai = eg(u) (4.9)\\nwhere u = t(bi − ai), g(u)= −γu + log(1− γ + γeu) and γ = −ai/(bi − ai).\\nNote that g(0) = g′(0) = 0. Also, g\\n′′\\n(u) ≤ 1/4 for all u> 0. By Taylor’s\\ntheorem, there is a ξ ∈ (0,u ) such that\\ng(u)= g(0) +ug\\n′\\n(0) + u2\\n2 g\\n′′\\n(ξ)\\n= u2\\n2 g\\n′′\\n(ξ) ≤ u2\\n8 = t2(bi − ai)2\\n8 .\\nHence,\\nEetYi ≤ eg(u) ≤ et2(bi−ai)2/8.\\nThe result follows from (4.8). ■\\nProof of Theorem 4.5. Let Yi =( 1 /n)(Xi − p). Then E(Yi) = 0 and\\na ≤ Yi ≤ b where a = −p/n and b =( 1 − p)/n. Also, ( b − a)2 =1 /n2.\\nApplying Theorem 4.4 we get\\nP(Xn − p>ϵ )= P\\n\\uf8f6∑\\ni\\nYi >ϵ\\n\\uf8f7\\n≤ e−tϵet2/(8n).\\nThe above holds for anyt> 0. In particular, taket =4 nϵ and we get P(Xn −\\np>ϵ ) ≤ e−2nϵ2\\n. By a similar argument we can show that P(Xn − p< −ϵ) ≤\\ne−2nϵ2\\n. Putting these together we get P\\n\\uf8f6\\n|Xn − p| >ϵ\\n\\uf8f7\\n≤ 2e−2nϵ2\\n. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 83, 'page_label': '84'}, page_content='68 4. Inequalities\\n4.5 Exercises\\n1. Let X ∼ Exponential(β). Find P(|X − µX|≥ kσX) for k> 1. Compare\\nthis to the bound you get from Chebyshev’s inequality.\\n2. Let X ∼ Poisson(λ). Use Chebyshev’s inequality to show that P(X ≥\\n2λ) ≤ 1/λ.\\n3. Let X1,...,X n ∼ Bernoulli(p) and Xn = n−1 ∑ n\\ni=1 Xi. Bound P(|Xn −\\np| >ϵ ) using Chebyshev’s inequality and using Hoeﬀding’s inequality.\\nShow that, when n is large, the bound from Hoeﬀding’s inequality is\\nsmaller than the bound from Chebyshev’s inequality.\\n4. Let X1,...,X n ∼ Bernoulli(p).\\n(a) Let α> 0 be ﬁxed and deﬁne\\nϵn =\\n√\\n1\\n2n log\\n\\uf8f62\\nα\\n\\uf8f7\\n.\\nLet ˆpn = n−1 ∑ n\\ni=1 Xi. Deﬁne Cn =( ˆpn − ϵn, ˆpn + ϵn). Use Hoeﬀding’s\\ninequality to show that\\nP(Cn contains p) ≥ 1 − α.\\nIn practice, we truncate the interval so it does not go below 0 or above\\n1.\\n(b) (Computer Experiment.) Let’s examine the properties of this conﬁ-\\ndence interval. Let α =0 .05 and p =0 .4. Conduct a simulation study\\nto see how often the interval contains p (called the coverage). Do this\\nfor various values ofn between 1 and 10000. Plot the coverage versusn.\\n(c) Plot the length of the interval versusn. Suppose we want the length\\nof the interval to be no more than .05. How large should n be?\\n5. Prove Mill’s inequality, Theorem 4.7. Hint. Note that P(|Z| >t )=\\n2P(Z>t ). Now write out what P(Z>t ) means and note that x/t > 1\\nwhenever x>t .\\n6. Let Z ∼ N(0,1). Find P(|Z| >t ) and plot this as a function of t. From\\nMarkov’s inequality, we have the bound P(|Z| >t ) ≤ E|Z|k\\ntk for any\\nk> 0. Plot these bounds for k =1 ,2,3,4,5 and compare them to the\\ntrue value of P(|Z| >t ). Also, plot the bound from Mill’s inequality.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 84, 'page_label': '85'}, page_content='4.5 Exercises 69\\n7. Let X1,...,X n ∼ N(0,1). Bound P(|Xn| >t ) using Mill’s inequality,\\nwhere Xn = n−1 ∑ n\\ni=1 Xi. Compare to the Chebyshev bound.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 85, 'page_label': '86'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 86, 'page_label': '87'}, page_content='5\\nConvergence of Random Variables\\n5.1 Introduction\\nThe most important aspect of probability theory concerns the behavior of\\nsequences of random variables. This part of probability is calledlarge sample\\ntheory,o r limit theory,o r asymptotic theory. The basic question is this:\\nwhat can we say about the limiting behavior of a sequence of random variables\\nX\\n1,X 2,X 3,... ? Since statistics and data mining are all about gathering data,\\nwe will naturally be interested in what happens as we gather more and more\\ndata.\\nIn calculus we say that a sequence of real numbers x\\nn converges to a limit\\nx if, for every ϵ> 0, |xn − x| <ϵ for all large n. In probability, convergence is\\nmore subtle. Going back to calculus for a moment, suppose that xn = x for\\nall n. Then, trivially, limn→∞ xn = x. Consider a probabilistic version of this\\nexample. Suppose that X1,X 2,... is a sequence of random variables which\\nare independent and suppose each has a N(0,1) distribution. Since these all\\nhave the same distribution, we are tempted to say that Xn “converges” to\\nX ∼ N(0,1). But this can’t quite be right since P(Xn = X) = 0 for all n.\\n(Two continuous random variables are equal with probability zero.)\\nHere is another example. Consider X1,X 2,... where Xi ∼ N(0,1/n). Intu-\\nitively, Xn is very concentrated around 0 for large n so we would like to say\\nthat Xn converges to 0. But P(Xn = 0) = 0 for all n. Clearly, we need to'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 87, 'page_label': '88'}, page_content='72 5. Convergence of Random Variables\\ndevelop some tools for discussing convergence in a rigorous way. This chapter\\ndevelops the appropriate methods.\\nThere are two main ideas in this chapter which we state informally here:\\n1. The law of large numberssays that the sample averageXn = n−1 ∑ n\\ni=1 Xi\\nconverges in probability to the expectation µ = E(Xi). This means\\nthat Xn is close to µ with high probability.\\n2. The central limit theoremsays that √n(Xn −µ) converges in dis-\\ntribution to a Normal distribution. This means that the sample average\\nhas approximately a Normal distribution for large n.\\n5.2 Types of Convergence\\nThe two main types of convergence are deﬁned as follows.\\n5.1 Deﬁnition. Let X1,X 2,... be a sequence of random variables and let\\nX be another random variable. Let Fn denote the cdf of Xn and let F\\ndenote the cdf of X.\\n1. Xn converges to X in probability, written Xn\\nP\\n−→X, if, for every\\nϵ> 0,\\nP(|Xn − X| >ϵ ) → 0 (5.1)\\nas n →∞ .\\n2. Xn converges to X in distribution, written Xn ⇝ X,i f\\nlim\\nn→∞\\nFn(t)= F(t) (5.2)\\nat all t for which F is continuous.\\nWhen the limiting random variable is a point mass, we change the notation\\nslightly. If P(X = c)=1a n d Xn\\nP\\n−→X then we write Xn\\nP\\n−→c. Similarly, if\\nXn ⇝ X we write Xn ⇝ c.\\nThere is another type of convergence which we introduce mainly because it\\nis useful for proving convergence in probability.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 88, 'page_label': '89'}, page_content='5.2 Types of Convergence 73\\nt\\nFn(t)\\nt\\nF(t)\\nFIGURE 5.1. Example 5.3. Xn converges in distribution to X because Fn(t) con-\\nverges to F(t) at all points except t = 0. Convergence is not required at t =0\\nbecause t = 0 is not a point of continuity for F.\\n5.2 Deﬁnition. Xn converges to X in quadratic mean (also called\\nconvergence in L2), written Xn\\nqm\\n−→X,i f\\nE(Xn − X)2 → 0 (5.3)\\nas n →∞ .\\nAgain, if X is a point mass at c we write Xn\\nqm\\n−→c instead of Xn\\nqm\\n−→X.\\n5.3 Example. Let Xn ∼ N(0,1/n). Intuitively, Xn is concentrating at 0 so\\nwe would like to say thatXn converges to 0. Let’s see if this is true. LetF be\\nthe distribution function for a point mass at 0. Note that √nXn ∼ N(0,1).\\nLet Z denote a standard normal random variable. Fort< 0, Fn(t)= P(Xn <\\nt)= P(√nXn < √nt)= P(Z< √nt) → 0 since √nt →− ∞.F o rt> 0,\\nFn(t)= P(Xn <t )= P(√nXn < √nt)= P(Z< √nt) → 1 since √nt →∞ .\\nHence, Fn(t) → F(t) for all t ̸= 0 and so Xn ⇝ 0. Notice that Fn( 0 )=1/2 ̸=\\nF(1/2) = 1 so convergence fails at t = 0. That doesn’t matter because t =0\\nis not a continuity point ofF and the deﬁnition of convergence in distribution\\nonly requires convergence at continuity points. See Figure 5.1. Now consider\\nconvergence in probability. For anyϵ> 0, using Markov’s inequality,\\nP(|X\\nn| >ϵ )= P(|Xn|2 >ϵ 2)\\n≤ E(X2\\nn)\\nϵ2 =\\n1\\nn\\nϵ2 → 0\\nas n →∞ . Hence, Xn\\nP\\n−→0. ■\\nThe next theorem gives the relationship between the types of convergence.\\nThe results are summarized in Figure 5.2.\\n5.4 Theorem. The following relationships hold:\\n(a) Xn\\nqm\\n−→X implies that Xn\\nP\\n−→X.\\n(b) Xn\\nP\\n−→X implies that Xn ⇝ X.\\n(c) If Xn ⇝ X and if P(X = c)=1 for some real numberc, then Xn\\nP\\n−→X.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 89, 'page_label': '90'}, page_content='74 5. Convergence of Random Variables\\nIn general, none of the reverse implications hold except the special case in\\n(c).\\nProof. We start by proving (a). Suppose thatXn\\nqm\\n−→X. Fix ϵ> 0. Then,\\nusing Markov’s inequality,\\nP(|Xn − X| >ϵ )= P(|Xn − X|2 >ϵ 2) ≤ E|Xn − X|2\\nϵ2 → 0.\\nProof of (b). This proof is a little more complicated. You may skip it if you\\nwish. Fix ϵ> 0 and let x be a continuity point of F. Then\\nFn(x)= P(Xn ≤ x)= P(Xn ≤ x, X ≤ x + ϵ)+ P(Xn ≤ x, X > x+ ϵ)\\n≤ P(X ≤ x + ϵ)+ P(|Xn − X| >ϵ )\\n= F(x + ϵ)+ P(|Xn − X| >ϵ ).\\nAlso,\\nF(x − ϵ)= P(X ≤ x − ϵ)= P(X ≤ x − ϵ, X\\nn ≤ x)+ P(X ≤ x − ϵ, Xn >x )\\n≤ Fn(x)+ P(|Xn − X| >ϵ ).\\nHence,\\nF(x − ϵ) − P(|Xn − X| >ϵ ) ≤ Fn(x) ≤ F(x + ϵ)+ P(|Xn − X| >ϵ ).\\nTake the limit as n →∞ to conclude that\\nF(x − ϵ) ≤ lim inf\\nn→∞\\nFn(x) ≤ lim sup\\nn→∞\\nFn(x) ≤ F(x + ϵ).\\nThis holds for all ϵ> 0. Take the limit as ϵ → 0 and use the fact that F is\\ncontinuous at x and conclude that limn Fn(x)= F(x).\\nProof of (c). Fix ϵ> 0. Then,\\nP(|Xn − c| >ϵ )= P(Xn <c − ϵ)+ P(Xn >c + ϵ)\\n≤ P(Xn ≤ c − ϵ)+ P(Xn >c + ϵ)\\n= Fn(c − ϵ)+1 − Fn(c + ϵ)\\n→ F(c − ϵ)+1 − F(c + ϵ)\\n= 0+1 − 1=0 .\\nLet us now show that the reverse implications do not hold.\\nConvergence in probability does not imply convergence in quadratic\\nmean. Let U ∼ Unif(0,1) and let Xn = √nI(0,1/n)(U). Then P(|Xn| >ϵ )='),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 90, 'page_label': '91'}, page_content='5.2 Types of Convergence 75\\nquadratic mean probability distribution\\npoint-mass distribution\\nFIGURE 5.2. Relationship between types of convergence.\\nP(√nI(0,1/n)(U) >ϵ )= P(0 ≤ U< 1/n)=1 /n → 0. Hence, Xn\\nP\\n−→0. But\\nE(X2\\nn)= n\\n∫1/n\\n0 du = 1 for all n so Xn does not converge in quadratic mean.\\nConvergence in distribution does not imply convergence in prob-\\nability. Let X ∼ N(0,1). Let Xn = −X for n =1 ,2,3,... ; hence Xn ∼\\nN(0,1). Xn has the same distribution function as X for all n so, trivially,\\nlimn Fn(x)= F(x) for all x. Therefore, Xn ⇝ X. But P(|Xn − X| >ϵ )=\\nP(|2X| >ϵ )= P(|X| >ϵ /2) ̸=0 .S oXn does not converge toX in probability.\\n■\\nWarning! One might conjecture that if Xn\\nP\\n−→b, then E(Xn) → b. This is\\nnot1 true. Let Xn be a random variable deﬁned by P(Xn = n2)=1 /n and\\nP(Xn =0 )=1 − (1/n). Now, P(|Xn| <ϵ )= P(Xn =0 )=1 − (1/n) → 1.\\nHence, Xn\\nP\\n−→0. However,E(Xn)=[ n2 ×(1/n)]+[0 ×(1−(1/n))] = n. Thus,\\nE(Xn) →∞ .\\nSummary. Stare at Figure 5.2.\\nSome convergence properties are preserved under transformations.\\n5.5 Theorem. Let Xn,X,Y n,Y be random variables. Let g be a continuous\\nfunction.\\n(a) If Xn\\nP\\n−→X and Yn\\nP\\n−→Y , then Xn + Yn\\nP\\n−→X + Y .\\n(b) If Xn\\nqm\\n−→X and Yn\\nqm\\n−→Y , then Xn + Yn\\nqm\\n−→X + Y .\\n(c) If Xn ⇝ X and Yn ⇝ c, then Xn + Yn ⇝ X + c.\\n(d) If Xn\\nP\\n−→X and Yn\\nP\\n−→Y , then XnYn\\nP\\n−→XY .\\n(e) If Xn ⇝ X and Yn ⇝ c, then XnYn ⇝ cX.\\n(f) If Xn\\nP\\n−→X, then g(Xn)\\nP\\n−→g(X).\\n(g) If Xn ⇝ X, then g(Xn) ⇝ g(X).\\nParts (c) and (e) are know asSlutzky’s theorem. It is worth noting that\\nXn ⇝ X and Yn ⇝ Y does not in general imply that Xn + Yn ⇝ X + Y .\\n1We can conclude that E(Xn) → b if Xn is uniformly integrable. See the appendix.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 91, 'page_label': '92'}, page_content='76 5. Convergence of Random Variables\\n5.3 The Law of Large Numbers\\nNow we come to a crowning achievement in probability, the law of large num-\\nbers. This theorem says that the mean of a large sample is close to the mean\\nof the distribution. For example, the proportion of heads of a large number\\nof tosses is expected to be close to 1/2. We now make this more precise.\\nLet X\\n1,X 2,... be an iid sample, let µ = E(X1) and 2 σ2 = V(X1). Recall\\nthat the sample mean is deﬁned as Xn = n−1 ∑ n\\ni=1 Xi and that E(Xn)= µ\\nand V(Xn)= σ2/n.\\n5.6 Theorem (The Weak Law of Large Numbers (WLLN)). 3\\nIf X1,...,X n are iid, then Xn\\nP\\n−→µ.\\nInterpretation of the WLLN: The distribution of Xn becomes more\\nconcentrated around µ as n gets large.\\nProof. Assume that σ< ∞. This is not necessary but it simpliﬁes the\\nproof. Using Chebyshev’s inequality,\\nP\\n\\uf8f6\\n|Xn − µ| >ϵ\\n\\uf8f7\\n≤ V(Xn)\\nϵ2 = σ2\\nnϵ2\\nwhich tends to 0 as n →∞ . ■\\n5.7 Example. Consider ﬂipping a coin for which the probability of heads is\\np. Let Xi denote the outcome of a single toss (0 or 1). Hence, p = P(Xi =\\n1) = E(Xi). The fraction of heads after n tosses is Xn. According to the law\\nof large numbers, Xn converges to p in probability. This does not mean that\\nXn will numerically equal p. It means that, when n is large, the distribution\\nof Xn is tightly concentrated around p. Suppose that p =1 /2. How large\\nshould n be so that P(.4 ≤ Xn ≤ .6) ≥ .7? First, E(Xn)= p =1 /2 and\\nV(Xn)= σ2/n = p(1 − p)/n =1 /(4n). From Chebyshev’s inequality,\\nP(.4 ≤ Xn ≤ .6) = P(|Xn − µ|≤ .1)\\n=1 − P(|Xn − µ| >. 1)\\n≥ 1 − 1\\n4n(.1)2 =1 − 25\\nn .\\nThe last expression will be larger than .7 if n = 84. ■\\n2Note that µ = E(Xi) is the same for all i so we can deﬁne µ = E(Xi) for any i.B y\\nconvention, we often write µ = E(X1).\\n3There is a stronger theorem in the appendix called the strong law of large numbers.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 92, 'page_label': '93'}, page_content='5.4 The Central Limit Theorem 77\\n5.4 The Central Limit Theorem\\nThe law of large numbers says that the distribution of Xn piles up near µ.\\nThis isn’t enough to help us approximate probability statements about Xn.\\nFor this we need the central limit theorem.\\nSuppose that X1,...,X n are iid with mean µ and variance σ2. The central\\nlimit theorem (CLT) says that Xn = n−1 ∑\\ni Xi has a distribution which is\\napproximately Normal with mean µ and variance σ2/n. This is remarkable\\nsince nothing is assumed about the distribution ofXi, except the existence of\\nthe mean and variance.\\n5.8 Theorem (The Central Limit Theorem (CLT)). Let X1,...,X n be iid\\nwith mean µ and variance σ2.L e tXn = n−1 ∑ n\\ni=1 Xi. Then\\nZn ≡ Xn − µ√\\nV(Xn)\\n=\\n√n(Xn − µ)\\nσ ⇝ Z\\nwhere Z ∼ N(0,1). In other words,\\nlim\\nn→∞\\nP(Zn ≤ z)=Φ ( z)=\\n∫ z\\n−∞\\n1√\\n2πe−x2/2dx.\\nInterpretation: Probability statements aboutXn can be approximated\\nusing a Normal distribution. It’s the probability statements that we\\nare approximating, not the random variable itself.\\nIn addition to Z\\nn ⇝ N(0,1), there are several forms of notation to denote\\nthe fact that the distribution of Zn is converging to a Normal. They all mean\\nthe same thing. Here they are:\\nZn ≈ N(0,1)\\nXn ≈ N\\n\\uf8f6\\nµ, σ2\\nn\\n\\uf8f7\\nXn − µ ≈ N\\n\\uf8f6\\n0, σ2\\nn\\n\\uf8f7\\n√n(Xn − µ) ≈ N\\n\\uf8f6\\n0,σ 2\\uf8f7\\n√n(Xn − µ)\\nσ ≈ N(0,1).\\n5.9 Example. Suppose that the number of errors per computer program has a\\nPoisson distribution with mean 5. We get 125 programs. LetX1,...,X 125 be'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 93, 'page_label': '94'}, page_content='78 5. Convergence of Random Variables\\nthe number of errors in the programs. We want to approximateP(Xn < 5.5).\\nLet µ = E(X1)= λ = 5 and σ2 = V(X1)= λ = 5. Then,\\nP(Xn < 5.5) = P\\n\\uf8f6√n(Xn − µ)\\nσ <\\n√n(5.5 − µ)\\nσ\\n\\uf8f7\\n≈ P(Z< 2.5) = .9938. ■\\nThe central limit theorem tells us thatZn = √n(Xn−µ)/σ is approximately\\nN(0,1). However, we rarely know σ. Later, we will see that we can estimate\\nσ2 from X1,...,X n by\\nS2\\nn = 1\\nn − 1\\nn∑\\ni=1\\n(Xi − Xn)2.\\nThis raises the following question: if we replaceσ with Sn, is the central limit\\ntheorem still true? The answer is yes.\\n5.10 Theorem. Assume the same conditions as the CLT. Then,\\n√n(Xn − µ)\\nSn\\n⇝ N(0,1).\\nYou might wonder, how accurate the normal approximation is. The answer\\nis given in the Berry-Ess`een theorem.\\n5.11 Theorem (The Berry-Ess`een Inequality). Suppose thatE|X1|3 < ∞. Then\\nsup\\nz\\n|P(Zn ≤ z) − Φ(z)|≤ 33\\n4\\nE|X1 − µ|3\\n√nσ3 . (5.4)\\nThere is also a multivariate version of the central limit theorem.\\n5.12 Theorem (Multivariate central limit theorem). Let X1,...,X n be iid ran-\\ndom vectors where\\nXi =\\n\\uf8eb\\n\\uf8ec\\uf8ec\\n\\uf8ec\\uf8ed\\nX\\n1i\\nX2i\\n..\\n.\\nX\\nki\\n\\uf8f6\\n\\uf8f7\\uf8f7\\n\\uf8f7\\uf8f8\\nwith mean\\nµ =\\n\\uf8eb\\n\\uf8ec\\uf8ec\\n\\uf8ec\\uf8ed\\nµ\\n1\\nµ2\\n..\\n.\\nµ\\nk\\n\\uf8f6\\n\\uf8f7\\uf8f7\\n\\uf8f7\\uf8f8 =\\n\\uf8eb\\n\\uf8ec\\uf8ec\\n\\uf8ec\\uf8ed\\nE(X\\n1i)\\nE(X2i)\\n..\\n.\\nE(X\\nki)\\n\\uf8f6\\n\\uf8f7\\uf8f7\\n\\uf8f7\\uf8f8'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 94, 'page_label': '95'}, page_content='5.5 The Delta Method 79\\nand variance matrix Σ.L e t\\nX =\\n\\uf8eb\\n\\uf8ec\\uf8ec\\n\\uf8ec\\uf8ed\\nX1\\nX2\\n..\\n.\\nXk\\n\\uf8f6\\n\\uf8f7\\uf8f7\\n\\uf8f7\\uf8f8.\\nwhere\\nXj = n−1 ∑ n\\ni=1 Xji. Then,\\n√n(X − µ) ⇝ N(0,Σ).\\n5.5 The Delta Method\\nIf Yn has a limiting Normal distribution then the delta method allows us to\\nﬁnd the limiting distribution of g(Yn) where g is any smooth function.\\n5.13 Theorem (The Delta Method). Suppose that\\n√n(Yn − µ)\\nσ ⇝ N(0,1)\\nand that g is a diﬀerentiable function such that g′(µ) ̸=0 . Then\\n√n(g(Yn) − g(µ))\\n|g′(µ)|σ ⇝ N(0,1).\\nIn other words,\\nYn ≈ N\\n\\uf8f6\\nµ, σ2\\nn\\n\\uf8f7\\nimplies that g(Yn) ≈ N\\n\\uf8f6\\ng(µ),(g′(µ))2 σ2\\nn\\n\\uf8f7\\n.\\n5.14 Example. Let X1,...,X n be iid with ﬁnite mean µ and ﬁnite variance\\nσ2. By the central limit theorem, √n(Xn − µ)/σ ⇝ N(0,1). Let Wn = eXn .\\nThus, Wn = g(Xn) where g(s)= es. Since g′(s)= es, the delta method\\nimplies that Wn ≈ N(eµ,e2µσ2/n). ■\\nThere is also a multivariate version of the delta method.\\n5.15 Theorem (The Multivariate Delta Method). Suppose thatYn =( Yn1,...,Y nk)\\nis a sequence of random vectors such that\\n√n(Yn − µ) ⇝ N(0,Σ).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 95, 'page_label': '96'}, page_content='80 5. Convergence of Random Variables\\nLet g : Rk → R and let\\n∇g(y)=\\n\\uf8eb\\n\\uf8ec\\uf8ec\\uf8ed\\n∂g\\n∂y1\\n..\\n.\\n∂g\\n∂yk\\n\\uf8f6\\n\\uf8f7\\uf8f7\\uf8f8.\\nLet ∇µ denote ∇g(y) evaluated at y = µ and assume that the elements of ∇µ\\nare nonzero. Then\\n√n(g(Yn) − g(µ)) ⇝ N\\n\\uf8f6\\n0,∇T\\nµ Σ∇µ\\n\\uf8f7\\n.\\n5.16 Example. Let\\n\\uf8f6\\nX11\\nX21\\n\\uf8f7\\n,\\n\\uf8f6\\nX12\\nX22\\n\\uf8f7\\n, ...,\\n\\uf8f6\\nX1n\\nX2n\\n\\uf8f7\\nbe iid random vectors with mean µ =( µ1,µ2)T and variance Σ. Let\\nX1 = 1\\nn\\nn∑\\ni=1\\nX1i, X2 = 1\\nn\\nn∑\\ni=1\\nX2i\\nand deﬁne Yn = X1X2. Thus, Yn = g(X1,X2) where g(s1,s2)= s1s2.B yt h e\\ncentral limit theorem,\\n√n\\n\\uf8f6 X1 − µ1\\nX2 − µ2\\n\\uf8f7\\n⇝ N(0,Σ).\\nNow\\n∇g(s)=\\n\\uf8f6\\n∂g\\n∂s1\\n∂g\\n∂s2\\n\\uf8f7\\n=\\n\\uf8f6 s2\\ns1\\n\\uf8f7\\nand so\\n∇T\\nµ Σ∇µ =( µ2 µ1)\\n\\uf8f6 σ11 σ12\\nσ12 σ22\\n\\uf8f7\\uf8f6 µ2\\nµ1\\n\\uf8f7\\n= µ2\\n2σ11 +2 µ1µ2σ12 + µ2\\n1σ22.\\nTherefore,\\n√n(X1X2 − µ1µ2) ⇝ N\\n\\uf8f6\\n0,µ2\\n2σ11 +2 µ1µ2σ12 + µ2\\n1σ22\\n\\uf8f7\\n. ■\\n5.6 Bibliographic Remarks\\nConvergence plays a central role in modern probability theory. For more de-\\ntails, see Grimmett and Stirzaker (1982), Karr (1993), and Billingsley (1979).\\nAdvanced convergence theory is explained in great detail in van der Vaart\\nand Wellner (1996) and and van der Vaart (1998).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 96, 'page_label': '97'}, page_content='5.7 Appendix 81\\n5.7 Appendix\\n5.7.1 Almost Sure and L1 Convergence\\nWe say that Xn converges almost surely to X, written Xn\\nas\\n−→X,i f\\nP({s : Xn(s) → X(s)})=1 .\\nWe say that Xn converges in L1 to X, written Xn\\nL1\\n−→X,i f\\nE|Xn − X|→ 0\\nas n →∞ .\\n5.17 Theorem. Let Xn and X be random variables. Then:\\n(a) Xn\\nas\\n−→X implies that Xn\\nP\\n−→X.\\n(b) Xn\\nqm\\n−→X implies that Xn\\nL1\\n−→X.\\n(c) Xn\\nL1\\n−→X implies that Xn\\nP\\n−→X.\\nThe weak law of large numbers says thatXn converges to E(X1) in proba-\\nbility. The strong law asserts that this is also true almost surely.\\n5.18 Theorem (The Strong Law of Large Numbers). Let X1,X 2,... be iid.I f\\nµ = E|X1| < ∞ then Xn\\nas\\n−→µ.\\nA sequence Xn is asymptotically uniformly integrable if\\nlim\\nM→∞\\nlim sup\\nn→∞\\nE (|Xn|I(|Xn| >M )) = 0.\\n5.19 Theorem. If Xn\\nP\\n−→b and Xn is asymptotically uniformly integrable,\\nthen E(Xn) → b.\\n5.7.2 Proof of the Central Limit Theorem\\nRecall that if X is a random variable, its moment generating function (mgf)\\nis ψX(t)= EetX. Assume in what follows that the mgf is ﬁnite in a neigh-\\nborhood around t =0 .\\n5.20 Lemma. Let Z1,Z2,... be a sequence of random variables. Letψn be the\\nmgf of Zn.L e tZ be another random variable and denote its mgf by ψ.I f\\nψn(t) → ψ(t) for all t in some open interval around 0, then Zn ⇝ Z.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 97, 'page_label': '98'}, page_content='82 5. Convergence of Random Variables\\nproof of the central limit theorem. Let Yi =( Xi − µ)/σ. Then,\\nZn = n−1/2 ∑\\ni Yi. Let ψ(t)b et h e mgf of Yi. The mgf of ∑\\ni Yi is (ψ(t))n\\nand mgf of Zn is [ψ(t/√n)]n ≡ ξn(t). Now ψ′(0) = E(Y1)=0 , ψ′′(0) =\\nE(Y 2\\n1 )= V(Y1)=1 .S o ,\\nψ(t)= ψ(0) +tψ′(0) + t2\\n2!ψ′′(0) + t3\\n3!ψ′′′(0) +···\\n= 1+0+ t2\\n2 + t3\\n3!ψ′′′(0) +···\\n=1 + t2\\n2 + t3\\n3!ψ′′′(0) +···\\nNow,\\nξn(t)=\\n[\\nψ\\n\\uf8f6 t√n\\n\\uf8f7]n\\n=\\n[\\n1+ t2\\n2n + t3\\n3!n3/2 ψ′′′(0) +···\\n]n\\n=\\n[\\n1+\\nt2\\n2 + t3\\n3!n1/2 ψ′′′(0) +···\\nn\\n]n\\n→ et2/2\\nwhich is the mgf of a N(0,1). The result follows from the previous Theorem.\\nIn the last step we used the fact that if an → a then\\n\\uf8f6\\n1+ an\\nn\\n\\uf8f7n\\n→ ea. ■\\n5.8 Exercises\\n1. Let X1,...,X n be iid with ﬁnite mean µ = E(X1) and ﬁnite variance\\nσ2 = V(X1). Let Xn be the sample mean and let S2\\nn be the sample\\nvariance.\\n(a) Show that E(S2\\nn)= σ2.\\n(b) Show that S2\\nn\\nP\\n−→σ2. Hint: Show thatS2\\nn = cnn−1 ∑ n\\ni=1 X2\\ni −dnX\\n2\\nn\\nwhere cn → 1 anddn → 1. Apply the law of large numbers ton−1 ∑ n\\ni=1 X2\\ni\\nand to Xn. Then use part (e) of Theorem 5.5.\\n2. Let X1,X 2,... be a sequence of random variables. Show that Xn\\nqm\\n−→b\\nif and only if\\nlim\\nn→∞\\nE(Xn)= b and lim\\nn→∞\\nV(Xn)=0 .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 98, 'page_label': '99'}, page_content='5.8 Exercises 83\\n3. Let X1,...,X n be iid and let µ = E(X1). Suppose that the variance is\\nﬁnite. Show that Xn\\nqm\\n−→µ.\\n4. Let X1,X 2,... be a sequence of random variables such that\\nP\\n\\uf8f6\\nXn = 1\\nn\\n\\uf8f7\\n=1 − 1\\nn2 and P (Xn = n)= 1\\nn2 .\\nDoes Xn converge in probability? DoesXn converge in quadratic mean?\\n5. Let X1,...,X n ∼ Bernoulli(p). Prove that\\n1\\nn\\nn∑\\ni=1\\nX2\\ni\\nP\\n−→p and 1\\nn\\nn∑\\ni=1\\nX2\\ni\\nqm\\n−→p.\\n6. Suppose that the height of men has mean 68 inches and standard de-\\nviation 2.6 inches. We draw 100 men at random. Find (approximately)\\nthe probability that the average height of men in our sample will be at\\nleast 68 inches.\\n7. Let λ\\nn =1 /n for n =1 ,2,... . Let Xn ∼ Poisson(λn).\\n(a) Show that Xn\\nP\\n−→0.\\n(b) Let Yn = nXn. Show that Yn\\nP\\n−→0.\\n8. Suppose we have a computer program consisting of n = 100 pages of\\ncode. Let Xi be the number of errors on the ith page of code. Suppose\\nthat the X′\\nis are Poisson with mean 1 and that they are independent.\\nLet Y = ∑ n\\ni=1 Xi be the total number of errors. Use the central limit\\ntheorem to approximate P(Y< 90).\\n9. Suppose that P(X =1 )= P(X = −1 )=1 /2. Deﬁne\\nXn =\\n{ X with probability 1 − 1\\nn\\nen with probability 1\\nn .\\nDoes Xn converge to X in probability? Does Xn converge to X in dis-\\ntribution? Does E(X − Xn)2 converge to 0?\\n10. Let Z ∼ N(0,1). Let t> 0. Show that, for any k> 0,\\nP(|Z| >t ) ≤ E|Z|k\\ntk .\\nCompare this to Mill’s inequality in Chapter 4.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 99, 'page_label': '100'}, page_content='84 5. Convergence of Random Variables\\n11. Suppose that Xn ∼ N(0,1/n) and let X be a random variable with\\ndistribution F(x)=0i f x< 0 and F(x)=1i f x ≥ 0. Does Xn converge\\nto X in probability? (Prove or disprove). Does Xn converge to X in\\ndistribution? (Prove or disprove).\\n12. Let X,X 1,X 2,X 3,... be random variables that are positive and integer\\nvalued. Show that Xn ⇝ X if and only if\\nlim\\nn→∞\\nP(Xn = k)= P(X = k)\\nfor every integer k.\\n13. Let Z1,Z2,... be iid random variables with density f. Suppose that\\nP(Zi > 0) = 1 and that λ = limx↓0 f(x) > 0. Let\\nXn = n min{Z1,...,Z n}.\\nShow that Xn ⇝ Z where Z has an exponential distribution with mean\\n1/λ.\\n14. Let X1,...,X n ∼ Uniform(0,1). Let Yn = X\\n2\\nn. Find the limiting distri-\\nbution of Yn.\\n15. Let \\uf8f6 X11\\nX21\\n\\uf8f7\\n,\\n\\uf8f6 X12\\nX22\\n\\uf8f7\\n, ...,\\n\\uf8f6 X1n\\nX2n\\n\\uf8f7\\nbe iid random vectors with mean µ =( µ1,µ2) and variance Σ. Let\\nX1 = 1\\nn\\nn∑\\ni=1\\nX1i, X2 = 1\\nn\\nn∑\\ni=1\\nX2i\\nand deﬁne Yn = X1/X2. Find the limiting distribution of Yn.\\n16. Construct an example where Xn ⇝ X and Yn ⇝ Y but Xn + Yn does\\nnot converge in distribution to X + Y .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 100, 'page_label': '101'}, page_content='Part II\\nStatistical Inference'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 101, 'page_label': '102'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 102, 'page_label': '103'}, page_content='6\\nModels, Statistical Inference and\\nLearning\\n6.1 Introduction\\nStatistical inference, or “learning” as it is called in computer science, is the\\nprocess of using data to infer the distribution that generated the data. A\\ntypical statistical inference question is:\\nGiven a sample X\\n1,...,X n ∼ F, how do we infer F?\\nIn some cases, we may want to infer only some feature of F such as its\\nmean.\\n6.2 Parametric and Nonparametric Models\\nA statistical model F is a set of distributions (or densities or regression\\nfunctions). A parametric model is a set F that can be parameterized by a\\nﬁnite number of parameters. For example, if we assume that the data come\\nfrom a Normal distribution, then the model is\\nF =\\n{\\nf(x;µ, σ)= 1\\nσ\\n√\\n2π exp\\n{\\n− 1\\n2σ2 (x − µ)2\\n}\\n,µ ∈ R,σ > 0\\n}\\n. (6.1)\\nThis is a two-parameter model. We have written the density as f(x;µ, σ)t o\\nshow thatx is a value of the random variable whereasµ and σ are parameters.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 103, 'page_label': '104'}, page_content='88 6. Models, Statistical Inference and Learning\\nIn general, a parametric model takes the form\\nF =\\n{\\nf(x; θ): θ ∈ Θ\\n}\\n(6.2)\\nwhere θ is an unknown parameter (or vector of parameters) that can take\\nvalues in theparameter spaceΘ. Ifθ is a vector but we are only interested in\\none component ofθ, we call the remaining parametersnuisance parameters.\\nA nonparametric model is a set F that cannot be parameterized by a ﬁnite\\nnumber of parameters. For example, FALL = {all cdf′s} is nonparametric. 1\\n6.1 Example (One-dimensional Parametric Estimation). Let X1, ... , Xn be in-\\ndependent Bernoulli(p) observations. The problem is to estimate the param-\\neter p. ■\\n6.2 Example (Two-dimensional Parametric Estimation). Suppose that X1, ... ,\\nXn ∼ F and we assume that the pdf f ∈ F where F is given in (6.1). In\\nthis case there are two parameters, µ and σ. The goal is to estimate the\\nparameters from the data. If we are only interested in estimatingµ, then µ is\\nthe parameter of interest and σ is a nuisance parameter. ■\\n6.3 Example (Nonparametric estimation of the cdf). Let X1, ... , Xn be inde-\\npendent observations from a cdf F. The problem is to estimate F assuming\\nonly that F ∈ FALL = {all cdf′s}. ■\\n6.4 Example (Nonparametric density estimation). Let X1,...,X n be indepen-\\ndent observations from acdf F and let f = F′ be the pdf. Suppose we want\\nto estimate the pdf f. It is not possible to estimate f assuming only that\\nF ∈ FALL. We need to assume some smoothness on f. For example, we might\\nassume that f ∈ F = FDENS\\n⋂ FSOB where FDENS is the set of all probability\\ndensity functions and\\nFSOB =\\n{\\nf :\\n∫\\n(f′′(x))2dx < ∞\\n}\\n.\\nThe class FSOB is called a Sobolev space; it is the set of functions that are\\nnot “too wiggly.” ■\\n6.5 Example (Nonparametric estimation of functionals). Let X1, ... , Xn ∼ F.\\nSuppose we want to estimate µ = E(X1)=\\n∫\\nxd F(x) assuming only that\\n1The distinction between parametric and nonparametric is more subtle than this but we don’t\\nneed a rigorous deﬁnition for our purposes.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 104, 'page_label': '105'}, page_content='6.2 Parametric and Nonparametric Models 89\\nµ exists. The mean µ may be thought of as a function of F: we can write\\nµ = T(F)=\\n∫\\nxd F(x). In general, any function of F is called a statis-\\ntical functional. Other examples of functionals are the variance T(F)=∫\\nx2dF(x) −\\n\\uf8f6∫\\nxdF(x)\\n\\uf8f72\\nand the median T(F)= F−1(1/2). ■\\n6.6 Example (Regression, prediction, and classiﬁcation). Suppose we observe pairs\\nof data (X1,Y1),... (Xn,Yn). Perhaps Xi is the blood pressure of subject i\\nand Yi is how long they live. X is called a predictor or regressor or fea-\\nture or independent variable. Y is called the outcome or the response\\nvariable or the dependent variable. We call r(x)= E(Y |X = x) the re-\\ngression function. If we assume that r ∈ F where F is ﬁnite dimensional —\\nthe set of straight lines for example — then we have a parametric regres-\\nsion model. If we assume that r ∈ F where F is not ﬁnite dimensional then\\nwe have a nonparametric regression model. The goal of predicting Y for\\na new patient based on their X value is called prediction.I f Y is discrete\\n(for example, live or die) then prediction is instead called classiﬁcation. If\\nour goal is to estimate the function r, then we call this regression or curve\\nestimation. Regression models are sometimes written as\\nY = r(X)+ ϵ (6.3)\\nwhere E(ϵ) = 0. We can always rewrite a regression model this way. To see\\nthis, deﬁne ϵ = Y − r(X) and hence Y = Y + r(X) − r(X)= r(X)+ ϵ.\\nMoreover, E(ϵ)= EE(ϵ|X)= E(E(Y − r(X))|X)= E(E(Y |X) − r(X)) =\\nE(r(X) − r(X) )=0 . ■\\nWhat’s Next?It is traditional in most introductory courses to start with\\nparametric inference. Instead, we will start with nonparametric inference and\\nthen we will cover parametric inference. In some respects, nonparametric in-\\nference is easier to understand and is more useful than parametric inference.\\nFrequentists and Bayesians.There are many approaches to statistical\\ninference. The two dominant approaches are called frequentist inference\\nand Bayesian inference. We’ll cover both but we will start with frequentist\\ninference. We’ll postpone a discussion of the pros and cons of these two until\\nlater.\\nSome Notation.If F = {f(x; θ): θ ∈ Θ} is a parametric model, we write\\nP\\nθ(X ∈ A)=\\n∫\\nA f(x; θ)dx and Eθ(r(X)) =\\n∫\\nr(x)f(x; θ)dx. The subscript θ\\nindicates that the probability or expectation is with respect tof(x; θ); it does\\nnot mean we are averaging over θ. Similarly, we write Vθ for the variance.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 105, 'page_label': '106'}, page_content='90 6. Models, Statistical Inference and Learning\\n6.3 Fundamental Concepts in Inference\\nMany inferential problems can be identiﬁed as being one of three types: es-\\ntimation, conﬁdence sets, or hypothesis testing. We will treat all of these\\nproblems in detail in the rest of the book. Here, we give a brief introduction\\nto the ideas.\\n6.3.1 Point Estimation\\nPoint estimation refers to providing a single “best guess” of some quantity\\nof interest. The quantity of interest could be a parameter in a parametric\\nmodel, a cdf F, a probability density function f, a regression function r,o r\\na prediction for a future value Y of some random variable.\\nBy convention, we denote a point estimate ofθ by ˆθ or ˆθ\\nn. Remember\\nthat θ is a ﬁxed, unknown quantity. The estimate ˆθ depends on the\\ndata so ˆθ is a random variable.\\nMore formally, let X1,...,X n be n iid data points from some distribution\\nF. A point estimator ˆθn of a parameter θ is some function of X1,...,X n:\\nˆθn = g(X1,...,X n).\\nThe bias of an estimator is deﬁned by\\nbias(ˆθn)= Eθ(ˆθn) − θ. (6.4)\\nWe say that ˆθn is unbiased if E(ˆθn)= θ. Unbiasedness used to receive much\\nattention but these days is considered less important; many of the estimators\\nwe will use are biased. A reasonable requirement for an estimator is that it\\nshould converge to the true parameter value as we collect more and more\\ndata. This requirement is quantiﬁed by the following deﬁnition:\\n6.7 Deﬁnition. A point estimator ˆθn of a parameter θ is consistent if\\nˆθn\\nP\\n−→θ.\\nThe distribution of ˆθn is called the sampling distribution. The standard\\ndeviation of ˆθn is called the standard error, denoted by se:\\nse = se(ˆθn)=\\n√\\nV(ˆθn). (6.5)\\nOften, the standard error depends on the unknown F. In those cases, se is\\nan unknown quantity but we usually can estimate it. The estimated standard\\nerror is denoted by ˆse.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 106, 'page_label': '107'}, page_content='6.3 Fundamental Concepts in Inference 91\\n6.8 Example. Let X1,...,X n ∼ Bernoulli(p) and let ˆpn = n−1 ∑\\ni Xi. Then\\nE(ˆpn)= n−1 ∑\\ni E(Xi)= p so ˆpn is unbiased. The standard error is se =√\\nV(ˆpn)=\\n√\\np(1 − p)/n. The estimated standard error is ˆse =\\n√\\nˆp(1 − ˆp)/n.\\n■\\nThe quality of a point estimate is sometimes assessed by themean squared\\nerror,o r mse deﬁned by\\nmse = Eθ(ˆθn − θ)2. (6.6)\\nKeep in mind that Eθ(·) refers to expectation with respect to the distribution\\nf(x1,...,x n; θ)=\\nn∏\\ni=1\\nf(xi; θ)\\nthat generated the data. It does not mean we are averaging over a distribution\\nfor θ.\\n6.9 Theorem. The mse can be written as\\nmse = bias2(ˆθn)+ Vθ(ˆθn). (6.7)\\nProof. Let θn = Eθ(ˆθn). Then\\nEθ(ˆθn − θ)2 = Eθ(ˆθn − θn + θn − θ)2\\n= Eθ(ˆθn − θn)2 +2 (θn − θ)Eθ(ˆθn − θn)+ Eθ(θn − θ)2\\n=( θn − θ)2 + Eθ(ˆθn − θn)2\\n= bias2(ˆθn)+ V(ˆθn)\\nwhere we have used the fact that Eθ(ˆθn − θn)= θn − θn =0 . ■\\n6.10 Theorem. If bias → 0 and se → 0 as n →∞ then ˆθn is consistent, that\\nis, ˆθn\\nP\\n−→θ.\\nProof. If bias → 0 and se → 0 then, by Theorem 6.9, MSE → 0. It\\nfollows that ˆθn\\nqm\\n−→θ. (Recall Deﬁnition 5.2.) The result follows from part (b)\\nof Theorem 5.4. ■\\n6.11 Example. Returning to the coin ﬂipping example, we have thatEp(ˆpn)=\\np so the bias = p − p = 0 and se =\\n√\\np(1 − p)/n → 0. Hence, ˆpn\\nP\\n−→p, that is,\\nˆpn is a consistent estimator. ■\\nMany of the estimators we will encounter will turn out to have, approxi-\\nmately, a Normal distribution.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 107, 'page_label': '108'}, page_content='92 6. Models, Statistical Inference and Learning\\n6.12 Deﬁnition. An estimator is asymptotically Normal if\\nˆθn − θ\\nse ⇝ N(0,1). (6.8)\\n6.3.2 Conﬁdence Sets\\nA1 − α conﬁdence interval for a parameter θ is an interval Cn =( a, b)\\nwhere a = a(X1,...,X n) and b = b(X1,...,X n) are functions of the data\\nsuch that\\nPθ(θ ∈ Cn) ≥ 1 − α, for all θ ∈ Θ. (6.9)\\nIn words, (a, b) traps θ with probability 1− α. We call 1− α the coverage of\\nthe conﬁdence interval.\\nWarning! Cn is random and θ is ﬁxed.\\nCommonly, people use 95 percent conﬁdence intervals, which corresponds\\nto choosing α =0 .05. If θ is a vector then we use a conﬁdence set (such as\\na sphere or an ellipse) instead of an interval.\\nWarning! There is much confusion about how to interpret a conﬁdence\\ninterval. A conﬁdence interval is not a probability statement about θ since\\nθ is a ﬁxed quantity, not a random variable. Some texts interpret conﬁdence\\nintervals as follows: if I repeat the experiment over and over, the interval will\\ncontain the parameter 95 percent of the time. This is correct but useless since\\nwe rarely repeat the same experiment over and over. A better interpretation\\nis this:\\nOn day 1, you collect data and construct a 95 percent conﬁdence\\ninterval for a parameter θ\\n1. On day 2, you collect new data and con-\\nstruct a 95 percent conﬁdence interval for an unrelated parameterθ2.\\nOn day 3, you collect new data and construct a 95 percent conﬁ-\\ndence interval for an unrelated parameter θ\\n3. You continue this way\\nconstructing conﬁdence intervals for a sequence of unrelated param-\\neters θ\\n1,θ 2,... Then 95 percent of your intervals will trap the true\\nparameter value. There is no need to introduce the idea of repeating\\nthe same experiment over and over.\\n6.13 Example. Every day, newspapers report opinion polls. For example, they\\nmight say that “83 percent of the population favor arming pilots with guns.”\\nUsually, you will see a statement like “this poll is accurate to within 4 points'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 108, 'page_label': '109'}, page_content='6.3 Fundamental Concepts in Inference 93\\n95 percent of the time.” They are saying that 83±4 is a 95 percent conﬁdence\\ninterval for the true but unknown proportion p of people who favor arming\\npilots with guns. If you form a conﬁdence interval this way every day for the\\nrest of your life, 95 percent of your intervals will contain the true parameter.\\nThis is true even though you are estimating a diﬀerent quantity (a diﬀerent\\npoll question) every day.\\n■\\n6.14 Example. The fact that a conﬁdence interval is not a probability state-\\nment about θ is confusing. Consider this example from Berger and Wolpert\\n(1984). Let θ be a ﬁxed, known real number and let X1,X 2 be independent\\nrandom variables such that P(Xi =1 )= P(Xi = −1 )=1 /2. Now deﬁne\\nYi = θ + Xi and suppose that you only observe Y1 and Y2. Deﬁne the follow-\\ning “conﬁdence interval” which actually only contains one point:\\nC =\\n{\\n{Y1 − 1} if Y1 = Y2\\n{(Y1 + Y2)/2} if Y1 ̸= Y2.\\nYou can check that, no matter what θ is, we have Pθ(θ ∈ C)=3 /4 so this\\nis a 75 percent conﬁdence interval. Suppose we now do the experiment and\\nwe get Y\\n1 = 15 and Y2 = 17. Then our 75 percent conﬁdence interval is{16}.\\nHowever, we are certain that θ = 16. If you wanted to make a probability\\nstatement about θ you would probably say thatP(θ ∈ C|Y1,Y2) = 1. There is\\nnothing wrong with saying that {16} is a 75 percent conﬁdence interval. But\\nis it not a probability statement about θ. ■\\nIn Chapter 11 we will discuss Bayesian methods in which we treatθ as if it\\nwere a random variable and we do make probability statements about θ.I n\\nparticular, we will make statements like “the probability thatθ is in Cn, given\\nthe data, is 95 percent.” However, these Bayesian intervals refer to degree-\\nof-belief probabilities. These Bayesian intervals will not, in general, trap the\\nparameter 95 percent of the time.\\n6.15 Example. In the coin ﬂipping setting, letC\\nn =( ˆpn −ϵn, ˆpn +ϵn) where\\nϵ2\\nn = log(2/α)/(2n). From Hoeﬀding’s inequality (4.4) it follows that\\nP(p ∈ Cn) ≥ 1 − α\\nfor every p. Hence, Cn i sa1 − α conﬁdence interval. ■\\nAs mentioned earlier, point estimators often have a limiting Normal dis-\\ntribution, meaning that equation (6.8) holds, that is, ˆθn ≈ N(θ, ˆse2). In this\\ncase we can construct (approximate) conﬁdence intervals as follows.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 109, 'page_label': '110'}, page_content='94 6. Models, Statistical Inference and Learning\\n6.16 Theorem (Normal-based Conﬁdence Interval). Suppose thatˆθn ≈ N(θ, ˆse2).\\nLet Φ be the cdf of a standard Normal and let zα/2 =Φ −1(1 − (α/2)), that\\nis, P(Z>z α/2)= α/2 and P(−zα/2 <Z<z α/2)=1 − α where Z ∼ N(0,1).\\nLet\\nCn =( ˆθn − zα/2 ˆse, ˆθn + zα/2 ˆse). (6.10)\\nThen\\nPθ(θ ∈ Cn) → 1 − α. (6.11)\\nProof. Let Zn =( ˆθn − θ)/ˆse. By assumption Zn ⇝ Z where Z ∼ N(0,1).\\nHence,\\nPθ(θ ∈ Cn)= Pθ\\n\\uf8f6\\nˆθn − zα/2 ˆse <θ< ˆθn + zα/2 ˆse\\n\\uf8f7\\n= Pθ\\n\\uf8f6\\n−zα/2 <\\nˆθn − θ\\nˆse <z α/2\\n\\uf8f7\\n→ P\\n\\uf8f6\\n−zα/2 <Z<z α/2\\n\\uf8f7\\n=1 − α. ■\\nFor 95 percent conﬁdence intervals, α =0 .05 and zα/2 =1 .96 ≈ 2 leading\\nto the approximate 95 percent conﬁdence interval ˆθn ± 2 ˆse.\\n6.17 Example. Let X1,...,X n ∼ Bernoulli(p) and let ˆpn = n−1 ∑ n\\ni=1 Xi.\\nThen V(ˆpn)= n−2 ∑ n\\ni=1 V(Xi)= n−2 ∑ n\\ni=1 p(1 − p)= n−2np(1 − p)= p(1 −\\np)/n. Hence, se =\\n√\\np(1 − p)/n and ˆse =\\n√\\nˆpn(1 − ˆpn)/n. By the Central\\nLimit Theorem, ˆpn ≈ N(p, ˆse2). Therefore, an approximate 1 − α conﬁdence\\ninterval is\\nˆpn ± zα/2 ˆse = ˆpn ± zα/2\\n√\\nˆpn(1 − ˆpn)\\nn .\\nCompare this with the conﬁdence interval in example 6.15. The Normal-based\\ninterval is shorter but it only has approximately (large sample) correct cover-\\nage.\\n■\\n6.3.3 Hypothesis Testing\\nIn hypothesis testing, we start with some default theory — called a null\\nhypothesis — and we ask if the data provide suﬃcient evidence to reject the\\ntheory. If not we retain the null hypothesis. 2\\n2The term “retaining the null hypothesis” is due to Chris Genovese. Other terminology is\\n“accepting the null” or “failing to reject the null.”'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 110, 'page_label': '111'}, page_content='6.4 Bibliographic Remarks 95\\n6.18 Example (Testing if a Coin is Fair). Let\\nX1,...,X n ∼ Bernoulli(p)\\nbe n independent coin ﬂips. Suppose we want to test if the coin is fair. LetH0\\ndenote the hypothesis that the coin is fair and let H1 denote the hypothesis\\nthat the coin is not fair. H0 is called the null hypothesis and H1 is called\\nthe alternative hypothesis. We can write the hypotheses as\\nH0 : p =1 /2 versus H1 : p ̸=1 /2.\\nIt seems reasonable to reject H0 if T = |ˆpn − (1/2)| is large. When we discuss\\nhypothesis testing in detail, we will be more precise about how largeT should\\nbe to reject H0. ■\\n6.4 Bibliographic Remarks\\nStatistical inference is covered in many texts. Elementary texts include DeG-\\nroot and Schervish (2002) and Larsen and Marx (1986). At the intermediate\\nlevel I recommend Casella and Berger (2002), Bickel and Doksum (2000), and\\nRice (1995). At the advanced level, Cox and Hinkley (2000), Lehmann and\\nCasella (1998), Lehmann (1986), and van der Vaart (1998).\\n6.5 Appendix\\nOur deﬁnition of conﬁdence interval requires that Pθ(θ ∈ Cn) ≥ 1 − α\\nfor all θ ∈ Θ. A pointwise asymptotic conﬁdence interval requires that\\nlim infn→∞ Pθ(θ ∈ Cn) ≥ 1 − α for all θ ∈ Θ. A uniform asymptotic con-\\nﬁdence interval requires that lim inf n→∞ infθ∈Θ Pθ(θ ∈ Cn) ≥ 1 − α. The\\napproximate Normal-based interval is a pointwise asymptotic conﬁdence in-\\nterval.\\n6.6 Exercises\\n1. Let X1,...,X n ∼ Poisson(λ) and let ˆλ = n−1 ∑ n\\ni=1 Xi. Find the bias,\\nse, and mse of this estimator.\\n2. Let X1,...,X n ∼ Uniform(0,θ ) and let ˆθ = max{X1,...,X n}. Find the\\nbias, se, and mse of this estimator.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 111, 'page_label': '112'}, page_content='96 6. Models, Statistical Inference and Learning\\n3. Let X1,...,X n ∼ Uniform(0,θ ) and let ˆθ =2 Xn. Find the bias, se, and\\nmse of this estimator.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 112, 'page_label': '113'}, page_content='7\\nEstimating the cdf and Statistical\\nFunctionals\\nThe ﬁrst inference problem we will consider is nonparametric estimation of the\\ncdf F. Then we will estimate statistical functionals, which are functions of\\ncdf, such as the mean, the variance, and the correlation. The nonparametric\\nmethod for estimating functionals is called the plug-in method.\\n7.1 The Empirical Distribution Function\\nLet X1,...,X n ∼ F be an iid sample where F is a distribution function on\\nthe real line. We will estimate F with the empirical distribution function,\\nwhich is deﬁned as follows.\\n7.1 Deﬁnition. The empirical distribution function ˆFn is the cdf\\nthat puts mass 1/n at each data point Xi. Formally,\\nˆFn(x)=\\n∑ n\\ni=1 I(Xi ≤ x)\\nn (7.1)\\nwhere\\nI(Xi ≤ x)=\\n{ 1i f Xi ≤ x\\n0i f Xi >x .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 113, 'page_label': '114'}, page_content='98 7. Estimating the cdf and Statistical Functionals\\n0.0 0.5 1.0 1.50.0 0.5 1.0\\nFIGURE 7.1. Nerve data. Each vertical line represents one data point. The solid\\nline is the empirical distribution function. The lines above and below the middle\\nline are a 95 percent conﬁdence band.\\n7.2 Example (Nerve Data). Cox and Lewis (1966) reported 799 waiting times\\nbetween successive pulses along a nerve ﬁber. Figure 7.1 shows the empirical\\ncdf ˆF\\nn. The data points are shown as small vertical lines at the bottom of\\nthe plot. Suppose we want to estimate the fraction of waiting times between\\n.4 and .6 seconds. The estimate is ˆF\\nn(.6) − ˆFn(.4) = .93 − .84 = .09. ■\\n7.3 Theorem. At any ﬁxed value of x,\\nE\\n\\uf8f6\\nˆFn(x)\\n\\uf8f7\\n= F(x),\\nV\\n\\uf8f6\\nˆFn(x)\\n\\uf8f7\\n= F(x)(1 − F(x))\\nn ,\\nmse = F(x)(1 − F(x))\\nn → 0,\\nˆFn(x)\\nP\\n−→ F(x).\\n7.4 Theorem (The Glivenko-Cantelli Theorem). Let X1,...,X n ∼ F. Then 1\\nsup\\nx\\n| ˆFn(x) − F(x)|\\nP\\n−→0.\\nNow we give an inequality that will be used to construct a conﬁdence band.\\n1More precisely, supx | ˆFn(x) − F(x)| converges to 0 almost surely.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 114, 'page_label': '115'}, page_content='7.2 Statistical Functionals 99\\n7.5 Theorem (The Dvoretzky-Kiefer-Wolfowitz (DKW) Inequality). Let X1, ... ,\\nXn ∼ F. Then, for any ϵ> 0,\\nP\\n\\uf8f6\\nsup\\nx\\n|F(x) − ˆFn(x)| >ϵ\\n\\uf8f7\\n≤ 2e−2nϵ2\\n. (7.2)\\nFrom the DKW inequality, we can construct a conﬁdence set as follows:\\nA Nonparametric 1 − α Conﬁdence Band for F\\nDeﬁne,\\nL(x) = max { ˆFn(x) − ϵn, 0}\\nU(x) = min { ˆFn(x)+ ϵn, 1}\\nwhere ϵn =\\n√\\n1\\n2n log\\n\\uf8f62\\nα\\n\\uf8f7\\n.\\nIt follows from (7.2) that for any F,\\nP\\n\\uf8f6\\nL(x) ≤ F(x) ≤ U(x) for all x\\n\\uf8f7\\n≥ 1 − α. (7.3)\\n7.6 Example. The dashed lines in Figure 7.1 give a 95 percent conﬁdence\\nband using ϵn =\\n√\\n1\\n2n log\\n\\uf8f62\\n.05\\n\\uf8f7\\n= .048. ■\\n7.2 Statistical Functionals\\nA statistical functional T(F) is any function of F. Examples are the mean\\nµ =\\n∫\\nxd F(x), the variance σ2 =\\n∫\\n(x − µ)2 dF(x) and the median m =\\nF−1(1/2).\\n7.7 Deﬁnition. The plug-in estimator of θ = T(F) is deﬁned by\\nˆθn = T( ˆFn).\\nIn other words, just plug in ˆFn for the unknown F.\\n7.8 Deﬁnition. If T(F)=\\n∫\\nr(x)dF(x) for some function r(x) then T is\\ncalled a linear functional.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 115, 'page_label': '116'}, page_content='100 7. Estimating the cdf and Statistical Functionals\\nThe reason T(F)=\\n∫\\nr(x)dF(x) is called a linear functional is because T\\nsatisﬁes\\nT(aF + bG)= aT(F)+ bT(G),\\nhence T is linear in its arguments. Recall that\\n∫\\nr(x)dF(x) is deﬁned to be∫\\nr(x)f(x)dx in the continuous case and ∑\\nj r(xj)f(xj) in the discrete. The\\nempirical cdf ˆFn(x) is discrete, putting mass 1/n at eachXi. Hence, ifT(F)=∫\\nr(x)dF(x) is a linear functional then we have:\\n7.9 Theorem. The plug-in estimator for linear functional\\nT(F)=\\n∫\\nr(x)dF(x) is:\\nT( ˆFn)=\\n∫\\nr(x)d ˆFn(x)= 1\\nn\\nn∑\\ni=1\\nr(Xi). (7.4)\\nSometimes we can ﬁnd the estimated standard error se of T( ˆFn) by doing\\nsome calculations. However, in other cases it is not obvious how to estimate\\nthe standard error. In the next chapter, we will discuss a general method for\\nﬁnding ˆse. For now, let us just assume that somehow we can ﬁnd ˆse.\\nIn many cases, it turns out that\\nT( ˆF\\nn) ≈ N(T(F), ˆse2). (7.5)\\nBy equation (6.11), an approximate 1−α conﬁdence interval forT(F) is then\\nT( ˆFn) ± zα/2 ˆse. (7.6)\\nWe will call this theNormal-based interval.For a 95 percent conﬁdence\\ninterval, zα/2 = z.05/2 =1 .96 ≈ 2 so the interval is\\nT( ˆFn) ± 2 ˆse.\\n7.10 Example (The mean). Let µ = T(F)=\\n∫\\nxd F(x). The plug-in estima-\\ntor is ˆµ =\\n∫\\nxd ˆFn(x)= Xn. The standard error is se =\\n√\\nV(Xn)= σ/√n.I f\\nˆσ denotes an estimate of σ, then the estimated standard error is ˆσ/√n. (In\\nthe next example, we shall see how to estimateσ.) A Normal-based conﬁdence\\ninterval for µ is Xn ± zα/2 ˆse. ■\\n7.11 Example (The Variance). Let σ2 = T(F)= V(X)=\\n∫\\nx2dF(x)−\\n\\uf8f6∫\\nxdF(x)\\n\\uf8f72\\n.\\nThe plug-in estimator is\\nˆσ2 =\\n∫\\nx2d ˆFn(x) −\\n\\uf8f6∫\\nxd ˆFn(x)\\n\\uf8f72'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 116, 'page_label': '117'}, page_content='7.2 Statistical Functionals 101\\n= 1\\nn\\nn∑\\ni=1\\nX2\\ni −\\n\\uf8f6\\n1\\nn\\nn∑\\ni=1\\nXi\\n\\uf8f72\\n= 1\\nn\\nn∑\\ni=1\\n(Xi − Xn)2.\\nAnother reasonable estimator of σ2 is the sample variance\\nS2\\nn = 1\\nn − 1\\nn∑\\ni=1\\n(Xi − Xn)2.\\nIn practice, there is little diﬀerence betweenˆσ2 and S2\\nn and you can use either\\none. Returning to the last example, we now see that the estimated standard\\nerror of the estimate of the mean is ˆse = ˆσ/√\\nn. ■\\n7.12 Example (The Skewness). Let µ and σ2 denote the mean and variance\\nof a random variable X. The skewness is deﬁned to be\\nκ = E(X − µ)3\\nσ3 =\\n∫\\n(x − µ)3dF(x)\\n{∫\\n(x − µ)2dF(x)\\n}3/2 .\\nThe skewness measures the lack of symmetry of a distribution. To ﬁnd the\\nplug-in estimate, ﬁrst recall that ˆµ = n−1 ∑\\ni Xi and ˆσ2 = n−1 ∑\\ni(Xi − ˆµ)2.\\nThe plug-in estimate of κ is\\nˆκ =\\n∫\\n(x − µ)3d ˆFn(x)\\n{∫\\n(x − µ)2d ˆFn(x)\\n}3/2 =\\n1\\nn\\n∑\\ni(Xi − ˆµ)3\\nˆσ3 . ■\\n7.13 Example (Correlation). Let Z =( X,Y ) and let ρ = T(F)= E(X −\\nµX)(Y −µY )/(σxσy) denote the correlation betweenX and Y , where F(x, y)\\nis bivariate. We can write\\nT(F)= a(T1(F),T 2(F),T 3(F),T 4(F),T 5(F))\\nwhere\\nT1(F)=\\n∫\\nxd F(z),T 2(F)=\\n∫\\nyd F(z),T 3(F)=\\n∫\\nxy dF(z),\\nT4(F)=\\n∫\\nx2 dF(z),T 5(F)=\\n∫\\ny2 dF(z),\\nand\\na(t1,...,t 5)= t3 − t1t2√\\n(t4 − t2\\n1)(t5 − t2\\n2)\\n.\\nReplace F with ˆFn in T1(F) , ..., T5(F), and take\\nˆρ = a(T1( ˆFn),T 2( ˆFn),T 3( ˆFn),T 4( ˆFn),T 5( ˆFn)).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 117, 'page_label': '118'}, page_content='102 7. Estimating the cdf and Statistical Functionals\\nWe get\\nˆρ =\\n∑\\ni(Xi − Xn)(Yi − Y n)√ ∑\\ni(Xi − Xn)2\\n√ ∑\\ni(Yi − Y n)2\\nwhich is called the sample correlation. ■\\n7.14 Example (Quantiles). Let F be strictly increasing with density f.F o r\\n0 <p< 1, the pth quantile is deﬁned by T(F)= F−1(p). The estimate if\\nT(F)i s ˆF−1\\nn (p). We have to be a bit careful since ˆFn is not invertible. To\\navoid ambiguity we deﬁne\\nˆF−1\\nn (p) = inf{x : ˆFn(x) ≥ p}.\\nWe call T( ˆFn)= ˆF−1\\nn (p) the pth sample quantile. ■\\nOnly in the ﬁrst example did we compute a standard error or a conﬁdence\\ninterval. How shall we handle the other examples? When we discuss parametric\\nmethods, we will develop formulas for standard errors and conﬁdence intervals.\\nBut in our nonparametric setting we need something else. In the next chapter,\\nwe will introduce the bootstrap for getting standard errors and conﬁdence\\nintervals.\\n7.15 Example (Plasma Cholesterol). Figure 7.2 shows histograms for plasma\\ncholesterol (in mg/dl) for 371 patients with chest pain (Scott et al. (1978)).\\nThe histograms show the percentage of patients in 10 bins. The ﬁrst histogram\\nis for 51 patients who had no evidence of heart disease while the second\\nhistogram is for 320 patients who had narrowing of the arteries. Is the mean\\ncholesterol diﬀerent in the two groups? Let us regard these data as samples\\nfrom two distributions F\\n1 and F2. Let µ1 =\\n∫\\nxdF1(x) and µ2 =\\n∫\\nxdF2(x)\\ndenote the means of the two populations. The plug-in estimates are ˆµ1 =∫\\nxd ˆFn,1(x)= Xn,1 = 195.27 and ˆµ2 =\\n∫\\nxd ˆFn,2(x)= Xn,2 = 216.19. Recall\\nthat the standard error of the sample mean ˆµ = 1\\nn\\n∑ n\\ni=1 Xi is\\nse(ˆµ)=\\n\\ued6a\\ued6b\\ued6b\\n√\\nV\\n\\uf8f6\\n1\\nn\\nn∑\\ni=1\\nXi\\n\\uf8f7\\n=\\n\\ued6a\\ued6b\\ued6b\\n√\\n1\\nn2\\nn∑\\ni=1\\nV(Xi)=\\n√\\nnσ2\\nn2 = σ√n\\nwhich we estimate by\\nˆse(ˆµ)= ˆσ√n\\nwhere\\nˆσ =\\n\\ued6a\\ued6b\\ued6b\\n√\\n1\\nn\\nn∑\\ni=1\\n(Xi − X)2.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 118, 'page_label': '119'}, page_content='7.2 Statistical Functionals 103\\nFor the two groups this yieldsˆse(ˆµ1)=5 .0 and ˆse(ˆµ2)=2 .4. Approximate 95\\npercent conﬁdence intervals for µ1 and µ2 are ˆµ1 ± 2ˆse(ˆµ1) = (185,205) and\\nˆµ2 ± 2ˆse(ˆµ2) = (211,221).\\nNow, consider the functional θ = T(F2) − T(F1) whose plug-in estimate is\\nˆθ = ˆµ2 − ˆµ1 = 216.19 − 195.2 7=2 0.92. The standard error of ˆθ is\\nse =\\n√\\nV(ˆµ2 − ˆµ1)=\\n√\\nV(ˆµ2)+ V(ˆµ1)=\\n√\\n(se(ˆµ1))2 +( se(ˆµ2))2\\nand we estimate this by\\nˆse =\\n√\\n(ˆse(ˆµ1))2 +( ˆse(ˆµ2))2 =5 .55.\\nAn approximate 95 percent conﬁdence interval forθ is ˆθ±2 ˆse(ˆθn)=( 9 .8,32.0).\\nThis suggests that cholesterol is higher among those with narrowed arteries.\\nWe should not jump to the conclusion (from these data) that cholesterol causes\\nheart disease. The leap from statistical evidence to causation is very subtle\\nand is discussed in Chapter 16.\\n■\\nplasma cholesterol for patients without heart disease\\n100 150 200 250 300 350 400\\nplasma cholesterol for patients with heart disease\\n100 150 200 250 300 350 400\\nFIGURE 7.2. Plasma cholesterol for 51 patients with no heart disease and 320\\npatients with narrowing of the arteries.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 119, 'page_label': '120'}, page_content='104 7. Estimating the cdf and Statistical Functionals\\n7.3 Bibliographic Remarks\\nThe Glivenko-Cantelli theorem is the tip of the iceberg. The theory of dis-\\ntribution functions is a special case of what are called empirical processes\\nwhich underlie much of modern statistical theory. Some references on empiri-\\ncal processes are Shorack and Wellner (1986) and van der Vaart and Wellner\\n(1996).\\n7.4 Exercises\\n1. Prove Theorem 7.3.\\n2. Let X1,...,X n ∼ Bernoulli(p) and let Y1,...,Y m ∼ Bernoulli(q). Find\\nthe plug-in estimator and estimated standard error for p. Find an ap-\\nproximate 90 percent conﬁdence interval for p. Find the plug-in esti-\\nmator and estimated standard error for p − q. Find an approximate 90\\npercent conﬁdence interval for p − q.\\n3. ( Computer Experiment.) Generate 100 observations from a N(0,1) dis-\\ntribution. Compute a 95 percent conﬁdence band for the cdf F (as\\ndescribed in the appendix). Repeat this 1000 times and see how often\\nthe conﬁdence band contains the true distribution function. Repeat us-\\ning data from a Cauchy distribution.\\n4. Let X\\n1,...,X n ∼ F and let ˆFn(x) be the empirical distribution func-\\ntion. For a ﬁxed x, use the central limit theorem to ﬁnd the limiting\\ndistribution of ˆFn(x).\\n5. Let x and y be two distinct points. Find Cov(ˆFn(x), ˆFn(y)).\\n6. Let X1,...,X n ∼ F and let ˆF be the empirical distribution function.\\nLet a<b be ﬁxed numbers and deﬁne θ = T(F)= F(b) − F(a). Let\\nˆθ = T( ˆFn)= ˆFn(b) − ˆFn(a). Find the estimated standard error of ˆθ.\\nFind an expression for an approximate 1 − α conﬁdence interval for θ.\\n7. Data on the magnitudes of earthquakes near Fiji are available on the\\nwebsite for this book. Estimate the cdf F(x). Compute and plot a 95\\npercent conﬁdence envelope for F (as described in the appendix). Find\\nan approximate 95 percent conﬁdence interval for F(4.9) − F(4.3).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 120, 'page_label': '121'}, page_content='7.4 Exercises 105\\n8. Get the data on eruption times and waiting times between eruptions of\\nthe Old Faithful geyser from the website. Estimate the mean waiting\\ntime and give a standard error for the estimate. Also, give a 90 percent\\nconﬁdence interval for the mean waiting time. Now estimate the median\\nwaiting time. In the next chapter we will see how to get the standard\\nerror for the median.\\n9. 100 people are given a standard antibiotic to treat an infection and\\nanother 100 are given a new antibiotic. In the ﬁrst group, 90 people\\nrecover; in the second group, 85 people recover. Letp\\n1 be the probability\\nof recovery under the standard treatment and letp2 be the probability of\\nrecovery under the new treatment. We are interested in estimatingθ =\\np1 − p2. Provide an estimate, standard error, an 80 percent conﬁdence\\ninterval, and a 95 percent conﬁdence interval forθ.\\n10. In 1975, an experiment was conducted to see if cloud seeding produced\\nrainfall. 26 clouds were seeded with silver nitrate and 26 were not. The\\ndecision to seed or not was made at random. Get the data from\\nhttp://lib.stat.cmu.edu/DASL/Stories/CloudSeeding.html\\nLet θ be the diﬀerence in the mean precipitation from the two groups.\\nEstimate θ. Estimate the standard error of the estimate and produce a\\n95 percent conﬁdence interval.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 121, 'page_label': '122'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 122, 'page_label': '123'}, page_content='8\\nThe Bootstrap\\nThe bootstrap is a method for estimating standard errors and computing\\nconﬁdence intervals. LetTn = g(X1,...,X n)b ea statistic, that is, Tn is any\\nfunction of the data. Suppose we want to know VF (Tn), the variance of Tn.\\nWe have written VF to emphasize that the variance usually depends on the\\nunknown distribution function F. For example, if Tn = Xn then VF (Tn)=\\nσ2/n where σ2 =\\n∫\\n(x−µ)2dF(x) and µ =\\n∫\\nxdF(x). Thus the variance ofTn\\nis a function of F. The bootstrap idea has two steps:\\nStep 1: Estimate VF (Tn) with VˆFn\\n(Tn).\\nStep 2: Approximate VˆFn\\n(Tn) using simulation.\\nForTn = Xn, we have for Step 1 thatVˆFn\\n(Tn)= ˆσ2/n where ˆσ2 = n−1 ∑ n\\ni=1(Xi−\\nXn). In this case, Step 1 is enough. However, in more complicated cases we\\ncannot write down a simple formula for VˆFn\\n(Tn) which is why we need Step\\n2. Before proceeding, let us discuss the idea of simulation.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 123, 'page_label': '124'}, page_content='108 8. The Bootstrap\\n8.1 Simulation\\nSuppose we draw an iid sample Y1,...,Y B from a distribution G. By the law\\nof large numbers,\\nY n = 1\\nB\\nB∑\\nj=1\\nYj\\nP\\n−→\\n∫\\nyd G(y)= E(Y )\\nas B →∞ . So if we draw a large sample from G, we can use the sample\\nmean Y n to approximate E(Y ). In a simulation, we can make B as large as\\nwe like, in which case, the diﬀerence betweenY n and E(Y ) is negligible. More\\ngenerally, if h is any function with ﬁnite mean then\\n1\\nB\\nB∑\\nj=1\\nh(Yj)\\nP\\n−→\\n∫\\nh(y)dG(y)= E(h(Y ))\\nas B →∞ . In particular,\\n1\\nB\\nB∑\\nj=1\\n(Yj − Y )2 = 1\\nB\\nB∑\\nj=1\\nY 2\\nj −\\n\\uf8f6\\n1\\nB\\nB∑\\nj=1\\nYj\\n\\uf8f72\\nP\\n−→\\n∫\\ny2dF(y) −\\n\\uf8f6∫\\nydF (y)\\n\\uf8f72\\n= V(Y ).\\nHence, we can use the sample variance of the simulated values to approximate\\nV(Y ).\\n8.2 Bootstrap Variance Estimation\\nAccording to what we just learned, we can approximate VˆFn\\n(Tn) by simula-\\ntion. Now VˆFn\\n(Tn) means “the variance of Tn if the distribution of the data\\nis ˆFn.” How can we simulate from the distribution of Tn when the data are\\nassumed to have distribution ˆFn? The answer is to simulateX∗\\n1 ,...,X ∗\\nn from\\nˆFn and then compute T∗\\nn = g(X∗\\n1 ,...,X ∗\\nn). This constitutes one draw from\\nthe distribution of Tn. The idea is illustrated in the following diagram:\\nReal world F =⇒ X1,...,X n =⇒ Tn = g(X1,...,X n)\\nBootstrap world ˆFn =⇒ X∗\\n1 ,...,X ∗\\nn =⇒ T∗\\nn = g(X∗\\n1 ,...,X ∗\\nn)\\nHow do we simulateX∗\\n1 ,...,X ∗\\nn from ˆFn? Notice that ˆFn puts mass 1/n at\\neach data point X1,...,X n. Therefore,'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 124, 'page_label': '125'}, page_content='8.2 Bootstrap Variance Estimation 109\\ndrawing an observation from ˆFn is equivalent to drawing\\none point at random from the original data set.\\nThus, to simulate X∗\\n1 ,...,X ∗\\nn ∼ ˆFn it suﬃces to draw n observations with\\nreplacement from X1,...,X n. Here is a summary:\\nBootstrap Variance Estimation\\n1. Draw X∗\\n1 ,...,X ∗\\nn ∼ ˆFn.\\n2. Compute T∗\\nn = g(X∗\\n1 ,...,X ∗\\nn).\\n3. Repeat steps 1 and 2, B times, to get T∗\\nn,1,...,T ∗\\nn,B.\\n4. Let\\nvboot = 1\\nB\\nB∑\\nb=1\\n\\uf8f6\\nT∗\\nn,b − 1\\nB\\nB∑\\nr=1\\nT∗\\nn,r\\n\\uf8f72\\n. (8.1)\\n8.1 Example. The following pseudocode shows how to use the bootstrap to\\nestimate the standard error of the median.\\nBootstrap for The Median\\nGiven data X = (X(1), ..., X(n)):\\nT <- median(X)\\nTboot <- vector of length B\\nfor(i in 1:B){\\nXstar <- sample of size n from X (with replacement)\\nTboot[i] <- median(Xstar)\\n}\\nse <- sqrt(variance(Tboot))\\nThe following schematic diagram will remind you that we are using two\\napproximations:\\nV\\nF (Tn)\\nnot so small\\n\\ued17\\ued1a\\ued19\\ued18≈ VˆFn\\n(Tn)\\nsmall\\n\\ued17\\ued1a\\ued19\\ued18≈ vboot.\\n8.2 Example. Consider the nerve data. Letθ = T(F)=\\n∫\\n(x−µ)3dF(x)/σ3 be\\nthe skewness. The skewness is a measure of asymmetry. A Normal distribution,'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 125, 'page_label': '126'}, page_content='110 8. The Bootstrap\\nfor example, has skewness 0. The plug-in estimate of the skewness is\\nˆθ = T( ˆFn)=\\n∫\\n(x − µ)3d ˆFn(x)\\nˆσ3 =\\n1\\nn\\n∑ n\\ni=1(Xi − Xn)3\\nˆσ3 =1 .76.\\nTo estimate the standard error with the bootstrap we follow the same steps\\nas with the median example except we compute the skewness from each\\nbootstrap sample. When applied to the nerve data, the bootstrap, based on\\nB =1 ,000 replications, yields a standard error for the estimated skewness of\\n.16.\\n■\\n8.3 Bootstrap Conﬁdence Intervals\\nThere are several ways to construct bootstrap conﬁdence intervals. Here we\\ndiscuss three methods.\\nMethod 1: The Normal Interval.The simplest method is the Normal interval\\nT\\nn ± zα/2 ˆseboot (8.2)\\nwhere ˆseboot = √vboot is the bootstrap estimate of the standard error. This\\ninterval is not accurate unless the distribution of Tn is close to Normal.\\nMethod 2: Pivotal Intervals. Let θ = T(F) and ˆθn = T( ˆFn) and deﬁne the\\npivot Rn = ˆθn −θ. Let ˆθ∗\\nn,1,..., ˆθ∗\\nn,B denote bootstrap replications of ˆθn. Let\\nH(r) denote the cdf of the pivot:\\nH(r)= PF (Rn ≤ r). (8.3)\\nDeﬁne C⋆\\nn =( a, b) where\\na = ˆθn − H−1\\n\\uf8f6\\n1 − α\\n2\\n\\uf8f7\\nand b = ˆθn − H−1\\n\\uf8f6α\\n2\\n\\uf8f7\\n. (8.4)\\nIt follows that\\nP(a ≤ θ ≤ b)= P(a − ˆθn ≤ θ − ˆθn ≤ b − ˆθn)\\n= P(ˆθn − b ≤ ˆθn − θ ≤ ˆθn − a)\\n= P(ˆθn − b ≤ Rn ≤ ˆθn − a)\\n= H(ˆθn − a) − H(ˆθn − b)\\n= H\\n\\uf8f6\\nH−1\\n\\uf8f6\\n1 − α\\n2\\n\\uf8f7\\uf8f7\\n− H\\n\\uf8f6\\nH−1\\n\\uf8f6α\\n2\\n\\uf8f7\\uf8f7\\n=1 − α\\n2 − α\\n2 =1 − α.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 126, 'page_label': '127'}, page_content='8.3 Bootstrap Conﬁdence Intervals 111\\nHence, C⋆\\nn is an exact 1 − α conﬁdence interval for θ. Unfortunately, a and b\\ndepend on the unknown distributionH but we can form a bootstrap estimate\\nof H:\\nˆH(r)= 1\\nB\\nB∑\\nb=1\\nI(R∗\\nn,b ≤ r) (8.5)\\nwhere R∗\\nn,b = ˆθ∗\\nn,b−ˆθn. Letr∗\\nβ denote theβ sample quantile of (R∗\\nn,1,...,R ∗\\nn,B)\\nand let θ∗\\nβ denote the β sample quantile of ( ˆθ∗\\nn,1,..., ˆθ∗\\nn,B). Note that r∗\\nβ =\\nθ∗\\nβ − ˆθn. It follows that an approximate 1−α conﬁdence interval isCn =( ˆa,ˆb)\\nwhere\\nˆa = ˆθn − ˆH−1\\n\\uf8f6\\n1 − α\\n2\\n\\uf8f7\\n= ˆθn − r∗\\n1−α/2 =2 ˆθn − θ∗\\n1−α/2\\nˆb = ˆθn − ˆH−1\\n\\uf8f6α\\n2\\n\\uf8f7\\n= ˆθn − r∗\\nα/2 =2 ˆθn − θ∗\\nα/2.\\nIn summary, the 1− α bootstrap pivotal conﬁdence interval is\\nCn =\\n\\uf8f6\\n2ˆθn − ˆθ∗\\n1−α/2, 2ˆθn − ˆθ∗\\nα/2\\n\\uf8f7\\n. (8.6)\\n8.3 Theorem. Under weak conditions on T(F),\\nPF (T(F) ∈ Cn) → 1 − α\\nas n →∞ , where Cn is given in (8.6).\\nMethod 3: Percentile Intervals. The bootstrap percentile interval is de-\\nﬁned by\\nCn =\\n\\uf8f6\\nθ∗\\nα/2,θ ∗\\n1−α/2\\n\\uf8f7\\n.\\nThe justiﬁcation for this interval is given in the appendix.\\n8.4 Example. For estimating the skewness of the nerve data, here are the\\nvarious conﬁdence intervals.\\nMethod 95% Interval\\nNormal (1.44, 2.09)\\nPivotal (1.48, 2.11)\\nPercentile (1.42, 2.03)\\nAll these conﬁdence intervals are approximate. The probability that T(F)\\nis in the interval is not exactly 1 − α. All three intervals have the same level\\nof accuracy. There are more accurate bootstrap conﬁdence intervals but they\\nare more complicated and we will not discuss them here.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 127, 'page_label': '128'}, page_content='112 8. The Bootstrap\\n8.5 Example (The Plasma Cholesterol Data). Let us return to the cholesterol\\ndata. Suppose we are interested in the diﬀerence of the medians. Pseudocode\\nfor the bootstrap analysis is as follows:\\nx1 <- first sample\\nx2 <- second sample\\nn1 <- length(x1)\\nn2 <- length(x2)\\nth.hat <- median(x2) - median(x1)\\nB <- 1000\\nTboot <- vector of length B\\nfor(i in 1:B){\\nxx1 <- sample of size n1 with replacement from x1\\nxx2 <- sample of size n2 with replacement from x2\\nTboot[i] <- median(xx2) - median(xx1)\\n}\\nse <- sqrt(variance(Tboot))\\nNormal <- (th.hat - 2*se, th.hat + 2*se)\\npercentile <- (quantile(Tboot,.025), quantile(Tboot,.975))\\npivotal <- ( 2*th.hat-quantile(Tboot,.975),\\n2*th.hat-quantile(Tboot,.025) )\\nThe point estimate is 18.5, the bootstrap standard error is 7.42 and the re-\\nsulting approximate 95 percent conﬁdence intervals are as follows:\\nMethod 95% Interval\\nNormal (3.7, 33.3)\\nPivotal (5.0, 34.0)\\nPercentile (5.0, 33.3)\\nSince these intervals exclude 0, it appears that the second group has higher\\ncholesterol although there is considerable uncertainty about how much higher\\nas reﬂected in the width of the intervals.\\n■\\nThe next two examples are based on small sample sizes. In practice, sta-\\ntistical methods based on very small sample sizes might not be reliable. We\\ninclude the examples for their pedagogical value but we do want to sound a\\nnote of caution about interpreting the results with some skepticism.\\n8.6 Example. Here is an example that was one of the ﬁrst used to illustrate\\nthe bootstrap by Bradley Efron, the inventor of the bootstrap. The data are\\nLSAT scores (for entrance to law school) and GPA.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 128, 'page_label': '129'}, page_content='8.3 Bootstrap Conﬁdence Intervals 113\\nLSAT 576 635 558 578 666 580 555 661\\n651 605 653 575 545 572 594\\nGPA 3.39 3.30 2.81 3.03 3.44 3.07 3.00 3.43\\n3.36 3.13 3.12 2.74 2.76 2.88 3.96\\nEach data point is of the form Xi =( Yi,Zi) where Yi = LSATi and Zi =\\nGPAi. The law school is interested in the correlation\\nθ =\\n∫∫\\n(y − µY )(z − µZ)dF(y,z )√ ∫\\n(y − µY )2dF(y)\\n∫\\n(z − µZ)2dF(z)\\n.\\nThe plug-in estimate is the sample correlation\\nˆθ =\\n∑\\ni(Yi − Y )(Zi − Z)√ ∑\\ni(Yi − Y )2 ∑\\ni(Zi − Z)2\\n.\\nThe estimated correlation is ˆθ = .776. The bootstrap based on B = 1000\\ngives ˆse = .137. Figure 8.1 shows the data and a histogram of the bootstrap\\nreplications ˆθ∗\\n1,..., ˆθ∗\\nB. This histogram is an approximation to the sampling\\ndistribution of ˆθ. The Normal-based 95 percent conﬁdence interval is .78 ±\\n2ˆse =( .51,1.00) while the percentile interval is (.46,.96). In large samples, the\\ntwo methods will show closer agreement. ■\\n8.7 Example. This example is from Efron and Tibshirani (1993). When drug\\ncompanies introduce new medications, they are sometimes required to show\\nbioequivalence. This means that the new drug is not substantially diﬀerent\\nthan the current treatment. Here are data on eight subjects who used medi-\\ncal patches to infuse a hormone into the blood. Each subject received three\\ntreatments: placebo, old-patch, new-patch.\\nsubject placebo old new old − placebo new − old\\n1 9243 17649 16449 8406 -1200\\n2 9671 12013 14614 2342 2601\\n3 11792 19979 17274 8187 -2705\\n4 13357 21816 23798 8459 1982\\n5 9055 13850 12560 4795 -1290\\n6 6290 9806 10157 3516 351\\n7 12412 17208 16570 4796 -638\\n8 18806 29044 26325 10238 -2719'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 129, 'page_label': '130'}, page_content='114 8. The Bootstrap\\n\\x7f\\n\\x7f\\n\\x7f\\n\\x7f\\n\\x7f\\n\\x7f\\n\\x7f\\n\\x7f\\n\\x7f\\n\\x7f \\x7f\\n\\x7f\\x7f\\n\\x7f\\n\\x7f\\nLSAT\\nGPA\\n560 580 600 620 640 660\\n2.8 3.0 3.2 3.4\\n0.2 0.4 0.6 0.8 1.0\\n0 50 100 150\\nBootstrap Samples\\nFIGURE 8.1. Law school data. The top panel shows the raw data. The bottom panel\\nis a histogram of the correlations computed from each bootstrap sample.\\nLet Z = old − placebo and Y = new − old. The Food and Drug Adminis-\\ntration (FDA) requirement for bioequivalence is that |θ|≤ .20 where\\nθ = EF (Y )\\nEF (Z).\\nThe plug-in estimate of θ is\\nˆθ = Y\\nZ = −452.3\\n6342 = −0.0713.\\nThe bootstrap standard error is ˆse =0 .105. To answer the bioequivalence\\nquestion, we compute a conﬁdence interval. From B = 1000 bootstrap repli-\\ncations we get the 95 percent interval (-0.24,0.15). This is not quite contained'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 130, 'page_label': '131'}, page_content='8.4 Bibliographic Remarks 115\\nin (-0.20,0.20) so at the 95 percent level we have not demonstrated bioequiv-\\nalence. Figure 8.2 shows the histogram of the bootstrap values. ■\\n-0.3 -0.2 -0.1 0.0 0.1 0.2\\n0 2 04 06 08 0\\nBootstrap Samples\\nFIGURE 8.2. Patch data.\\n8.4 Bibliographic Remarks\\nThe bootstrap was invented by Efron (1979). There are several books on these\\ntopics including Efron and Tibshirani (1993), Davison and Hinkley (1997),\\nHall (1992) and Shao and Tu (1995). Also, see section 3.6 of van der Vaart\\nand Wellner (1996).\\n8.5 Appendix\\n8.5.1 The Jackknife\\nThere is another method for computing standard errors called thejackknife,\\ndue to Quenouille (1949). It is less computationally expensive than the boot-'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 131, 'page_label': '132'}, page_content='116 8. The Bootstrap\\nstrap but is less general. Let Tn = T(X1,...,X n) be a statistic and T(−i) de-\\nnote the statistic with theith observation removed. LetTn = n−1 ∑ n\\ni=1 T(−i).\\nThe jackknife estimate of var(Tn)i s\\nvjack = n − 1\\nn\\nn∑\\ni=1\\n(T(−i) − Tn)2\\nand the jackknife estimate of the standard error is ˆsejack = √vjack. Under\\nsuitable conditions on T, it can be shown that vjack consistently estimates\\nvar(Tn) in the sense that vjack/var(Tn)\\nP\\n−→1. However, unlike the bootstrap,\\nthe jackknife does not produce consistent estimates of the standard error of\\nsample quantiles.\\n8.5.2 Justiﬁcation For The Percentile Interval\\nSuppose there exists a monotone transformation U = m(T) such that U ∼\\nN(φ, c2) where φ = m(θ). We do not suppose we know the transformation,\\nonly that one exists. Let U∗\\nb = m(θ∗\\nn,b). Let u∗\\nβ be the β sample quantile of\\nthe U∗\\nb ’s. Since a monotone transformation preserves quantiles, we have that\\nu∗\\nα/2 = m(θ∗\\nα/2). Also, since U ∼ N(φ, c2), the α/2 quantile of U is φ − zα/2c.\\nHence u∗\\nα/2 = φ − zα/2c. Similarly, u∗\\n1−α/2 = φ + zα/2c. Therefore,\\nP(θ∗\\nα/2 ≤ θ ≤ θ∗\\n1−α/2)= P(m(θ∗\\nα/2) ≤ m(θ) ≤ m(θ∗\\n1−α/2))\\n= P(u∗\\nα/2 ≤ φ ≤ u∗\\n1−α/2)\\n= P(U − czα/2 ≤ φ ≤ U + czα/2)\\n= P(−zα/2 ≤ U − φ\\nc ≤ zα/2)\\n=1 − α.\\nAn exact normalizing transformation will rarely exist but there may exist\\napproximate normalizing transformations.\\n8.6 Exercises\\n1. Consider the data in Example 8.6. Find the plug-in estimate of the\\ncorrelation coeﬃcient. Estimate the standard error using the bootstrap.\\nFind a 95 percent conﬁdence interval using the Normal, pivotal, and\\npercentile methods.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 132, 'page_label': '133'}, page_content='8.6 Exercises 117\\n2. ( Computer Experiment.) Conduct a simulation to compare the various\\nbootstrap conﬁdence interval methods. Let n = 50 and let T(F)=∫\\n(x − µ)3dF(x)/σ3 be the skewness. Draw Y1,...,Y n ∼ N(0,1) and\\nset Xi = eYi , i =1 ,...,n . Construct the three types of bootstrap 95\\npercent intervals forT(F) from the data X1,...,X n. Repeat this whole\\nthing many times and estimate the true coverage of the three intervals.\\n3. Let\\nX1,...,X n ∼ t3\\nwhere n = 25. Let θ = T(F)=( q.75 − q.25)/1.34 where qp denotes the\\npth quantile. Do a simulation to compare the coverage and length of the\\nfollowing conﬁdence intervals for θ: (i) Normal interval with standard\\nerror from the bootstrap, (ii) bootstrap percentile interval, and (iii)\\npivotal bootstrap interval.\\n4. Let X\\n1,...,X n be distinct observations (no ties). Show that there are\\n\\uf8f62n − 1\\nn\\n\\uf8f7\\ndistinct bootstrap samples.\\nHint: Imagine putting n balls into n buckets.\\n5. Let X1,...,X n be distinct observations (no ties). LetX∗\\n1 ,...,X ∗\\nn denote\\na bootstrap sample and letX\\n∗\\nn = n−1 ∑ n\\ni=1 X∗\\ni . Find:E(X\\n∗\\nn|X1,...,X n),\\nV(X\\n∗\\nn|X1,...,X n), E(X\\n∗\\nn) and V(X\\n∗\\nn).\\n6. ( Computer Experiment.) Let X1, ..., Xn Normal(µ,1). Let θ = eµ and let\\nˆθ = eX. Create a data set (using µ = 5) consisting of n=100 observa-\\ntions.\\n(a) Use the bootstrap to get the se and 95 percent conﬁdence interval\\nfor θ.\\n(b) Plot a histogram of the bootstrap replications. This is an estimate\\nof the distribution of ˆθ. Compare this to the true sampling distribution\\nof ˆθ.\\n7. Let X1, ..., Xn ∼ Uniform(0,θ ). Let ˆθ = Xmax = max{X1, ..., Xn}. Gen-\\nerate a data set of size 50 with θ =1 .\\n(a) Find the distribution of ˆθ. Compare the true distribution ofˆθ to the\\nhistograms from the bootstrap.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 133, 'page_label': '134'}, page_content='118 8. The Bootstrap\\n(b) This is a case where the bootstrap does very poorly. In fact, we can\\nprove that this is the case. Show that P(ˆθ = ˆθ) = 0 and yet P(ˆθ∗ =\\nˆθ) ≈ .632. Hint: show that, P(ˆθ∗ = ˆθ)=1 − (1 − (1/n))n then take the\\nlimit as n gets large.\\n8. Let Tn = X\\n2\\nn, µ = E(X1), αk =\\n∫\\n|x−µ|kdF(x) and ˆαk = n−1 ∑ n\\ni=1 |Xi−\\nXn|k. Show that\\nvboot = 4X\\n2\\nn ˆα2\\nn + 4Xn ˆα3\\nn2 + ˆα4\\nn3 .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 134, 'page_label': '135'}, page_content='9\\nParametric Inference\\nWe now turn our attention to parametric models, that is, models of the form\\nF =\\n{\\nf(x;θ): θ ∈ Θ\\n}\\n(9.1)\\nwhere the Θ ⊂ Rk is the parameter space and θ =( θ1,...,θ k) is the param-\\neter. The problem of inference then reduces to the problem of estimating the\\nparameter θ.\\nStudents learning statistics often ask: how would we ever know that the\\ndistribution that generated the data is in some parametric model? This is\\nan excellent question. Indeed, we would rarely have such knowledge which\\nis why nonparametric methods are preferable. Still, studying methods for\\nparametric models is useful for two reasons. First, there are some cases where\\nbackground knowledge suggests that a parametric model provides a reasonable\\napproximation. For example, counts of traﬃc accidents are known from prior\\nexperience to follow approximately a Poisson model. Second, the inferential\\nconcepts for parametric models provide background for understanding certain\\nnonparametric methods.\\nWe begin with a brief discussion about parameters of interest and nuisance\\nparameters in the next section, then we will discuss two methods for estimat-\\ning θ, the method of moments and the method of maximum likelihood.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 135, 'page_label': '136'}, page_content='120 9. Parametric Inference\\n9.1 Parameter of Interest\\nOften, we are only interested in some function T(θ). For example, if X ∼\\nN(µ, σ2) then the parameter is θ =( µ, σ). If our goal is to estimate µ then\\nµ = T(θ) is called the parameter of interest and σ is called a nuisance\\nparameter. The parameter of interest might be a complicated function of θ\\nas in the following example.\\n9.1 Example. Let X1,...,X n ∼ Normal(µ, σ2). The parameter is θ =( µ, σ)\\nand the parameter space is Θ = {(µ, σ): µ ∈ R,σ > 0}. Suppose that Xi is\\nthe outcome of a blood test and suppose we are interested in τ, the fraction\\nof the population whose test score is larger than 1. Let Z denote a standard\\nNormal random variable. Then\\nτ = P(X> 1 )=1 − P(X< 1 )=1 − P\\n\\uf8f6X − µ\\nσ < 1 − µ\\nσ\\n\\uf8f7\\n=1 − P\\n\\uf8f6\\nZ< 1 − µ\\nσ\\n\\uf8f7\\n=1 − Φ\\n\\uf8f61 − µ\\nσ\\n\\uf8f7\\n.\\nThe parameter of interest is τ = T(µ, σ)=1 − Φ((1 − µ)/σ). ■\\n9.2 Example. Recall that X has a Gamma(α, β) distribution if\\nf(x; α, β)= 1\\nβαΓ(α)xα−1e−x/β,x > 0\\nwhere α, β >0 and\\nΓ(α)=\\n∫ ∞\\n0\\nyα−1e−ydy\\nis the Gamma function. The parameter is θ =( α, β). The Gamma distri-\\nbution is sometimes used to model lifetimes of people, animals, and elec-\\ntronic equipment. Suppose we want to estimate the mean lifetime. Then\\nT(α, β)= E\\nθ(X1)= αβ. ■\\n9.2 The Method of Moments\\nThe ﬁrst method for generating parametric estimators that we will study\\nis called the method of moments. We will see that these estimators are not\\noptimal but they are often easy to compute. They are are also useful as starting\\nvalues for other methods that require iterative numerical routines.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 136, 'page_label': '137'}, page_content='9.2 The Method of Moments 121\\nSuppose that the parameter θ =( θ1,...,θ k) has k components. For 1 ≤\\nj ≤ k, deﬁne the jth moment\\nαj ≡ αj(θ)= Eθ(Xj)=\\n∫\\nxjdFθ(x) (9.2)\\nand the jth sample moment\\nˆαj = 1\\nn\\nn∑\\ni=1\\nXj\\ni . (9.3)\\n9.3 Deﬁnition. The method of moments estimator ˆθn is deﬁned to be\\nthe value of θ such that\\nα1(ˆθn)= ˆα1\\nα2(ˆθn)= ˆα2\\n..\\n. ..\\n. ..\\n.\\nα\\nk(ˆθn)= ˆαk. (9.4)\\nFormula (9.4) deﬁnes a system of k equations with k unknowns.\\n9.4 Example. Let X1,...,X n ∼ Bernoulli(p). Then α1 = Ep(X)= p and\\nˆα1 = n−1 ∑ n\\ni=1 Xi. By equating these we get the estimator\\nˆpn = 1\\nn\\nn∑\\ni=1\\nXi. ■\\n9.5 Example. Let X1,...,X n ∼ Normal(µ, σ2). Then, α1 = Eθ(X1)= µ\\nand α2 = Eθ(X2\\n1)= Vθ(X1)+( Eθ(X1))2 = σ2 + µ2. We need to solve the\\nequations1\\nˆµ = 1\\nn\\nn∑\\ni=1\\nXi\\nˆσ2 + ˆµ2 = 1\\nn\\nn∑\\ni=1\\nX2\\ni .\\nThis is a system of 2 equations with 2 unknowns. The solution is\\nˆµ = Xn\\n1Recall that V(X)= E(X2) − (E(X))2. Hence, E(X2)= V(X)+( E(X))2.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 137, 'page_label': '138'}, page_content='122 9. Parametric Inference\\nˆσ2 = 1\\nn\\nn∑\\ni=1\\n(Xi − Xn)2. ■\\n9.6 Theorem. Let ˆθn denote the method of moments estimator. Under appro-\\npriate conditions on the model, the following statements hold:\\n1. The estimate ˆθn exists with probability tending to 1.\\n2. The estimate is consistent: ˆθn\\nP\\n−→θ.\\n3. The estimate is asymptotically Normal:\\n√n(ˆθn − θ) ⇝ N(0,Σ)\\nwhere\\nΣ= gEθ(YY T )gT ,\\nY =( X,X 2,...,X k)T , g =( g1,...,g k) and gj = ∂α−1\\nj (θ)/∂θ.\\nThe last statement in the theorem above can be used to ﬁnd standard errors\\nand conﬁdence intervals. However, there is an easier way: the bootstrap. We\\ndefer discussion of this until the end of the chapter.\\n9.3 Maximum Likelihood\\nThe most common method for estimating parameters in a parametric model is\\nthe maximum likelihood method. Let X\\n1, ... , Xn be iid with pdf f(x;θ).\\n9.7 Deﬁnition. The likelihood function is deﬁned by\\nLn(θ)=\\nn∏\\ni=1\\nf(Xi;θ). (9.5)\\nThe log-likelihood function is deﬁned by ℓn(θ) = logLn(θ).\\nThe likelihood function is just the joint density of the data, except that we\\ntreat it is a function of the parameter θ. Thus, Ln :Θ → [0,∞). The\\nlikelihood function is not a density function: in general, it is not true that\\nLn(θ) integrates to 1 (with respect to θ).\\n9.8 Deﬁnition. The maximum likelihood estimator mle, denoted by\\nˆθn, is the value of θ that maximizes Ln(θ).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 138, 'page_label': '139'}, page_content='9.3 Maximum Likelihood 123\\n0.0 0.2 0.4 0.6 0.8 1.0\\np\\nˆpn\\nFIGURE 9.1. Likelihood function for Bernoulli withn = 20 and ∑ n\\ni=1 Xi = 12. The\\nmle is ˆpn =1 2/2 0=0 .6.\\nThe maximum of ℓn(θ) occurs at the same place as the maximum ofLn(θ),\\nso maximizing the log-likelihood leads to the same answer as maximizing the\\nlikelihood. Often, it is easier to work with the log-likelihood.\\n9.9 Remark. If we multiply L\\nn(θ) by any positive constantc (not depending\\non θ) then this will not change themle. Hence, we shall often drop constants\\nin the likelihood function.\\n9.10 Example. Suppose thatX1,...,X n ∼ Bernoulli(p). The probability func-\\ntion is f(x;p)= px(1−p)1−x for x =0 ,1. The unknown parameter isp. Then,\\nLn(p)=\\nn∏\\ni=1\\nf(Xi; p)=\\nn∏\\ni=1\\npXi (1 − p)1−Xi = pS(1 − p)n−S\\nwhere S = ∑\\ni Xi. Hence,\\nℓn(p)= S log p +( n − S) log(1− p).\\nTake the derivative ofℓn(p), set it equal to 0 to ﬁnd that themle is ˆpn = S/n.\\nSee Figure 9.1. ■\\n9.11 Example. Let X1,...,X n ∼ N(µ, σ2). The parameter is θ =( µ, σ) and\\nthe likelihood function (ignoring some constants) is:\\nLn(µ, σ)=\\n∏\\ni\\n1\\nσ exp\\n{\\n− 1\\n2σ2 (Xi − µ)2\\n}\\n= σ−n exp\\n{\\n− 1\\n2σ2\\n∑\\ni\\n(Xi − µ)2\\n}'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 139, 'page_label': '140'}, page_content='124 9. Parametric Inference\\n= σ−n exp\\n{\\n−nS2\\n2σ2\\n}\\nexp\\n{\\n−n(X − µ)2\\n2σ2\\n}\\nwhere X = n−1 ∑\\ni Xi is the sample mean and S2 = n−1 ∑\\ni(Xi − X)2. The\\nlast equality above follows from the fact that∑\\ni(Xi −µ)2 = nS2 +n(X −µ)2\\nwhich can be veriﬁed by writing ∑\\ni(Xi − µ)2 = ∑\\ni(Xi − X + X − µ)2 and\\nthen expanding the square. The log-likelihood is\\nℓ(µ, σ)= −n log σ − nS2\\n2σ2 − n(X − µ)2\\n2σ2 .\\nSolving the equations\\n∂ℓ(µ, σ)\\n∂µ = 0 and ∂ℓ(µ, σ)\\n∂σ =0 ,\\nwe conclude that ˆµ = X and ˆσ = S. It can be veriﬁed that these are indeed\\nglobal maxima of the likelihood. ■\\n9.12 Example (A Hard Example). Here is an example that many people ﬁnd\\nconfusing. Let X1,...,X n ∼ Unif (0,θ ). Recall that\\nf(x;θ)=\\n{ 1/θ 0 ≤ x ≤ θ\\n0 otherwise .\\nConsider a ﬁxed value of θ. Suppose θ<X i for some i. Then, f(Xi;θ)=0\\nand hence Ln(θ)= ∏\\ni f(Xi;θ) = 0. It follows that Ln(θ)=0i fa n y Xi >θ .\\nTherefore, Ln(θ)=0i f θ<X (n) where X(n) = max {X1,...,X n}.N o w\\nconsider any θ ≥ X(n). For everyXi we then have thatf(Xi;θ)=1 /θ so that\\nLn(θ)= ∏\\ni f(Xi;θ)= θ−n. In conclusion,\\nLn(θ)=\\n{ \\uf8f61\\nθ\\n\\uf8f7n\\nθ ≥ X(n)\\n0 θ<X (n).\\nSee Figure 9.2. Now Ln(θ) is strictly decreasing over the interval [ X(n),∞).\\nHence, ˆθn = X(n). ■\\nThe maximum likelihood estimators for the multivariate Normal and the\\nmultinomial can be found in Theorems 14.5 and 14.3.\\n9.4 Properties of Maximum Likelihood Estimators\\nUnder certain conditions on the model, the maximum likelihood estimatorˆθn\\npossesses many properties that make it an appealing choice of estimator. The\\nmain properties of the mle are:'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 140, 'page_label': '141'}, page_content='9.4 Properties of Maximum Likelihood Estimators 125\\n0.0 0.5 1.0 1.5 2.0\\n0.0 0.5 1.0 1.5\\n0.0 0.5 1.0 1.5 2.0\\n0.0 0.5 1.0 1.5\\n0.0 0.5 1.0 1.5 2.0\\n0.0 0.5 1.0 1.5\\n0.6 0.8 1.0 1.2 1.4\\n0.0 0.5 1.0 1.5\\nθ = .75 θ =1\\nθ =1 .25\\nxx\\nx θ\\nf(x; θ)\\nf(x; θ)\\nf(x; θ)\\nLn(θ)\\nFIGURE 9.2. Likelihood function for Uniform (0 ,θ ). The vertical lines show the\\nobserved data. The ﬁrst three plots show f(x; θ) for three diﬀerent values of θ.\\nWhen θ<X (n) = max {X1,...,X n}, as in the ﬁrst plot, f(X(n); θ)=0a n d\\nhence Ln(θ)= ∏n\\ni=1 f(Xi; θ) = 0. Otherwise f(Xi; θ)=1 /θ for each i and hence\\nLn(θ)= ∏n\\ni=1 f(Xi; θ)=( 1 /θ)n. The last plot shows the likelihood function.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 141, 'page_label': '142'}, page_content='126 9. Parametric Inference\\n1. The mle is consistent: ˆθn\\nP\\n−→θ⋆ where θ⋆ denotes the true value of the\\nparameter θ;\\n2. The mle is equivariant:i f ˆθn is the mle of θ then g(ˆθn)i st h emle of\\ng(θ);\\n3. The mle is asymptotically Normal:( ˆθ − θ⋆ )/ˆse ⇝ N(0,1); also, the\\nestimated standard error ˆse can often be computed analytically;\\n4. The mle is asymptotically optimal or eﬃcient: roughly, this means\\nthat among all well-behaved estimators, the mle has the smallest vari-\\nance, at least for large samples;\\n5. The mle is approximately the Bayes estimator. (This point will be ex-\\nplained later.)\\nWe will spend some time explaining what these properties mean and why\\nthey are good things. In suﬃciently complicated problems, these properties\\nwill no longer hold and the mle will no longer be a good estimator. For now\\nwe focus on the simpler situations where the mle works well. The properties\\nwe discuss only hold if the model satisﬁes certain regularity conditions.\\nThese are essentially smoothness conditions on f(x;θ). Unless otherwise\\nstated, we shall tacitly assume that these conditions hold.\\n9.5 Consistency of Maximum Likelihood Estimators\\nConsistency means that the mle converges in probability to the true value.\\nTo proceed, we need a deﬁnition. If f and g are pdf’s, deﬁne the Kullback-\\nLeibler distance 2 between f and g to be\\nD(f,g )=\\n∫\\nf(x) log\\n\\uf8f6f(x)\\ng(x)\\n\\uf8f7\\ndx. (9.6)\\nIt can be shown that D(f,g ) ≥ 0 and D(f,f ) = 0. For any θ,ψ ∈ Θ write\\nD(θ,ψ ) to mean D(f(x; θ),f (x; ψ)).\\nWe will say that the modelF is identiﬁable if θ ̸= ψ implies thatD(θ,ψ ) >\\n0. This means that diﬀerent values of the parameter correspond to diﬀerent\\ndistributions. We will assume from now on the the model is identiﬁable.\\n2This is not a distance in the formal sense because D(f,g ) is not symmetric.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 142, 'page_label': '143'}, page_content='9.6 Equivariance of the mle 127\\nLet θ⋆ denote the true value of θ. Maximizing ℓn(θ) is equivalent to maxi-\\nmizing\\nMn(θ)= 1\\nn\\n∑\\ni\\nlog f(Xi; θ)\\nf(Xi; θ⋆ ).\\nThis follows sinceMn(θ)= n−1(ℓn(θ)−ℓn(θ⋆ )) and ℓn(θ⋆ ) is a constant (with\\nrespect to θ). By the law of large numbers, Mn(θ) converges to\\nEθ⋆\\n\\uf8f6\\nlog f(Xi; θ)\\nf(Xi; θ⋆ )\\n\\uf8f7\\n=\\n∫\\nlog\\n\\uf8f6f(x; θ)\\nf(x; θ⋆ )\\n\\uf8f7\\nf(x; θ⋆ )dx\\n= −\\n∫\\nlog\\n\\uf8f6f(x; θ⋆ )\\nf(x; θ)\\n\\uf8f7\\nf(x; θ⋆ )dx\\n= −D(θ⋆ ,θ ).\\nHence, Mn(θ) ≈− D(θ⋆ ,θ ) which is maximized at θ⋆ since −D(θ⋆ ,θ ⋆ )=0\\nand −D(θ⋆ ,θ ) < 0 for θ ̸= θ⋆ . Therefore, we expect that the maximizer will\\ntend to θ⋆ . To prove this formally, we need more thanMn(θ)\\nP\\n−→ −D(θ⋆ ,θ ).\\nWe need this convergence to be uniform over θ. We also have to make sure\\nthat the function D(θ⋆ ,θ ) is well behaved. Here are the formal details.\\n9.13 Theorem. Let θ⋆ denote the true value of θ. Deﬁne\\nMn(θ)= 1\\nn\\n∑\\ni\\nlog f(Xi; θ)\\nf(Xi; θ⋆ )\\nand M(θ)= −D(θ⋆ ,θ ). Suppose that\\nsup\\nθ∈Θ\\n|Mn(θ) − M(θ)|\\nP\\n−→0 (9.7)\\nand that, for every ϵ> 0,\\nsup\\nθ:|θ−θ⋆ |≥ϵ\\nM(θ) <M (θ⋆ ). (9.8)\\nLet ˆθn denote the mle. Then ˆθn\\nP\\n−→θ⋆ .\\nThe proof is in the appendix.\\n9.6 Equivariance of the mle\\n9.14 Theorem. Let τ = g(θ) be a function ofθ.L e tˆθn be the mle of θ. Then\\nˆτn = g(ˆθn) is the mle of τ.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 143, 'page_label': '144'}, page_content='128 9. Parametric Inference\\nProof. Let h = g−1 denote the inverse of g. Then ˆθn = h(ˆτn). For any τ,\\nL(τ)= ∏\\ni f(xi;h(τ)) = ∏\\ni f(xi;θ)= L(θ) where θ = h(τ). Hence, for anyτ,\\nLn(τ)= L(θ) ≤L (ˆθ)= Ln(ˆτ). ■\\n9.15 Example. Let X1,...,X n ∼ N(θ, 1). The mlefor θ is ˆθn = Xn. Let\\nτ = eθ. Then, the mle for τ is ˆτ = eˆθ = eX. ■\\n9.7 Asymptotic Normality\\nIt turns out that the distribution of ˆθn is approximately Normal and we can\\ncompute its approximate variance analytically. To explore this, we ﬁrst need\\na few deﬁnitions.\\n9.16 Deﬁnition. The score function is deﬁned to be\\ns(X;θ)= ∂ log f(X;θ)\\n∂θ . (9.9)\\nThe Fisher information is deﬁned to be\\nIn(θ)= Vθ\\n\\uf8f6 n∑\\ni=1\\ns(Xi;θ)\\n\\uf8f7\\n=\\nn∑\\ni=1\\nVθ (s(Xi;θ)). (9.10)\\nFor n = 1 we will sometimes write I(θ) instead of I1(θ). It can be shown\\nthat Eθ(s(X;θ)) = 0. It then follows thatVθ(s(X;θ)) = Eθ(s2(X;θ)). In fact,\\na further simpliﬁcation of In(θ) is given in the next result.\\n9.17 Theorem. In(θ)= nI(θ). Also,\\nI(θ)= −Eθ\\n\\uf8f6\\n∂2 log f(X;θ)\\n∂θ2\\n\\uf8f7\\n= −\\n∫ \\uf8f6\\n∂2 log f(x;θ)\\n∂θ2\\n\\uf8f7\\nf(x; θ)dx. (9.11)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 144, 'page_label': '145'}, page_content='9.7 Asymptotic Normality 129\\n9.18 Theorem (Asymptotic Normality of the mle). Let se =\\n√\\nV(ˆθn).\\nUnder appropriate regularity conditions, the following hold:\\n1. se ≈\\n√\\n1/In(θ) and\\n(ˆθn − θ)\\nse ⇝ N(0,1). (9.12)\\n2. Let ˆse =\\n√\\n1/In(ˆθn). Then,\\n(ˆθn − θ)\\nˆse ⇝ N(0,1). (9.13)\\nThe proof is in the appendix. The ﬁrst statement says that ˆθn ≈ N(θ, se)\\nwhere the approximate standard error of ˆθn is se =\\n√\\n1/In(θ). The second\\nstatement says that this is still true even if we replace the standard error by\\nits estimated standard error ˆse =\\n√\\n1/In(ˆθn).\\nInformally, the theorem says that the distribution of the mle can be ap-\\nproximated with N(θ, ˆse2). From this fact we can construct an (asymptotic)\\nconﬁdence interval.\\n9.19 Theorem. Let\\nCn =\\n\\uf8f6\\nˆθn − zα/2 ˆse, ˆθn + zα/2 ˆse\\n\\uf8f7\\n.\\nThen, Pθ(θ ∈ Cn) → 1 − α as n →∞ .\\nProof. Let Z denote a standard normal random variable. Then,\\nPθ(θ ∈ Cn)= Pθ\\n\\uf8f6\\nˆθn − zα/2 ˆse ≤ θ ≤ ˆθn + zα/2 ˆse\\n\\uf8f7\\n= Pθ\\n\\uf8f6\\n−zα/2 ≤\\nˆθn − θ\\nˆse ≤ zα/2\\n\\uf8f7\\n→ P(−zα/2 <Z<z α/2)=1 − α. ■\\nFor α = .05, zα/2 =1 .96 ≈ 2, so:\\nˆθn ± 2 ˆse (9.14)\\nis an approximate 95 percent conﬁdence interval.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 145, 'page_label': '146'}, page_content='130 9. Parametric Inference\\nWhen you read an opinion poll in the newspaper, you often see a statement\\nlike: the poll is accurate to within one point, 95 percent of the time. They are\\nsimply giving a 95 percent conﬁdence interval of the form ˆθ\\nn ± 2 ˆse.\\n9.20 Example. Let X1,...,X n ∼ Bernoulli(p). The mle is ˆpn = ∑\\ni Xi/n\\nand f(x;p)= px(1 − p)1−x, log f(x;p)= xlog p +( 1− x) log(1− p),\\ns(X;p)= X\\np − 1 − X\\n1 − p ,\\nand\\n−s′(X;p)= X\\np2 + 1 − X\\n(1 − p)2 .\\nThus,\\nI(p)= Ep(−s′(X;p)) = p\\np2 + (1 − p)\\n(1 − p)2 = 1\\np(1 − p).\\nHence,\\nˆse = 1√\\nIn(ˆpn)\\n= 1√\\nnI(ˆpn)\\n=\\n{ˆp(1 − ˆp)\\nn\\n}1/2\\n.\\nAn approximate 95 percent conﬁdence interval is\\nˆpn ± 2\\n{ˆpn(1 − ˆpn)\\nn\\n}1/2\\n. ■\\n9.21 Example. Let X1,...,X n ∼ N(θ,σ 2) where σ2 is known. The score\\nfunction is s(X;θ)=( X − θ)/σ2 and s′(X;θ)= −1/σ2 so that I1(θ)=1 /σ2.\\nThe mle is ˆθn = Xn. According to Theorem 9.18, Xn ≈ N(θ,σ 2/n). In this\\ncase, the Normal approximation is actually exact. ■\\n9.22 Example. Let X1,...,X n ∼ Poisson(λ). Then ˆλn = Xn and some cal-\\nculations show that I1(λ)=1 /λ,s o\\nˆse = 1√\\nnI(ˆλn)\\n=\\n√\\nˆλn\\nn .\\nTherefore, an approximate 1−α conﬁdence interval forλ is ˆλn ±zα/2\\n√\\nˆλn/n.\\n■\\n9.8 Optimality\\nSuppose that X1,...,X n ∼ N(θ,σ 2). The mle is ˆθn = Xn. Another reason-\\nable estimator of θ is the sample median ˜θn. The mle satisﬁes\\n√n(ˆθn − θ) ⇝ N(0,σ 2).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 146, 'page_label': '147'}, page_content='9.9 The Delta Method 131\\nIt can be proved that the median satisﬁes\\n√n(˜θn − θ) ⇝ N\\n\\uf8f6\\n0,σ 2 π\\n2\\n\\uf8f7\\n.\\nThis means that the median converges to the right value but has a larger\\nvariance than the mle.\\nMore generally, consider two estimators Tn and Un and suppose that\\n√n(Tn − θ) ⇝ N(0,t 2),\\nand that √n(Un − θ) ⇝ N(0,u 2).\\nWe deﬁne the asymptotic relative eﬃciency of U to T by are(U, T)= t2/u2.\\nIn the Normal example, are(˜θn, ˆθn)=2 /π = .63. The interpretation is that\\nif you use the median, you are eﬀectively using only a fraction of the data.\\n9.23 Theorem. If ˆθn is the mle and ˜θn is any other estimator then 3\\nare(˜θn, ˆθn) ≤ 1.\\nThus, the mle has the smallest (asymptotic) variance and we say that the\\nmle is eﬃcient or asymptotically optimal.\\nThis result is predicated upon the assumed model being correct. If the model\\nis wrong, the mle may no longer be optimal. We will discuss optimality in\\nmore generality when we discuss decision theory in Chapter 12.\\n9.9 The Delta Method\\nLet τ = g(θ) where g is a smooth function. The maximum likelihood esti-\\nmator of τ is ˆτ = g(ˆθ). Now we address the following question: what is the\\ndistribution of ˆτ?\\n9.24 Theorem (The Delta Method). If τ = g(θ) where g is diﬀerentiable\\nand g′(θ) ̸=0 then\\n(ˆτn − τ)\\nˆse(ˆτ) ⇝ N(0,1) (9.15)\\n3The result is actually more subtle than this but the details are too complicated to consider\\nhere.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 147, 'page_label': '148'}, page_content='132 9. Parametric Inference\\nwhere ˆτn = g(ˆθn) and\\nˆse(ˆτn)= |g′(ˆθ)| ˆse(ˆθn) (9.16)\\nHence, if\\nCn =\\n\\uf8f6\\nˆτn − zα/2 ˆse(ˆτn), ˆτn + zα/2 ˆse(ˆτn)\\n\\uf8f7\\n(9.17)\\nthen Pθ(τ ∈ Cn) → 1 − α as n →∞ .\\n9.25 Example. Let X1,...,X n ∼ Bernoulli(p) and let ψ = g(p) = log(p/(1 −\\np)). The Fisher information function is I(p)=1 /(p(1 − p)) so the estimated\\nstandard error of the mle ˆpn is\\nˆse =\\n√\\nˆpn(1 − ˆpn)\\nn .\\nThe mle of ψ is ˆψ = log ˆp/(1 − ˆp). Since, g′(p)=1 /(p(1 − p)), according to\\nthe delta method\\nˆse( ˆψn)= |g′(ˆpn)|ˆse(ˆpn)= 1√\\nnˆpn(1 − ˆpn)\\n.\\nAn approximate 95 percent conﬁdence interval is\\nˆψn ± 2√\\nnˆpn(1 − ˆpn)\\n. ■\\n9.26 Example. Let X1,...,X n ∼ N(µ, σ2). Suppose that µ is known, σ is\\nunknown and that we want to estimateψ = logσ. The log-likelihood isℓ(σ)=\\n−n log σ − 1\\n2σ2\\n∑\\ni(xi −µ)2. Diﬀerentiate and set equal to 0 and conclude that\\nˆσn =\\n√ ∑\\ni(Xi − µ)2\\nn .\\nTo get the standard error we need the Fisher information. First,\\nlog f(X;σ)= −log σ − (X − µ)2\\n2σ2\\nwith second derivative\\n1\\nσ2 − 3(X − µ)2\\nσ4 ,\\nand hence\\nI(σ)= − 1\\nσ2 + 3σ2\\nσ4 = 2\\nσ2 .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 148, 'page_label': '149'}, page_content='9.10 Multiparameter Models 133\\nTherefore, ˆse = ˆσn/\\n√\\n2n. Let ψ = g(σ) = log σ. Then, ˆψn = log ˆσn. Since\\ng′ =1 /σ,\\nˆse( ˆψn)= 1\\nˆσn\\nˆσn√\\n2n = 1√\\n2n,\\nand an approximate 95 percent conﬁdence interval is ˆψn ± 2/\\n√\\n2n. ■\\n9.10 Multiparameter Models\\nThese ideas can directly be extended to models with several parameters. Let\\nθ =( θ1,...,θ k) and letˆθ =( ˆθ1,..., ˆθk)b et h emle. Letℓn = ∑ n\\ni=1 log f(Xi; θ),\\nHjj = ∂2ℓn\\n∂θ2\\nj\\nand Hjk = ∂2ℓn\\n∂θj∂θk\\n.\\nDeﬁne the Fisher Information Matrix by\\nIn(θ)= −\\n\\uf8ee\\n\\uf8ef\\uf8ef\\n\\uf8ef\\uf8f0\\nE\\nθ(H11) Eθ(H12) ··· Eθ(H1k)\\nEθ(H21) Eθ(H22) ··· Eθ(H2k)\\n..\\n. ..\\n. ..\\n. ..\\n.\\nE\\nθ(Hk1) Eθ(Hk2) ··· Eθ(Hkk)\\n\\uf8f9\\n\\uf8fa\\uf8fa\\n\\uf8fa\\uf8fb. (9.18)\\nLet J\\nn(θ)= I−1\\nn (θ) be the inverse of In.\\n9.27 Theorem. Under appropriate regularity conditions,\\n(ˆθ − θ) ≈ N(0,Jn).\\nAlso, if ˆθj is the jth component of ˆθ, then\\n(ˆθj − θj)\\nˆsej\\n⇝ N(0,1) (9.19)\\nwhere ˆse2\\nj = Jn(j, j) is the jth diagonal element of Jn. The approximate co-\\nvariance of ˆθj and ˆθk is Cov(ˆθj, ˆθk) ≈ Jn(j, k).\\nThere is also a multiparameter delta method. Let τ = g(θ1,...,θ k)b ea\\nfunction and let\\n∇g =\\n\\uf8eb\\n\\uf8ec\\uf8ec\\n\\uf8ec\\n\\uf8ec\\n\\uf8ec\\uf8ed\\n∂g\\n∂θ1\\n..\\n.\\n∂g\\n∂θk\\n\\uf8f6\\n\\uf8f7\\uf8f7\\n\\uf8f7\\n\\uf8f7\\n\\uf8f7\\uf8f8\\nbe the gradient of g.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 149, 'page_label': '150'}, page_content='134 9. Parametric Inference\\n9.28 Theorem (Multiparameter delta method). Suppose that ∇g evaluated at\\nˆθ is not 0. Let ˆτ = g(ˆθ). Then\\n(ˆτ − τ)\\nˆse(ˆτ) ⇝ N(0,1)\\nwhere\\nˆse(ˆτ)=\\n√\\n(ˆ∇g)T ˆJn(ˆ∇g), (9.20)\\nˆJn = Jn(ˆθn) and ˆ∇g is ∇g evaluated at θ = ˆθ.\\n9.29 Example. Let X1,...,X n ∼ N(µ, σ2). Let τ = g(µ, σ)= σ/µ. In Excer-\\ncise 8 you will show that\\nIn(µ, σ)=\\n[ n\\nσ2 0\\n0 2n\\nσ2\\n]\\n.\\nHence,\\nJn = I−1\\nn (µ, σ)= 1\\nn\\n[ σ2 0\\n0 σ2\\n2\\n]\\n.\\nThe gradient of g is\\n∇g =\\n\\uf8f6 − σ\\nµ2\\n1\\nµ\\n\\uf8f7\\n.\\nThus,\\nˆse(ˆτ)=\\n√\\n(ˆ∇g)T ˆJn(ˆ∇g)= 1√n\\n√\\n1\\nˆµ4 + ˆσ2\\n2ˆµ2 . ■\\n9.11 The Parametric Bootstrap\\nFor parametric models, standard errors and conﬁdence intervals may also be\\nestimated using the bootstrap. There is only one change. In the nonparametric\\nbootstrap, we sampled X\\n∗\\n1 ,...,X ∗\\nn from the empirical distribution ˆFn.I nt h e\\nparametric bootstrap we sample instead fromf(x; ˆθn). Here, ˆθn could be the\\nmle or the method of moments estimator.\\n9.30 Example. Consider example 9.29. To get the bootstrap standard er-\\nror, simulate X1,...,X ∗\\nn ∼ N(ˆµ, ˆσ2), compute ˆµ∗ = n−1 ∑\\ni X∗\\ni and ˆσ2∗ =\\nn−1 ∑\\ni(X∗\\ni − ˆµ∗)2. Then compute ˆτ∗ = g(ˆµ∗, ˆσ∗)= ˆσ∗/ˆµ∗. Repeating this B\\ntimes yields bootstrap replications\\nˆτ∗\\n1 ,..., ˆτ∗\\nB'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 150, 'page_label': '151'}, page_content='9.12 Checking Assumptions 135\\nand the estimated standard error is\\nˆseboot =\\n√ ∑ B\\nb=1(ˆτ∗\\nb − ˆτ)2\\nB . ■\\nThe bootstrap is much easier than the delta method. On the other hand,\\nthe delta method has the advantage that it gives a closed form expression for\\nthe standard error.\\n9.12 Checking Assumptions\\nIf we assume the data come from a parametric model, then it is a good idea to\\ncheck that assumption. One possibility is to check the assumptions informally\\nby inspecting plots of the data. For example, if a histogram of the data looks\\nvery bimodal, then the assumption of Normality might be questionable. A\\nformal way to test a parametric model is to use a goodness-of-ﬁt test. See\\nSection 10.8.\\n9.13 Appendix\\n9.13.1 Proofs\\nProof of Theorem 9.13. Since ˆθn maximizes Mn(θ), we have Mn(ˆθn) ≥\\nMn(θ⋆ ). Hence,\\nM(θ⋆ ) − M(ˆθn)= Mn(θ⋆ ) − M(ˆθn)+ M(θ⋆ ) − Mn(θ⋆ )\\n≤ Mn(ˆθn) − M(ˆθn)+ M(θ⋆ ) − Mn(θ⋆ )\\n≤ sup\\nθ\\n|Mn(θ) − M(θ)| + M(θ⋆ ) − Mn(θ⋆ )\\nP\\n−→ 0\\nwhere the last line follows from (9.7). It follows that, for any δ> 0,\\nP\\n\\uf8f6\\nM(ˆθn) <M (θ⋆ ) − δ\\n\\uf8f7\\n→ 0.\\nPick any ϵ> 0. By (9.8), there exists δ> 0 such that |θ −θ⋆ |≥ ϵ implies that\\nM(θ) <M (θ⋆ ) − δ. Hence,\\nP(|ˆθn − θ⋆ | >ϵ ) ≤ P\\n\\uf8f6\\nM(ˆθn) <M (θ⋆ ) − δ\\n\\uf8f7\\n→ 0. ■\\nNext we want to prove Theorem 9.18. First we need a lemma.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 151, 'page_label': '152'}, page_content='136 9. Parametric Inference\\n9.31 Lemma. The score function satisﬁes\\nEθ [s(X;θ)] = 0.\\nProof. Note that 1 =\\n∫\\nf(x;θ)dx. Diﬀerentiate both sides of this equation\\nto conclude that\\n0= ∂\\n∂θ\\n∫\\nf(x;θ)dx =\\n∫ ∂\\n∂θ f(x;θ)dx\\n=\\n∫ ∂f (x;θ)\\n∂θ\\nf(x;θ)f(x;θ)dx =\\n∫ ∂ log f(x;θ)\\n∂θ f(x;θ)dx\\n=\\n∫\\ns(x;θ)f(x;θ)dx = Eθs(X;θ). ■\\nProof of Theorem 9.18.Let ℓ(θ) = logL(θ). Then,\\n0= ℓ′(ˆθ) ≈ ℓ′(θ)+( ˆθ − θ)ℓ′′(θ).\\nRearrange the above equation to get ˆθ − θ = −ℓ′(θ)/ℓ′′(θ) or, in other words,\\n√n(ˆθ − θ)=\\n1√n ℓ′(θ)\\n− 1\\nn ℓ′′(θ) ≡ TOP\\nBOTTOM.\\nLet Yi = ∂ log f(Xi;θ)/∂θ. Recall that E(Yi) = 0 from the previous lemma\\nand also V(Yi)= I(θ). Hence,\\nTOP = n−1/2 ∑\\ni\\nYi = √nY = √n(Y − 0) ⇝ W ∼ N(0,I (θ))\\nby the central limit theorem. Let Ai = −∂2 log f(Xi;θ)/∂θ2. Then E(Ai)=\\nI(θ) and\\nBOTTOM = A\\nP\\n−→I(θ)\\nby the law of large numbers. Apply Theorem 5.5 part (e), to conclude that\\n√n(ˆθ − θ) ⇝ W\\nI(θ)\\nd\\n= N\\n\\uf8f6\\n0, 1\\nI(θ)\\n\\uf8f7\\n.\\nAssuming that I(θ) is a continuous function ofθ, it follows thatI(ˆθn)\\nP\\n−→I(θ).\\nNow\\nˆθn − θ\\nˆse = √nI1/2(ˆθn)(ˆθn − θ)\\n=\\n{√nI1/2(θ)(ˆθn − θ)\\n}\\n√\\nI(ˆθn)\\nI(θ) .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 152, 'page_label': '153'}, page_content='9.13 Appendix 137\\nThe ﬁrst term tends in distribution to N(0,1). The second term tends in\\nprobability to 1. The result follows from Theorem 5.5 part (e). ■\\nOutline of Proof of Theorem 9.24.Write\\nˆτn = g(ˆθn) ≈ g(θ)+( ˆθn − θ)g′(θ)= τ +( ˆθn − θ)g′(θ).\\nThus, √n(ˆτn − τ) ≈ √n(ˆθn − θ)g′(θ),\\nand hence √\\nnI(θ)(ˆτn − τ)\\ng′(θ) ≈\\n√\\nnI(θ)(ˆθn − θ).\\nTheorem 9.18 tells us that the right-hand side tends in distribution to a N(0,1).\\nHence, √\\nnI(θ)(ˆτn − τ)\\ng′(θ) ⇝ N(0,1)\\nor, in other words,\\nˆτn ≈ N\\n\\uf8f6\\nτ, se2(ˆτn)\\n\\uf8f7\\n,\\nwhere\\nse2(ˆτn)= (g′(θ))2\\nnI(θ) .\\nThe result remains true if we substitute ˆθn for θ by Theorem 5.5 part (e). ■\\n9.13.2 Suﬃciency\\nA statistic is a function T(Xn) of the data. A suﬃcient statistic is a statistic\\nthat contains all the information in the data. To make this more formal, we\\nneed some deﬁnitions.\\n9.32 Deﬁnition. Write xn ↔ yn if f(xn;θ)= cf (yn;θ) for some constant\\nc that might depend on xn and yn but not θ. A statistic T(xn) is\\nsuﬃcient if T(xn) ↔ T(yn) implies that xn ↔ yn.\\nNotice that if xn ↔ yn, then the likelihood function based on xn has the\\nsame shape as the likelihood function based onyn. Roughly speaking, a statis-\\ntic is suﬃcient if we can calculate the likelihood function knowing onlyT(Xn).\\n9.33 Example. Let X1,...,X n ∼ Bernoulli(p). Then L(p)= pS(1 − p)n−S\\nwhere S = ∑\\ni Xi,s o S is suﬃcient. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 153, 'page_label': '154'}, page_content='138 9. Parametric Inference\\n9.34 Example. Let X1,...,X n ∼ N(µ, σ) and let T =( X,S ). Then\\nf(Xn;µ, σ)=\\n\\uf8f6 1\\nσ\\n√\\n2π\\n\\uf8f7n\\nexp\\n{\\n−nS2\\n2σ2\\n}\\nexp\\n{\\n−n(X − µ)2\\n2σ2\\n}\\nwhere S2 is the sample variance. The last expression depends on the data\\nonly through T and therefore, T =( X,S ) is a suﬃcient statistic. Note that\\nU = (17X,S ) is also a suﬃcient statistic. If I tell you the value ofU then you\\ncan easily ﬁgure out T and then compute the likelihood. Suﬃcient statistics\\nare far from unique. Consider the following statistics for the N(µ, σ2) model:\\nT1(Xn)=( X1,...,X n)\\nT2(Xn)=( X,S )\\nT3(Xn)= X\\nT4(Xn)=( X,S,X 3).\\nThe ﬁrst statistic is just the whole data set. This is suﬃcient. The second\\nis also suﬃcient as we proved above. The third is not suﬃcient: you can’t\\ncompute L(µ, σ) if I only tell you\\nX. The fourth statistic T4 is suﬃcient. The\\nstatistics T1 and T4 are suﬃcient but they contain redundant information.\\nIntuitively, there is a sense in whichT2 is a “more concise” suﬃcient statistic\\nthan either T1 or T4. We can express this formally by noting that T2 is a\\nfunction of T1 and similarly, T2 is a function of T4. For example, T2 = g(T4)\\nwhere g(a1,a2,a3)=( a1,a2). ■\\n9.35 Deﬁnition. A statistic T is minimal suﬃcient if (i) it is\\nsuﬃcient; and (ii) it is a function of every other suﬃcient statistic.\\n9.36 Theorem. T is minimal suﬃcient if the following is true:\\nT(xn)= T(yn) if and only if xn ↔ yn.\\nA statistic induces a partition on the set of outcomes. We can think of\\nsuﬃciency in terms of these partitions.\\n9.37 Example. Let X1,X 2 ∼ Bernoulli(θ). Let V = X1, T = ∑\\ni Xi and\\nU =( T,X 1). Here is the set of outcomes and the statistics:\\nX1 X2 VTU\\n00 0 0 (0,0)\\n01 0 1 (1,0)\\n10 1 1 (1,1)\\n11 1 2 (2,1)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 154, 'page_label': '155'}, page_content='9.13 Appendix 139\\nThe partitions induced by these statistics are:\\nV −→ { (0,0),(0,1)}, {(1,0),(1,1)}\\nT −→ { (0,0)}, {(0,1),(1,0)}, {(1,1)}\\nU −→ { (0,0)}, {(0,1)}, {(1,0)}, {(1,1)}.\\nThen V is not suﬃcient but T and U are suﬃcient. T is minimal suﬃcient;\\nU is not minimal since if xn =( 1,0) and yn =( 0,1), then xn ↔ yn yet\\nU(xn) ̸= U(yn). The statistic W =1 7T generates the same partition as T.I t\\nis also minimal suﬃcient. ■\\n9.38 Example. For a N(µ, σ2) model, T =( X,S ) is a minimal suﬃcient\\nstatistic. For the Bernoulli model,T = ∑\\ni Xi is a minimal suﬃcient statistic.\\nFor the Poisson model,T = ∑\\ni Xi is a minimal suﬃcient statistic. Check that\\nT =( ∑\\ni Xi,X 1) is suﬃcient but not minimal suﬃcient. Check that T = X1\\nis not suﬃcient. ■\\nI did not give the usual deﬁnition of suﬃciency. The usual deﬁnition is this:\\nT is suﬃcient if the distribution of Xn given T(Xn)= t does not depend on\\nθ. In other words, T is suﬃcient if f(x1,...,x n|t;θ)= h(x1,...,x n,t ) where\\nh is some function that does not depend on θ.\\n9.39 Example. Two coin ﬂips. Let X =( X1,X 2) ∼ Bernoulli(p). Then T =\\nX1 + X2 is suﬃcient. To see this, we need the distribution of (X1,X 2) given\\nT = t. Since T can take 3 possible values, there are 3 conditional distributions\\nto check. They are: (i) the distribution of (X1,X 2) given T =0 :\\nP(X1 =0 ,X 2 =0 |t =0 )=1 ,P (X1 =0 ,X 2 =1 |t =0 )=0 ,\\nP(X1 =1 ,X 2 =0 |t =0 )=0 ,P (X1 =1 ,X 2 =1 |t =0 )=0 ;\\n(ii) the distribution of (X1,X 2) given T =1 :\\nP(X1 =0 ,X 2 =0 |t =1 )=0 ,P (X1 =0 ,X 2 =1 |t =1 )= 1\\n2,\\nP(X1 =1 ,X 2 =0 |t =1 )= 1\\n2,P (X1 =1 ,X 2 =1 |t =1 )=0 ; a n d\\n(iii) the distribution of (X1,X 2) given T =2 :\\nP(X1 =0 ,X 2 =0 |t =2 )=0 ,P (X1 =0 ,X 2 =1 |t =2 )=0 ,\\nP(X1 =1 ,X 2 =0 |t =2 )=0 ,P (X1 =1 ,X 2 =1 |t =2 )=1 .\\nNone of these depend on the parameter p. Thus, the distribution of X1,X 2|T\\ndoes not depend on θ,s o T is suﬃcient. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 155, 'page_label': '156'}, page_content='140 9. Parametric Inference\\n9.40 Theorem (Factorization Theorem). T is suﬃcient if and only if there are\\nfunctions g(t, θ) and h(x) such that f(xn;θ)= g(t(xn),θ )h(xn).\\n9.41 Example. Return to the two coin ﬂips. Let t = x1 + x2. Then\\nf(x1,x2;θ)= f(x1;θ)f(x2;θ)\\n= θx1 (1 − θ)1−x1 θx2 (1 − θ)1−x2\\n= g(t, θ)h(x1,x2)\\nwhere g(t, θ)= θt(1 − θ)2−t and h(x1,x2) = 1. Therefore, T = X1 + X2 is\\nsuﬃcient. ■\\nNow we discuss an implication of suﬃciency in point estimation. Let ˆθ be\\nan estimator of θ. The Rao-Blackwell theorem says that an estimator should\\nonly depend on the suﬃcient statistic, otherwise it can be improved. Let\\nR(θ, ˆθ)= E\\nθ(θ − ˆθ)2 denote the mse of the estimator.\\n9.42 Theorem (Rao-Blackwell). Let ˆθ be an estimator and letT be a suﬃcient\\nstatistic. Deﬁne a new estimator by\\n˜θ = E(ˆθ|T).\\nThen, for every θ, R(θ, ˜θ) ≤ R(θ, ˆθ).\\n9.43 Example. Consider ﬂipping a coin twice. Let ˆθ = X1. This is a well-\\ndeﬁned (and unbiased) estimator. But it is not a function of the suﬃcient\\nstatistic T = X\\n1 + X2. However, note that ˜θ = E(X1|T)=( X1 + X2)/2. By\\nthe Rao-Blackwell Theorem, ˜θ has MSE at least as small as ˆθ = X1. The\\nsame applies with n coin ﬂips. Again deﬁne ˆθ = X1 and T = ∑\\ni Xi. Then\\n˜θ = E(X1|T)= n−1 ∑\\ni Xi has improved mse. ■\\n9.13.3 Exponential Families\\nMost of the parametric models we have studied so far are special cases of\\na general class of models called exponential families. We say that {f(x;θ):\\nθ ∈ Θ} is a one-parameter exponential family if there are functionsη(θ),\\nB(θ), T(x) and h(x) such that\\nf(x;θ)= h(x)eη(θ)T(x)−B(θ).\\nIt is easy to see that T(X) is suﬃcient. We call T the natural suﬃcient\\nstatistic.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 156, 'page_label': '157'}, page_content='9.13 Appendix 141\\n9.44 Example. Let X ∼ Poisson(θ). Then\\nf(x;θ)= θxe−θ\\nx! = 1\\nx!ex log θ−θ\\nand hence, this is an exponential family withη(θ) = logθ, B(θ)= θ, T(x)= x,\\nh(x)=1 /x!. ■\\n9.45 Example. Let X ∼ Binomial(n, θ). Then\\nf(x;θ)=\\n\\uf8f6n\\nx\\n\\uf8f7\\nθx(1 − θ)n−x =\\n\\uf8f6n\\nx\\n\\uf8f7\\nexp\\n{\\nxlog\\n\\uf8f6 θ\\n1 − θ\\n\\uf8f7\\n+ n log(1 − θ)\\n}\\n.\\nIn this case,\\nη(θ) = log\\n\\uf8f6 θ\\n1 − θ\\n\\uf8f7\\n,B (θ)= −n log(θ)\\nand\\nT(x)= x, h(x)=\\n\\uf8f6n\\nx\\n\\uf8f7\\n.\\n■\\nWe can rewrite an exponential family as\\nf(x;η)= h(x)eηT (x)−A(η)\\nwhere η = η(θ) is called the natural parameter and\\nA(η) = log\\n∫\\nh(x)eηT (x)dx.\\nFor example a Poisson can be written asf(x;η)= eηx−eη\\n/x! where the natural\\nparameter is η = logθ.\\nLet X1,...,X n be iid from an exponential family. Then f(xn;θ)i sa n\\nexponential family:\\nf(xn;θ)= hn(xn)hn(xn)eη(θ)Tn(xn)−Bn(θ)\\nwhere hn(xn)= ∏\\ni h(xi), Tn(xn)= ∑\\ni T(xi) and Bn(θ)= nB(θ). This\\nimplies that ∑\\ni T(Xi) is suﬃcient.\\n9.46 Example. Let X1,...,X n ∼ Uniform(0,θ ). Then\\nf(xn;θ)= 1\\nθn I(x(n) ≤ θ)\\nwhere I is 1 if the term inside the brackets is true and 0 otherwise, and\\nx(n) = max{x1,...,x n}.T h u sT(Xn)= max{X1,...,X n} is suﬃcient. But\\nsince T(Xn) ̸= ∑\\ni T(Xi), this cannot be an exponential family. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 157, 'page_label': '158'}, page_content='142 9. Parametric Inference\\n9.47 Theorem. Let X have density in an exponential family. Then,\\nE(T(X)) = A′(η), V(T(X)) = A′′(η).\\nIf θ =( θ1,...,θ k) is a vector, then we say that f(x;θ) has exponential\\nfamily form if\\nf(x;θ)= h(x) exp\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\nk∑\\nj=1\\nηj(θ)Tj(x) − B(θ)\\n\\uf8fc\\n\\uf8fd\\n\\uf8fe.\\nAgain, T =( T1,...,T k) is suﬃcient. An iid sample of size n also has expo-\\nnential form with suﬃcient statistic (∑\\ni T1(Xi),..., ∑\\ni Tk(Xi)).\\n9.48 Example. Consider the normal family with θ =( µ, σ). Now,\\nf(x;θ) = exp\\n{ µ\\nσ2 x − x2\\n2σ2 − 1\\n2\\n\\uf8f6µ2\\nσ2 + log(2πσ2)\\n\\uf8f7}\\n.\\nThis is exponential with\\nη1(θ)= µ\\nσ2 ,T 1(x)= x\\nη2(θ)= − 1\\n2σ2 ,T 2(x)= x2\\nB(θ)= 1\\n2\\n\\uf8f6µ2\\nσ2 + log(2πσ2)\\n\\uf8f7\\n,h (x)=1 .\\nHence, with n iid samples, (∑\\ni Xi,∑\\ni X2\\ni ) is suﬃcient. ■\\nAs before we can write an exponential family as\\nf(x;η)= h(x) exp\\n{\\nTT (x)η − A(η)\\n}\\n,\\nwhere A(η) = log\\n∫\\nh(x)eTT (x)ηdx. It can be shown that\\nE(T(X)) = ˙A(η) V(T(X)) = ¨A(η),\\nwhere the ﬁrst expression is the vector of partial derivatives and the second\\nis the matrix of second derivatives.\\n9.13.4 Computing Maximum Likelihood Estimates\\nIn some cases we can ﬁnd the mle ˆθ analytically. More often, we need to\\nﬁnd the mle by numerical methods. We will brieﬂy discuss two commonly'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 158, 'page_label': '159'}, page_content='9.13 Appendix 143\\nused methods: (i) Newton-Raphson, and (ii) the EM algorithm. Both are\\niterative methods that produce a sequence of values θ0,θ 1,... that, under\\nideal conditions, converge to the mle ˆθ. In each case, it is helpful to use a\\ngood starting value θ0. Often, the method of moments estimator is a good\\nstarting value.\\nNewton-Raphson. To motivate Newton-Raphson, let’s expand the deriva-\\ntive of the log-likelihood around θj:\\n0= ℓ′(ˆθ) ≈ ℓ′(θj)+( ˆθ − θj)ℓ\\n′′\\n(θj).\\nSolving for ˆθ gives\\nˆθ ≈ θj − ℓ\\n′\\n(θj)\\nℓ\\n′′\\n(θj).\\nThis suggests the following iterative scheme:\\nˆθj+1 = θj − ℓ\\n′\\n(θj)\\nℓ\\n′′\\n(θj).\\nIn the multiparameter case, the mle ˆθ =( ˆθ1,..., ˆθk) is a vector and the\\nmethod becomes\\nˆθj+1 = θj − H−1ℓ\\n′\\n(θj)\\nwhere ℓ\\n′\\n(θj) is the vector of ﬁrst derivatives and H is the matrix of second\\nderivatives of the log-likelihood.\\nThe EM Algorithm.The letters EM stand for Expectation-Maximization.\\nThe idea is to iterate between taking an expectation then maximizing. Sup-\\npose we have data Y whose density f(y;θ) leads to a log-likelihood that is\\nhard to maximize. But suppose we can ﬁnd another random variable Z such\\nthat f(y;θ)=\\n∫\\nf(y,z ;θ) dz and such that the likelihood based on f(y,z ;θ)\\nis easy to maximize. In other words, the model of interest is the marginal of a\\nmodel with a simpler likelihood. In this case, we callY the observed data and\\nZ the hidden (or latent or missing) data. If we could just “ﬁll in” the missing\\ndata, we would have an easy problem. Conceptually, the EM algorithm works\\nby ﬁlling in the missing data, maximizing the log-likelihood, and iterating.\\n9.49 Example (Mixture of Normals). Sometimes it is reasonable to assume that\\nthe distribution of the data is a mixture of two normals. Think of heights of\\npeople being a mixture of men and women’s heights. Let φ(y;µ, σ) denote\\na normal density with mean µ and standard deviation σ. The density of a\\nmixture of two Normals is\\nf(y;θ)=( 1 − p)φ(y;µ\\n0,σ 0)+ pφ(y;µ1,σ 1).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 159, 'page_label': '160'}, page_content='144 9. Parametric Inference\\nThe idea is that an observation is drawn from the ﬁrst normal with probability\\np and the second with probability 1−p. However, we don’t know which Normal\\nit was drawn from. The parameters are θ =( µ0,σ 0,µ1,σ 1,p ). The likelihood\\nfunction is\\nL(θ)=\\nn∏\\ni=1\\n[(1 − p)φ(yi;µ0,σ 0)+ pφ(yi;µ1,σ 1)].\\nMaximizing this function over the ﬁve parameters is hard. Imaging that we\\nwere given extra information telling us which of the two normals every observa-\\ntion came from. These “complete” data are of the form (Y\\n1,Z1),..., (Yn,Zn),\\nwhere Zi = 0 represents the ﬁrst normal and Zi = 1 represents the second.\\nNote that P(Zi =1 )= p. We shall soon see that the likelihood for the com-\\nplete data (Y1,Z1),..., (Yn,Zn) is much simpler than the likelihood for the\\nobserved data Y1,...,Y n. ■\\nNow we describe the EM algorithm.\\nThe EM Algorithm\\n(0) Pick a starting value θ0. Now for j =1 ,2,..., repeat steps 1 and 2\\nbelow:\\n(1) (The E-step): Calculate\\nJ(θ|θ\\nj)= Eθj\\n\\uf8f6\\nlog f(Y n,Z n;θ)\\nf(Y n,Z n;θj)\\n⏐⏐\\n⏐\\n⏐Y\\nn = yn\\n\\uf8f7\\n.\\nThe expectation is over the missing data Zn treating θi and the observed\\ndata Y n as ﬁxed.\\n(2) Find θj+1 to maximize J(θ|θj).\\nWe now show that the EM algorithm always increases the likelihood, that\\nis, L(θj+1) ≥L (θj). Note that\\nJ(θj+1|θj)= Eθj\\n\\uf8f6\\nlog f(Y n,Z n;θj+1)\\nf(Y n,Z n;θj)\\n⏐⏐\\n⏐\\n⏐Y\\nn = yn\\n\\uf8f7\\n= log f(yn;θj+1)\\nf(yn;θj) + Eθj\\n\\uf8f6\\nlog f(Zn|Y n;θj+1)\\nf(Zn|Y n;θj)\\n⏐⏐\\n⏐\\n⏐Y\\nn = yn\\n\\uf8f7\\nand hence\\nL(θj+1)\\nL(θj) = log f(yn;θj+1)\\nf(yn;θj)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 160, 'page_label': '161'}, page_content='9.13 Appendix 145\\n= J(θj+1|θj) − Eθj\\n\\uf8f6\\nlog f(Zn|Y n;θj+1)\\nf(Zn|Y n;θj)\\n⏐⏐\\n⏐\\n⏐Y\\nn = yn\\n\\uf8f7\\n= J(θj+1|θj)+ K(fj,fj+1)\\nwhere fj = f(yn;θj) andfj+1 = f(yn;θj+1) andK(f,g )=\\n∫\\nf(x) log(f(x)/g(x))dx\\nis the Kullback-Leibler distance. Now, θj+1 was chosen to maximize J(θ|θj).\\nHence, J(θj+1|θj) ≥ J(θj|θj) = 0. Also, by the properties of Kullback-Leibler\\ndivergence, K(fj,fj+1) ≥ 0. Hence, L(θj+1) ≥L (θj) as claimed.\\n9.50 Example (Continuation of Example 9.49). Consider again the mixture of\\ntwo normals but, for simplicity assume thatp =1 /2, σ1 = σ2 = 1. The density\\nis\\nf(y;µ1,µ2)= 1\\n2φ(y;µ0,1) + 1\\n2φ(y;µ1,1).\\nDirectly maximizing the likelihood is hard. Introduce latent variablesZ1,...,Z n\\nwhere Zi =0i f Yi is from φ(y;µ0,1), and Zi =1i f Yi is from φ(y;µ1,1),\\nP(Zi =1 )= P(Zi =0 )=1 /2, f(yi|Zi =0 )= φ(y;µ0,1) and f(yi|Zi =1 )=\\nφ(y;µ1,1). So f(y)= ∑ 1\\nz=0 f(y,z ) where we have dropped the parameters\\nfrom the density to avoid notational overload. We can write\\nf(z,y )= f(z)f(y|z)= 1\\n2φ(y;µ0,1)1−zφ(y;µ1,1)z.\\nHence, the complete likelihood is\\nn∏\\ni=1\\nφ(yi;µ0,1)1−zi φ(yi;µ1,1)zi .\\nThe complete log-likelihood is then\\n˜ℓ = −1\\n2\\nn∑\\ni=1\\n(1 − zi)(yi − µ0) − 1\\n2\\nn∑\\ni=1\\nzi(yi − µ1).\\nAnd so\\nJ(θ|θj)= −1\\n2\\nn∑\\ni=1\\n(1 − E(Zi|yn,θ j))(yi − µ0) − 1\\n2\\nn∑\\ni=1\\nE(Zi|yn,θ j))(yi − µ1).\\nSince Zi is binary, E(Zi|yn,θ j)= P(Zi =1 |yn,θ j) and, by Bayes’ theorem,\\nP(Zi =1 |yn,θ i)= f(yn|Zi =1 ;θj)P(Zi =1 )\\nf(yn|Zi =1 ;θj)P(Zi =1 )+ f(yn|Zi =0 ;θj)P(Zi =0 )\\n= φ(yi;µj\\n1,1)1\\n2\\nφ(yi;µj\\n1,1)1\\n2 + φ(yi;µj\\n0,1)1\\n2\\n= φ(yi;µj\\n1,1)\\nφ(yi;µj\\n1,1) +φ(yi;µj\\n0,1)\\n= τ(i).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 161, 'page_label': '162'}, page_content='146 9. Parametric Inference\\nTake the derivative ofJ(θ|θj) with respect to µ1 and µ2, set them equal to 0\\nto get\\nˆµj+1\\n1 =\\n∑ n\\ni=1 τiyi∑ n\\ni=1 τi\\nand\\nˆµj+1\\n0 =\\n∑ n\\ni=1(1 − τi)yi∑ n\\ni=1(1 − τi) .\\nWe then recompute τi using ˆµj+1\\n1 and ˆµj+1\\n0 and iterate. ■\\n9.14 Exercises\\n1. Let X1,...,X n ∼ Gamma(α, β). Find the method of moments estimator\\nfor α and β.\\n2. Let X1,...,X n ∼ Uniform(a, b) where a and b are unknown parameters\\nand a<b .\\n(a) Find the method of moments estimators for a and b.\\n(b) Find the mle ˆa and ˆb.\\n(c) Let τ =\\n∫\\nxd F(x). Find the mle of τ.\\n(d) Let ˆτ be the mle of τ. Let ˜τ be the nonparametric plug-in estimator\\nof τ =\\n∫\\nxd F(x). Suppose that a =1 , b = 3, and n = 10. Find the mse\\nof ˆτ by simulation. Find the mse of ˜τ analytically. Compare.\\n3. Let X1,...,X n ∼ N(µ, σ2). Let τ be the .95 percentile, i.e.P(X<τ )=\\n.95.\\n(a) Find the mle of τ.\\n(b) Find an expression for an approximate 1− α conﬁdence interval for\\nτ.\\n(c) Suppose the data are:\\n3.23 -2.50 1.88 -0.68 4.43 0.17\\n1.03 -0.07 -0.01 0.76 1.76 3.18\\n0.33 -0.31 0.30 -0.61 1.52 5.43\\n1.54 2.28 0.42 2.33 -1.03 4.00\\n0.39\\nFind the mle ˆτ. Find the standard error using the delta method. Find\\nthe standard error using the parametric bootstrap.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 162, 'page_label': '163'}, page_content='9.14 Exercises 147\\n4. Let X1,...,X n ∼ Uniform(0,θ ). Show that the mle is consistent. Hint:\\nLet Y = max{X1, ..., Xn}. For any c, P(Y< c )= P(X1 <c , X2 <\\nc, ..., Xn <c )= P(X1 <c )P(X2 <c )...P(Xn <c ).\\n5. Let X1,...,X n ∼ Poisson(λ). Find the method of moments estimator,\\nthe maximum likelihood estimator and the Fisher information I(λ).\\n6. Let X1, ..., Xn ∼ N(θ, 1). Deﬁne\\nYi =\\n{\\n1i f Xi > 0\\n0i f Xi ≤ 0.\\nLet ψ = P(Y1 =1 ).\\n(a) Find the maximum likelihood estimator ˆψ of ψ.\\n(b) Find an approximate 95 percent conﬁdence interval for ψ.\\n(c) Deﬁne ˜ψ =( 1/n) ∑\\ni Yi. Show that ˜ψ is a consistent estimator of ψ.\\n(d) Compute the asymptotic relative eﬃciency of ˜ψ to ˆψ. Hint: Use the\\ndelta method to get the standard error of the mle. Then compute the\\nstandard error (i.e. the standard deviation) of ˜ψ.\\n(e) Suppose that the data are not really normal. Show that ˆψ is not\\nconsistent. What, if anything, does ˆψ converge to?\\n7. (Comparing two treatments.) n1 people are given treatment 1 and n2\\npeople are given treatment 2. LetX1 be the number of people on treat-\\nment 1 who respond favorably to the treatment and let X2 be the\\nnumber of people on treatment 2 who respond favorably. Assume that\\nX\\n1 ∼ Binomial(n1,p 1) X2 ∼ Binomial(n2,p 2). Let ψ = p1 − p2.\\n(a) Find the mle ˆψ for ψ.\\n(b) Find the Fisher information matrix I(p1,p 2).\\n(c) Use the multiparameter delta method to ﬁnd the asymptotic stan-\\ndard error of ˆψ.\\n(d) Suppose that n1 = n2 = 200, X1 = 160 and X2 = 148. Find ˆψ. Find\\nan approximate 90 percent conﬁdence interval for ψ using (i) the delta\\nmethod and (ii) the parametric bootstrap.\\n8. Find the Fisher information matrix for Example 9.29.\\n9. Let X\\n1, ..., Xn ∼ Normal(µ,1). Let θ = eµ and let ˆθ = eX be the mle.\\nCreate a data set (using µ = 5) consisting of n=100 observations.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 163, 'page_label': '164'}, page_content='148 9. Parametric Inference\\n(a) Use the delta method to get ˆse and a 95 percent conﬁdence interval\\nfor θ. Use the parametric bootstrap to get ˆse and 95 percent conﬁdence\\ninterval forθ. Use the nonparametric bootstrap to get ˆse and 95 percent\\nconﬁdence interval for θ. Compare your answers.\\n(b) Plot a histogram of the bootstrap replications for the parametric\\nand nonparametric bootstraps. These are estimates of the distribution\\nof ˆθ. The delta method also gives an approximation to this distribution\\nnamely, Normal(ˆθ, se\\n2). Compare these to the true sampling distribu-\\ntion of ˆθ (which you can get by simulation). Which approximation —\\nparametric bootstrap, bootstrap, or delta method — is closer to the true\\ndistribution?\\n10. Let X\\n1, ..., Xn ∼ Uniform(0,θ ). The mle is ˆθ = X(n) = max{X1, ..., Xn}.\\nGenerate a dataset of size 50 with θ =1 .\\n(a) Find the distribution of ˆθ analytically. Compare the true distribu-\\ntion of ˆθ to the histograms from the parametric and nonparametric\\nbootstraps.\\n(b) This is a case where the nonparametric bootstrap does very poorly.\\nShow that for the parametric bootstrap P(ˆθ∗ = ˆθ) = 0, but for the\\nnonparametric bootstrap P(ˆθ∗ = ˆθ) ≈ .632. Hint: show that, P(ˆθ∗ =\\nˆθ)=1 − (1 − (1/n))n then take the limit as n gets large. What is the\\nimplication of this?'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 164, 'page_label': '165'}, page_content='10\\nHypothesis Testing and p-values\\nSuppose we want to know if exposure to asbestos is associated with lung\\ndisease. We take some rats and randomly divide them into two groups. We\\nexpose one group to asbestos and leave the second group unexposed. Then\\nwe compare the disease rate in the two groups. Consider the following two\\nhypotheses:\\nThe Null Hypothesis: The disease rate is the same in the two groups.\\nThe Alternative Hypothesis: The disease rate is not the same in the two\\ngroups.\\nIf the exposed group has a much higher rate of disease than the unexposed\\ngroup then we will reject the null hypothesis and conclude that the evidence\\nfavors the alternative hypothesis. This is an example of hypothesis testing.\\nMore formally, suppose that we partition the parameter space Θ into two\\ndisjoint sets Θ\\n0 and Θ1 and that we wish to test\\nH0 : θ ∈ Θ0 versus H1 : θ ∈ Θ1. (10.1)\\nWe call H0 the null hypothesis and H1 the alternative hypothesis.\\nLet X be a random variable and letX be the range ofX. We test a hypoth-\\nesis by ﬁnding an appropriate subset of outcomesR ⊂X called the rejection'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 165, 'page_label': '166'}, page_content='150 10. Hypothesis Testing and p-values\\nRetain Null Reject Null\\nH0 true √ type I error\\nH1 true type II error √\\nTABLE 10.1. Summary of outcomes of hypothesis testing.\\nregion.I f X ∈ R we reject the null hypothesis, otherwise, we do not reject\\nthe null hypothesis:\\nX ∈ R =⇒ reject H0\\nX/∈ R =⇒ retain (do not reject) H0\\nUsually, the rejection region R is of the form\\nR =\\n{\\nx : T(x) >c\\n}\\n(10.2)\\nwhere T is a test statistic and c is a critical value. The problem in hy-\\npothesis testing is to ﬁnd an appropriate test statistic T and an appropriate\\ncritical value c.\\nWarning! There is a tendency to use hypothesis testing methods even\\nwhen they are not appropriate. Often, estimation and conﬁdence intervals are\\nbetter tools. Use hypothesis testing only when you want to test a well-deﬁned\\nhypothesis.\\nHypothesis testing is like a legal trial. We assume someone is innocent\\nunless the evidence strongly suggests that he is guilty. Similarly, we retainH\\n0\\nunless there is strong evidence to reject H0. There are two types of errors we\\ncan make. Rejecting H0 when H0 is true is called a type I error. Retaining\\nH0 when H1 is true is called a type II error . The possible outcomes for\\nhypothesis testing are summarized in Tab. 10.1.\\n10.1 Deﬁnition. The power function of a test with rejection regionR is\\ndeﬁned by\\nβ(θ)= Pθ(X ∈ R). (10.3)\\nThe size of a test is deﬁned to be\\nα = sup\\nθ∈Θ0\\nβ(θ). (10.4)\\nA test is said to have level α if its size is less than or equal to α.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 166, 'page_label': '167'}, page_content='10. Hypothesis Testing and p-values 151\\nA hypothesis of the formθ = θ0 is called a simple hypothesis. A hypoth-\\nesis of the form θ>θ 0 or θ<θ 0 is called a composite hypothesis. A test\\nof the form\\nH0 : θ = θ0 versus H1 : θ ̸= θ0\\nis called a two-sided test. A test of the form\\nH0 : θ ≤ θ0 versus H1 : θ>θ 0\\nor\\nH0 : θ ≥ θ0 versus H1 : θ<θ 0\\nis called a one-sided test. The most common tests are two-sided.\\n10.2 Example. Let X1,...,X n ∼ N(µ, σ) where σ is known. We want to test\\nH0 : µ ≤ 0 versus H1 : µ> 0. Hence, Θ 0 =( −∞,0] and Θ 1 =( 0 ,∞).\\nConsider the test:\\nreject H0 if T>c\\nwhere T = X. The rejection region is\\nR =\\n{\\n(x1,...,x n): T(x1,...,x n) >c\\n}\\n.\\nLet Z denote a standard Normal random variable. The power function is\\nβ(µ)= Pµ\\n\\uf8f6\\nX>c\\n\\uf8f7\\n= Pµ\\n\\uf8f6√n(X − µ)\\nσ >\\n√n(c − µ)\\nσ\\n\\uf8f7\\n= P\\n\\uf8f6\\nZ>\\n√n(c − µ)\\nσ\\n\\uf8f7\\n=1 − Φ\\n\\uf8f6√n(c − µ)\\nσ\\n\\uf8f7\\n.\\nThis function is increasing in µ. See Figure 10.1. Hence\\nsize = sup\\nµ≤0\\nβ(µ)= β( 0 )=1− Φ\\n\\uf8f6√nc\\nσ\\n\\uf8f7\\n.\\nFor a size α test, we set this equal to α and solve for c to get\\nc = σ Φ−1(1 − α)√n .\\nWe reject when X>σ Φ−1(1 − α)/√n. Equivalently, we reject when\\n√n (X − 0)\\nσ >z α.\\nwhere zα =Φ −1(1 − α). ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 167, 'page_label': '168'}, page_content='152 10. Hypothesis Testing and p-values\\nα\\nµ\\nβ(µ)\\nH0 H1\\nFIGURE 10.1. The power function for Example 10.2. The size of the test is the\\nlargest probability of rejecting H0 when H0 is true. This occurs at µ = 0 hence the\\nsize is β(0). We choose the critical value c so that β(0) = α.\\nIt would be desirable to ﬁnd the test with highest power under H1, among\\nall size α tests. Such a test, if it exists, is called most powerful. Finding\\nmost powerful tests is hard and, in many cases, most powerful tests don’t\\neven exist. Instead of going into detail about when most powerful tests exist,\\nwe’ll just consider four widely used tests: the Wald test,\\n1 the χ2 test, the\\npermutation test, and the likelihood ratio test.\\n10.1 The Wald Test\\nLet θ be a scalar parameter, let ˆθ be an estimate of θ and let ˆse be the\\nestimated standard error of ˆθ.\\n1The test is named after Abraham Wald (1902–1950), who was a very inﬂuential mathe-\\nmatical statistician. Wald died in a plane crash in India in 1950.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 168, 'page_label': '169'}, page_content='10.1 The Wald Test 153\\n10.3 Deﬁnition. The Wald Test\\nConsider testing\\nH0 : θ = θ0 versus H1 : θ ̸= θ0.\\nAssume that ˆθ is asymptotically Normal:\\n(ˆθ − θ0)\\nˆse ⇝ N(0,1).\\nThe size α Wald test is: reject H0 when |W| >z α/2 where\\nW =\\nˆθ − θ0\\nˆse . (10.5)\\n10.4 Theorem. Asymptotically, the Wald test has size α, that is,\\nPθ0\\n\\uf8f6\\n|W| >z α/2\\n\\uf8f7\\n→ α\\nas n →∞ .\\nProof. Under θ = θ0,( ˆθ − θ0)/ˆse ⇝ N(0,1). Hence, the probability of\\nrejecting when the null θ = θ0 is true is\\nPθ0\\n\\uf8f6\\n|W| >z α/2\\n\\uf8f7\\n= Pθ0\\n\\uf8f6\\n|ˆθ − θ0|\\nˆse >z α/2\\n\\uf8f7\\n→ P\\n\\uf8f6\\n|Z| >z α/2\\n\\uf8f7\\n= α\\nwhere Z ∼ N(0,1). ■\\n10.5 Remark. An alternative version of the Wald test statistic is W =( ˆθ −\\nθ0)/se0 where se0 is the standard error computed at θ = θ0. Both versions of\\nthe test are valid.\\nLet us consider the power of the Wald test when the null hypothesis is false.\\n10.6 Theorem. Suppose the true value ofθ is θ⋆ ̸= θ0. The powerβ(θ⋆ ) — the\\nprobability of correctly rejecting the null hypothesis — is given (approximately)\\nby\\n1 − Φ\\n\\uf8f6θ\\n0 − θ⋆\\nˆse + zα/2\\n\\uf8f7\\n+Φ\\n\\uf8f6θ0 − θ⋆\\nˆse − zα/2\\n\\uf8f7\\n. (10.6)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 169, 'page_label': '170'}, page_content='154 10. Hypothesis Testing and p-values\\nRecall that ˆse tends to 0 as the sample size increases. Inspecting (10.6)\\nclosely we note that: (i) the power is large if θ⋆ is far from θ0, and (ii) the\\npower is large if the sample size is large.\\n10.7 Example (Comparing Two Prediction Algorithms). We test a prediction\\nalgorithm on a test set of sizem and we test a second prediction algorithm on\\na second test set of size n. Let X be the number of incorrect predictions for\\nalgorithm 1 and let Y be the number of incorrect predictions for algorithm\\n2. Then X ∼ Binomial(m, p1) and Y ∼ Binomial(n, p2). To test the null\\nhypothesis that p1 = p2 write\\nH0 : δ = 0 versus H1 : δ ̸=0\\nwhere δ = p1 − p2. The mle is ˆδ = ˆp1 − ˆp2 with estimated standard error\\nˆse =\\n√\\nˆp1(1 − ˆp1)\\nm + ˆp2(1 − ˆp2)\\nn .\\nThe size α Wald test is to reject H0 when |W| >z α/2 where\\nW =\\nˆδ − 0\\nˆse = ˆp1 − ˆp2√\\nˆp1(1−ˆp1)\\nm + ˆp2(1−ˆp2)\\nn\\n.\\nThe power of this test will be largest when p1 is far from p2 and when the\\nsample sizes are large.\\nWhat if we used the same test set to test both algorithms? The two samples\\nare no longer independent. Instead we use the following strategy. Let Xi =1\\nif algorithm 1 is correct on test case i and Xi = 0 otherwise. Let Yi =1i f\\nalgorithm 2 is correct on test casei, andYi = 0 otherwise. DeﬁneDi = Xi−Yi.\\nA typical dataset will look something like this:\\nTest Case Xi Yi Di = Xi − Yi\\n1 10 1\\n2 11 0\\n3 11 0\\n4 01 - 1\\n5 00 0\\n..\\n.\\n.\\n.\\n. ..\\n. ..\\n.\\nn\\n01 - 1\\nLet\\nδ = E(Di)= E(Xi) − E(Yi)= P(Xi =1 ) − P(Yi =1 ).\\nThe nonparametric plug-in estimate ofδ is ˆδ = D = n−1 ∑ n\\ni=1 Di and ˆse(ˆδ)=\\nS/√n, where S2 = n−1 ∑ n\\ni=1(Di − D)2. To test H0 : δ = 0 versus H1 : δ ̸=0'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 170, 'page_label': '171'}, page_content='10.1 The Wald Test 155\\nwe use W = ˆδ/ ˆse and reject H0 if |W| >z α/2. This is called a paired\\ncomparison. ■\\n10.8 Example (Comparing Two Means). Let X1,...,X m and Y1, ... , Yn be\\ntwo independent samples from populations with means µ1 and µ2, respec-\\ntively. Let’s test the null hypothesis that µ1 = µ2. Write this as H0 : δ =0\\nversus H1 : δ ̸= 0 where δ = µ1 − µ2. Recall that the nonparametric plug-in\\nestimate of δ is ˆδ = X − Y with estimated standard error\\nˆse =\\n√\\ns2\\n1\\nm + s2\\n2\\nn\\nwhere s2\\n1 and s2\\n2 are the sample variances. The size α Wald test rejects H0\\nwhen |W| >z α/2 where\\nW =\\nˆδ − 0\\nˆse = X − Y√\\ns2\\n1\\nm + s2\\n2\\nn\\n. ■\\n10.9 Example (Comparing Two Medians). Consider the previous example again\\nbut let us test whether the medians of the two distributions are the same.\\nThus, H\\n0 : δ = 0 versus H1 : δ ̸= 0 where δ = ν1 − ν2 where ν1 and ν2 are\\nthe medians. The nonparametric plug-in estimate ofδ is ˆδ = ˆν1 − ˆν2 where ˆν1\\nand ˆν2 are the sample medians. The estimated standard error ˆse of ˆδ can be\\nobtained from the bootstrap. The Wald test statistic is W = ˆδ/ ˆse. ■\\nThere is a relationship between the Wald test and the 1 − α asymptotic\\nconﬁdence interval ˆθ ± ˆse zα/2.\\n10.10 Theorem. The size α Wald test rejects H0 : θ = θ0 versus H1 : θ ̸= θ0\\nif and only if θ0 /∈ C where\\nC =( ˆθ − ˆse zα/2, ˆθ + ˆse zα/2).\\nThus, testing the hypothesis is equivalent to checking whether the null value\\nis in the conﬁdence interval.\\nWarning! When we reject H0 we often say that the result isstatistically\\nsigniﬁcant. A result might be statistically signiﬁcant and yet the size of the\\neﬀect might be small. In such a case we have a result that is statistically sig-\\nniﬁcant but not scientiﬁcally or practically signiﬁcant. The diﬀerence between\\nstatistical signiﬁcance and scientiﬁc signiﬁcance is easy to understand in light\\nof Theorem 10.10. Any conﬁdence interval that excludesθ\\n0 corresponds to re-\\njecting H0. But the values in the interval could be close toθ0 (not scientiﬁcally\\nsigniﬁcant) or far from θ0 (scientiﬁcally signiﬁcant). See Figure 10.2.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 171, 'page_label': '172'}, page_content='156 10. Hypothesis Testing and p-values\\nθ0\\nθ\\nθ0\\nθ\\nFIGURE 10.2. Scientiﬁc signiﬁcance versus statistical signiﬁcance. A level α test\\nrejects H0 : θ = θ0 if and only if the 1 − α conﬁdence interval does not include\\nθ0. Here are two diﬀerent conﬁdence intervals. Both excludeθ0 so in both cases the\\ntest would reject H0. But in the ﬁrst case, the estimated value of θ is close to θ0 so\\nthe ﬁnding is probably of little scientiﬁc or practical value. In the second case, the\\nestimated value of θ is far from θ\\n0 so the ﬁnding is of scientiﬁc value. This shows\\ntwo things. First, statistical signiﬁcance does not imply that a ﬁnding is of scientiﬁc\\nimportance. Second, conﬁdence intervals are often more informative than tests.\\n10.2 p-values\\nReporting “reject H0” or “retain H0” is not very informative. Instead, we\\ncould ask, for every α, whether the test rejects at that level. Generally, if the\\ntest rejects at level α it will also reject at level α′ >α . Hence, there is a\\nsmallest α at which the test rejects and we call this number the p-value. See\\nFigure 10.3.\\n10.11 Deﬁnition. Suppose that for every α ∈ (0,1) we have a size α test\\nwith rejection regionRα. Then,\\np-value = inf\\n{\\nα : T(Xn) ∈ Rα\\n}\\n.\\nThat is, the p-value is the smallest level at which we can reject H0.\\nInformally, the p-value is a measure of the evidence againstH0: the smaller\\nthe p-value, the stronger the evidence against H0. Typically, researchers use\\nthe following evidence scale:'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 172, 'page_label': '173'}, page_content='10.2 p-values 157\\nNo\\nYes\\nReject?\\nα01\\np-value\\nFIGURE 10.3. p-values explained. For each α we can ask: does our test reject H0\\nat level α? The p-value is the smallest α at which we do reject H0. If the evidence\\nagainst H0 is strong, the p-value will be small.\\np-value evidence\\n<. 01 very strong evidence against H0\\n.01 – .05 strong evidence against H0\\n.05 – .10 weak evidence against H0\\n>. 1 little or no evidence against H0\\nWarning! A large p-value is not strong evidence in favor of H0. A large\\np-value can occur for two reasons: (i)H0 is true or (ii) H0 is false but the test\\nhas low power.\\nWarning! Do not confuse the p-value withP(H0|Data). 2 The p-value is\\nnot the probability that the null hypothesis is true.\\nThe following result explains how to compute the p-value.\\n2We discuss quantities like P(H0|Data) in the chapter on Bayesian inference.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 173, 'page_label': '174'}, page_content='158 10. Hypothesis Testing and p-values\\n10.12 Theorem. Suppose that the size α test is of the form\\nreject H0 if and only if T(Xn) ≥ cα.\\nThen,\\np-value = sup\\nθ∈Θ0\\nPθ(T(Xn) ≥ T(xn))\\nwhere xn is the observed value of Xn.I f Θ0 = {θ0} then\\np-value =Pθ0 (T(Xn) ≥ T(xn)).\\nWe can express Theorem 10.12 as follows:\\nThe p-value is the probability (under H0) of observing a value of the\\ntest statistic the same as or more extreme than what was actually\\nobserved.\\n10.13 Theorem. Let w =( ˆθ − θ0)/ˆse denote the observed value of the\\nWald statistic W. The p-value is given by\\np − value =Pθ0 (|W| > |w|) ≈ P(|Z| > |w|) = 2Φ(−|w|) (10.7)\\nwhere Z ∼ N(0,1).\\nTo understand this last theorem, look at Figure 10.4.\\nHere is an important property of p-values.\\n10.14 Theorem. If the test statistic has a continuous distribution, then under\\nH0 : θ = θ0, the p-value has a Uniform (0,1) distribution. Therefore, if we\\nreject H0 when the p-value is less than α, the probability of a type I error is\\nα.\\nIn other words, if H0 is true, the p-value is like a random draw from a\\nUnif(0,1) distribution. If H1 is true, the distribution of the p-value will tend\\nto concentrate closer to 0.\\n10.15 Example. Recall the cholesterol data from Example 7.15. To test if the\\nmeans are diﬀerent we compute\\nW =\\nˆδ − 0\\nˆse = X − Y√\\ns2\\n1\\nm + s2\\n2\\nn\\n= 216.2 − 195.3√\\n52 +2 .42 =3 .78.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 174, 'page_label': '175'}, page_content='10.3 The χ2 Distribution 159\\n|w|−|w|\\nα/2α/2\\nFIGURE 10.4. The p-value is the smallest α at which you would reject H0.T o\\nﬁnd the p-value for the Wald test, we ﬁndα such that |w| and −|w| are just at the\\nboundary of the rejection region. Here,w is the observed value of the Wald statistic:\\nw =( ˆθ − θ0)/ˆse. This implies that the p-value is the tail area P(|Z| > |w|) where\\nZ ∼ N(0, 1).\\nTo compute the p-value, let Z ∼ N(0,1) denote a standard Normal random\\nvariable. Then,\\np-value =P(|Z| > 3.7 8 )=2P(Z< −3.78) = .0002\\nwhich is very strong evidence against the null hypothesis. To test if the me-\\ndians are diﬀerent, let ˆν1 and ˆν2 denote the sample medians. Then,\\nW = ˆν1 − ˆν2\\nˆse = 212.5 − 194\\n7.7 =2 .4\\nwhere the standard error 7.7 was found using the bootstrap. The p-value is\\np-value =P(|Z| > 2.4 )=2 P(Z< −2.4) = .02\\nwhich is strong evidence against the null hypothesis. ■\\n10.3 The χ2 Distribution\\nBefore proceeding we need to discuss the χ2 distribution. Let Z1,...,Z k be\\nindependent, standard Normals. Let V = ∑ k\\ni=1 Z2\\ni . Then we say that V has\\na χ2 distribution with k degrees of freedom, written V ∼ χ2\\nk. The probability\\ndensity of V is\\nf(v)= v(k/2)−1e−v/2\\n2k/2Γ(k/2)\\nfor v> 0. It can be shown thatE(V )= k and V(V )=2 k. We deﬁne the upper\\nα quantile χ2\\nk,α = F−1(1−α) where F is the cdf. That is, P(χ2\\nk >χ 2\\nk,α\\n)= α.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 175, 'page_label': '176'}, page_content='160 10. Hypothesis Testing and p-values\\nt\\nα\\nFIGURE 10.5. The p-value is the smallest α at which we would reject H0.T oﬁ n d\\nthe p-value for the χ2\\nk−1 test, we ﬁnd α such that the observed value t of the test\\nstatistic is just at the boundary of the rejection region. This implies that the p-value\\nis the tail area P(χ\\n2\\nk−1 >t ).\\n10.4 Pearson’s χ2 Test For Multinomial Data\\nPearson’s χ2 test is used for multinomial data. Recall that ifX =( X1,...,X k)\\nhas a multinomial (n, p) distribution, then the mle of p is ˆp =( ˆp1,..., ˆpk)=\\n(X1/ n ,...,X k/n).\\nLet p0 =( p01,...,p 0k) be some ﬁxed vector and suppose we want to test\\nH0 : p = p0 versus H1 : p ̸= p0.\\n10.16 Deﬁnition. Pearson’s χ2 statistic is\\nT =\\nk∑\\nj=1\\n(Xj − np0j)2\\nnp0j\\n=\\nk∑\\nj=1\\n(Xj − Ej)2\\nEj\\nwhere Ej = E(Xj)= np0j is the expected value of Xj under H0.\\n10.17 Theorem. Under H0, T ⇝ χ2\\nk−1. Hence the test: reject H0 if T>\\nχ2\\nk−1,α has asymptotic level α. The p-value is P(χ2\\nk−1 >t ) where t is the\\nobserved value of the test statistic.\\nTheorem 10.17 is illustrated in Figure 10.5.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 176, 'page_label': '177'}, page_content='10.5 The Permutation Test 161\\n10.18 Example (Mendel’s peas). Mendel bred peas with round yellow seeds\\nand wrinkled green seeds. There are four types of progeny: round yellow,\\nwrinkled yellow, round green, and wrinkled green. The number of each type\\nis multinomial with probability p =( p\\n1,p 2,p 3,p 4). His theory of inheritance\\npredicts that p is equal to\\np0 ≡\\n\\uf8f69\\n16, 3\\n16, 3\\n16, 1\\n16\\n\\uf8f7\\n.\\nIn n = 556 trials he observedX = (315,101,108,32). We will testH0 : p = p0\\nversus H1 : p ̸= p0. Since, np01 = 312.75,n p02 = np03 = 104.25, and np04 =\\n34.75, the test statistic is\\nχ2 = (315 − 312.75)2\\n312.75 + (101 − 104.25)2\\n104.25\\n+(108 − 104.25)2\\n104.25 + (32 − 34.75)2\\n34.75 =0 .47.\\nThe α = .05 value for a χ2\\n3 is 7.815. Since 0.47 is not larger than 7.815 we do\\nnot reject the null. The p-value is\\np-value =P(χ2\\n3 >. 47) = .93\\nwhich is not evidence againstH0. Hence, the data do not contradict Mendel’s\\ntheory.3■\\nIn the previous example, one could argue that hypothesis testing is not the\\nright tool. Hypothesis testing is useful to see if there is evidence to rejectH0.\\nThis is appropriate whenH0 corresponds to the status quo. It is not useful for\\nproving that H0 is true. Failure to reject H0 might occur because H0 is true,\\nbut it might occur just because the test has low power. Perhaps a conﬁdence\\nset for the distance between p and p\\n0 might be more useful in this example.\\n10.5 The Permutation Test\\nThe permutation test is a nonparametric method for testing whether two\\ndistributions are the same. This test is “exact,” meaning that it is not based\\non large sample theory approximations. Suppose that X\\n1, ... , Xm ∼ FX and\\nY1, ... , Yn ∼ FY are two independent samples and H0 is the hypothesis that\\n3There is some controversy about whether Mendel’s results are “too good.”'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 177, 'page_label': '178'}, page_content='162 10. Hypothesis Testing and p-values\\nthe two samples are identically distributed. This is the type of hypothesis we\\nwould consider when testing whether a treatment diﬀers from a placebo. More\\nprecisely we are testing\\nH\\n0 : FX = FY versus H1 : FX ̸= FY .\\nLet T(x1,...,x m,y 1,...,y n) be some test statistic, for example,\\nT(X1,...,X m,Y1,...,Y n)= |Xm − Y n|.\\nLet N = m+n and consider forming all N! permutations of the dataX1, ... ,\\nXm,Y1, ... , Yn. For each permutation, compute the test statistic T. Denote\\nthese values by T1,...,T N!. Under the null hypothesis, each of these values is\\nequally likely. 4 The distribution P0 that puts mass 1/N! on each Tj is called\\nthe permutation distribution of T. Let tobs be the observed value of the\\ntest statistic. Assuming we reject when T is large, the p-value is\\np-value =P0(T>t obs)= 1\\nN!\\nN!∑\\nj=1\\nI(Tj >t obs).\\n10.19 Example. Here is a toy example to make the idea clear. Suppose the\\ndata are: ( X1,X 2,Y1)=( 1 ,9,3). Let T(X1,X 2,Y1)= |X − Y | = 2. The\\npermutations are:\\npermutation value of T probability\\n(1,9,3) 2 1/6\\n(9,1,3) 2 1/6\\n(1,3,9) 7 1/6\\n(3,1,9) 7 1/6\\n(3,9,1) 5 1/6\\n(9,3,1) 5 1/6\\nThe p-value is P(T> 2 )=4 /6.\\n■\\nUsually, it is not practical to evaluate allN! permutations. We can approx-\\nimate the p-value by sampling randomly from the set of permutations. The\\nfraction of times T\\nj >t obs among these samples approximates the p-value.\\n4More precisely, under the null hypothesis, given the ordered data values,\\nX1,...,X m,Y 1,...,Y n is uniformly distributed over the N! permutations of the data.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 178, 'page_label': '179'}, page_content='10.5 The Permutation Test 163\\nAlgorithm for Permutation Test\\n1. Compute the observed value of the test statistic\\ntobs = T(X1,...,X m,Y1,...,Y n).\\n2. Randomly permute the data. Compute the statistic again using the\\npermuted data.\\n3. Repeat the previous step B times and let T1,...,T B denote the\\nresulting values.\\n4. The approximate p-value is\\n1\\nB\\nB∑\\nj=1\\nI(Tj >t obs).\\n10.20 Example. DNA microarrays allow researchers to measure the expres-\\nsion levels of thousands of genes. The data are the levels of messenger RNA\\n(mRNA) of each gene, which is thought to provide a measure of how much\\nprotein that gene produces. Roughly, the larger the number, the more active\\nthe gene. The table below, reproduced from Efron et al. (2001) shows the\\nexpression levels for genes from ten patients with two types of liver cancer\\ncells. There are 2,638 genes in this experiment but here we show just the ﬁrst\\ntwo. The data are log-ratios of the intensity levels of two diﬀerent color dyes\\nused on the arrays.\\nType I Type II\\nPatient 1 2 3 4 5 678 9 1 0\\nGene 1 230 -1,350 -1,580 -400 -760 970 110 -50 -190 -200\\nGene 2 470 -850 -.8 -280 120 390 -1730 -1360 -1 -330\\n..\\n.\\n..\\n.\\n..\\n.\\n..\\n.\\n..\\n.\\n..\\n.\\n.\\n.\\n.\\n..\\n.\\n..\\n.\\n..\\n.\\n..\\n.\\nLet’s test whether the median level of gene 1 is diﬀerent between the two\\ngroups. Letν1 denote the median level of gene 1 of Type I and letν2 denote the\\nmedian level of gene 1 of Type II. The absolute diﬀerence of sample medians\\nis T = |ˆν\\n1 − ˆν2| = 710. Now we estimate the permutation distribution by\\nsimulation and we ﬁnd that the estimated p-value is .045. Thus, if we use a\\nα = .05 level of signiﬁcance, we would say that there is evidence to reject the\\nnull hypothesis of no diﬀerence.\\n■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 179, 'page_label': '180'}, page_content='164 10. Hypothesis Testing and p-values\\nIn large samples, the permutation test usually gives similar results to a test\\nthat is based on large sample theory. The permutation test is thus most useful\\nfor small samples.\\n10.6 The Likelihood Ratio Test\\nThe Wald test is useful for testing a scalar parameter. The likelihood ratio\\ntest is more general and can be used for testing a vector-valued parameter.\\n10.21 Deﬁnition. Consider testing\\nH0 : θ ∈ Θ0 versus H1 : θ/∈ Θ0.\\nThe likelihood ratio statistic is\\nλ = 2 log\\n\\uf8f6supθ∈Θ L(θ)\\nsupθ∈Θ0 L(θ)\\n\\uf8f7\\n= 2 log\\n\\uf8f6\\nL(ˆθ)\\nL(ˆθ0)\\n\\uf8f7\\nwhere ˆθ is the mle and ˆθ0 is the mle when θ is restricted to lie in Θ0.\\nYou might have expected to see the maximum of the likelihood over Θ c\\n0\\ninstead of Θ in the numerator. In practice, replacing Θ c\\n0\\nwith Θ has little\\neﬀect on the test statistic. Moreover, the theoretical properties ofλ are much\\nsimpler if the test statistic is deﬁned this way.\\nThe likelihood ratio test is most useful when Θ 0 consists of all parameter\\nvalues θ such that some coordinates of θ are ﬁxed at particular values.\\n10.22 Theorem. Suppose that θ =( θ1,...,θ q,θ q+1,...,θ r).L e t\\nΘ0 = {θ :( θq+1,...,θ r)=( θ0,q+1,...,θ 0,r)}.\\nLet λ be the likelihood ratio test statistic. UnderH0 : θ ∈ Θ0,\\nλ(xn) ⇝ χ2\\nr−q,α\\nwhere r − q is the dimension of Θ minus the dimension of Θ0. The p-value\\nfor the test is P(χ2\\nr−q >λ ).\\nFor example, ifθ =( θ1,θ 2,θ 3,θ 4,θ 5) and we want to test the null hypothesis\\nthat θ4 = θ5 = 0 then the limiting distribution has 5 − 3 = 2 degrees of\\nfreedom.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 180, 'page_label': '181'}, page_content='10.7 Multiple Testing 165\\n10.23 Example (Mendel’s Peas Revisited). Consider example 10.18 again. The\\nlikelihood ratio test statistic for H0 : p = p0 versus H1 : p ̸= p0 is\\nλ = 2 log\\n\\uf8f6L(ˆp)\\nL(p0)\\n\\uf8f7\\n=2\\n4∑\\nj=1\\nXj log\\n\\uf8f6 ˆpj\\np0j\\n\\uf8f7\\n=2\\n\\uf8f6\\n315 log\\n\\uf8f6315\\n556\\n9\\n16\\n\\uf8f7\\n+ 101 log\\n\\uf8f6101\\n556\\n3\\n16\\n\\uf8f7\\n+108 log\\n\\uf8f6108\\n556\\n3\\n16\\n\\uf8f7\\n+ 32 log\\n\\uf8f6 32\\n556\\n1\\n16\\n\\uf8f7\\uf8f7\\n=0 .48.\\nUnder H1 there are four parameters. However, the parameters must sum to\\none so the dimension of the parameter space is three. Under H0 there are no\\nfree parameters so the dimension of the restricted parameter space is zero. The\\ndiﬀerence of these two dimensions is three. Therefore, the limiting distribution\\nof λ under H\\n0 is χ2\\n3 and the p-value is\\np-value =P(χ2\\n3 >. 48) = .92.\\nThe conclusion is the same as with the χ2 test. ■\\nWhen the likelihood ratio test and theχ2 test are both applicable, as in the\\nlast example, they usually lead to similar results as long as the sample size is\\nlarge.\\n10.7 Multiple Testing\\nIn some situations we may conduct many hypothesis tests. In example 10.20,\\nthere were actually 2,638 genes. If we tested for a diﬀerence for each gene,\\nwe would be conducting 2,638 separate hypothesis tests. Suppose each test\\nis conducted at level α. For any one test, the chance of a false rejection of\\nthe null is α. But the chance of at least one false rejection is much higher.\\nThis is themultiple testing problem.The problem comes up in many data\\nmining situations where one may end up testing thousands or even millions of\\nhypotheses. There are many ways to deal with this problem. Here we discuss\\ntwo methods.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 181, 'page_label': '182'}, page_content='166 10. Hypothesis Testing and p-values\\nConsider m hypothesis tests:\\nH0i versus H1i,i =1 ,...,m\\nand let P1,...,P m denote the m p-values for these tests.\\nThe Bonferroni Method\\nGiven p-values P1,...,P m, reject null hypothesis H0i if\\nPi < α\\nm.\\n10.24 Theorem. Using the Bonferroni method, the probability of falsely re-\\njecting any null hypotheses is less than or equal to α.\\nProof. Let R be the event that at least one null hypothesis is falsely\\nrejected. Let Ri be the event that the ith null hypothesis is falsely rejected.\\nRecall that if A1,...,A k are events then P(⋃k\\ni=1 Ai) ≤ ∑ k\\ni=1 P(Ai). Hence,\\nP(R)= P\\n\\uf8f6m⋃\\ni=1\\nRi\\n\\uf8f7\\n≤\\nm∑\\ni=1\\nP(Ri)=\\nm∑\\ni=1\\nα\\nm = α\\nfrom Theorem 10.14. ■\\n10.25 Example. In the gene example, usingα = .05, we have that.05/2,638 =\\n.00001895375. Hence, for any gene with p-value less than .00001895375, we\\ndeclare that there is a signiﬁcant diﬀerence. ■\\nThe Bonferroni method is very conservative because it is trying to make\\nit unlikely that you would make even one false rejection. Sometimes, a more\\nreasonable idea is to control the false discovery rate (FDR) which is de-\\nﬁned as the mean of the number of false rejections divided by the number of\\nrejections.\\nSuppose we reject all null hypotheses whose p-values fall below some thresh-\\nold. Let m\\n0 be the number of null hypotheses that are true and let m1 =\\nm − m0. The tests can be categorized in a 2 × 2 as in Table 10.2.\\nDeﬁne the False Discovery Proportion (FDP)\\nFDP =\\n{ V/R if R> 0\\n0i f R =0 .\\nThe FDP is the proportion of rejections that are incorrect. Next deﬁne FDR =\\nE(FDP).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 182, 'page_label': '183'}, page_content='10.7 Multiple Testing 167\\nH0 Not Rejected H0 Rejected Total\\nH0 True U V m0\\nH0 False T S m1\\nTotal m − R R m\\nTABLE 10.2. Types of outcomes in multiple testing.\\nThe Benjamini-Hochberg (BH) Method\\n1. Let P(1) < ··· <P (m) denote the ordered p-values.\\n2. Deﬁne\\nℓi = iα\\nCmm, and R = max\\n{\\ni : P(i) <ℓ i\\n}\\n(10.8)\\nwhere Cm is deﬁned to be 1 if the p-values are independent and\\nCm = ∑ m\\ni=1(1/i) otherwise.\\n3. Let T = P(R); we call T the BH rejection threshold.\\n4. Reject all null hypotheses H0i for which Pi ≤ T.\\n10.26 Theorem (Benjamini and Hochberg). If the procedure above isapplied,\\nthen regardless of how many nulls are true and regardless of the distribution\\nof the p-values when the null hypothesis is false,\\nFDR = E(FDP) ≤ m\\n0\\nm α ≤ α.\\n10.27 Example. Figure 10.6 shows six ordered p-values plotted as vertical\\nlines. If we tested at levelα without doing any correction for multiple testing,\\nwe would reject all hypotheses whose p-values are less than α. In this case,\\nthe four hypotheses corresponding to the four smallest p-values are rejected.\\nThe Bonferroni method rejects all hypotheses whose p-values are less than\\nα/m. In this case, this leads to no rejections. The BH threshold corresponds\\nto the last p-value that falls under the line with slope α. This leads to two\\nhypotheses being rejected in this case.\\n■\\n10.28 Example. Suppose that 10 independent hypothesis tests are carried\\nleading to the following ordered p-values:\\n0.00017 0.00448 0.00671 0.00907 0.01220\\n0.33626 0.39341 0.53882 0.58125 0.98617'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 183, 'page_label': '184'}, page_content='168 10. Hypothesis Testing and p-values\\n/Bullet/Circle\\n/Bullet/Circle\\n/Bullet/Circle\\n/Bullet/Circle\\n/Bullet/Circle\\n/Bullet/Circle\\nThreshold\\nreject don’t reject\\nα\\nT\\nα/m\\nFIGURE 10.6. The Benjamini-Hochberg (BH) procedure. For uncorrected testing\\nwe reject when Pi <α . For Bonferroni testing we reject when Pi <α / m. The BH\\nprocedure rejects when Pi ≤ T. The BH threshold T corresponds to the rightmost\\nundercrossing of the upward sloping line.\\nWith α =0 .05, the Bonferroni test rejects any hypothesis whose p-value is\\nless than α/1 0=0 .005. Thus, only the ﬁrst two hypotheses are rejected. For\\nthe BH test, we ﬁnd the largesti such that P(i) <i α / m, which in this case is\\ni = 5. Thus we reject the ﬁrst ﬁve hypotheses. ■\\n10.8 Goodness-of-ﬁt Tests\\nThere is another situation where testing arises, namely, when we want to check\\nwhether the data come from an assumed parametric model. There are many\\nsuch tests; here is one.\\nLet F = {f(x;θ): θ ∈ Θ} be a parametric model. Suppose the data take\\nvalues on the real line. Divide the line into k disjoint intervals I\\n1,...,I k.F o r\\nj =1 ,...,k , let\\npj(θ)=\\n∫\\nIj\\nf(x;θ) dx\\nbe the probability that an observation falls into intervalIj under the assumed\\nmodel. Here, θ =( θ1,...,θ s) are the parameters in the assumed model. Let\\nNj be the number of observations that fall intoIj. The likelihood for θ based'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 184, 'page_label': '185'}, page_content='10.9 Bibliographic Remarks 169\\non the counts N1,...,N k is the multinomial likelihood\\nQ(θ)=\\nk∏\\nj=1\\npi(θ)Nj .\\nMaximizing Q(θ) yields estimates ˜θ =( ˜θ1,..., ˜θs)o f θ. Now deﬁne the test\\nstatistic\\nQ =\\nk∑\\nj=1\\n(Nj − npj(˜θ))2\\nnpj(˜θ)\\n. (10.9)\\n10.29 Theorem. Let H0 be the null hypothesis that the data areiiddraws from\\nthe model F = {f(x;θ): θ ∈ Θ}. Under H − 0, the statistic Q deﬁned in\\nequation (10.9) converges in distribution to aχ2\\nk−1−s random variable. Thus,\\nthe (approximate) p-value for the test is P(χ2\\nk−1−s >q ) where q denotes the\\nobserved value of Q.\\nIt is tempting to replace ˜θ in (10.9) with the mle ˆθ. However, this will not\\nresult in a statistic whose limiting distribution is a χ2\\nk−1−s. However, it can\\nbe shown — due to a theorem of Herman Chernoﬀ and Erich Lehmann from\\n1954 — that the p-value is bounded approximately by the p-values obtained\\nusing a χ\\n2\\nk−1−s and a χ2\\nk−1.\\nGoodness-of-ﬁt testing has some serious limitations. If reject H0 then we\\nconclude we should not use the model. But if we do not reject H0 we can-\\nnot conclude that the model is correct. We may have failed to reject simply\\nbecause the test did not have enough power. This is why it is better to use\\nnonparametric methods whenever possible rather than relying on parametric\\nassumptions.\\n10.9 Bibliographic Remarks\\nThe most complete book on testing is Lehmann (1986). See also Chapter 8 of\\nCasella and Berger (2002) and Chapter 9 of Rice (1995). The FDR method is\\ndue to Benjamini and Hochberg (1995). Some of the exercises are from Rice\\n(1995).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 185, 'page_label': '186'}, page_content='170 10. Hypothesis Testing and p-values\\n10.10 Appendix\\n10.10.1 The Neyman-Pearson Lemma\\nIn the special case of a simple null H0 : θ = θ0 and a simple alternative\\nH1 : θ = θ1 we can say precisely what the most powerful test is.\\n10.30 Theorem (Neyman-Pearson). Suppose we test H0 : θ = θ0 versus H1 :\\nθ = θ1.L e t\\nT = L(θ1)\\nL(θ0) =\\n∏n\\ni=1 f(xi;θ1)∏n\\ni=1 f(xi;θ0).\\nSuppose we reject H0 when T>k . If we choose k so that Pθ0 (T>k )= α\\nthen this test is the most powerful, size α test. That is, among all tests with\\nsize α, this test maximizes the power β(θ1).\\n10.10.2 The t-test\\nTo test H0 : µ = µ0 where µ = E(Xi) is the mean, we can use the Wald test.\\nWhen the data are assumed to be Normal and the sample size is small, it is\\ncommon instead to use the t-test. A random variable T has a t-distribution\\nwith k degrees of freedomif it has density\\nf(t)= Γ\\n\\uf8f6\\nk+1\\n2\\n\\uf8f7\\n√\\nkπΓ\\n\\uf8f6k\\n2\\n\\uf8f7\\uf8f6\\n1+ t2\\nk\\n\\uf8f7(k+1)/2 .\\nWhen the degrees of freedom k →∞ , this tends to a Normal distribution.\\nWhen k = 1 it reduces to a Cauchy.\\nLet X1,...,X n ∼ N(µ, σ2) where θ =( µ, σ2) are both unknown. Suppose\\nwe want to test µ = µ0 versus µ ̸= µ0. Let\\nT =\\n√n(Xn − µ0)\\nSn\\nwhere S2\\nn is the sample variance. For large samples T ≈ N(0,1) under H0.\\nThe exact distribution of T under H0 is tn−1. Hence if we reject when |T| >\\ntn−1,α/2 then we get a size α test. However, when n is moderately large, the\\nt-test is essentially identical to the Wald test.\\n10.11 Exercises\\n1. Prove Theorem 10.6.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 186, 'page_label': '187'}, page_content='10.11 Exercises 171\\n2. Prove Theorem 10.14.\\n3. Prove Theorem 10.10.\\n4. Prove Theorem 10.12.\\n5. Let X\\n1, ..., Xn ∼ Uniform(0,θ ) and let Y = max{X1, ..., Xn}.W ew a n t\\nto test\\nH0 : θ =1 /2 versus H1 : θ> 1/2.\\nThe Wald test is not appropriate sinceY does not converge to a Normal.\\nSuppose we decide to test this hypothesis by rejecting H0 when Y> c .\\n(a) Find the power function.\\n(b) What choice of c will make the size of the test .05?\\n(c) In a sample of size n = 20 with Y=0.48 what is the p-value? What\\nconclusion about H\\n0 would you make?\\n(d) In a sample of size n = 20 with Y=0.52 what is the p-value? What\\nconclusion about H0 would you make?\\n6. There is a theory that people can postpone their death until after an\\nimportant event. To test the theory, Phillips and King (1988) collected\\ndata on deaths around the Jewish holiday Passover. Of 1919 deaths, 922\\ndied the week before the holiday and 997 died the week after. Think of\\nthis as a binomial and test the null hypothesis thatθ =1 /2. Report and\\ninterpret the p-value. Also construct a conﬁdence interval forθ.\\n7. In 1861, 10 essays appeared in the New Orleans Daily Crescent. They\\nwere signed “Quintus Curtius Snodgrass” and some people suspected\\nthey were actually written by Mark Twain. To investigate this, we will\\nconsider the proportion of three letter words found in an author’s work.\\nFrom eight Twain essays we have:\\n.225 .262 .217 .240 .230 .229 .235 .217\\nFrom 10 Snodgrass essays we have:\\n.209 .205 .196 .210 .202 .207 .224 .223 .220 .201\\n(a) Perform a Wald test for equality of the means. Use the nonparamet-\\nric plug-in estimator. Report the p-value and a 95 per cent conﬁdence\\ninterval for the diﬀerence of means. What do you conclude?\\n(b) Now use a permutation test to avoid the use of large sample methods.\\nWhat is your conclusion? (Brinegar (1963)).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 187, 'page_label': '188'}, page_content='172 10. Hypothesis Testing and p-values\\n8. Let X1,...,X n ∼ N(θ, 1). Consider testing\\nH0 : θ = 0 versus θ =1 .\\nLet the rejection region be R = {xn : T(xn) >c } where T(xn)=\\nn−1 ∑ n\\ni=1 Xi.\\n(a) Find c so that the test has size α.\\n(b) Find the power under H1, that is, ﬁnd β(1).\\n(c) Show that β(1) → 1a s n →∞ .\\n9. Let ˆθ be the mle of a parameter θ and let ˆse = {nI(ˆθ)}−1/2 where I(θ)\\nis the Fisher information. Consider testing\\nH0 : θ = θ0 versus θ ̸= θ0.\\nConsider the Wald test with rejection region R = {xn : |Z| >z α/2}\\nwhere Z =( ˆθ − θ0)/ˆse. Let θ1 >θ 0 be some alternative. Show that\\nβ(θ1) → 1.\\n10. Here are the number of elderly Jewish and Chinese women who died\\njust before and after the Chinese Harvest Moon Festival.\\nWeek Chinese Jewish\\n-2 55 141\\n-1 33 145\\n1 70 139\\n2 49 161\\nCompare the two mortality patterns. (Phillips and Smith (1990)).\\n11. A randomized, double-blind experiment was conducted to assess the\\neﬀectiveness of several drugs for reducing postoperative nausea. The\\ndata are as follows.\\nNumber of Patients Incidence of Nausea\\nPlacebo 80 45\\nChlorpromazine 75 26\\nDimenhydrinate 85 52\\nPentobarbital (100 mg) 67 35\\nPentobarbital (150 mg) 85 37'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 188, 'page_label': '189'}, page_content='10.11 Exercises 173\\n(a) Test each drug versus the placebo at the 5 per cent level. Also, report\\nthe estimated odds–ratios. Summarize your ﬁndings.\\n(b) Use the Bonferroni and the FDR method to adjust for multiple\\ntesting. (Beecher (1959)).\\n12. Let X1, ..., Xn ∼ Poisson(λ).\\n(a) Let λ0 > 0. Find the size α Wald test for\\nH0 : λ = λ0 versus H1 : λ ̸= λ0.\\n(b) (Computer Experiment.) Let λ0 =1 , n = 20 and α = .05. Simulate\\nX1,...,X n ∼ Poisson(λ0) and perform the Wald test. Repeat many\\ntimes and count how often you reject the null. How close is the type I\\nerror rate to .05?\\n13. Let X\\n1,...,X n ∼ N(µ, σ2). Construct the likelihood ratio test for\\nH0 : µ = µ0 versus H1 : µ ̸= µ0.\\nCompare to the Wald test.\\n14. Let X1,...,X n ∼ N(µ, σ2). Construct the likelihood ratio test for\\nH0 : σ = σ0 versus H1 : σ ̸= σ0.\\nCompare to the Wald test.\\n15. Let X ∼ Binomial(n, p). Construct the likelihood ratio test for\\nH0 : p = p0 versus H1 : p ̸= p0.\\nCompare to the Wald test.\\n16. Let θ be a scalar parameter and suppose we test\\nH0 : θ = θ0 versus H1 : θ ̸= θ0.\\nLet W be the Wald test statistic and let λ be the likelihood ratio test\\nstatistic. Show that these tests are equivalent in the sense that\\nW2\\nλ\\nP\\n−→1\\nas n →∞ . Hint: Use a Taylor expansion of the log-likelihood ℓ(θ)t o\\nshow that\\nλ ≈\\n\\uf8f6√n(ˆθ − θ0)\\n\\uf8f72\\uf8f6\\n− 1\\nnℓ′′(ˆθ)\\n\\uf8f7\\n.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 189, 'page_label': '190'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 190, 'page_label': '191'}, page_content='11\\nBayesian Inference\\n11.1 The Bayesian Philosophy\\nThe statistical methods that we have discussed so far are known asfrequen-\\ntist (or classical) methods. The frequentist point of view is based on the\\nfollowing postulates:\\nF1 Probability refers to limiting relative frequencies. Probabilities are ob-\\njective properties of the real world.\\nF2 Parameters are ﬁxed, unknown constants. Because they are not ﬂuctu-\\nating, no useful probability statements can be made about parameters.\\nF3 Statistical procedures should be designed to have well-deﬁned long run\\nfrequency properties. For example, a 95 percent conﬁdence interval should\\ntrap the true value of the parameter with limiting frequency at least 95\\npercent.\\nThere is another approach to inference called Bayesian inference. The\\nBayesian approach is based on the following postulates:'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 191, 'page_label': '192'}, page_content='176 11. Bayesian Inference\\nB1 Probability describes degree of belief, not limiting frequency. As such,\\nwe can make probability statements about lots of things, not just data\\nwhich are subject to random variation. For example, I might say that\\n“the probability that Albert Einstein drank a cup of tea on August 1,\\n1948” is .35. This does not refer to any limiting frequency. It reﬂects my\\nstrength of belief that the proposition is true.\\nB2 We can make probability statements about parameters, even though\\nthey are ﬁxed constants.\\nB3 We make inferences about a parameter θ by producing a probability\\ndistribution for θ. Inferences, such as point estimates and interval esti-\\nmates, may then be extracted from this distribution.\\nBayesian inference is a controversial approach because it inherently em-\\nbraces a subjective notion of probability. In general, Bayesian methods pro-\\nvide no guarantees on long run performance. The ﬁeld of statistics puts more\\nemphasis on frequentist methods although Bayesian methods certainly have\\na presence. Certain data mining and machine learning communities seem to\\nembrace Bayesian methods very strongly. Let’s put aside philosophical ar-\\nguments for now and see how Bayesian inference is done. We’ll conclude this\\nchapter with some discussion on the strengths and weaknesses of the Bayesian\\napproach.\\n11.2 The Bayesian Method\\nBayesian inference is usually carried out in the following way.\\n1. We choose a probability density f(θ) — called the prior distribution\\n— that expresses our beliefs about a parameter θ before we see any\\ndata.\\n2. We choose a statistical model f(x|θ) that reﬂects our beliefs about x\\ngiven θ. Notice that we now write this as f(x|θ) instead of f(x;θ).\\n3. After observing data X1,...,X n, we update our beliefs and calculate\\nthe posterior distribution f(θ|X1,...,X n).\\nTo see how the third step is carried out, ﬁrst suppose that θ is discrete and\\nthat there is a single, discrete observation X. We should use a capital letter'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 192, 'page_label': '193'}, page_content='11.2 The Bayesian Method 177\\nnow to denote the parameter since we are treating it like a random variable,\\nso let Θ denote the parameter. Now, in this discrete setting,\\nP(Θ = θ|X = x)= P(X = x,Θ= θ)\\nP(X = x)\\n= P(X = x|Θ= θ)P(Θ = θ)∑\\nθ P(X = x|Θ= θ)P(Θ = θ)\\nwhich you may recognize from Chapter 1 as Bayes’ theorem. The version\\nfor continuous variables is obtained by using density functions:\\nf(θ|x)= f(x|θ)f(θ)∫\\nf(x|θ)f(θ)dθ. (11.1)\\nIf we have n iid observations X1,...,X n, we replace f(x|θ) with\\nf(x1,...,x n|θ)=\\nn∏\\ni=1\\nf(xi|θ)= Ln(θ).\\nNotation.We will writeXn to mean (X1,...,X n) andxn to mean (x1,...,x n).\\nNow,\\nf(θ|xn)= f(xn|θ)f(θ)∫\\nf(xn|θ)f(θ)dθ = Ln(θ)f(θ)\\ncn\\n∝L n(θ)f(θ) (11.2)\\nwhere\\ncn =\\n∫\\nLn(θ)f(θ)dθ (11.3)\\nis called the normalizing constant. Note that cn does not depend on θ.W e\\ncan summarize by writing:\\nPosterior is proportional to Likelihood times Prior\\nor, in symbols,\\nf(θ|xn) ∝L (θ)f(θ).\\nYou might wonder, doesn’t it cause a problem to throw away the constant\\ncn? The answer is that we can always recover the constant later if we need to.\\nWhat do we do with the posterior distribution? First, we can get a point\\nestimate by summarizing the center of the posterior. Typically, we use the\\nmean or mode of the posterior. The posterior mean is\\nθn =\\n∫\\nθf(θ|xn)dθ =\\n∫\\nθLn(θ)f(θ)∫\\nLn(θ)f(θ)dθ. (11.4)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 193, 'page_label': '194'}, page_content='178 11. Bayesian Inference\\nWe can also obtain a Bayesian interval estimate. We ﬁnd a and b such that∫a\\n−∞ f(θ|xn)dθ =\\n∫∞\\nb f(θ|xn)dθ = α/2. Let C =( a, b). Then\\nP(θ ∈ C|xn)=\\n∫ b\\na\\nf(θ|xn) dθ =1 − α\\nso C is a 1 − α posterior interval.\\n11.1 Example. Let X1,...,X n ∼ Bernoulli(p). Suppose we take the uniform\\ndistribution f(p) = 1 as a prior. By Bayes’ theorem, the posterior has the\\nform\\nf(p|xn) ∝ f(p)Ln(p)= ps(1 − p)n−s = ps+1−1(1 − p)n−s+1−1\\nwhere s = ∑ n\\ni=1 xi is the number of successes. Recall that a random variable\\nhas a Beta distribution with parameters α and β if its density is\\nf(p; α, β)= Γ(α + β)\\nΓ(α)Γ(β)pα−1(1 − p)β−1.\\nWe see that the posterior for p is a Beta distribution with parameters s +1\\nand n − s + 1. That is,\\nf(p|xn)= Γ(n +2 )\\nΓ(s + 1)Γ(n − s +1 )p(s+1)−1(1 − p)(n−s+1)−1.\\nWe write this as\\np|xn ∼ Beta(s +1 ,n − s +1 ).\\nNotice that we have ﬁgured out the normalizing constant without actually\\ndoing the integral\\n∫\\nLn(p)f(p)dp. The mean of a Beta( α, β) distribution is\\nα/(α + β) so the Bayes estimator is\\np = s +1\\nn +2 . (11.5)\\nIt is instructive to rewrite the estimator as\\np = λnˆp +( 1− λn)˜p (11.6)\\nwhere ˆp = s/n is the mle, ˜p =1 /2 is the prior mean andλn = n/(n+2 )≈ 1.\\nA 95 percent posterior interval can be obtained by numerically ﬁndinga and\\nb such that\\n∫b\\na f(p|xn) dp = .95.\\nSuppose that instead of a uniform prior, we use the prior p ∼ Beta(α, β).\\nIf you repeat the calculations above, you will see thatp|xn ∼ Beta(α + s, β+'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 194, 'page_label': '195'}, page_content='11.2 The Bayesian Method 179\\nn − s). The ﬂat prior is just the special case with α = β = 1. The posterior\\nmean is\\np = α + s\\nα + β + n =\\n\\uf8f6 n\\nα + β + n\\n\\uf8f7\\nˆp +\\n\\uf8f6 α + β\\nα + β + n\\n\\uf8f7\\np0\\nwhere p0 = α/(α + β) is the prior mean. ■\\nIn the previous example, the prior was a Beta distribution and the posterior\\nwas a Beta distribution. When the prior and the posterior are in the same\\nfamily, we say that the prior is conjugate with respect to the model.\\n11.2 Example. Let X\\n1,...,X n ∼ N(θ,σ 2). For simplicity, let us assume that\\nσ is known. Suppose we take as a prior θ ∼ N(a, b2). In problem 1 in the\\nexercises it is shown that the posterior for θ is\\nθ|Xn ∼ N(θ,τ 2) (11.7)\\nwhere\\nθ = wX +( 1− w)a,\\nw =\\n1\\nse2\\n1\\nse2 + 1\\nb2\\n, 1\\nτ2 = 1\\nse2 + 1\\nb2 ,\\nand se = σ/√n is the standard error of the mle X. This is another example\\nof a conjugate prior. Note that w → 1 and τ/se → 1a s n →∞ . So, for large\\nn, the posterior is approximately N(ˆθ, se2). The same is true if n is ﬁxed but\\nb →∞ , which corresponds to letting the prior become very ﬂat.\\nContinuing with this example, let us ﬁnd C =( c, d) such that P(θ ∈\\nC|Xn)= .95. We can do this by choosing c and d such that P(θ<c |Xn)=\\n.025 and P(θ>d |Xn)= .025. So, we want to ﬁnd c such that\\nP(θ<c |Xn)= P\\n\\uf8f6\\nθ − θ\\nτ < c − θ\\nτ\\n⏐⏐\\n⏐\\n⏐\\n⏐X\\nn\\n\\uf8f7\\n= P\\n\\uf8f6\\nZ< c − θ\\nτ\\n\\uf8f7\\n= .025.\\nWe know that P(Z< −1.96) = .025. So,\\nc − θ\\nτ = −1.96\\nimplying thatc = θ−1.96τ. By similar arguments,d = θ+1.96. So a 95 percent\\nBayesian interval isθ±1.96 τ. Since θ ≈ ˆθ and τ ≈ se, the 95 percent Bayesian\\ninterval is approximated by ˆθ ± 1.96 se which is the frequentist conﬁdence\\ninterval. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 195, 'page_label': '196'}, page_content='180 11. Bayesian Inference\\n11.3 Functions of Parameters\\nHow do we make inferences about a functionτ = g(θ)? Remember in Chapter\\n3 we solved the following problem: given the densityfX for X, ﬁnd the density\\nfor Y = g(X). We now simply apply the same reasoning. The posterior cdf\\nfor τ is\\nH(τ|xn)= P(g(θ) ≤ τ|xn)=\\n∫\\nA\\nf(θ|xn)dθ\\nwhere A = {θ : g(θ) ≤ τ}. The posterior density is h(τ|xn)= H′(τ|xn).\\n11.3 Example. Let X1,...,X n ∼ Bernoulli(p) and f(p) = 1 so that p|Xn ∼\\nBeta(s +1 ,n − s + 1) with s = ∑ n\\ni=1 xi. Let ψ = log(p/(1 − p)). Then\\nH(ψ|xn)= P(Ψ ≤ ψ|xn)= P\\n\\uf8f6\\nlog\\n\\uf8f6 P\\n1 − P\\n\\uf8f7\\n≤ ψ\\n⏐⏐\\n⏐\\n⏐\\n⏐x\\nn\\n\\uf8f7\\n= P\\n\\uf8f6\\nP ≤ eψ\\n1+ eψ\\n⏐⏐\\n⏐\\n⏐\\n⏐x\\nn\\n\\uf8f7\\n=\\n∫ eψ/(1+eψ)\\n0\\nf(p|xn) dp\\n= Γ(n +2 )\\nΓ(s + 1)Γ(n − s +1 )\\n∫ eψ/(1+eψ)\\n0\\nps(1 − p)n−s dp\\nand\\nh(ψ|xn)= H′(ψ|xn)\\n= Γ(n +2 )\\nΓ(s + 1)Γ(n − s +1 )\\n\\uf8f6 eψ\\n1+ eψ\\n\\uf8f7s \\uf8f6 1\\n1+ eψ\\n\\uf8f7n−s\\n\\uf8eb\\n\\uf8ed\\n∂\\n\\uf8f6\\neψ\\n1+eψ\\n\\uf8f7\\n∂ψ\\n\\uf8f6\\n\\uf8f8\\n= Γ(n +2 )\\nΓ(s + 1)Γ(n − s +1 )\\n\\uf8f6 eψ\\n1+ eψ\\n\\uf8f7s \\uf8f6 1\\n1+ eψ\\n\\uf8f7n−s \\uf8f6 1\\n1+ eψ\\n\\uf8f72\\n= Γ(n +2 )\\nΓ(s + 1)Γ(n − s +1 )\\n\\uf8f6 eψ\\n1+ eψ\\n\\uf8f7s \\uf8f6 1\\n1+ eψ\\n\\uf8f7n−s+2\\nfor ψ ∈ R. ■\\n11.4 Simulation\\nThe posterior can often be approximated by simulation. Suppose we draw\\nθ1,...,θ B ∼ p(θ|xn). Then a histogram ofθ1,...,θ B approximates the poste-\\nrior density p(θ|xn). An approximation to the posterior meanθn = E(θ|xn)i s'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 196, 'page_label': '197'}, page_content='11.5 Large Sample Properties of Bayes’ Procedures 181\\nB−1 ∑ B\\nj=1 θj. The posterior 1−α interval can be approximated by (θα/2,θ 1−α/2)\\nwhere θα/2 is the α/2 sample quantile of θ1,...,θ B.\\nOnce we have a sample θ1,...,θ B from f(θ|xn), let τi = g(θi). Then\\nτ1,...,τ B is a sample fromf(τ|xn). This avoids the need to do any analytical\\ncalculations. Simulation is discussed in more detail in Chapter 24.\\n11.4 Example. Consider again Example 11.3. We can approximate the pos-\\nterior for ψ without doing any calculus. Here are the steps:\\n1. Draw P1,...,P B ∼ Beta(s +1 ,n − s + 1).\\n2. Let ψi = log(Pi/(1 − Pi)) for i =1 ,...,B .\\nNow ψ1,...,ψ B are iid draws from h(ψ|xn). A histogram of these values\\nprovides an estimate of h(ψ|xn). ■\\n11.5 Large Sample Properties of Bayes’ Procedures\\nIn the Bernoulli and Normal examples we saw that the posterior mean was\\nclose to the mle. This is true in greater generality.\\n11.5 Theorem. Let ˆθn be themle and let ˆse =1 /\\n√\\nnI(ˆθn). Under appropriate\\nregularity conditions, the posterior is approximately Normal with meanˆθn and\\nstandard deviation ˆse. Hence, θn ≈ ˆθn. Also, ifCn =( ˆθn −zα/2 ˆse, ˆθn +zα/2 ˆse)\\nis the asymptotic frequentist 1 − α conﬁdence interval, then Cn is also an\\napproximate 1 − α Bayesian posterior interval:\\nP(θ ∈ Cn|Xn) → 1 − α.\\nThere is also a Bayesian delta method. Let τ = g(θ). Then\\nτ|Xn ≈ N(ˆτ, ˜se2)\\nwhere ˆτ = g(ˆθ) and ˜se = ˆse |g′(ˆθ)|.\\n11.6 Flat Priors, Improper Priors, and\\n“Noninformative” Priors\\nAn important question in Bayesian inference is: where does one get the prior\\nf(θ)? One school of thought, called subjectivism says that the prior should'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 197, 'page_label': '198'}, page_content='182 11. Bayesian Inference\\nreﬂect our subjective opinion aboutθ (before the data are collected). This may\\nbe possible in some cases but is impractical in complicated problems especially\\nif there are many parameters. Moreover, injecting subjective opinion into the\\nanalysis is contrary to the goal of making scientiﬁc inference as objective\\nas possible. An alternative is to try to deﬁne some sort of “noninformative\\nprior.” An obvious candidate for a noninformative prior is to use a ﬂat prior\\nf(θ) ∝ constant.\\nIn the Bernoulli example, taking f(p) = 1 leads to p|X\\nn ∼ Beta(s +1 ,n −\\ns + 1) as we saw earlier, which seemed very reasonable. But unfettered use of\\nﬂat priors raises some questions.\\nImproper Priors. Let X ∼ N(θ,σ 2) with σ known. Suppose we adopt\\na ﬂat prior f(θ) ∝ c where c> 0 is a constant. Note that\\n∫\\nf(θ)dθ = ∞ so\\nthis is not a probability density in the usual sense. We call such a prior an\\nimproper prior. Nonetheless, we can still formally carry out Bayes’ theorem\\nand compute the posterior density by multiplying the prior and the likelihood:\\nf(θ) ∝L\\nn(θ)f(θ) ∝L n(θ). This gives θ|Xn ∼ N(X,σ 2/n) and the resulting\\npoint and interval estimators agree exactly with their frequentist counterparts.\\nIn general, improper priors are not a problem as long as the resulting posterior\\nis a well-deﬁned probability distribution.\\nFlat Priors are Not Invariant.Let X ∼ Bernoulli(p) and suppose we\\nuse the ﬂat prior f(p) = 1. This ﬂat prior presumably represents our lack of\\ninformation about p before the experiment. Now let ψ = log(p/(1 − p)). This\\nis a transformation of p and we can compute the resulting distribution for ψ,\\nnamely,\\nf\\nΨ(ψ)= eψ\\n(1 +eψ)2\\nwhich is not ﬂat. But if we are ignorant about p then we are also ignorant\\nabout ψ so we should use a ﬂat prior for ψ. This is a contradiction. In short,\\nthe notion of a ﬂat prior is not well deﬁned because a ﬂat prior on a parameter\\ndoes not imply a ﬂat prior on a transformed version of the parameter. Flat\\npriors are not transformation invariant.\\nJeffreys’ Prior. Jeﬀreys came up with a rule for creating priors. The\\nrule is: take\\nf(θ) ∝ I(θ)\\n1/2\\nwhere I(θ) is the Fisher information function. This rule turns out to be trans-\\nformation invariant. There are various reasons for thinking that this prior\\nmight be a useful prior but we will not go into details here.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 198, 'page_label': '199'}, page_content='11.7 Multiparameter Problems 183\\n11.6 Example. Consider the Bernoulli (p) model. Recall that\\nI(p)= 1\\np(1 − p).\\nJeﬀreys’ rule says to use the prior\\nf(p) ∝\\n√\\nI(p)= p−1/2(1 − p)−1/2.\\nThis is a Beta (1/2,1/2) density. This is very close to a uniform density.■\\nIn a multiparameter problem, the Jeﬀreys’ prior is deﬁned to be f(θ) ∝√\\n|I(θ)| where |A| denotes the determinant of a matrix A and I(θ)i st h e\\nFisher information matrix.\\n11.7 Multiparameter Problems\\nSuppose that θ =( θ1,...,θ p). The posterior density is still given by\\nf(θ|xn) ∝L n(θ)f(θ). (11.8)\\nThe question now arises of how to extract inferences about one parameter.\\nThe key is to ﬁnd the marginal posterior density for the parameter of interest.\\nSuppose we want to make inferences about θ\\n1. The marginal posterior for θ1\\nis\\nf(θ1|xn)=\\n∫\\n···\\n∫\\nf(θ1,··· ,θ p|xn)dθ2 ...d θ p. (11.9)\\nIn practice, it might not be feasible to do this integral. Simulation can help.\\nDraw randomly from the posterior:\\nθ1,...,θ B ∼ f(θ|xn)\\nwhere the superscripts index the diﬀerent draws. Each θj is a vector θj =\\n(θj\\n1,...,θ j\\np). Now collect together the ﬁrst component of each draw:\\nθ1\\n1,...,θ B\\n1 .\\nThese are a sample from f(θ1|xn) and we have avoided doing any integrals.\\n11.7 Example (Comparing Two Binomials). Suppose we have n1 control pa-\\ntients and n2 treatment patients and that X1 control patients survive while\\nX2 treatment patients survive. We want to estimate τ = g(p1,p 2)= p2 − p1.\\nThen,\\nX1 ∼ Binomial(n1,p 1) and X2 ∼ Binomial(n2,p 2).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 199, 'page_label': '200'}, page_content='184 11. Bayesian Inference\\nIf f(p1,p 2) = 1, the posterior is\\nf(p1,p 2|x1,x2) ∝ px1\\n1 (1 − p1)n1−x1 px2\\n2 (1 − p2)n2−x2 .\\nNotice that (p1,p 2) live on a rectangle (a square, actually) and that\\nf(p1,p 2|x1,x2)= f(p1|x1)f(p2|x2)\\nwhere\\nf(p1|x1) ∝ px1\\n1 (1 − p1)n1−x1 and f(p2|x2) ∝ px2\\n2 (1 − p2)n2−x2\\nwhich implies that p1 and p2 are independent under the posterior. Also,\\np1|x1 ∼ Beta(x1 +1 ,n 1 − x1 + 1) and p2|x2 ∼ Beta(x2 +1 ,n 2 − x2 + 1).\\nIf we simulate P1,1,...,P 1,B ∼ Beta(x1 +1 ,n 1 − x1 + 1) andP2,1,...,P 2,B ∼\\nBeta(x2 +1,n 2 −x2 +1), then τb = P2,b −P1,b, b =1 ,...,B , is a sample from\\nf(τ|x1,x2). ■\\n11.8 Bayesian Testing\\nHypothesis testing from a Bayesian point of view is a complex topic. We\\nwill only give a brief sketch of the main idea here. The Bayesian approach\\nto testing involves putting a prior on H\\n0 and on the parameter θ and then\\ncomputing P(H0|Xn). Consider the case where θ is scalar and we are testing\\nH0 : θ = θ0 versus H1 : θ ̸= θ0.\\nIt is usually reasonable to use the prior P(H0)= P(H1)=1 /2 (although this\\nis not essential in what follows). Under H1 we need a prior for θ. Denote this\\nprior density by f(θ). From Bayes’ theorem\\nP(H0|Xn = xn)= f(xn|H0)P(H0)\\nf(xn|H0)P(H0)+ f(xn|H1)P(H1)\\n=\\n1\\n2f(xn | θ0)\\n1\\n2f(xn | θ0)+ 1\\n2f(xn | H1)\\n= f(xn | θ0)\\nf(xn | θ0)+\\n∫\\nf(xn | θ)f(θ)dθ\\n= L(θ0)\\nL(θ0)+\\n∫\\nL(θ)f(θ)dθ.\\nWe saw that, in estimation problems, the prior was not very inﬂuential and\\nthat the frequentist and Bayesian methods gave similar answers. This is not'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 200, 'page_label': '201'}, page_content='11.9 Strengths and Weaknesses of Bayesian Inference 185\\nthe case in hypothesis testing. Also, one can’t use improper priors in testing\\nbecause this leads to an undeﬁned constant in the denominator of the expres-\\nsion above. Thus, if you use Bayesian testing you must choose the priorf(θ)\\nvery carefully. It is possible to get a prior-free bound on P(H\\n0|Xn = xn).\\nNotice that 0 ≤\\n∫\\nL(θ)f(θ)dθ ≤L (ˆθ). Hence,\\nL(θ0)\\nL(θ0)+ L(ˆθ)\\n≤ P(H0|Xn = xn) ≤ 1.\\nThe upper bound is not very interesting, but the lower bound is non-trivial.\\n11.9 Strengths and Weaknesses of Bayesian Inference\\nBayesian inference is appealing when prior information is available since Bayes’\\ntheorem is a natural way to combine prior information with data. Some peo-\\nple ﬁnd Bayesian inference psychologically appealing because it allows us to\\nmake probability statements about parameters. In contrast, frequentist infer-\\nence provides conﬁdence sets C\\nn which trap the parameter 95 percent of the\\ntime, but we cannot say thatP(θ ∈ Cn|Xn) is .95. In the frequentist approach\\nwe can make probability statements aboutCn, not θ. However, psychological\\nappeal is not a compelling scientiﬁc argument for using one type of inference\\nover another.\\nIn parametric models, with large samples, Bayesian and frequentist methods\\ngive approximately the same inferences. In general, they need not agree.\\nHere are three examples that illustrate the strengths and weakness of Bayesian\\ninference. The ﬁrst example is Example 6.14 revisited. This example shows\\nthe psychological appeal of Bayesian inference. The second and third show\\nthat Bayesian methods can fail.\\n11.8 Example (Example 6.14 revisited). We begin by reviewing the example.\\nLet θ be a ﬁxed, known real number and let X\\n1,X 2 be independent random\\nvariables such that P(Xi =1 )= P(Xi = −1 )=1 /2. Now deﬁne Yi = θ + Xi\\nand suppose that you only observe Y1 and Y2. Let\\nC =\\n{\\n{Y1 − 1} if Y1 = Y2\\n{(Y1 + Y2)/2} if Y1 ̸= Y2.\\nThis is a 75 percent conﬁdence set since, no matter whatθ is, Pθ(θ ∈ C)=3 /4.\\nSuppose we observe Y1 = 15 and Y2 = 17. Then our 75 percent conﬁdence\\ninterval is {16}. However, we are certain, in this case, that θ = 16. So calling'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 201, 'page_label': '202'}, page_content='186 11. Bayesian Inference\\nthis a 75 percent conﬁdence set, bothers many people. Nonetheless, C is a\\nvalid 75 percent conﬁdence set. It will trap the true value 75 percent of the\\ntime.\\nThe Bayesian solution is more satisfying to many. For simplicity, assume\\nthat θ is an integer. Let f(θ) be a prior mass function such that f(θ) > 0 for\\nevery integer θ. When Y =( Y\\n1,Y2) = (15,17), the likelihood function is\\nL(θ)=\\n{\\n1/4 θ =1 6\\n0 otherwise .\\nApplying Bayes’ theorem we see that\\nP(Θ = θ|Y = (15,17)) =\\n{\\n1 θ =1 6\\n0 otherwise .\\nHence, P(θ ∈ C|Y = (15,17)) = 1. There is nothing wrong with saying that\\n{16} is a 75 percent conﬁdence interval. But is it not a probability statement\\nabout θ. ■\\n11.9 Example. This is a simpliﬁed version of the example in Robins and Ritov\\n(1997). The data consist of n iid triples\\n(X1,R 1,Y1),..., (Xn,Yn,R n).\\nLet B be a ﬁnite but very large number, likeB = 100100. Any realistic sample\\nsize n will be small compared to B. Let\\nθ =( θ1,...,θ B)\\nbe a vector of unknown parameters such that 0 ≤ θj ≤ 1 for 1 ≤ j ≤ B. Let\\nξ =( ξ1,...,ξ B)\\nbe a vector of known numbers such that\\n0 <δ ≤ ξj ≤ 1 − δ< 1, 1 ≤ j ≤ B,\\nwhere δ is some, small, positive number. Each data point (Xi,R i,Yi) is drawn\\nin the following way:\\n1. Draw Xi uniformly from {1,...,B }.\\n2. Draw Ri ∼ Bernoulli(ξXi ).\\n3. If Ri = 1, then draw Yi ∼ Bernoulli(θXi ). If Ri = 0, do not draw Yi.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 202, 'page_label': '203'}, page_content='11.9 Strengths and Weaknesses of Bayesian Inference 187\\nThe model may seem a little artiﬁcial but, in fact, it is caricature of some\\nreal missing data problems in which some data points are not observed. In\\nthis example, Ri = 0 can be thought of as meaning “missing.” Our goal is to\\nestimate\\nψ = P(Yi =1 ).\\nNote that\\nψ = P(Yi =1 )=\\nB∑\\nj=1\\nP(Yi =1 |X = j)P(X = j)\\n= 1\\nB\\nB∑\\nj=1\\nθj ≡ g(θ)\\nso ψ = g(θ) is a function of θ.\\nLet us consider a Bayesian analysis ﬁrst. The likelihood of a single obser-\\nvation is\\nf(Xi,R i,Yi)= f(Xi)f(Ri|Xi)f(Yi|Xi)Ri .\\nThe last term is raised to the powerRi since, if Ri = 0, thenYi is not observed\\nand hence that term drops out of the likelihood. Sincef(Xi)=1 /B and that\\nYi and Ri are Bernoulli,\\nf(Xi)f(Ri|Xi)f(Yi|Xi)Ri = 1\\nB ξRi\\nXi (1 − ξXi )1−Ri θYiRi\\nXi (1 − θXi )(1−Yi)Ri .\\nThus, the likelihood function is\\nL(θ)=\\nn∏\\ni=1\\nf(Xi)f(Ri|Xi)f(Yi|Xi)Ri\\n=\\nn∏\\ni=1\\n1\\nB ξRi\\nXi (1 − ξXi )1−Ri θYiRi\\nXi (1 − θXi )(1−Yi)Ri\\n∝ θYiRi\\nXi (1 − θXi )(1−Yi)Ri .\\nWe have dropped all the terms involvingB and the ξj’s since these are known\\nconstants, not parameters. The log-likelihood is\\nℓ(θ)=\\nn∑\\ni=1\\nYi Ri log θXi +( 1− Yi) Ri log(1 − θXi )\\n=\\nB∑\\nj=1\\nnj log θj +\\nB∑\\nj=1\\nmj log(1 − θj)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 203, 'page_label': '204'}, page_content='188 11. Bayesian Inference\\nwhere\\nnj =# {i : Yi =1 ,R i =1 ,X i = j}\\nmj =# {i : Yi =0 ,R i =1 ,X i = j}.\\nNow, nj = mj = 0 for most j since B is so much larger than n. This has\\nseveral implications. First, the mle for most θj is not deﬁned. Second, for\\nmost θj, the posterior distribution is equal to the prior distribution, since\\nthose θj do not appear in the likelihood. Hence, f(θ|Data) ≈ f(θ). It follows\\nthat f(ψ|Data) ≈ f(ψ). In other words, the data provide little information\\nabout ψ in a Bayesian analysis.\\nNow we consider a frequentist solution. Deﬁne\\nˆψ = 1\\nn\\nn∑\\ni=1\\nRiYi\\nξXi\\n. (11.10)\\nWe will now show that this estimator is unbiased and has small mean-squared\\nerror. It can be shown (see Exercise 7) that\\nE( ˆψ)= ψ and V( ˆψ) ≤ 1\\nnδ2 . (11.11)\\nTherefore, the mse is of order 1/n which goes to 0 fairly quickly as we collect\\nmore data, no matter how largeB is. The estimator deﬁned in (11.10) is called\\nthe Horwitz-Thompson estimator. It cannot be derived from a Bayesian or\\nlikelihood point of view since it involves the terms ξXi . These terms drop\\nout of the log-likelihood and hence will not show up in any likelihood-based\\nmethod including Bayesian estimators.\\nThe moral of the story is this. Bayesian methods are tied to the likeli-\\nhood function. But in high dimensional (and nonparametric) problems, the\\nlikelihood may not yield accurate inferences.\\n■\\n11.10 Example. Suppose that f is a probability density function and that\\nf(x)= cg(x)\\nwhere g(x) > 0 is a known function and c is unknown. In principle we can\\ncompute c since\\n∫\\nf(x) dx = 1 implies thatc =1 /\\n∫\\ng(x) dx. But in many cases\\nwe can’t do the integral\\n∫\\ng(x) dx since g might be a complicated function and\\nx could be high dimensional. Despite the fact that c is not known, it is often\\npossible to draw a sampleX1,...,X n from f; see Chapter 24. Can we use the\\nsample to estimate the normalizing constantc? Here is a frequentist solution:'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 204, 'page_label': '205'}, page_content='11.10 Bibliographic Remarks 189\\nLet ˆfn(x) be a consistent estimate of the densityf. Chapter 20 explains how to\\nconstruct such an estimate. Choose any pointx and note that c = f(x)/g(x).\\nHence, ˆc = ˆf(x)/g(x) is a consistent estimate ofc. Now let us try to solve this\\nproblem from a Bayesian approach. Letπ(c) be a prior such thatπ(c) > 0 for\\nall c> 0. The likelihood function is\\nLn(c)=\\nn∏\\ni=1\\nf(Xi)=\\nn∏\\ni=1\\ncg(Xi)= cn\\nn∏\\ni=1\\ng(Xi) ∝ cn.\\nHence the posterior is proportional to cnπ(c). The posterior does not depend\\non X1,...,X n, so we come to the startling conclusion that, from the Bayesian\\npoint of view, there is no information in the data about c. Moreover, the\\nposterior mean is ∫∞\\n0 cn+1π(c) dc∫∞\\n0 cnπ(c) dc\\nwhich tends to inﬁnity as n increases. ■\\nThese last two examples illustrate an important point. Bayesians are slaves\\nto the likelihood function. When the likelihood goes awry, so will Bayesian\\ninference.\\nWhat should we conclude from all this? The important thing is to under-\\nstand that frequentist and Bayesian methods are answering diﬀerent ques-\\ntions. To combine prior beliefs with data in a principled way, use Bayesian in-\\nference. To construct procedures with guaranteed long run performance, such\\nas conﬁdence intervals, use frequentist methods. Generally, Bayesian methods\\nrun into problems when the parameter space is high dimensional. In particu-\\nlar, 95 percent posterior intervals need not contain the true value 95 percent\\nof the time (in the frequency sense).\\n11.10 Bibliographic Remarks\\nSome references on Bayesian inference include Carlin and Louis (1996), Gel-\\nman et al. (1995), Lee (1997), Robert (1994), and Schervish (1995). See Cox\\n(1993), Diaconis and Freedman (1986), Freedman (1999), Barron et al. (1999),\\nGhosal et al. (2000), Shen and Wasserman (2001), and Zhao (2000) for discus-\\nsions of some of the technicalities of nonparametric Bayesian inference. The\\nRobins-Ritov example is discussed in detail in Robins and Ritov (1997) where\\nit is cast more properly as a nonparametric problem. Example 11.10 is due to\\nEdward George (personal communication). See Berger and Delampady (1987)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 205, 'page_label': '206'}, page_content='190 11. Bayesian Inference\\nand Kass and Raftery (1995) for a discussion of Bayesian testing. See Kass\\nand Wasserman (1996) for a discussion of noninformative priors.\\n11.11 Appendix\\nProof of Theorem 11.5.\\nIt can be shown that the eﬀect of the prior diminishes as n increases so\\nthat f(θ|Xn) ∝L n(θ)f(θ) ≈L n(θ). Hence, log f(θ|Xn) ≈ ℓ(θ). Now, ℓ(θ) ≈\\nℓ(ˆθ)+( θ − ˆθ)ℓ′(ˆθ)+[( θ − ˆθ)2/2]ℓ′′(ˆθ)= ℓ(ˆθ)+[( θ − ˆθ)2/2]ℓ′′(ˆθ) since ℓ′(ˆθ)=0 .\\nExponentiating, we get approximately that\\nf(θ|Xn) ∝ exp\\n{\\n−1\\n2\\n(θ − ˆθ)2\\nσ2n\\n}\\nwhere σ2\\nn = −1/ℓ′′(ˆθn). So the posterior of θ is approximately Normal with\\nmean ˆθ and variance σ2\\nn. Let ℓi = logf(Xi|θ), then\\n1\\nσ2n\\n= −ℓ′′(ˆθn)=\\n∑\\ni\\n−ℓ′′\\ni (ˆθn)\\n= n\\n\\uf8f61\\nn\\n\\uf8f7∑\\ni\\n−ℓ′′\\ni (ˆθn) ≈ nEθ\\n[\\n−ℓ′′\\ni (ˆθn)\\n]\\n= nI(ˆθn)\\nand hence σn ≈ se(ˆθ). ■\\n11.12 Exercises\\n1. Verify (11.7).\\n2. Let X1, ..., Xn ∼ Normal(µ,1).\\n(a) Simulate a data set (using µ = 5) consisting of n=100 observations.\\n(b) Take f(µ) = 1 and ﬁnd the posterior density. Plot the density.\\n(c) Simulate 1,000 draws from the posterior. Plot a histogram of the\\nsimulated values and compare the histogram to the answer in (b).\\n(d) Let θ = eµ. Find the posterior density for θ analytically and by\\nsimulation.\\n(e) Find a 95 percent posterior interval for µ.\\n(f) Find a 95 percent conﬁdence interval for θ.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 206, 'page_label': '207'}, page_content='11.12 Exercises 191\\n3. Let X1, ..., Xn ∼ Uniform(0,θ ). Let f(θ) ∝ 1/θ. Find the posterior\\ndensity.\\n4. Suppose that 50 people are given a placebo and 50 are given a new\\ntreatment. 30 placebo patients show improvement while 40 treated pa-\\ntients show improvement. Letτ = p\\n2 −p1 where p2 is the probability of\\nimproving under treatment andp1 is the probability of improving under\\nplacebo.\\n(a) Find themle of τ. Find the standard error and 90 percent conﬁdence\\ninterval using the delta method.\\n(b) Find the standard error and 90 percent conﬁdence interval using the\\nparametric bootstrap.\\n(c) Use the prior f(p1,p 2) = 1. Use simulation to ﬁnd the posterior\\nmean and posterior 90 percent interval for τ.\\n(d) Let\\nψ = log\\n\\uf8f6\\uf8f6 p1\\n1 − p1\\n\\uf8f7\\n÷\\n\\uf8f6 p2\\n1 − p2\\n\\uf8f7\\uf8f7\\nbe the log-odds ratio. Note that ψ =0i f p1 = p2. Find the mle of ψ.\\nUse the delta method to ﬁnd a 90 percent conﬁdence interval for ψ.\\n(e) Use simulation to ﬁnd the posterior mean and posterior 90 percent\\ninterval for ψ.\\n5. Consider the Bernoulli(p) observations\\n0101000000\\nPlot the posterior for p using these priors: Beta(1/2,1/2), Beta(1,1),\\nBeta(10,10), Beta(100,100).\\n6. Let X\\n1,...,X n ∼ Poisson(λ).\\n(a) Let λ ∼ Gamma(α, β) be the prior. Show that the posterior is also\\na Gamma. Find the posterior mean.\\n(b) Find the Jeﬀreys’ prior. Find the posterior.\\n7. In Example 11.9, verify (11.11).\\n8. Let X ∼ N(µ,1). Consider testing\\nH\\n0 : µ = 0 versus H1 : µ ̸=0 .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 207, 'page_label': '208'}, page_content='192 11. Bayesian Inference\\nTake P(H0)= P(H1)=1 /2. Let the prior for µ under H1 be µ ∼\\nN(0,b 2). Find an expression for P(H0|X = x). Compare P(H0|X = x)\\nto the p-value of the Wald test. Do the comparison numerically for a\\nvariety of values of x and b. Now repeat the problem using a sample of\\nsize n. You will see that the posterior probability ofH\\n0 can be large even\\nwhen the p-value is small, especially whenn is large. This disagreement\\nbetween Bayesian and frequentist testing is called the Jeﬀreys-Lindley\\nparadox.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 208, 'page_label': '209'}, page_content='12\\nStatistical Decision Theory\\n12.1 Preliminaries\\nWe have considered several point estimators such as the maximum likelihood\\nestimator, the method of moments estimator, and the posterior mean. In fact,\\nthere are many other ways to generate estimators. How do we choose among\\nthem? The answer is found in decision theory which is a formal theory for\\ncomparing statistical procedures.\\nConsider a parameter θ which lives in a parameter space Θ. Let ˆθ be an\\nestimator of θ. In the language of decision theory, an estimator is sometimes\\ncalled a decision rule and the possible values of the decision rule are called\\nactions.\\nWe shall measure the discrepancy between θ and ˆθ using a loss function\\nL(θ, ˆθ). Formally, L maps Θ × Θi n t oR. Here are some examples of loss\\nfunctions:\\nL(θ, ˆθ)=( θ − ˆθ)\\n2 squared error loss,\\nL(θ, ˆθ)= |θ − ˆθ| absolute error loss,\\nL(θ, ˆθ)= |θ − ˆθ|p Lp loss,\\nL(θ, ˆθ)=0i f θ = ˆθ o r1i f θ ̸=ˆθ zero–one loss,\\nL(θ, ˆθ)=\\n∫\\nlog\\n\\uf8f6\\nf(x; θ)\\nf(x; ˆθ)\\n\\uf8f7\\nf(x; θ)dx Kullback–Leibler loss.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 209, 'page_label': '210'}, page_content='194 12. Statistical Decision Theory\\nBear in mind in what follows that an estimator ˆθ is a function of the data.\\nTo emphasize this point, sometimes we will write ˆθ as ˆθ(X). To assess an\\nestimator, we evaluate the average loss or risk.\\n12.1 Deﬁnition. The risk of an estimator ˆθ is\\nR(θ, ˆθ)= Eθ\\n\\uf8f6\\nL(θ, ˆθ)\\n\\uf8f7\\n=\\n∫\\nL(θ, ˆθ(x))f(x;θ)dx.\\nWhen the loss function is squared error, the risk is just the mse (mean\\nsquared error):\\nR(θ, ˆθ)= Eθ(ˆθ − θ)2 = mse = Vθ(ˆθ)+ bias2\\nθ(ˆθ).\\nIn the rest of the chapter, if we do not state what loss function we are using,\\nassume the loss function is squared error.\\n12.2 Comparing Risk Functions\\nTo compare two estimators we can compare their risk functions. However, this\\ndoes not provide a clear answer as to which estimator is better. Consider the\\nfollowing examples.\\n12.2 Example. Let X ∼ N(θ, 1) and assume we are using squared error\\nloss. Consider two estimators: ˆθ\\n1 = X and ˆθ2 = 3. The risk functions are\\nR(θ, ˆθ1)= Eθ(X − θ)2 = 1 and R(θ, ˆθ2)= Eθ(3 − θ)2 =( 3− θ)2. If 2 <θ< 4\\nthen R(θ, ˆθ2) <R (θ, ˆθ1), otherwise, R(θ, ˆθ1) <R (θ, ˆθ2). Neither estimator\\nuniformly dominates the other; see Figure 12.1. ■\\n12.3 Example. Let X1,...,X n ∼ Bernoulli(p). Consider squared error loss\\nand let ˆp1 = X. Since this has 0 bias, we have that\\nR(p, ˆp1)= V(X)= p(1 − p)\\nn .\\nAnother estimator is\\nˆp2 = Y + α\\nα + β + n\\nwhere Y = ∑ n\\ni=1 Xi and α and β are positive constants. This is the posterior\\nmean using a Beta (α, β) prior. Now,\\nR(p, ˆp2)= Vp(ˆp2)+( biasp(ˆp2))2'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 210, 'page_label': '211'}, page_content='12.2 Comparing Risk Functions 195\\n012345\\n0\\n1\\n2\\n3\\nR(θ, ˆθ1)\\nR(θ, ˆθ2)\\nθ\\nFIGURE 12.1. Comparing two risk functions. Neither risk function dominates the\\nother at all values of θ.\\n= Vp\\n\\uf8f6 Y + α\\nα + β + n\\n\\uf8f7\\n+\\n\\uf8f6\\nEp\\n\\uf8f6 Y + α\\nα + β + n\\n\\uf8f7\\n− p\\n\\uf8f72\\n= np(1 − p)\\n(α + β + n)2 +\\n\\uf8f6 np + α\\nα + β + n − p\\n\\uf8f72\\n.\\nLet α = β =\\n√\\nn/4. (In Example 12.12 we will explain this choice.) The\\nresulting estimator is\\nˆp2 = Y +\\n√\\nn/4\\nn + √n\\nand the risk function is\\nR(p, ˆp2)= n\\n4(n + √n)2 .\\nThe risk functions are plotted in ﬁgure 12.2. As we can see, neither estimator\\nuniformly dominates the other.\\nThese examples highlight the need to be able to compare risk functions.\\nTo do so, we need a one-number summary of the risk function. Two such\\nsummaries are the maximum risk and the Bayes risk.\\n12.4 Deﬁnition. The maximum risk is\\nR(ˆθ) = sup\\nθ\\nR(θ, ˆθ) (12.1)\\nand the Bayes risk is\\nr(f, ˆθ)=\\n∫\\nR(θ, ˆθ)f(θ)dθ (12.2)\\nwhere f(θ) is a prior for θ.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 211, 'page_label': '212'}, page_content='196 12. Statistical Decision Theory\\nRisk\\np\\nFIGURE 12.2. Risk functions for ˆp1 and ˆp2 in Example 12.3. The solid curve is\\nR(ˆp1). The dotted line is R(ˆp2).\\n12.5 Example. Consider again the two estimators in Example 12.3. We have\\nR(ˆp1) = max\\n0≤p≤1\\np(1 − p)\\nn = 1\\n4n\\nand\\nR(ˆp2) = max\\np\\nn\\n4(n + √n)2 = n\\n4(n + √n)2 .\\nBased on maximum risk, ˆp2 is a better estimator since R(ˆp2) < R(ˆp1). How-\\never, when n is large, R(ˆp1) has smaller risk except for a small region in the\\nparameter space near p =1 /2. Thus, many people prefer ˆp1 to ˆp2. This il-\\nlustrates that one-number summaries like maximum risk are imperfect. Now\\nconsider the Bayes risk. For illustration, let us take f(p) = 1. Then\\nr(f, ˆp\\n1)=\\n∫\\nR(p, ˆp1)dp =\\n∫ p(1 − p)\\nn dp = 1\\n6n\\nand\\nr(f, ˆp2)=\\n∫\\nR(p, ˆp2)dp = n\\n4(n + √n)2 .\\nFor n ≥ 20, r(f, ˆp2) >r (f, ˆp1) which suggests that ˆp1 is a better estimator.\\nThis might seem intuitively reasonable but this answer depends on the choice\\nof prior. The advantage of using maximum risk, despite its problems, is that\\nit does not require one to choose a prior.\\n■\\nThese two summaries of the risk function suggest two diﬀerent methods\\nfor devising estimators: choosing ˆθ to minimize the maximum risk leads to'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 212, 'page_label': '213'}, page_content='12.3 Bayes Estimators 197\\nminimax estimators; choosing ˆθ to minimize the Bayes risk leads to Bayes\\nestimators.\\n12.6 Deﬁnition. A decision rule that minimizes the Bayes risk is called a\\nBayes rule. Formally, ˆθ is a Bayes rule with respect to the prior f if\\nr(f, ˆθ) = inf\\n˜θ\\nr(f, ˜θ) (12.3)\\nwhere the inﬁmum is over all estimators ˜θ. An estimator that minimizes\\nthe maximum risk is called a minimax rule. Formally, ˆθ is minimax if\\nsup\\nθ\\nR(θ, ˆθ) = inf\\n˜θ\\nsup\\nθ\\nR(θ, ˜θ) (12.4)\\nwhere the inﬁmum is over all estimators ˜θ.\\n12.3 Bayes Estimators\\nLet f be a prior. From Bayes’ theorem, the posterior density is\\nf(θ|x)= f(x|θ)f(θ)\\nm(x) = f(x|θ)f(θ)∫\\nf(x|θ)f(θ)dθ (12.5)\\nwhere m(x)=\\n∫\\nf(x, θ)dθ =\\n∫\\nf(x|θ)f(θ)dθ is the marginal distribution of\\nX. Deﬁne the posterior risk of an estimator ˆθ(x)b y\\nr(ˆθ|x)=\\n∫\\nL(θ, ˆθ(x))f(θ|x)dθ. (12.6)\\n12.7 Theorem. The Bayes risk r(f, ˆθ) satisﬁes\\nr(f, ˆθ)=\\n∫\\nr(ˆθ|x)m(x) dx.\\nLet ˆθ(x) be the value ofθ that minimizesr(ˆθ|x). Then ˆθ is the Bayes estimator.\\nProof. We can rewrite the Bayes risk as follows:\\nr(f, ˆθ)=\\n∫\\nR(θ, ˆθ)f(θ)dθ =\\n∫ \\uf8f6∫\\nL(θ, ˆθ(x))f(x|θ)dx\\n\\uf8f7\\nf(θ)dθ\\n=\\n∫∫\\nL(θ, ˆθ(x))f(x, θ)dxdθ =\\n∫∫\\nL(θ, ˆθ(x))f(θ|x)m(x)dxdθ\\n=\\n∫ \\uf8f6∫\\nL(θ, ˆθ(x))f(θ|x)dθ\\n\\uf8f7\\nm(x) dx =\\n∫\\nr(ˆθ|x)m(x) dx.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 213, 'page_label': '214'}, page_content='198 12. Statistical Decision Theory\\nIf we choose ˆθ(x) to be the value ofθ that minimizes r(ˆθ|x) then we will mini-\\nmize the integrand at everyx and thus minimize the integral\\n∫\\nr(ˆθ|x)m(x)dx.\\n■\\nNow we can ﬁnd an explicit formula for the Bayes estimator for some speciﬁc\\nloss functions.\\n12.8 Theorem. If L(θ, ˆθ)=( θ − ˆθ)2 then the Bayes estimator is\\nˆθ(x)=\\n∫\\nθf(θ|x)dθ = E(θ|X = x). (12.7)\\nIf L(θ, ˆθ)= |θ − ˆθ| then the Bayes estimator is the median of the posterior\\nf(θ|x).I f L(θ, ˆθ) is zero–one loss, then the Bayes estimator is the mode of the\\nposterior f(θ|x).\\nProof. We will prove the theorem for squared error loss. The Bayes rule\\nˆθ(x) minimizes r(ˆθ|x)=\\n∫\\n(θ − ˆθ(x))2f(θ|x)dθ. Taking the derivative ofr(ˆθ|x)\\nwith respect to ˆθ(x) and setting it equal to 0 yields the equation 2\\n∫\\n(θ −\\nˆθ(x))f(θ|x)dθ = 0. Solving for ˆθ(x) we get 12.7. ■\\n12.9 Example. Let X1,...,X n ∼ N(µ, σ2) where σ2 is known. Suppose we\\nuse a N(a, b2) prior for µ. The Bayes estimator with respect to squared error\\nloss is the posterior mean, which is\\nˆθ(X1,...,X n)= b2\\nb2 + σ2\\nn\\nX +\\nσ2\\nn\\nb2 + σ2\\nn\\na. ■\\n12.4 Minimax Rules\\nFinding minimax rules is complicated and we cannot attempt a complete\\ncoverage of that theory here but we will mention a few key results. The main\\nmessage to take away from this section is: Bayes estimators with a constant\\nrisk function are minimax.\\n12.10 Theorem. Let ˆθ\\nf be the Bayes rule for some prior f:\\nr(f, ˆθf ) = inf\\nˆθ\\nr(f, ˆθ). (12.8)\\nSuppose that\\nR(θ, ˆθf ) ≤ r(f, ˆθf ) for all θ. (12.9)\\nThen ˆθf is minimax and f is called a least favorable prior.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 214, 'page_label': '215'}, page_content='12.4 Minimax Rules 199\\nProof. Suppose that ˆθf is not minimax. Then there is another ruleˆθ0 such\\nthat supθ R(θ, ˆθ0) < supθ R(θ, ˆθf ). Since the average of a function is always\\nless than or equal to its maximum, we have that r(f, ˆθ0) ≤ supθ R(θ, ˆθ0).\\nHence,\\nr(f, ˆθ0) ≤ sup\\nθ\\nR(θ, ˆθ0) < sup\\nθ\\nR(θ, ˆθf ) ≤ r(f, ˆθf )\\nwhich contradicts (12.8). ■\\n12.11 Theorem. Suppose that ˆθ is the Bayes rule with respect to some\\nprior f. Suppose further that ˆθ has constant risk: R(θ, ˆθ)= c for some c.\\nThen ˆθ is minimax.\\nProof. The Bayes risk isr(f, ˆθ)=\\n∫\\nR(θ, ˆθ)f(θ)dθ = c and henceR(θ, ˆθ) ≤\\nr(f, ˆθ) for all θ. Now apply the previous theorem. ■\\n12.12 Example. Consider the Bernoulli model with squared error loss. In\\nexample 12.3 we showed that the estimator\\nˆp(Xn)=\\n∑ n\\ni=1 Xi +\\n√\\nn/4\\nn + √n\\nhas a constant risk function. This estimator is the posterior mean, and hence\\nthe Bayes rule, for the prior Beta( α, β) with α = β =\\n√\\nn/4. Hence, by the\\nprevious theorem, this estimator is minimax. ■\\n12.13 Example. Consider again the Bernoulli but with loss function\\nL(p, ˆp)= (p − ˆp)2\\np(1 − p).\\nLet\\nˆp(Xn)= ˆp =\\n∑ n\\ni=1 Xi\\nn .\\nThe risk is\\nR(p, ˆp)= E\\n\\uf8f6(ˆp − p)2\\np(1 − p)\\n\\uf8f7\\n= 1\\np(1 − p)\\n\\uf8f6p(1 − p)\\nn\\n\\uf8f7\\n= 1\\nn\\nwhich, as a function of p, is constant. It can be shown that, for this loss\\nfunction, ˆp(Xn) is the Bayes estimator under the prior f(p) = 1. Hence, ˆp is\\nminimax. ■\\nA natural question to ask is: what is the minimax estimator for a Normal\\nmodel?'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 215, 'page_label': '216'}, page_content='200 12. Statistical Decision Theory\\nθ\\n0 0.5-0.5\\nFIGURE 12.3. Risk function for constrained Normal with m=.5. The two short\\ndashed lines show the least favorable prior which puts its mass at two points.\\n12.14 Theorem. Let X1,...,X n ∼ N(θ, 1) and let ˆθ = X. Then ˆθ is minimax\\nwith respect to any well-behaved loss function. 1 It is the only estimator with\\nthis property.\\nIf the parameter space is restricted, then the theorem above does not apply\\nas the next example shows.\\n12.15 Example. Suppose that X ∼ N(θ, 1) and that θ is known to lie in the\\ninterval [−m, m] where 0 <m< 1. The unique, minimax estimator under\\nsquared error loss is\\nˆθ(X)= m tanh(mX)\\nwhere tanh(z)=( ez −e−z)/(ez +e−z). It can be shown that this is the Bayes\\nrule with respect to the prior that puts mass 1/2 at m and mass 1/2 at −m.\\nMoreover, it can be shown that the risk is not constant but it does satisfy\\nR(θ, ˆθ) ≤ r(f, ˆθ) for all θ; see Figure 12.3. Hence, Theorem 12.10 implies that\\nˆθ is minimax.\\n■\\n1“Well-behaved” means that the level sets must be convex and symmetric about the origin.\\nThe result holds up to sets of measure 0.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 216, 'page_label': '217'}, page_content='12.5 Maximum Likelihood, Minimax, and Bayes 201\\n12.5 Maximum Likelihood, Minimax, and Bayes\\nFor parametric models that satisfy weak regularity conditions, the maximum\\nlikelihood estimator is approximately minimax. Consider squared error loss\\nwhich is squared bias plus variance. In parametric models with large samples,\\nit can be shown that the variance term dominates the bias so the risk of the\\nmle ˆθ roughly equals the variance:\\n2\\nR(θ, ˆθ)= Vθ(ˆθ)+ bias2 ≈ Vθ(ˆθ).\\nAs we saw in Chapter 9, the variance of the mle is approximately\\nV(ˆθ) ≈ 1\\nnI(θ)\\nwhere I(θ) is the Fisher information. Hence,\\nnR(θ, ˆθ) ≈ 1\\nI(θ). (12.10)\\nFor any other estimatorθ′, it can be shown that for largen, R(θ,θ ′) ≥ R(θ, ˆθ).\\nMore precisely,\\nlim\\nϵ→0\\nlim sup\\nn→∞\\nsup\\n|θ−θ′ |<ϵ\\nnR (θ′, ˆθ) ≥ 1\\nI(θ). (12.11)\\nThis says that, in a local, large sample sense, themle is minimax. It can also\\nbe shown that the mle is approximately the Bayes rule.\\nIn summary:\\nIn most parametric models, with large samples, the mle is approxi-\\nmately minimax and Bayes.\\nThere is a caveat: these results break down when the number of parameters\\nis large as the next example shows.\\n12.16 Example (Many Normal means). Let Yi ∼ N(θi,σ 2/n), i =1 ,...,n .\\nLet Y =( Y1,...,Y n) denote the data and let θ =( θ1,...,θ n) denote the\\nunknown parameters. Assume that\\nθ ∈ Θn ≡\\n{\\n(θ1,...,θ n):\\nn∑\\ni=1\\nθ2\\ni ≤ c2\\n}\\n2Typically, the squared bias is orderO(n−2) while the variance is of order O(n−1).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 217, 'page_label': '218'}, page_content='202 12. Statistical Decision Theory\\nfor some c> 0. In this model, there are as many parameters as observations.3\\nThe mle is ˆθ = Y =( Y1,...,Y n). Under the loss functionL(θ, ˆθ)= ∑ n\\ni=1(ˆθi −\\nθi)2, the risk of themle is R(θ, ˆθ)= σ2. It can be shown that the minimax risk\\nis approximately σ2/(σ2 + c2) and one can ﬁnd an estimator ˜θ that achieves\\nthis risk. Sinceσ2/(σ2 +c2) <σ 2, we see that˜θ has smaller risk than themle.\\nIn practice, the diﬀerence between the risks can be substantial. This shows\\nthat maximum likelihood is not an optimal estimator in high dimensional\\nproblems.\\n■\\n12.6 Admissibility\\nMinimax estimators and Bayes estimators are “good estimators” in the sense\\nthat they have small risk. It is also useful to characterize bad estimators.\\n12.17 Deﬁnition. An estimator ˆθ is inadmissible if there exists another\\nrule ˆθ′ such that\\nR(θ, ˆθ′) ≤ R(θ, ˆθ) for all θ and\\nR(θ, ˆθ′) <R (θ, ˆθ) for at least one θ.\\nOtherwise, ˆθ is admissible.\\n12.18 Example. Let X ∼ N(θ, 1) and consider estimating θ with squared\\nerror loss. Let ˆθ(X) = 3. We will show that ˆθ is admissible. Suppose not.\\nThen there exists a diﬀerent ruleˆθ′ with smaller risk. In particular,R(3, ˆθ′) ≤\\nR(3, ˆθ) = 0. Hence, 0 = R(3, ˆθ′)=\\n∫\\n(ˆθ′(x) − 3)2f(x;3 )dx. Thus, ˆθ′(x)=3 .\\nSo there is no rule that beats ˆθ. Even though ˆθ is admissible it is clearly a\\nbad decision rule. ■\\n12.19 Theorem (Bayes Rules Are Admissible). Suppose that Θ ⊂ R and that\\nR(θ, ˆθ) is a continuous function ofθ for every ˆθ.L e tf be a prior density with\\nfull support, meaning that, for every θ and every ϵ> 0,\\n∫θ+ϵ\\nθ−ϵ f(θ)dθ > 0.L e t\\nˆθf be the Bayes’ rule. If the Bayes risk is ﬁnite then ˆθf is admissible.\\nProof. Suppose ˆθf is inadmissible. Then there exists a better rule ˆθ such\\nthat R(θ, ˆθ) ≤ R(θ, ˆθf ) for all θ and R(θ0, ˆθ) <R (θ0, ˆθf ) for some θ0. Let\\n3The many Normal means problem is more general than it looks. Many nonparametric esti-\\nmation problems are mathematically equivalent to this model.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 218, 'page_label': '219'}, page_content='12.6 Admissibility 203\\nν = R(θ0, ˆθf ) − R(θ0, ˆθ) > 0. Since R is continuous, there is an ϵ> 0 such\\nthat R(θ, ˆθf ) − R(θ, ˆθ) >ν /2 for all θ ∈ (θ0 − ϵ, θ0 + ϵ). Now,\\nr(f, ˆθf ) − r(f, ˆθ)=\\n∫\\nR(θ, ˆθf )f(θ)dθ −\\n∫\\nR(θ, ˆθ)f(θ)dθ\\n=\\n∫ [\\nR(θ, ˆθf ) − R(θ, ˆθ)\\n]\\nf(θ)dθ\\n≥\\n∫ θ0+ϵ\\nθ0−ϵ\\n[\\nR(θ, ˆθf ) − R(θ, ˆθ)\\n]\\nf(θ)dθ\\n≥ ν\\n2\\n∫ θ0+ϵ\\nθ0−ϵ\\nf(θ)dθ\\n> 0.\\nHence, r(f, ˆθf ) >r (f, ˆθ). This implies thatˆθf does not minimizer(f, ˆθ) which\\ncontradicts the fact that ˆθf is the Bayes rule. ■\\n12.20 Theorem. Let X1,...,X n ∼ N(µ, σ2). Under squared error loss, X is\\nadmissible.\\nThe proof of the last theorem is quite technical and is omitted but the idea\\nis as follows: The posterior mean is admissible for any strictly positive prior.\\nTake the prior to be N(a, b\\n2). When b2 is very large, the posterior mean is\\napproximately equal to X.\\nHow are minimaxity and admissibility linked? In general, a rule may be one,\\nboth, or neither. But here are some facts linking admissibility and minimaxity.\\n12.21 Theorem. Suppose that ˆθ has constant risk and is admissible. Then it\\nis minimax.\\nProof. The risk is R(θ, ˆθ)= c for some c.I f ˆθ were not minimax then\\nthere exists a rule ˆθ′ such that\\nR(θ, ˆθ′) ≤ sup\\nθ\\nR(θ, ˆθ′) < sup\\nθ\\nR(θ, ˆθ)= c.\\nThis would imply that ˆθ is inadmissible. ■\\nNow we can prove a restricted version of Theorem 12.14 for squared error\\nloss.\\n12.22 Theorem. Let X1,...,X n ∼ N(θ, 1). Then, under squared error loss,\\nˆθ = X is minimax.\\nProof. According to Theorem 12.20, ˆθ is admissible. The risk of ˆθ is 1/n\\nwhich is constant. The result follows from Theorem 12.21. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 219, 'page_label': '220'}, page_content='204 12. Statistical Decision Theory\\nAlthough minimax rules are not guaranteed to be admissible they are “close\\nto admissible.” Say that ˆθ is strongly inadmissible if there exists a rule ˆθ′\\nand an ϵ> 0 such that R(θ, ˆθ′) <R (θ, ˆθ) − ϵ for all θ.\\n12.23 Theorem. If ˆθ is minimax, then it is not strongly inadmissible.\\n12.7 Stein’s Paradox\\nSuppose that X ∼ N(θ, 1) and consider estimating θ with squared error loss.\\nFrom the previous section we know thatˆθ(X)= X is admissible. Now consider\\nestimating two, unrelated quantities θ =( θ1,θ 2) and suppose that X1 ∼\\nN(θ1,1) and X2 ∼ N(θ2,1) independently, with lossL(θ, ˆθ)= ∑ 2\\nj=1(θj −ˆθj)2.\\nNot surprisingly, ˆθ(X)= X is again admissible where X =( X1,X 2). Now\\nconsider the generalization to k normal means. Let θ =( θ1,...,θ k), X =\\n(X1,...,X k) with Xi ∼ N(θi,1) (independent) and loss L(θ, ˆθ)= ∑ k\\nj=1(θj −\\nˆθj)2. Stein astounded everyone when he proved that, ifk ≥ 3, then ˆθ(X)= X\\nis inadmissible. It can be shown that the James-Stein estimator ˆθS has\\nsmaller risk, where ˆθS =( ˆθS\\n1 ,..., ˆθS\\nk ),\\nˆθS\\ni (X)=\\n\\uf8f6\\n1 − k − 2∑\\ni X2\\ni\\n\\uf8f7+\\nXi (12.12)\\nand (z)+ = max{z, 0}. This estimator shrinks theXi’s towards 0. The message\\nis that, when estimating many parameters, there is great value in shrinking the\\nestimates. This observation plays an important role in modern nonparametric\\nfunction estimation.\\n12.8 Bibliographic Remarks\\nAspects of decision theory can be found in Casella and Berger (2002), Berger\\n(1985), Ferguson (1967), and Lehmann and Casella (1998).\\n12.9 Exercises\\n1. In each of the following models, ﬁnd the Bayes risk and the Bayes esti-\\nmator, using squared error loss.\\n(a) X ∼ Binomial(n, p), p ∼ Beta(α, β).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 220, 'page_label': '221'}, page_content='12.9 Exercises 205\\n(b) X ∼ Poisson(λ), λ ∼ Gamma(α, β).\\n(c) X ∼ N(θ,σ 2) where σ2 is known and θ ∼ N(a, b2).\\n2. Let X1,...,X n ∼ N(θ,σ 2) and suppose we estimateθ with loss function\\nL(θ, ˆθ)=( θ − ˆθ)2/σ2. Show that X is admissible and minimax.\\n3. Let Θ = {θ1,...,θ k} be a ﬁnite parameter space. Prove that the poste-\\nrior mode is the Bayes estimator under zero–one loss.\\n4. (Casella and Berger (2002).) Let X1,...,X n be a sample from a distri-\\nbution with variance σ2. Consider estimators of the form bS2 where S2\\nis the sample variance. Let the loss function for estimating σ2 be\\nL(σ2, ˆσ2)= ˆσ2\\nσ2 − 1 − log\\n\\uf8f6ˆσ2\\nσ2\\n\\uf8f7\\n.\\nFind the optimal value of b that minimizes the risk for all σ2.\\n5. (Berliner (1983).) Let X ∼ Binomial(n, p) and suppose the loss function\\nis\\nL(p, ˆp)=\\n\\uf8f6\\n1 − ˆp\\np\\n\\uf8f72\\nwhere 0 <p< 1. Consider the estimator ˆp(X) = 0. This estimator falls\\noutside the parameter space (0 ,1) but we will allow this. Show that\\nˆp(X) = 0 is the unique, minimax rule.\\n6. ( Computer Experiment.) Compare the risk of the mle and the James-\\nStein estimator (12.12) by simulation. Try various values ofn and vari-\\nous vectors θ. Summarize your results.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 221, 'page_label': '222'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 222, 'page_label': '223'}, page_content='Part III\\nStatistical Models and\\nMethods'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 223, 'page_label': '224'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 224, 'page_label': '225'}, page_content='13\\nLinear and Logistic Regression\\nRegression is a method for studying the relationship between a response\\nvariable Y and a covariate X. The covariate is also called a predictor\\nvariable or a feature. 1 One way to summarize the relationship between X\\nand Y is through the regression function\\nr(x)= E(Y |X = x)=\\n∫\\nyf (y|x)dy. (13.1)\\nOur goal is to estimate the regression function r(x) from data of the form\\n(Y1,X 1),..., (Yn,X n) ∼ FX,Y .\\nIn this Chapter, we take a parametric approach and assume thatr is linear.\\nIn Chapters 20 and 21 we discuss nonparametric regression.\\n13.1 Simple Linear Regression\\nThe simplest version of regression is whenXi is simple (one-dimensional) and\\nr(x) is assumed to be linear:\\nr(x)= β0 + β1x.\\n1The term “regression” is due to Sir Francis Galton (1822-1911) who noticed that tall and\\nshort men tend to have sons with heights closer to the mean. He called this “regression towards\\nthe mean.”'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 225, 'page_label': '226'}, page_content='210 13. Linear and Logistic Regression\\n4.0 4.5 5.0 5.5\\n4.0 4.1 4.2 4.3 4.4 4.5 4.6\\nlog surface temperature (Y)\\nlog light intensity (X)\\nFIGURE 13.1. Data on nearby stars. The solid line is the least squares line.\\nThis model is called thethe simple linear regression model. We will make\\nthe further simplifying assumption that V(ϵi|X = x)= σ2 does not depend\\non x. We can thus write the linear regression model as follows.\\n13.1 Deﬁnition. The Simple Linear Regression Model\\nYi = β0 + β1Xi + ϵi (13.2)\\nwhere E(ϵi|Xi)=0 and V(ϵi|Xi)= σ2.\\n13.2 Example. Figure 13.1 shows a plot of log surface temperature (Y) versus\\nlog light intensity (X) for some nearby stars. Also on the plot is an estimated\\nlinear regression line which will be explained shortly.\\n■\\nThe unknown parameters in the model are the intercept β0 and the slope\\nβ1 and the variance σ2. Let ˆβ0 and ˆβ1 denote estimates of β0 and β1. The\\nﬁtted line is\\nˆr(x)= ˆβ0 + ˆβ1x. (13.3)\\nThe predicted values or ﬁtted values are ˆYi = ˆr(Xi) and the residuals\\nare deﬁned to be\\nˆϵi = Yi − ˆYi = Yi −\\n\\uf8f6\\nˆβ0 + ˆβ1Xi\\n\\uf8f7\\n. (13.4)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 226, 'page_label': '227'}, page_content='13.1 Simple Linear Regression 211\\nThe residual sums of squaresor rss, which measures how well the line ﬁts\\nthe data, is deﬁned by rss = ∑ n\\ni=1 ˆϵ2\\ni .\\n13.3 Deﬁnition. The least squares estimates are the values ˆβ0 and ˆβ1\\nthat minimize rss = ∑ n\\ni=1 ˆϵ2\\ni .\\n13.4 Theorem. The least squares estimates are given by\\nˆβ1 =\\n∑ n\\ni=1(Xi − Xn)(Yi − Y n)∑ n\\ni=1(Xi − Xn)2 , (13.5)\\nˆβ0 = Y n − ˆβ1Xn. (13.6)\\nAn unbiased estimate of σ2 is\\nˆσ2 =\\n\\uf8f6 1\\nn − 2\\n\\uf8f7 n∑\\ni=1\\nˆϵ2\\ni . (13.7)\\n13.5 Example. Consider the star data from Example 13.2. The least squares\\nestimates are ˆβ0 =3 .58 and ˆβ1 =0 .166. The ﬁtted line ˆr(x)=3 .5 8+0.166 x\\nis shown in Figure 13.1. ■\\n13.6 Example (The 2001 Presidential Election). Figure 13.2 shows the plot of\\nvotes for Buchanan (Y) versus votes for Bush (X) in Florida. The least squares\\nestimates (omitting Palm Beach County) and the standard errors are\\nˆβ\\n0 =6 6 .0991 ˆse(ˆβ0)=1 7 .2926\\nˆβ1 =0 .0035 ˆse(ˆβ1)=0 .0002.\\nThe ﬁtted line is\\nBuchanan = 66.0991 + 0.0035 Bush.\\n(We will see later how the standard errors were computed.) Figure 13.2 also\\nshows the residuals. The inferences from linear regression are most accurate\\nwhen the residuals behave like random normal numbers. Based on the residual\\nplot, this is not the case in this example. If we repeat the analysis replacing\\nvotes with log(votes) we get\\nˆβ\\n0 = −2.3298 ˆse(ˆβ0)=0 .3529\\nˆβ1 =0 .730300 ˆse(ˆβ1)=0 .0358.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 227, 'page_label': '228'}, page_content='212 13. Linear and Logistic Regression\\n0 125000 250000\\n0 1500 3000\\n0 125000 250000\\n−500 0 500\\n7 8 9 10 11 12 13\\n2345678\\n7 8 9 10 11 12 13\\n−1 0 1\\nBush\\nBuchanan\\nBush\\nresiduals\\nBush\\nBuchanan\\nBush\\nresiduals\\nFIGURE 13.2. Voting Data for Election 2000. See example 13.6.\\nThis gives the ﬁt\\nlog(Buchanan) = −2.3298 + 0.7303 log(Bush) .\\nThe residuals look much healthier. Later, we shall address the following ques-\\ntion: how do we see if Palm Beach County has a statistically plausible out-\\ncome?\\n■\\n13.2 Least Squares and Maximum Likelihood\\nSuppose we add the assumption that ϵi|Xi ∼ N(0,σ 2), that is,\\nYi|Xi ∼ N(µi,σ 2)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 228, 'page_label': '229'}, page_content='13.2 Least Squares and Maximum Likelihood 213\\nwhere µi = β0 + β1Xi. The likelihood function is\\nn∏\\ni=1\\nf(Xi,Yi)=\\nn∏\\ni=1\\nfX(Xi)fY |X(Yi|Xi)\\n=\\nn∏\\ni=1\\nfX(Xi) ×\\nn∏\\ni=1\\nfY |X(Yi|Xi)\\n= L1 ×L 2\\nwhere L1 = ∏n\\ni=1 fX(Xi) and\\nL2 =\\nn∏\\ni=1\\nfY |X(Yi|Xi). (13.8)\\nThe term L1 does not involve the parameters β0 and β1. We shall focus on\\nthe second term L2 which is called the conditional likelihood, given by\\nL2 ≡L (β0,β1,σ )=\\nn∏\\ni=1\\nfY |X(Yi|Xi) ∝ σ−n exp\\n{\\n− 1\\n2σ2\\n∑\\ni\\n(Yi − µi)2\\n}\\n.\\nThe conditional log-likelihood is\\nℓ(β0,β1,σ )= −n log σ − 1\\n2σ2\\nn∑\\ni=1\\n\\uf8f6\\nYi − (β0 + β1Xi)\\n\\uf8f72\\n. (13.9)\\nTo ﬁnd the mle of (β0,β1) we maximize ℓ(β0,β1,σ ). From (13.9) we see that\\nmaximizing the likelihood is the same as minimizing therss ∑ n\\ni=1\\n\\uf8f6\\nYi −(β0 +\\nβ1Xi)\\n\\uf8f72\\n. Therefore, we have shown the following:\\n13.7 Theorem. Under the assumption of Normality, the least squares estima-\\ntor is also the maximum likelihood estimator.\\nWe can also maximize ℓ(β0,β1,σ ) over σ, yielding the mle\\nˆσ2 = 1\\nn\\n∑\\ni\\nˆϵ2\\ni . (13.10)\\nThis estimator is similar to, but not identical to, the unbiased estimator.\\nCommon practice is to use the unbiased estimator (13.7).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 229, 'page_label': '230'}, page_content='214 13. Linear and Logistic Regression\\n13.3 Properties of the Least Squares Estimators\\nWe now record the standard errors and limiting distribution of the least\\nsquares estimator. In regression problems, we usually focus on the proper-\\nties of the estimators conditional on X\\nn =( X1,...,X n). Thus, we state the\\nmeans and variances as conditional means and variances.\\n13.8 Theorem. Let ˆβT =( ˆβ0, ˆβ1)T denote the least squares estimators.\\nThen,\\nE(ˆβ|Xn)=\\n\\uf8f6\\nβ0\\nβ1\\n\\uf8f7\\nV(ˆβ|Xn)= σ2\\nns 2\\nX\\n\\uf8f6 1\\nn\\n∑ n\\ni=1 X2\\ni −Xn\\n−Xn 1\\n\\uf8f7\\n(13.11)\\nwhere s2\\nX = n−1 ∑ n\\ni=1(Xi − Xn)2.\\nThe estimated standard errors of ˆβ0 and ˆβ1 are obtained by taking the\\nsquare roots of the corresponding diagonal terms of V(ˆβ|Xn) and inserting\\nthe estimate ˆσ for σ. Thus,\\nˆse(ˆβ0)= ˆσ\\nsX\\n√n\\n√ ∑ n\\ni=1 X2\\ni\\nn (13.12)\\nˆse(ˆβ1)= ˆσ\\nsX\\n√n. (13.13)\\nWe should really write these as ˆse(ˆβ0|Xn) and ˆse(ˆβ1|Xn) but we will use the\\nshorter notation ˆse(ˆβ0) and ˆse(ˆβ1).\\n13.9 Theorem. Under appropriate conditions we have:\\n1. (Consistency): ˆβ0\\nP\\n−→β0 and ˆβ1\\nP\\n−→β1.\\n2. (Asymptotic Normality):\\nˆβ0 − β0\\nˆse(ˆβ0)\\n⇝ N(0,1) and\\nˆβ1 − β1\\nˆse(ˆβ1)\\n⇝ N(0,1).\\n3. Approximate 1 − α conﬁdence intervals for β0 and β1 are\\nˆβ0 ± zα/2 ˆse(ˆβ0) and ˆβ1 ± zα/2 ˆse(ˆβ1). (13.14)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 230, 'page_label': '231'}, page_content='13.4 Prediction 215\\n4. The Wald test 2 for testing H0 : β1 =0 versus H1 : β1 ̸=0 is: reject H0\\nif |W| >z α/2 where W = ˆβ1/ˆse(ˆβ1).\\n13.10 Example. For the election data, on the log scale, a 95 percent conﬁ-\\ndence interval is .7303 ± 2(.0358) = (.66,.80). The Wald statistics for testing\\nH0 : β1 = 0 versus H1 : β1 ̸=0i s |W| = |.7303 − 0|/.0358 = 20.40 with a\\np-value of P(|Z| > 20.40) ≈ 0. This is strong evidence that that the true slope\\nis not 0. ■\\n13.4 Prediction\\nSuppose we have estimated a regression model ˆr(x)= ˆβ0 + ˆβ1x from data\\n(X1,Y1),..., (Xn,Yn). We observe the value X = x∗ of the covariate for a\\nnew subject and we want to predict their outcome Y∗. An estimate of Y∗ is\\nˆY∗ = ˆβ0 + ˆβ1x∗. (13.15)\\nUsing the formula for the variance of the sum of two random variables,\\nV(ˆY∗)= V(ˆβ0 + ˆβ1x∗)= V(ˆβ0)+ x2\\n∗V(ˆβ1)+2 x∗Cov(ˆβ0, ˆβ1).\\nTheorem 13.8 gives the formulas for all the terms in this equation. The es-\\ntimated standard error ˆse(ˆY∗) is the square root of this variance, with ˆσ2 in\\nplace of σ2. However, the conﬁdence interval for Y∗ is not of the usual form\\nˆY∗ ± zα/2 ˆse. The reason for this is explained in Exercise 10. The correct form\\nof the conﬁdence interval is given in the following theorem.\\n13.11 Theorem (Prediction Interval). Let\\nˆξ 2\\nn = ˆσ2\\n\\uf8f6∑ n\\ni=1(Xi − X∗)2\\nn ∑\\ni(Xi − X)2 +1\\n\\uf8f7\\n. (13.16)\\nAn approximate 1 − α prediction interval for Y∗ is\\nˆY∗ ± zα/2 ˆξn. (13.17)\\n2Recall from equation (10.5) that the Wald statistic for testing H0 : β = β0 versus H1 :\\nβ ̸= β0 is W =( ˆβ − β0)/ˆse(ˆβ).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 231, 'page_label': '232'}, page_content='216 13. Linear and Logistic Regression\\n13.12 Example (Election Data Revisited). On the log scale, our linear regres-\\nsion gives the following prediction equation:\\nlog(Buchanan) = −2.3298 + 0.7303 log(Bush).\\nIn Palm Beach, Bush had 152,954 votes and Buchanan had 3,467 votes. On the\\nlog scale this is 11.93789 and 8.151045. How likely is this outcome, assuming\\nour regression model is appropriate? Our prediction for log Buchanan votes\\n-2.3298 + .7303 (11.93789)=6.388441. Now, 8.151045 is bigger than 6.388441\\nbut is it “signiﬁcantly” bigger? Let us compute a conﬁdence interval. We\\nﬁnd that ˆξ\\nn = .093775 and the approximate 95 percent conﬁdence interval is\\n(6.200,6.578) which clearly excludes 8.151. Indeed, 8.151 is nearly 20 standard\\nerrors from ˆY\\n∗. Going back to the vote scale by exponentiating, the conﬁdence\\ninterval is (493,717) compared to the actual number of votes which is 3,467.\\n■\\n13.5 Multiple Regression\\nNow suppose that the covariate is a vector of length k. The data are of the\\nform\\n(Y1,X 1),..., (Yi,X i),..., (Yn,X n)\\nwhere\\nXi =( Xi1,...,X ik).\\nHere, Xi is the vector of k covariate values for theith observation. The linear\\nregression model is\\nYi =\\nk∑\\nj=1\\nβjXij + ϵi (13.18)\\nfor i =1 ,...,n , where E(ϵi|X1i,...,X ki) = 0. Usually we want to include an\\nintercept in the model which we can do by settingXi1 = 1 for i =1 ,...,n .A t\\nthis point it will be more convenient to express the model in matrix notation.\\nThe outcomes will be denoted by\\nY =\\n\\uf8eb\\n\\uf8ec\\uf8ec\\n\\uf8ec\\uf8ed\\nY\\n1\\nY2\\n..\\n.\\nY\\nn\\n\\uf8f6\\n\\uf8f7\\uf8f7\\n\\uf8f7\\uf8f8'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 232, 'page_label': '233'}, page_content='13.5 Multiple Regression 217\\nand the covariates will be denoted by\\nX =\\n\\uf8eb\\n\\uf8ec\\uf8ec\\n\\uf8ec\\uf8ed\\nX\\n11 X12 ... X 1k\\nX21 X22 ... X 2k\\n..\\n.\\n..\\n.\\n..\\n. ..\\n.\\nX\\nn1 Xn2 ... X nk\\n\\uf8f6\\n\\uf8f7\\uf8f7\\n\\uf8f7\\uf8f8.\\nEach row is one observation; the columns correspond to thek covariates. Thus,\\nX i sa( n × k) matrix. Let\\nβ =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\nβ\\n1\\n..\\n.\\nβ\\nk\\n\\uf8f6\\n\\uf8f7\\uf8f8 and ϵ =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\nϵ1\\n..\\n.\\nϵ\\nn\\n\\uf8f6\\n\\uf8f7\\uf8f8.\\nThen we can write (13.18) as\\nY = Xβ + ϵ. (13.19)\\nThe form of the least squares estimate is given in the following theorem.\\n13.13 Theorem. Assuming that the (k × k) matrix XT X is invertible,\\nˆβ =( XT X)−1XT Y (13.20)\\nV(ˆβ|Xn)= σ2(XT X)−1 (13.21)\\nˆβ ≈ N(β,σ 2(XT X)−1). (13.22)\\nThe estimate regression function is ˆr(x)= ∑ k\\nj=1\\nˆβjxj. An unbiased esti-\\nmate of σ2 is\\nˆσ2 =\\n\\uf8f6 1\\nn − k\\n\\uf8f7 n∑\\ni=1\\nˆϵ2\\ni\\nwhere ˆϵ = X ˆβ −Y is the vector of residuals. An approximate 1−α conﬁdence\\ninterval for βj is\\nˆβj ± zα/2 ˆse(ˆβj) (13.23)\\nwhere ˆse2(ˆβj)i st h ejth diagonal element of the matrix ˆσ2 (XT X)−1.\\n13.14 Example. Crime data on 47 states in 1960 can be obtained from\\nhttp://lib.stat.cmu.edu/DASL/Stories/USCrime.html.\\nIf we ﬁt a linear regression of crime rate on 10 variables we get the following:'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 233, 'page_label': '234'}, page_content='218 13. Linear and Logistic Regression\\nCovariate ˆβj ˆse(ˆβj ) t value p-value\\n(Intercept) -589.39 167.59 -3.51 0.001 **\\nAge 1.04 0.45 2.33 0.025 *\\nSouthern State 11.29 13.24 0.85 0.399\\nEducation 1.18 0.68 1.7 0.093\\nExpenditures 0.96 0.25 3.86 0.000 ***\\nLabor 0.11 0.15 0.69 0.493\\nNumber of Males 0.30 0.22 1.36 0.181\\nPopulation 0.09 0.14 0.65 0.518\\nUnemployment (14–24) -0.68 0.48 -1.4 0.165\\nUnemployment (25–39) 2.15 0.95 2.26 0.030 *\\nWealth -0.08 0.09 -0.91 0.367\\nThis table is typical of the output of a multiple regression program. The “t-\\nvalue” is the Wald test statistic for testingH0 : βj = 0 versusH1 : βj ̸= 0. The\\nasterisks denote “degree of signiﬁcance” and more asterisks denote smaller\\np-values. The example raises several important questions: (1) should we elim-\\ninate some variables from this model? (2) should we interpret these relation-\\nships as causal? For example, should we conclude that low crime prevention\\nexpenditures cause high crime rates? We will address question (1) in the next\\nsection. We will not address question (2) until Chapter 16.\\n■\\n13.6 Model Selection\\nExample 13.14 illustrates a problem that often arises in multiple regression.\\nWe may have data on many covariates but we may not want to include all of\\nthem in the model. A smaller model with fewer covariates has two advantages:\\nit might give better predictions than a big model and it is more parsimonious\\n(simpler). Generally, as you add more variables to a regression, the bias of the\\npredictions decreases and the variance increases. Too few covariates yields high\\nbias; this called underﬁtting. Too many covariates yields high variance; this\\ncalled overﬁtting. Good predictions result from achieving a good balance\\nbetween bias and variance.\\nIn model selection there are two problems: (i) assigning a “score” to each\\nmodel which measures, in some sense, how good the model is, and (ii) search-\\ning through all the models to ﬁnd the model with the best score.\\nLet us ﬁrst discuss the problem of scoring models. Let S ⊂{ 1,...,k } and\\nlet X\\nS = {Xj : j ∈ S} denote a subset of the covariates. Let βS denote the\\ncoeﬃcients of the corresponding set of covariates and let ˆβS denote the least\\nsquares estimate of βS. Also, let XS denote the X matrix for this subset of'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 234, 'page_label': '235'}, page_content='13.6 Model Selection 219\\ncovariates and deﬁne ˆrS(x) to be the estimated regression function. The pre-\\ndicted values from model S are denoted by ˆYi(S)= ˆrS(Xi). The prediction\\nrisk is deﬁned to be\\nR(S)=\\nn∑\\ni=1\\nE(ˆYi(S) − Y ∗\\ni )2 (13.24)\\nwhere Y ∗\\ni denotes the value of a future observation of Yi at covariate value\\nXi. Our goal is to choose S to make R(S) small.\\nThe training error is deﬁned to be\\nˆRtr(S)=\\nn∑\\ni=1\\n(ˆYi(S) − Yi)2.\\nThis estimate is very biased as an estimate of R(S).\\n13.15 Theorem. The training error is a downward-biased estimate of the pre-\\ndiction risk:\\nE( ˆRtr(S)) <R (S).\\nIn fact,\\nbias( ˆRtr(S)) = E( ˆRtr(S)) − R(S)= −2\\n∑\\ni=1\\nCov(ˆYi,Yi). (13.25)\\nThe reason for the bias is that the data are being used twice: to estimate\\nthe parameters and to estimate the risk. When we ﬁt a complex model with\\nmany parameters, the covariance Cov(ˆY\\ni,Yi) will be large and the bias of the\\ntraining error gets worse. Here are some better estimates of risk.\\nMallow’s Cp statistic is deﬁned by\\nˆR(S)= ˆRtr(S)+2 |S|ˆσ2 (13.26)\\nwhere |S| denotes the number of terms in S and ˆσ2 is the estimate of σ2\\nobtained from the full model (with all covariates in the model). This is simply\\nthe training error plus a bias correction. This estimate is named in honor of\\nColin Mallows who invented it. The ﬁrst term in (13.26) measures the ﬁt of\\nthe model while the second measure the complexity of the model. Think of\\nthe C\\np statistic as:\\nlack of ﬁt + complexity penalty .\\nThus, ﬁnding a good model involves trading oﬀ ﬁt and complexity.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 235, 'page_label': '236'}, page_content='220 13. Linear and Logistic Regression\\nA related method for estimating risk is AIC (Akaike Information Cri-\\nterion). The idea is to choose S to maximize\\nℓS −| S| (13.27)\\nwhere ℓS is the log-likelihood of the model evaluated at the mle. 3 This can\\nbe thought of “goodness of ﬁt” minus “complexity.” In linear regression with\\nNormal errors (and taking σ equal to its estimate from the largest model),\\nmaximizing AIC is equivalent to minimizing Mallow’sC\\np; see Exercise 8. The\\nappendix contains more explanation about AIC.\\nYet another method for estimating risk isleave-one-out cross-validation.\\nIn this case, the risk estimator is\\nˆRCV (S)=\\nn∑\\ni=1\\n(Yi − ˆY(i))2 (13.28)\\nwhere ˆY(i) is the prediction for Yi obtained by ﬁtting the model withYi omit-\\nted. It can be shown that\\nˆRCV (S)=\\nn∑\\ni=1\\n\\uf8f6\\nYi − ˆYi(S)\\n1 − Uii(S)\\n\\uf8f72\\n(13.29)\\nwhere Uii(S)i st h eith diagonal element of the matrix\\nU(S)= XS(XT\\nS XS)−1XT\\nS . (13.30)\\nThus, one need not actually drop each observation and re-ﬁt the model. A\\ngeneralization is k-fold cross-validation. Here we divide the data into k\\ngroups; often people take k = 10. We omit one group of data and ﬁt the\\nmodels to the remaining data. We use the ﬁtted model to predict the data\\nin the group that was omitted. We then estimate the risk by ∑\\ni(Yi − ˆYi)2\\nwhere the sum is over the the data points in the omitted group. This process is\\nrepeated for each of thek groups and the resulting risk estimates are averaged.\\nFor linear regression, MallowsCp and cross-validation often yield essentially\\nthe same results so one might as well use Mallows’ method. In some of the\\nmore complex problems we will discuss later, cross-validation will be more\\nuseful.\\nAnother scoring method is BIC (Bayesian information criterion). Here we\\nchoose a model to maximize\\nBIC(S)= ℓ\\nS − |S|\\n2 log n. (13.31)\\n3Some texts use a slightly diﬀerent deﬁnition of AIC which involves multiplying the deﬁnition\\nhere by 2 or -2. This has no eﬀect on which model is selected.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 236, 'page_label': '237'}, page_content='13.6 Model Selection 221\\nThe BIC score has a Bayesian interpretation. Let S = {S1,...,S m} denote\\na set of models. Suppose we assign the prior P(Sj)=1 /m over the models.\\nAlso, assume we put a smooth prior on the parameters within each model. It\\ncan be shown that the posterior probability for a model is approximately,\\nP(S\\nj|data) ≈ eBIC (Sj)\\n∑\\nr eBIC (Sr) .\\nHence, choosing the model with highest BIC is like choosing the model with\\nhighest posterior probability. The BIC score also has an information-theoretic\\ninterpretation in terms of something called minimum description length. The\\nBIC score is identical to MallowsC\\np except that it puts a more severe penalty\\nfor complexity. It thus leads one to choose a smaller model than the other\\nmethods.\\nNow let us turn to the problem of model search. If there are k covariates\\nthen there are 2\\nk possible models. We need to search through all these models,\\nassign a score to each one, and choose the model with the best score. If k is\\nnot too large we can do a complete search over all the models. Whenk is large,\\nthis is infeasible. In that case we need to search over a subset of all the models.\\nTwo common methods are forward and backward stepwise regression.\\nIn forward stepwise regression, we start with no covariates in the model. We\\nthen add the one variable that leads to the best score. We continue adding\\nvariables one at a time until the score does not improve. Backwards stepwise\\nregression is the same except that we start with the biggest model and drop\\none variable at a time. Both are greedy searches; nether is guaranteed to\\nﬁnd the model with the best score. Another popular method is to do random\\nsearching through the set of all models. However, there is no reason to expect\\nthis to be superior to a deterministic search.\\n13.16 Example. We applied backwards stepwise regression to the crime data\\nusing AIC. The following was obtained from the program R. This program\\nuses a slightly diﬀerent deﬁnition of AIC. With their deﬁnition, we seek the\\nsmallest (not largest) possible AIC. This is the same is minimizing Mallows\\nC\\np.\\nThe full model (which includes all covariates) has AIC= 310.37. In ascend-\\ning order, the AIC scores for deleting one variable are as follows:\\nvariable Pop Labor South Wealth Males U1 Educ. U2 Age Expend\\nAIC 308 309 309 309 310 310 312 314 315 324\\nFor example, if we dropped Pop from the model and kept the other terms,\\nthen the AIC score would be 308. Based on this information we drop “pop-'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 237, 'page_label': '238'}, page_content='222 13. Linear and Logistic Regression\\nulation” from the model and the current AIC score is 308. Now we consider\\ndropping a variable from the current model. The AIC scores are:\\nvariable South Labor Wealth Males U1 Education U2 Age Expend\\nAIC 308 308 308 309 309 310 313 313 329\\nWe then drop “Southern” from the model. This process is continued until\\nthere is no gain in AIC by dropping any variables. In the end, we are left with\\nthe following model:\\nCrime = 1 .2 Age + .75 Education + .87 Expenditure\\n+ .34 Males − .86 U1 + 2 .31 U2.\\nWarning! This does not yet address the question of which variables are\\ncauses of crime.\\n■\\nThere is another method for model selection that avoids having to search\\nthrough all possible models. This method, which is due to Zheng and Loh\\n(1995), does not seek to minimize prediction errors. Rather, it assumes some\\nsubset of the β\\nj’s are exactly equal to 0 and tries to ﬁnd the true model,\\nthat is, the smallest sub-model consisting of nonzero βj terms. The method\\nis carried out as follows.\\nZheng-Loh Model Selection Method 4\\n1. Fit the full model with all k covariates and let Wj = ˆβj/ˆse(ˆβj) denote\\nthe Wald test statistic for H0 : βj = 0 versus H1 : βj ̸=0 .\\n2. Order the test statistics from largest to smallest in absolute value:\\n|W(1)|≥| W(2)|≥···≥| W(k)|.\\n3. Let ˆj be the value of j that minimizes\\nrss(j)+ j ˆσ2 log n\\nwhere rss(j) is the residual sums of squares from the model with\\nthe j largest Wald statistics.\\n4. Choose, as the ﬁnal model, the regression with the ˆj terms with the\\nlargest absolute Wald statistics.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 238, 'page_label': '239'}, page_content='13.7 Logistic Regression 223\\nx0\\n1\\nFIGURE 13.3. The logistic function p = ex/(1 +ex).\\nZheng and Loh showed that, under appropriate conditions, this method\\nchooses the true model with probability tending to one as the sample size\\nincreases.\\n13.7 Logistic Regression\\nSo far we have assumed thatYi is real valued.Logistic regression is a para-\\nmetric method for regression when Yi ∈{ 0,1} is binary. For a k-dimensional\\ncovariate X, the model is\\npi ≡ pi(β) ≡ P(Yi =1 |X = x)= eβ0+∑ k\\nj=1 βjxij\\n1+ eβ0+∑ k\\nj=1 βjxij\\n(13.32)\\nor, equivalently,\\nlogit(pi)= β0 +\\nk∑\\nj=1\\nβjxij (13.33)\\nwhere\\nlogit(p) = log\\n\\uf8f6 p\\n1 − p\\n\\uf8f7\\n. (13.34)\\nThe name “logistic regression” comes from the fact that ex/(1 +ex) is called\\nthe logistic function. A plot of the logistic for a one-dimensional covariate is\\nshown in Figure 13.3.\\nBecause the Y\\ni’s are binary, the data are Bernoulli:\\nYi|Xi = xi ∼ Bernoulli(pi).\\nHence the (conditional) likelihood function is\\nL(β)=\\nn∏\\ni=1\\npi(β)Yi (1 − pi(β))1−Yi . (13.35)\\n4This is just one version of their method. In particular, the penaltyj log n is only one choice\\nfrom a set of possible penalty functions.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 239, 'page_label': '240'}, page_content='224 13. Linear and Logistic Regression\\nThe mle ˆβ has to be obtained by maximizing L(β) numerically. There is\\na fast numerical algorithm called reweighted least squares. The steps are as\\nfollows:\\nReweighted Least Squares Algorithm\\nChoose starting values ˆβ0 =( ˆβ0\\n0,..., ˆβ0\\nk) and compute p0\\ni using equation\\n(13.32), for i =1 ,...,n . Set s = 0 and iterate the following steps until\\nconvergence.\\n1. Set\\nZi = logit(ps\\ni )+ Yi − ps\\ni\\nps\\ni\\n(1 − ps\\ni ),i =1 ,...,n .\\n2. Let W be a diagonal matrix with (i, i) element equal to ps\\ni (1 − ps\\ni ).\\n3. Set\\nˆβs =( XT WX )−1XT WY.\\nThis corresponds to doing a (weighted) linear regression of Z on Y .\\n4. Set s = s + 1 and go back to the ﬁrst step.\\nThe Fisher information matrix I can also be obtained numerically. The\\nestimate standard error of ˆβj is the (j, j) element of J = I−1. Model selection\\nis usually done using the AIC score ℓS −| S|.\\n13.17 Example. The Coronary Risk-Factor Study (CORIS) data involve 462\\nmales between the ages of 15 and 64 from three rural areas in South Africa,\\n(Rousseauw et al. (1983)). The outcomeY is the presence (Y = 1) or absence\\n(Y = 0) of coronary heart disease. There are 9 covariates: systolic blood\\npressure, cumulative tobacco (kg), ldl (low density lipoprotein cholesterol),\\nadiposity, famhist (family history of heart disease), typea (type-A behavior),\\nobesity, alcohol (current alcohol consumption), and age. A logistic regression\\nyields the following estimates and Wald statistics W\\nj for the coeﬃcients:'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 240, 'page_label': '241'}, page_content='13.8 Bibliographic Remarks 225\\nCovariate ˆβj ˆse Wj p-value\\nIntercept -6.145 1.300 -4.738 0.000\\nsbp 0.007 0.006 1.138 0.255\\ntobacco 0.079 0.027 2.991 0.003\\nldl 0.174 0.059 2.925 0.003\\nadiposity 0.019 0.029 0.637 0.524\\nfamhist 0.925 0.227 4.078 0.000\\ntypea 0.040 0.012 3.233 0.001\\nobesity -0.063 0.044 -1.427 0.153\\nalcohol 0.000 0.004 0.027 0.979\\nage 0.045 0.012 3.754 0.000\\nAre you surprised by the fact that systolic blood pressure is not signiﬁcant\\nor by the minus sign for the obesity coeﬃcient? If yes, then you are confusing\\nassociation and causation. This issue is discussed in Chapter 16. The fact\\nthat blood pressure is not signiﬁcant does not mean that blood pressure is\\nnot an important cause of heart disease. It means that it is not an important\\npredictor of heart disease relative to the other variables in the model.\\n■\\n13.8 Bibliographic Remarks\\nA succinct book on linear regression is Weisberg (1985). A data-mining view\\nof regression is given in Hastie et al. (2001). The Akaike Information Criterion\\n(AIC) is due to Akaike (1973). The Bayesian Information Criterion (BIC) is\\ndue to Schwarz (1978). References on logistic regression include Agresti (1990)\\nand Dobson (2001).\\n13.9 Appendix\\nThe Akaike Information Criterion (AIC). Consider a set of models\\n{M1,M 2,... }. Let ˆfj(x) denote the estimated probability function obtained\\nby using the maximum likelihood estimator of model Mj. Thus, ˆfj(x)=\\nˆf(x; ˆβj) where ˆβj is the mle of the set of parameters βj for model Mj.W e\\nwill use the loss function D(f, ˆf) where\\nD(f,g )=\\n∑\\nx\\nf(x) log\\n\\uf8f6f(x)\\ng(x)\\n\\uf8f7\\nis the Kullback-Leibler distance between two probability functions. The cor-\\nresponding risk function is R(f, ˆf)= E(D(f, ˆf). Notice that D(f, ˆf)= c −'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 241, 'page_label': '242'}, page_content='226 13. Linear and Logistic Regression\\nA(f, ˆf) where c = ∑\\nx f(x) logf(x) does not depend on ˆf and\\nA(f, ˆf)=\\n∑\\nx\\nf(x) log ˆf(x).\\nThus, minimizing the risk is equivalent to maximizing a(f, ˆf) ≡ E(A(f, ˆf)).\\nIt is tempting to estimatea(f, ˆf)b y ∑\\nx\\nˆf(x) log ˆf(x) but, just as the train-\\ning error in regression is a highly biased estimate of prediction risk, it is also\\nthe case that ∑\\nx\\nˆf(x) log ˆf(x) is a highly biased estimate of a(f, ˆf). In fact,\\nthe bias is approximately equal to |Mj|. Thus:\\n13.18 Theorem. AIC(Mj) is an approximately unbiased estimate ofa(f, ˆf).\\n13.10 Exercises\\n1. Prove Theorem 13.4.\\n2. Prove the formulas for the standard errors in Theorem 13.8. You should\\nregard the Xi’s as ﬁxed constants.\\n3. Consider the regression through the origin model:\\nYi = βXi + ϵ.\\nFind the least squares estimate for β. Find the standard error of the\\nestimate. Find conditions that guarantee that the estimate is consistent.\\n4. Prove equation (13.25).\\n5. In the simple linear regression model, construct a Wald test for H\\n0 :\\nβ1 =1 7β0 versus H1 : β1 ̸=1 7β0.\\n6. Get the passenger car mileage data from\\nhttp://lib.stat.cmu.edu/DASL/Dataﬁles/carmpgdat.html\\n(a) Fit a simple linear regression model to predict MPG (miles per\\ngallon) from HP (horsepower). Summarize your analysis including a\\nplot of the data with the ﬁtted line.\\n(b) Repeat the analysis but use log(MPG) as the response. Compare\\nthe analyses.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 242, 'page_label': '243'}, page_content='13.10 Exercises 227\\n7. Get the passenger car mileage data from\\nhttp://lib.stat.cmu.edu/DASL/Dataﬁles/carmpgdat.html\\n(a) Fit a multiple linear regression model to predict MPG (miles per\\ngallon) from the other variables. Summarize your analysis.\\n(b) Use Mallow C\\np to select a best sub-model. To search through the\\nmodels try (i) forward stepwise, (ii) backward stepwise. Summarize your\\nﬁndings.\\n(c) Use the Zheng-Loh model selection method and compare to (b).\\n(d) Perform all possible regressions. CompareC\\np and BIC. Compare the\\nresults.\\n8. Assume a linear regression model with Normal errors. Take σ known.\\nShow that the model with highest AIC (equation (13.27)) is the model\\nwith the lowest Mallows C\\np statistic.\\n9. In this question we will take a closer look at the AIC method. Let\\nX1,...,X n be iid observations. Consider two modelsM0 and M1. Un-\\nder M0 the data are assumed to be N(0,1) while under M1 the data\\nare assumed to be N(θ, 1) for some unknown θ ∈ R:\\nM0 : X1,...,X n ∼ N(0,1)\\nM1 : X1,...,X n ∼ N(θ, 1),θ ∈ R.\\nThis is just another way to view the hypothesis testing problem: H0 :\\nθ = 0 versus H1 : θ ̸= 0. Let ℓn(θ) be the log-likelihood function.\\nThe AIC score for a model is the log-likelihood at the mle minus the\\nnumber of parameters. (Some people multiply this score by 2 but that\\nis irrelevant.) Thus, the AIC score forM\\n0 is AIC0 = ℓn(0) and the AIC\\nscore for M1 is AIC1 = ℓn(ˆθ) − 1. Suppose we choose the model with\\nthe highest AIC score. Let Jn denote the selected model:\\nJn =\\n{ 0i f AIC0 >A I C1\\n1i f AIC1 >A I C0.\\n(a) Suppose that M0 is the true model, i.e. θ = 0. Find\\nlim\\nn→∞\\nP (Jn =0 ).\\nNow compute limn→∞ P (Jn = 0) when θ ̸=0 .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 243, 'page_label': '244'}, page_content='228 13. Linear and Logistic Regression\\n(b) The fact that limn→∞ P (Jn =0 ) ̸= 1 whenθ = 0 is why some people\\nsay that AIC “overﬁts.” But this is not quite true as we shall now see.\\nLet φ\\nθ(x) denote a Normal density function with mean θ and variance\\n1. Deﬁne\\nˆfn(x)=\\n{\\nφ0(x)i f Jn =0\\nφˆθ(x)i f Jn =1 .\\nIf θ = 0, show that D(φ0, ˆfn)\\np\\n→ 0a s n →∞ where\\nD(f,g )=\\n∫\\nf(x) log\\n\\uf8f6f(x)\\ng(x)\\n\\uf8f7\\ndx\\nis the Kullback-Leibler distance. Show also thatD(φθ, ˆfn)\\np\\n→ 0i f θ ̸=0 .\\nHence, AIC consistently estimates the true density even if it “over-\\nshoots” the correct model.\\n(c) Repeat this analysis for BIC which is the log-likelihood minus (p/2) logn\\nwhere p is the number of parameters and n is sample size.\\n10. In this question we take a closer look at prediction intervals. Let θ =\\nβ\\n0 + β1X∗ and let ˆθ = ˆβ0 + ˆβ1X∗. Thus, ˆY∗ = ˆθ while Y∗ = θ + ϵ.N o w ,\\nˆθ ≈ N(θ, se2) where\\nse2 = V(ˆθ)= V(ˆβ0 + ˆβ1x∗).\\nNote thatV(ˆθ) is the same asV(ˆY∗). Now, ˆθ±2\\n√\\nV(ˆθ) is an approximate\\n95 percent conﬁdence interval forθ = β0+β1x∗ using the usual argument\\nfor a conﬁdence interval. But, as you shall now show, it is not a valid\\nconﬁdence interval for Y\\n∗.\\n(a) Let s =\\n√\\nV(ˆY∗). Show that\\nP(ˆY∗ − 2s<Y ∗ < ˆY∗ +2 s) ≈ P\\n\\uf8f6\\n−2 <N\\n\\uf8f6\\n0,1+ σ2\\ns2\\n\\uf8f7\\n< 2\\n\\uf8f7\\n̸=0 .95.\\n(b) The problem is that the quantity of interestY∗ is equal to a param-\\neter θ plus a random variable. We can ﬁx this by deﬁning\\nξ2\\nn = V(ˆY∗)+ σ2 =\\n[∑\\ni(xi − x∗)2\\nn ∑\\ni(xi − x)2 +1\\n]\\nσ2.\\nIn practice, we substitute ˆσ for σ and we denote the resulting quantity\\nby ˆξn. Now consider the interval ˆY∗ ± 2 ˆξn. Show that\\nP(ˆY∗ − 2ˆξn <Y ∗ < ˆY∗ +2 ˆξn) ≈ P (−2 <N (0,1) < 2) ≈ 0.95.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 244, 'page_label': '245'}, page_content='13.10 Exercises 229\\n11. Get the Coronary Risk-Factor Study (CORIS) data from the book web\\nsite. Use backward stepwise logistic regression based on AIC to select a\\nmodel. Summarize your results.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 245, 'page_label': '246'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 246, 'page_label': '247'}, page_content='14\\nMultivariate Models\\nIn this chapter we revisit the Multinomial model and the multivariate Normal.\\nLet us ﬁrst review some notation from linear algebra. In what follows, x and\\ny are vectors and A is a matrix.\\nLinear Algebra Notation\\nxT y inner product ∑\\nj xjyj\\n|A| determinant\\nAT transpose of A\\nA−1 inverse of A\\nI the identity matrix\\ntr(A) trace of a square matrix; sum of its diagonal elements\\nA1/2 square root matrix\\nThe trace satisﬁes tr(AB) = tr(BA) and tr(A) + tr(B). Also, tr(a)= a if a\\nis a scalar. A matrix is positive deﬁnite if xT Σx> 0 for all nonzero vectors\\nx. If a matrix A is symmetric and positive deﬁnite, its square rootA1/2 exists\\nand has the following properties: (1) A1/2 is symmetric; (2) A = A1/2A1/2;\\n(3) A1/2A−1/2 = A−1/2A1/2 = I where A−1/2 =( A1/2)−1.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 247, 'page_label': '248'}, page_content='232 14. Multivariate Models\\n14.1 Random Vectors\\nMultivariate models involve a random vector X of the form\\nX =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\nX1\\n..\\n.\\nX\\nk\\n\\uf8f6\\n\\uf8f7\\uf8f8.\\nThe mean of a random vector X is deﬁned by\\nµ =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\nµ1\\n..\\n.\\nµ\\nk\\n\\uf8f6\\n\\uf8f7\\uf8f8 =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\nE(X1)\\n..\\n.\\nE(X\\nk)\\n\\uf8f6\\n\\uf8f7\\uf8f8. (14.1)\\nThe covariance matrix Σ, also written V(X), is deﬁned to be\\nΣ=\\n\\uf8ee\\n\\uf8ef\\uf8ef\\n\\uf8ef\\uf8f0\\nV(X\\n1) Cov(X1,X 2) ··· Cov(X1,X k)\\nCov(X2,X 1) V(X2) ··· Cov(X2,X k)\\n..\\n. ..\\n. ..\\n. ..\\n.\\nCov(X\\nk,X 1) Cov(Xk,X 2) ··· V(Xk)\\n\\uf8f9\\n\\uf8fa\\uf8fa\\n\\uf8fa\\uf8fb. (14.2)\\nThis is also called the variance matrix or the variance–covariance matrix. The\\ninverse Σ\\n−1 is called the precision matrix.\\n14.1 Theorem. Let a be a vector of length k and let X be a random vector\\nof the same length with mean µ and variance Σ. Then E(aT X)= aT µ and\\nV(aT X)= aT Σa.I f A is a matrix with k columns, then E(AX)= Aµ and\\nV(AX)= AΣAT .\\nNow suppose we have a random sample of n vectors:\\n\\uf8eb\\n\\uf8ec\\uf8ec\\n\\uf8ec\\uf8ed\\nX\\n11\\nX21\\n..\\n.\\nX\\nk1\\n\\uf8f6\\n\\uf8f7\\uf8f7\\n\\uf8f7\\uf8f8,\\n\\uf8eb\\n\\uf8ec\\uf8ec\\n\\uf8ec\\uf8ed\\nX\\n12\\nX22\\n..\\n.\\nX\\nk2\\n\\uf8f6\\n\\uf8f7\\uf8f7\\n\\uf8f7\\uf8f8, ...,\\n\\uf8eb\\n\\uf8ec\\uf8ec\\n\\uf8ec\\uf8ed\\nX\\n1n\\nX2n\\n..\\n.\\nX\\nkn\\n\\uf8f6\\n\\uf8f7\\uf8f7\\n\\uf8f7\\uf8f8. (14.3)\\nThe sample mean\\nX is a vector deﬁned by\\nX =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\nX1\\n..\\n.\\nXk\\n\\uf8f6\\n\\uf8f7\\uf8f8'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 248, 'page_label': '249'}, page_content='14.2 Estimating the Correlation 233\\nwhere Xi = n−1 ∑ n\\nj=1 Xij. The sample variance matrix, also called the co-\\nvariance matrix or the variance–covariance matrix, is\\nS =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\n\\uf8ef\\uf8f0\\ns\\n11 s12 ··· s1k\\ns12 s22 ··· s2k\\n..\\n.\\n..\\n.\\n..\\n. ..\\n.\\ns\\n1k s2k ··· skk\\n\\uf8f9\\n\\uf8fa\\uf8fa\\n\\uf8fa\\uf8fb (14.4)\\nwhere\\ns\\nab = 1\\nn − 1\\nn∑\\nj=1\\n(Xaj − Xa)(Xbj − Xb).\\nIt follows that E(X)= µ. and E(S)=Σ .\\n14.2 Estimating the Correlation\\nConsider n data points from a bivariate distribution:\\n\\uf8f6 X11\\nX21\\n\\uf8f7\\n,\\n\\uf8f6 X12\\nX22\\n\\uf8f7\\n,··· ,\\n\\uf8f6 X1n\\nX2n\\n\\uf8f7\\n.\\nRecall that the correlation between X1 and X2 is\\nρ = E((X1 − µ1)(X2 − µ2))\\nσ1σ2\\n(14.5)\\nwhere σ2\\nj = V(Xji), j =1 ,2. The nonparametric plug-in estimator is the\\nsample correlation 1\\nˆρ =\\n∑ n\\ni=1(X1i − X1)(X2i − X2)\\ns1s2\\n(14.6)\\nwhere\\ns2\\nj = 1\\nn − 1\\nn∑\\ni=1\\n(Xji − Xj)2.\\nWe can construct a conﬁdence interval for ρ by applying the delta method.\\nHowever, it turns out that we get a more accurate conﬁdence interval by ﬁrst\\nconstructing a conﬁdence interval for a function θ = f(ρ) and then applying\\n1More precisely, the plug-in estimator hasn rather than n − 1 in the formula for sj but this\\ndiﬀerence is small.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 249, 'page_label': '250'}, page_content='234 14. Multivariate Models\\nthe inverse function f−1. The method, due to Fisher, is as follows: Deﬁne f\\nand its inverse by\\nf(r)= 1\\n2\\n\\uf8f6\\nlog(1 +r) − log(1 − r)\\n\\uf8f7\\nf−1(z)= e2z − 1\\ne2z +1 .\\nApproximate Conﬁdence Interval for The Correlation\\n1. Compute\\nˆθ = f(ˆρ)= 1\\n2\\n\\uf8f6\\nlog(1 + ˆρ) − log(1 − ˆρ)\\n\\uf8f7\\n.\\n2. Compute the approximate standard error of ˆθ which can be shown to\\nbe\\nˆse(ˆθ)= 1√n − 3.\\n3. An approximate 1 − α conﬁdence interval for θ = f(ρ)i s\\n(a, b) ≡\\n\\uf8f6\\nˆθ − zα/2√n − 3, ˆθ + zα/2√n − 3\\n\\uf8f7\\n.\\n4. Apply the inverse transformation f−1(z) to get a conﬁdence interval\\nfor ρ: \\uf8f6e2a − 1\\ne2a +1 , e2b − 1\\ne2b +1\\n\\uf8f7\\n.\\nYet another method for getting a conﬁdence interval for ρ is to use the\\nbootstrap.\\n14.3 Multivariate Normal\\nRecall that a vector X has a multivariate Normal distribution, denoted by\\nX ∼ N(µ,Σ), if its density is\\nf(x; µ,Σ) = 1\\n(2π)k/2|Σ|1/2 exp\\n{\\n−1\\n2(x − µ)T Σ−1(x − µ)\\n}\\n(14.7)\\nwhere µ is a vector of length k a n dΣi sa k × k symmetric, positive deﬁnite\\nmatrix. Then E(X)= µ and V(X)=Σ .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 250, 'page_label': '251'}, page_content='14.4 Multinomial 235\\n14.2 Theorem. The following properties hold:\\n1. If Z ∼ N(0,1) and X = µ +Σ 1/2Z, then X ∼ N(µ,Σ).\\n2. If X ∼ N(µ,Σ), then Σ−1/2(X − µ) ∼ N(0,1).\\n3. If X ∼ N(µ,Σ) a is a vector of the same length as X, then aT X ∼\\nN(aT µ, aT Σa).\\n4. Let\\nV =( X − µ)T Σ−1(X − µ).\\nThen V ∼ χ2\\nk.\\n14.3 Theorem. Given a random sample of size n from a N(µ,Σ), the log-\\nlikelihood is (up to a constant not depending onµ or Σ) given by\\nℓ(µ,Σ) = −n\\n2 (X − µ)T Σ−1(X − µ) − n\\n2 tr(Σ−1S) − n\\n2 log |Σ|.\\nThe mle is\\nˆµ = X and ˆΣ=\\n\\uf8f6n − 1\\nn\\n\\uf8f7\\nS. (14.8)\\n14.4 Multinomial\\nLet us now review the Multinomial distribution. The data take the form\\nX =( X1,...,X k) where each Xj is a count. Think of drawing n balls (with\\nreplacement) from an urn which has balls withk diﬀerent colors. In this case,\\nXj is the number of balls of the kth color. Let p =( p1,...,p k) where pj ≥ 0\\nand ∑ k\\nj=1 pj = 1 and suppose that pj is the probability of drawing a ball of\\ncolor j.\\n14.4 Theorem. Let X ∼ Multinomial(n, p). Then the marginal distribution\\nof Xj is Xj ∼ Binomial(n, pj). The mean and variance of X are\\nE(X)=\\n\\uf8eb\\n\\uf8ec\\uf8ed\\nnp1\\n..\\n.\\nnp\\nk\\n\\uf8f6\\n\\uf8f7\\uf8f8\\nand\\nV(X)=\\n\\uf8eb\\n\\uf8ec\\uf8ec\\n\\uf8ec\\uf8ed\\nnp\\n1(1 − p1) −np1p2 ··· − np1pk\\n−np1p2 np2(1 − p2) ··· − np2pk\\n..\\n. ..\\n. ..\\n.\\n..\\n.\\n−np\\n1pk −np2pk ··· npk(1 − pk)\\n\\uf8f6\\n\\uf8f7\\uf8f7\\n\\uf8f7\\uf8f8.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 251, 'page_label': '252'}, page_content='236 14. Multivariate Models\\nProof. That Xj ∼ Binomial(n, pj) follows easily. Hence,E(Xj)= npj and\\nV(Xj)= npj(1 − pj). To compute Cov(Xi,X j) we proceed as follows: Notice\\nthat Xi+Xj ∼ Binomial(n, pi+pj) and soV(Xi+Xj)= n(pi+pj)(1−pi−pj).\\nOn the other hand,\\nV(Xi + Xj)= V(Xi)+ V(Xj)+2 Cov(Xi,X j)\\n= npi(1 − pi)+ npj(1 − pj)+2 Cov(Xi,X j).\\nEquating this last expression withn(pi+pj)(1−pi−pj) implies thatCov(Xi,X j)=\\n−npipj. ■\\n14.5 Theorem. The maximum likelihood estimator of p is\\nˆp =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\nˆp1\\n..\\n.\\nˆp\\nk\\n\\uf8f6\\n\\uf8f7\\uf8f8 =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\nX1\\nn\\n..\\n.\\nXk\\nn\\n\\uf8f6\\n\\uf8f7\\uf8f8 = X\\nn .\\nProof. The log-likelihood (ignoring a constant) is\\nℓ(p)=\\nk∑\\nj=1\\nXj log pj.\\nWhen we maximize ℓ we have to be careful since we must enforce the con-\\nstraint that∑\\nj pj = 1. We use the method of Lagrange multipliers and instead\\nmaximize\\nA(p)=\\nk∑\\nj=1\\nXj log pj + λ\\n\\uf8f6∑\\nj\\npj − 1\\n\\uf8f7\\n.\\nNow\\n∂A(p)\\n∂pj\\n= Xj\\npj\\n+ λ.\\nSetting ∂A(p)\\n∂pj\\n= 0 yields ˆpj = −Xj/λ. Since ∑\\nj ˆpj = 1 we see that λ = −n\\nand hence ˆpj = Xj/n as claimed. ■\\nNext we would like to know the variability of the mle. We can either\\ncompute the variance matrix of ˆp directly or we can approximate the vari-\\nability of the mle by computing the Fisher information matrix. These two\\napproaches give the same answer in this case. The direct approach is easy:\\nV(ˆp)= V(X/n)= n\\n−2V(X), and so\\nV(ˆp)= 1\\nnΣ'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 252, 'page_label': '253'}, page_content='14.5 Bibliographic Remarks 237\\nwhere\\nΣ=\\n\\uf8eb\\n\\uf8ec\\uf8ec\\n\\uf8ec\\uf8ed\\np\\n1(1 − p1) −p1p2 ··· − p1pk\\n−p1p2 p2(1 − p2) ··· − p2pk\\n..\\n.\\n..\\n.\\n..\\n.\\n..\\n.\\n−p\\n1pk −p2pk ··· pk(1 − pk)\\n\\uf8f6\\n\\uf8f7\\uf8f7\\n\\uf8f7\\uf8f8.\\nFor large n, ˆp has approximately a multivariate Normal distribution.\\n14.6 Theorem. As n →∞ ,\\n√\\nn(ˆp − p) ⇝ N(0,Σ).\\n14.5 Bibliographic Remarks\\nSome references on multivariate analysis are Johnson and Wichern (1982) and\\nAnderson (1984). The method for constructing the conﬁdence interval for the\\ncorrelation described in this chapter is due to Fisher (1921).\\n14.6 Appendix\\nProof of Theorem 14.3. Denote the ith random vector by Xi. The log-\\nlikelihood is\\nℓ(µ,Σ) =\\nn∑\\ni=1\\nf(Xi; µ,Σ)\\n= −kn\\n2 log(2π) − n\\n2 log |Σ|− 1\\n2\\nn∑\\ni=1\\n(Xi − µ)T Σ−1(Xi − µ).\\nNow,\\nn∑\\ni=1\\n(Xi − µ)T Σ−1(Xi − µ)\\n=\\nn∑\\ni=1\\n[(Xi − X)+( X − µ)]T Σ−1[(Xi − X)+( X − µ)]\\n=\\nn∑\\ni=1\\n[\\n(Xi − X)T Σ−1(Xi − X)\\n]\\n+ n(X − µ)T Σ−1(X − µ)\\nsince ∑ n\\ni=1(Xi −X)Σ−1(X −µ) = 0. Also, notice that (Xi −µ)T Σ−1(Xi −µ)\\nis a scalar, so\\nn∑\\ni=1\\n(Xi − µ)T Σ−1(Xi − µ)=\\nn∑\\ni=1\\ntr\\n[\\n(Xi − µ)T Σ−1(Xi − µ)\\n]'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 253, 'page_label': '254'}, page_content='238 14. Multivariate Models\\n=\\nn∑\\ni=1\\ntr\\n[\\nΣ−1(Xi − µ)(Xi − µ)T ]\\n=t r\\n[\\nΣ−1\\nn∑\\ni=1\\n(Xi − µ)(Xi − µ)T\\n]\\n= n tr\\n[\\nΣ−1S\\n]\\nand the conclusion follows. ■\\n14.7 Exercises\\n1. Prove Theorem 14.1.\\n2. Find the Fisher information matrix for the mle of a Multinomial.\\n3. ( Computer Experiment.) Write a function to generate nsim observations\\nfrom a Multinomial(n, p) distribution.\\n4. ( Computer Experiment.) Write a function to generate nsim observations\\nfrom a Multivariate normal with given mean µ and covariance matrix\\nΣ.\\n5. ( Computer Experiment.) Generate 100 random vectors from a N(µ,Σ)\\ndistribution where\\nµ =\\n\\uf8f6 3\\n8\\n\\uf8f7\\n, Σ=\\n\\uf8f6 11\\n12\\n\\uf8f7\\n.\\nPlot the simulation as a scatterplot. Estimate the mean and covariance\\nmatrix Σ. Find the correlation ρ between X1 and X2. Compare this\\nwith the sample correlations from your simulation. Find a 95 percent\\nconﬁdence interval for ρ. Use two methods: the bootstrap and Fisher’s\\nmethod. Compare.\\n6. ( Computer Experiment.) Repeat the previous exercise 1000 times. Com-\\npare the coverage of the two conﬁdence intervals forρ.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 254, 'page_label': '255'}, page_content='15\\nInference About Independence\\nIn this chapter we address the following questions:\\n(1) How do we test if two random variables are independent?\\n(2) How do we estimate the strength of dependence between two\\nrandom variables?\\nWhen Y and Z are not independent, we say that they are dependent or\\nassociated or related. If Y and Z are associated, it does not imply that Y\\ncauses Z or that Z causes Y . Causation is discussed in Chapter 16.\\nRecall that we write Y ⨿ Z to mean that Y and Z are independent and we\\nwrite Y /gluonbelement/gluonelement/gluonelement/gluonelement/gluonelement/gluoneelementZ to mean that Y and Z are dependent.\\n15.1 Two Binary Variables\\nSuppose thatY and Z are both binary and consider data (Y1,Z1), ... ,( Yn,Zn).\\nWe can represent the data as a two-by-two table:\\nY =0 Y =1\\nZ =0 X00 X01 X0·\\nZ =1 X10 X11 X1·\\nX·0 X·1 n = X··'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 255, 'page_label': '256'}, page_content='240 15. Inference About Independence\\nwhere\\nXij = number of observations for which Y = i and Z = j.\\nThe dotted subscripts denote sums. Thus,\\nXi· =\\n∑\\nj\\nXij,X ·j =\\n∑\\ni\\nXij,n = X·· =\\n∑\\ni,j\\nXij.\\nThis is a convention we use throughout the remainder of the book. Denote\\nthe corresponding probabilities by:\\nY =0 Y =1\\nZ =0 p00 p01 p0·\\nZ =1 p10 p11 p1·\\np·0 p·1 1\\nwhere pij = P(Z = i, Y = j). Let X =( X00,X 01,X 10,X 11) denote the vector\\nof counts. ThenX ∼ Multinomial(n, p) where p =( p00,p 01,p 10,p 11). It is now\\nconvenient to introduce two new parameters.\\n15.1 Deﬁnition. The odds ratio is deﬁned to be\\nψ = p00p11\\np01p10\\n. (15.1)\\nThe log odds ratio is deﬁned to be\\nγ = log(ψ). (15.2)\\n15.2 Theorem. The following statements are equivalent:\\n1. Y ⨿ Z.\\n2. ψ =1 .\\n3. γ =0 .\\n4. For i, j ∈{ 0,1}, pij = pi·p·j.\\nNow consider testing\\nH0 : Y ⨿ Z versus H1 : Y /gluonbelement/gluonelement/gluonelement/gluonelement/gluonelement/gluoneelementZ. (15.3)\\nFirst we consider the likelihood ratio test. Under H1, X ∼ Multinomial(n, p)\\nand the mle is the vector ˆp = X/n. Under H0, we again have that X ∼\\nMultinomial(n, p) but the restricted mle is computed under the constraint\\npij = pi·p·j This leads to the following test:'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 256, 'page_label': '257'}, page_content='15.1 Two Binary Variables 241\\n15.3 Theorem. The likelihood ratio test statistic for (15.3) is\\nT =2\\n1∑\\ni=0\\n1∑\\nj=0\\nXij log\\n\\uf8f6XijX··\\nXi·X·j\\n\\uf8f7\\n. (15.4)\\nUnder H0, T ⇝ χ2\\n1. Thus, an approximate level α test is obtained by\\nrejecting H0 when T>χ 2\\n1,α.\\nAnother popular test for independence is Pearson’s χ2 test.\\n15.4 Theorem. Pearson’s χ2 test statistic for independence is\\nU =\\n1∑\\ni=0\\n1∑\\nj=0\\n(Xij − Eij)2\\nEij\\n(15.5)\\nwhere\\nEij = Xi·X·j\\nn .\\nUnder H0, U ⇝ χ2\\n1. Thus, an approximate level α test is obtained by\\nrejecting H0 when U>χ 2\\n1,α.\\nHere is the intuition for the Pearson test. Under H0, pij = pi·p·j,s ot h e\\nmaximum likelihood estimator of pij under H0 is\\nˆpij = ˆpi·ˆp·j = Xi·\\nn\\nX·j\\nn .\\nThus, the expected number of observations in the (i,j) cell is\\nEij = nˆpij = Xi·X·j\\nn .\\nThe statistic U compares the observed and expected counts.\\n15.5 Example. The following data from Johnson and Johnson (1972) relate\\ntonsillectomy and Hodgkins disease. 1\\nHodgkins Disease No Disease\\nTonsillectomy 90 165 255\\nNo Tonsillectomy 84 307 391\\nTotal 174 472 646\\n1The data are actually from a case-control study; see the appendix for an explanation of\\ncase-control studies.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 257, 'page_label': '258'}, page_content='242 15. Inference About Independence\\nWe would like to know if tonsillectomy is related to Hodgkins disease. The\\nlikelihood ratio statistic isT =1 4.75 and the p-value isP(χ2\\n1 > 14.75) = .0001.\\nThe χ2 statistic is U =1 4.96 and the p-value isP(χ2\\n1 > 14.96) = .0001. We re-\\nject the null hypothesis of independence and conclude that tonsillectomy is as-\\nsociated with Hodgkins disease. This does not mean that tonsillectomies cause\\nHodgkins disease. Suppose, for example, that doctors gave tonsillectomies to\\nthe most seriously ill patients. Then the association between tonsillectomies\\nand Hodgkins disease may be due to the fact that those with tonsillectomies\\nwere the most ill patients and hence more likely to have a serious disease.\\n■\\nWe can also estimate the strength of dependence by estimating the odds\\nratio ψ and the log-odds ratio γ.\\n15.6 Theorem. The mle’s of ψ and γ are\\nˆψ = X00X11\\nX01X10\\n, ˆγ = log ˆψ. (15.6)\\nThe asymptotic standard errors (computed using the delta method) are\\nˆse(ˆγ)=\\n√\\n1\\nX00\\n+ 1\\nX01\\n+ 1\\nX10\\n+ 1\\nX11\\n(15.7)\\nˆse( ˆψ)= ˆψ ˆse(ˆγ). (15.8)\\n15.7 Remark. For small sample sizes, ˆψ and ˆγ can have a very large variance.\\nIn this case, we often use the modiﬁed estimator\\nˆψ =\\n\\uf8f6\\nX00 + 1\\n2\\n\\uf8f7\\uf8f6\\nX11 + 1\\n2\\n\\uf8f7\\n\\uf8f6\\nX01 + 1\\n2\\n\\uf8f7\\uf8f6\\nX10 + 1\\n2\\n\\uf8f7. (15.9)\\nAnother test for independence is the Wald test for γ = 0 given by W =\\n(ˆγ − 0)/ˆse(ˆγ) .A1 − α conﬁdence interval for γ is ˆγ ± zα/2 ˆse(ˆγ).\\nA1 − α conﬁdence interval for ψ can be obtained in two ways. First, we\\ncould use ˆψ ± zα/2 ˆse( ˆψ). Second, since ψ = eγ we could use\\nexp\\n{\\nˆγ ± zα/2 ˆse(ˆγ)\\n}\\n. (15.10)\\nThis second method is usually more accurate.\\n15.8 Example. In the previous example,\\nˆψ = 90 × 307\\n165 × 84 =1 .99\\nand\\nˆγ = log(1.99) = .69.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 258, 'page_label': '259'}, page_content='15.2 Two Discrete Variables 243\\nSo tonsillectomy patients were twice as likely to have Hodgkins disease. The\\nstandard error of ˆγ is\\n√\\n1\\n90 + 1\\n84 + 1\\n165 + 1\\n307 = .18.\\nThe Wald statistic is W = .69/.1 8=3 .84 whose p-value is P(|Z| > 3.84) =\\n.0001, the same as the other tests. A 95 per cent conﬁdence interval for γ is\\nˆγ±2(.1 8 )=(.33,1.05). A 95 per cent conﬁdence interval forψ is (e.33,e1.05)=\\n(1.39,2.86). ■\\n15.2 Two Discrete Variables\\nNow suppose that Y ∈{ 1,...,I } and Z ∈{ 1,...,J } are two discrete vari-\\nables. The data can be represented as an I × J table of counts:\\nY =1 Y =2 ··· Y = j ··· Y = J\\nZ =1 X11 X12 ··· X1j ··· X1J X1·\\n..\\n.\\n.\\n.\\n. ..\\n. ..\\n. ..\\n. ..\\n. ..\\n.\\n.\\n.\\n.\\nZ = i\\nXi1 Xi2 ··· Xij ··· XiJ Xi·\\n..\\n.\\n.\\n.\\n. ..\\n. ..\\n. ..\\n. ..\\n. ..\\n.\\n.\\n.\\n.\\nZ = I\\nXI1 XI2 ··· XIj ··· XIJ XI·\\nX·1 X·2 ··· X·j ··· X·J n\\nwhere\\nXij = number of observations for which Z = i and Y = j.\\nConsider testing\\nH0 : Y ⨿ Z versus H1 : Y /gluonbelement/gluonelement/gluonelement/gluonelement/gluonelement/gluoneelementZ. (15.11)\\n15.9 Theorem. The likelihood ratio test statistic for (15.11) is\\nT =2\\nI∑\\ni=1\\nJ∑\\nj=1\\nXij log\\n\\uf8f6Xij X··\\nXi· X·j\\n\\uf8f7\\n. (15.12)\\nThe limiting distribution of T under the null hypothesis of independence\\nis χ2\\nν where ν =( I − 1)(J − 1). Pearson’s χ2 test statistic is\\nU =\\nI∑\\ni=1\\nJ∑\\nj=1\\n(Xij − Eij)2\\nEij\\n. (15.13)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 259, 'page_label': '260'}, page_content='244 15. Inference About Independence\\nAsymptotically, under H0, U has a χ2\\nν distribution where\\nν =( I − 1)(J − 1).\\n15.10 Example. These data are from Dunsmore et al. (1987). Patients with\\nHodgkins disease are classiﬁed by their response to treatment and by histo-\\nlogical type.\\nType\\nPositive Response Partial Response No Response\\nLP 74 18 12 104\\nNS 68 16 12 96\\nMC 154 54 58 266\\nLD 18 10 44 72\\nThe χ2 test statistic is 75.89 with 2 × 3 = 6 degrees of freedom. The p-value\\nis P(χ2\\n6 > 75.89) ≈ 0. The likelihood ratio test statistic is 68.30 with 2×3=6\\ndegrees of freedom. The p-value is P(χ2\\n6 > 68.30) ≈ 0. Thus there is strong\\nevidence that response to treatment and histological type are associated. ■\\n15.3 Two Continuous Variables\\nNow suppose that Y and Z are both continuous. If we assume that the joint\\ndistribution of Y and Z is bivariate Normal, then we measure the dependence\\nbetween Y and Z by means of the correlation coeﬃcient ρ. Tests, estimates,\\nand conﬁdence intervals for ρ in the Normal case are given in the previous\\nchapter in Section 14.2. If we do not assume Normality then we can still use the\\nmethods in Section 14.2 to draw inferences about the correlationρ. However,\\nif we conclude thatρ is 0, we cannot conclude thatY and Z are independent,\\nonly that they are uncorrelated. Fortunately, the reverse direction is valid:\\nif we conclude that Y and Z are correlated than we can conclude they are\\ndependent.\\n15.4 One Continuous Variable and One Discrete\\nSuppose that Y ∈{ 1,...,I } is discrete and Z is continuous. Let Fi(z)=\\nP(Z ≤ z|Y = i) denote the cdf of Z conditional on Y = i.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 260, 'page_label': '261'}, page_content='15.5 Appendix 245\\n15.11 Theorem. When Y ∈{ 1,...,I } is discrete and Z is continuous, then\\nY ⨿ Z if and only if F1 = ··· = FI.\\nIt follows from the previous theorem that to test for independence, we need\\nto test\\nH0 : F1 = ··· = FI versus H1 : not H0.\\nFor simplicity, we consider the case where I = 2. To test the null hypothesis\\nthat F1 = F2 we will use the two sample Kolmogorov-Smirnov test. Let\\nn1 denote the number of observations for which Yi = 1 and let n2 denote the\\nnumber of observations for which Yi = 2. Let\\nˆF1(z)= 1\\nn1\\nn∑\\ni=1\\nI(Zi ≤ z)I(Yi =1 )\\nand\\nˆF2(z)= 1\\nn2\\nn∑\\ni=1\\nI(Zi ≤ z)I(Yi =2 )\\ndenote the empirical distribution function of Z given Y = 1 and Y =2\\nrespectively. Deﬁne the test statistic\\nD = sup\\nx\\n| ˆF1(x) − ˆF2(x)|.\\n15.12 Theorem. Let\\nH(t)=1 − 2\\n∞∑\\nj=1\\n(−1)j−1e−2j2t2\\n. (15.14)\\nUnder the null hypothesis that F1 = F2,\\nlim\\nn→∞\\nP\\n\\uf8f6√ n1n2\\nn1 + n2\\nD ≤ t\\n\\uf8f7\\n= H(t).\\nIt follows from the theorem that an approximate levelα test is obtained by\\nrejecting H0 when √ n1n2\\nn1 + n2\\nD>H −1(1 − α).\\n15.5 Appendix\\nInterpreting The Odds Ratios. Suppose event A as probability P(A).\\nThe odds of A are deﬁned as odds( A)= P(A)/(1 − P(A)). It follows that'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 261, 'page_label': '262'}, page_content='246 15. Inference About Independence\\nP(A) = odds(A)/(1 + odds(A)). Let E be the event that someone is exposed\\nto something (smoking, radiation, etc) and let D be the event that they get\\na disease. The odds of getting the disease given that you are exposed are:\\nodds(D|E)= P(D|E)\\n1 − P(D|E)\\nand the odds of getting the disease given that you are not exposed are:\\nodds(D|Ec)= P(D|Ec)\\n1 − P(D|Ec).\\nThe odds ratio is deﬁned to be\\nψ = odds(D|E)\\nodds(D|Ec).\\nIf ψ = 1 then disease probability is the same for exposed and unexposed. This\\nimplies that these events are independent. Recall that the log-odds ratio is\\ndeﬁned as γ = log(ψ). Independence corresponds to γ =0 .\\nConsider this table of probabilities and corresponding table of data:\\nDc D\\nEc p00 p01 p0·\\nE p10 p11 p1·\\np·0 p·1 1\\nDc D\\nEc X00 X01 X0·\\nE X10 X11 X1·\\nX·0 X·1 X··\\nNow\\nP(D|E)= p11\\np10 + p11\\nand P(D|Ec)= p01\\np00 + p01\\n,\\nand so\\nodds(D|E)= p11\\np10\\nand odds( D|Ec)= p01\\np00\\n,\\nand therefore,\\nψ = p11p00\\np01p10\\n.\\nTo estimate the parameters, we have to ﬁrst consider how the data were\\ncollected. There are three methods.\\nMultinomial Sampling. We draw a sample from the population and,\\nfor each person, record their exposure and disease status. In this case, X =\\n(X00,X 01,X 10,X 11) ∼ Multinomial(n, p). We then estimate the probabilities\\nin the table by ˆpij = Xij/n and\\nˆψ = ˆp11ˆp00\\nˆp01ˆp10\\n= X11X00\\nX01X10\\n.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 262, 'page_label': '263'}, page_content='15.5 Appendix 247\\nProspective Sampling. (Cohort Sampling).We get some exposed and\\nunexposed people and count the number with disease in each group. Thus,\\nX01 ∼ Binomial(X0·,P(D|Ec))\\nX11 ∼ Binomial(X1·,P(D|E)).\\nWe should really write x0· and x1· instead of X0· and X1· since in this case,\\nthese are ﬁxed not random, but for notational simplicity I’ll keep using capital\\nletters. We can estimateP(D|E) and P(D|E\\nc) but we cannot estimate all the\\nprobabilities in the table. Still, we can estimate ψ since ψ is a function of\\nP(D|E) and P(D|Ec). Now\\nˆP(D|E)= X11\\nX1·\\nand ˆP(D|Ec)= X01\\nX0·\\n.\\nThus,\\nˆψ = X11X00\\nX01X10\\njust as before.\\nCase-Control (Retrospective) Sampling.Here we get some diseased\\nand non-diseased people and we observe how many are exposed. This is much\\nmore eﬃcient if the disease is rare. Hence,\\nX\\n10 ∼ Binomial(X·0,P(E|Dc))\\nX11 ∼ Binomial(X·1,P(E|D)).\\nFrom these data we can estimate P(E|D) and P(E|Dc). Surprisingly, we can\\nalso still estimate ψ. To understand why, note that\\nP(E|D)= p11\\np01 + p11\\n, 1 − P(E|D)= p01\\np01 + p11\\n, odds(E|D)= p11\\np01\\n.\\nBy a similar argument,\\nodds(E|Dc)= p10\\np00\\n.\\nHence,\\nodds(E|D)\\nodds(E|Dc) = p11p00\\np01p10\\n= ψ.\\nFrom the data, we form the following estimates:\\nˆP(E|D)= X11\\nX·1\\n, 1− ˆP(E|D)= X01\\nX·1\\n, ˆodds(E|D)= X11\\nX01\\n, ˆodds(E|Dc)= X10\\nX00\\n.\\nTherefore,\\nˆψ = X00X11\\nX01X10\\n.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 263, 'page_label': '264'}, page_content='248 15. Inference About Independence\\nSo in all three data collection methods, the estimate of ψ turns out to be the\\nsame.\\nIt is tempting to try to estimateP(D|E)−P(D|Ec). In a case-control design,\\nthis quantity is not estimable. To see this, we apply Bayes’ theorem to get\\nP(D|E) − P(D|Ec)= P(E|D)P(D)\\nP(E) − P(Ec|D)P(D)\\nP(Ec) .\\nBecause of the way we obtained the data,P(D) is not estimable from the data.\\nHowever, we can estimateξ = P(D|E)/P(D|Ec), which is called the relative\\nrisk, under the rare disease assumption.\\n15.13 Theorem. Let ξ = P(D|E)/P(D|Ec). Then\\nψ\\nξ → 1\\nas P(D) → 0.\\nThus, under the rare disease assumption, the relative risk is approximately\\nthe same as the odds ratio and, as we have seen, we can estimate the odds\\nratio.\\n15.6 Exercises\\n1. Prove Theorem 15.2.\\n2. Prove Theorem 15.3.\\n3. Prove Theorem 15.6.\\n4. The New York Times(January 8, 2003, page A12) reported the following\\ndata on death sentencing and race, from a study in Maryland:\\n2\\nDeath Sentence No Death Sentence\\nBlack Victim 14 641\\nWhite Victim 62 594\\nAnalyze the data using the tools from this chapter. Interpret the results.\\nExplain why, based only on this information, you can’t make causal\\nconclusions. (The authors of the study did use much more information\\nin their full report.)\\n2The data here are an approximate re-creation using the information in the article.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 264, 'page_label': '265'}, page_content='15.6 Exercises 249\\n5. Analyze the data on the variables Age and Financial Status from:\\nhttp://lib.stat.cmu.edu/DASL/Dataﬁles/montanadat.html\\n6. Estimate the correlation between temperature and latitude using the\\ndata from\\nhttp://lib.stat.cmu.edu/DASL/Dataﬁles/USTemperatures.html\\nUse the correlation coeﬃcient. Provide estimates, tests, and conﬁdence\\nintervals.\\n7. Test whether calcium intake and drop in blood pressure are associated.\\nUse the data in\\nhttp://lib.stat.cmu.edu/DASL/Dataﬁles/Calcium.html'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 265, 'page_label': '266'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 266, 'page_label': '267'}, page_content='16\\nCausal Inference\\nRoughly speaking, the statement “ X causes Y ” means that changing the\\nvalue of X will change the distribution of Y . When X causes Y , X and Y\\nwill be associated but the reverse is not, in general, true. Association does not\\nnecessarily imply causation. We will consider two frameworks for discussing\\ncausation. The ﬁrst uses counterfactual random variables. The second, pre-\\nsented in the next chapter, uses directed acyclic graphs.\\n16.1 The Counterfactual Model\\nSuppose that X is a binary treatment variable whereX = 1 means “treated”\\nand X = 0 means “not treated.” We are using the word “treatment” in a\\nvery broad sense. Treatment might refer to a medication or something like\\nsmoking. An alternative to “treated/not treated” is “exposed/not exposed”\\nbut we shall use the former.\\nLet Y be some outcome variable such as presence or absence of disease.\\nTo distinguish the statement “ X is associated Y ” from the statement “ X\\ncauses Y ” we need to enrich our probabilistic vocabulary. Speciﬁcally, we will\\ndecompose the response Y into a more ﬁne-grained object.\\nWe introduce two new random variables ( C\\n0,C1), called potential out-\\ncomes with the following interpretation: C0 is the outcome if the subject is'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 267, 'page_label': '268'}, page_content='252 16. Causal Inference\\nnot treated (X = 0) and C1 is the outcome if the subject is treated (X = 1).\\nHence,\\nY =\\n{\\nC0 if X =0\\nC1 if X =1 .\\nWe can express the relationship between Y and (C0,C1) more succinctly by\\nY = CX. (16.1)\\nEquation (16.1) is called the consistency relationship.\\nHere is a toy dataset to make the idea clear:\\nXYC 0 C1\\n044 *\\n077 *\\n022 *\\n088 *\\n13* 3\\n15* 5\\n18* 8\\n19* 9\\nThe asterisks denote unobserved values. When X = 0 we don’t observe C\\n1,\\nin which case we say that C1 is a counterfactual since it is the outcome\\nyou would have had if, counter to the fact, you had been treated ( X = 1).\\nSimilarly, when X = 1 we don’t observe C0, and we say that C0 is counter-\\nfactual. There are four types of subjects:\\nType C0 C1\\nSurvivors 1 1\\nResponders 0 1\\nAnti-responders 1 0\\nDoomed 0 0\\nThink of the potential outcomes (C\\n0,C1) as hidden variables that contain all\\nthe relevant information about the subject.\\nDeﬁne the average causal eﬀect or average treatment eﬀect to be\\nθ = E(C1) − E(C0). (16.2)\\nThe parameter θ has the following interpretation: θ is the mean if everyone\\nwere treated (X = 1) minus the mean if everyone were not treated (X = 0).\\nThere are other ways of measuring the causal eﬀect. For example, if C0 and\\nC1 are binary, we deﬁne the causal odds ratio\\nP(C1 =1 )\\nP(C1 =0 ) ÷ P(C0 =1 )\\nP(C0 =0 )'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 268, 'page_label': '269'}, page_content='16.1 The Counterfactual Model 253\\nand the causal relative risk\\nP(C1 =1 )\\nP(C0 =1 ).\\nThe main ideas will be the same whatever causal eﬀect we use. For simplicity,\\nwe shall work with the average causal eﬀect θ.\\nDeﬁne the association to be\\nα = E(Y |X =1 ) − E(Y |X =0 ). (16.3)\\nAgain, we could use odds ratios or other summaries if we wish.\\n16.1 Theorem (Association Is Not Causation). In general, θ ̸= α.\\n16.2 Example. Suppose the whole population is as follows:\\nXYC 0 C1\\n000 0 ∗\\n000 0 ∗\\n000 0 ∗\\n000 0 ∗\\n111 ∗ 1\\n111 ∗ 1\\n111 ∗ 1\\n111 ∗ 1\\nAgain, the asterisks denote unobserved values. Notice thatC0 = C1 for every\\nsubject, thus, this treatment has no eﬀect. Indeed,\\nθ = E(C1) − E(C0)= 1\\n8\\n8∑\\ni=1\\nC1i − 1\\n8\\n8∑\\ni=1\\nC0i\\n= 0+0+0+0+1+1+1+1\\n8 − 0+0+0+0+1+1+1+1\\n8\\n=0 .\\nThus, the average causal eﬀect is 0. The observed data are only the X’s and\\nY ’s, from which we can estimate the association:\\nα = E(Y |X =1 ) − E(Y |X =0 )\\n= 1+1+1+1\\n4 − 0+0+0+0\\n4 =1 .\\nHence, θ ̸= α.\\nTo add some intuition to this example, imagine that the outcome variable\\nis 1 if “healthy” and 0 if “sick”. Suppose that X = 0 means that the subject'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 269, 'page_label': '270'}, page_content='254 16. Causal Inference\\ndoes not take vitamin C and that X = 1 means that the subject does take\\nvitamin C. Vitamin C has no causal eﬀect since C0 = C1 for each subject. In\\nthis example there are two types of people: healthy people ( C0,C1)=( 1 ,1)\\nand unhealthy people (C0,C1)=( 0 ,0). Healthy people tend to take vitamin\\nC while unhealthy people don’t. It is this association between ( C0,C1) and\\nX that creates an association between X and Y . If we only had data on X\\nand Y we would conclude that X and Y are associated. Suppose we wrongly\\ninterpret this causally and conclude that vitamin C prevents illness. Next we\\nmight encourage everyone to take vitamin C. If most people comply with our\\nadvice, the population will look something like this:\\nXYC\\n0 C1\\n000 0 ∗\\n100 0 ∗\\n100 0 ∗\\n100 0 ∗\\n111 ∗ 1\\n111 ∗ 1\\n111 ∗ 1\\n111 ∗ 1\\nNow α =( 4/7) − (0/1 )=4 /7. We see that α went down from 1 to 4/7.\\nOf course, the causal eﬀect never changed but the naive observer who does\\nnot distinguish association and causation will be confused because his advice\\nseems to have made things worse instead of better.\\n■\\nIn the last example, θ = 0 and α = 1. It is not hard to create examples in\\nwhich α> 0 and yet θ< 0. The fact that the association and causal eﬀects\\ncan have diﬀerent signs is very confusing to many people.\\nThe example makes it clear that, in general, we cannot use the association\\nto estimate the causal eﬀect θ. The reason that θ ̸= α is that (C0,C1)w a s\\nnot independent of X. That is, treatment assignment was not independent of\\nperson type.\\nCan we ever estimate the causal eﬀect? The answer is: sometimes. In par-\\nticular, random assignment to treatment makes it possible to estimate θ.\\n16.3 Theorem. Suppose we randomly assign subjects to treatment and that\\nP(X =0 ) > 0 and P(X =1 ) > 0. Then α = θ. Hence, any consistent estima-\\ntor of α is a consistent estimator of θ. In particular, a consistent estimator\\nis\\nˆθ = ˆE(Y |X =1 ) − ˆE(Y |X =0 )'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 270, 'page_label': '271'}, page_content='16.2 Beyond Binary Treatments 255\\n= Y 1 − Y 0\\nis a consistent estimator of θ, where\\nY 1 = 1\\nn1\\nn∑\\ni=1\\nYiXi, Y 0 = 1\\nn0\\nn∑\\ni=1\\nYi(1 − Xi),\\nn1 = ∑ n\\ni=1 Xi, and n0 = ∑ n\\ni=1(1 − Xi).\\nProof. Since X is randomly assigned,X is independent of (C0,C1). Hence,\\nθ = E(C1) − E(C0)\\n= E(C1|X =1 ) − E(C0|X = 0) since X ⨿ (C0,C1)\\n= E(Y |X =1 ) − E(Y |X = 0) since Y = CX\\n= α.\\nThe consistency follows from the law of large numbers. ■\\nIf Z is a covariate, we deﬁne the conditional causal eﬀect by\\nθz = E(C1|Z = z) − E(C0|Z = z).\\nFor example, if Z denotes gender with values Z = 0 (women) and Z =1\\n(men), then θ0 is the causal eﬀect among women and θ1 is the causal eﬀect\\namong men. In a randomized experiment,θz = E(Y |X =1 ,Z = z)−E(Y |X =\\n0,Z = z) and we can estimate the conditional causal eﬀect using appropriate\\nsample averages.\\nSummary of the Counterfactual Model\\nRandom variables: (C0,C1,X,Y ).\\nConsistency relationship: Y = CX.\\nCausal Eﬀect: θ = E(C1) − E(C0).\\nAssociation: α = E(Y |X =1 ) − E(Y |X = 0).\\nRandom assignment =⇒ (C0,C1) ⨿ X =⇒ θ = α.\\n16.2 Beyond Binary Treatments\\nLet us now generalize beyond the binary case. Suppose that X ∈X .F o r\\nexample, X could be the dose of a drug in which caseX ∈ R. The counterfac-\\ntual vector (C0,C1) now becomes the counterfactual function C(x) where'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 271, 'page_label': '272'}, page_content='256 16. Causal Inference\\n0123456789 1 0 1 1\\n0\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\nx\\nC(x)\\nX\\nY = C(X)\\nFIGURE 16.1. A counterfactual function C(x). The outcome Y is the value of the\\ncurve C(x) evaluated at the observed dose X.\\nC(x) is the outcome a subject would have if he received dosex. The observed\\nresponse is given by the consistency relation\\nY ≡ C(X). (16.4)\\nSee Figure 16.1. The causal regression function is\\nθ(x)= E(C(x)). (16.5)\\nThe regression function, which measures association, is r(x)= E(Y |X = x).\\n16.4 Theorem. In general, θ(x) ̸= r(x). However, when X is randomly as-\\nsigned, θ(x)= r(x).\\n16.5 Example. An example in whichθ(x) is constant butr(x) is not constant\\nis shown in Figure 16.2. The ﬁgure shows the counterfactual functions for\\nfour subjects. The dots represent their X values X\\n1,X 2,X 3,X 4. Since Ci(x)\\nis constant over x for all i, there is no causal eﬀect and hence\\nθ(x)= C1(x)+ C2(x)+ C3(x)+ C4(x)\\n4'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 272, 'page_label': '273'}, page_content='16.3 Observational Studies and Confounding 257\\nis constant. Changing the dose x will not change anyone’s outcome. The four\\ndots in the lower plot represent the observed data points Y1 = C1(X1),Y2 =\\nC2(X2),Y3 = C3(X3),Y4 = C4(X4). The dotted line represents the regression\\nr(x)= E(Y |X = x). Although there is no causal eﬀect, there is an association\\nsince the regression curve r(x) is not constant. ■\\n16.3 Observational Studies and Confounding\\nA study in which treatment (or exposure) is not randomly assigned is called an\\nobservational study.In these studies, subjects select their own value of the\\nexposure X. Many of the health studies you read about in the newspaper are\\nlike this. As we saw, association and causation could in general be quite diﬀer-\\nent. This discrepancy occurs in non-randomized studies because the potential\\noutcome C is not independent of treatment X. However, suppose we could\\nﬁnd groupings of subjects such that, within groups, X and {C(x): x ∈X }\\nare independent. This would happen if the subjects are very similar within\\ngroups. For example, suppose we ﬁnd people who are very similar in age, gen-\\nder, educational background, and ethnic background. Among these people we\\nmight feel it is reasonable to assume that the choice of X is essentially ran-\\ndom. These other variables are calledconfounding variables.\\n1 If we denote\\nthese other variables collectively asZ, then we can express this idea by saying\\nthat\\n{C(x): x ∈X} ⨿ X|Z. (16.6)\\nEquation (16.6) means that, within groups of Z, the choice of treatment X\\ndoes not depend on type, as represented by {C(x): x ∈X }. If (16.6) holds\\nand we observe Z then we say that there is no unmeasured confounding.\\n16.6 Theorem. Suppose that (16.6) holds. Then,\\nθ(x)=\\n∫\\nE(Y |X = x, Z = z)dFZ(z)dz. (16.7)\\nIf ˆr(x, z) is a consistent estimate of the regression function E(Y |X = x, Z =\\nz), then a consistent estimate of θ(x) is\\nˆθ(x)= 1\\nn\\nn∑\\ni=1\\nˆr(x, Zi).\\n1A more precise deﬁnition of confounding is given in the next chapter.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 273, 'page_label': '274'}, page_content='258 16. Causal Inference\\n012345\\n0\\n1\\n2\\n3\\nC1(x)\\nC2(x)\\nC3(x)\\nC4(x)\\nx\\n/Bullet\\n/Bullet\\n/Bullet\\n/Bullet\\n012345\\n0\\n1\\n2\\n3\\nθ(x)\\n/Bullet\\n/Bullet\\n/Bullet\\n/Bullet\\nY1\\nY2\\nY3\\nY4\\nx\\nFIGURE 16.2. The top plot shows the counterfactual function C(x) for four sub-\\njects. The dots represent theirX values. SinceCi(x) is constant overx for all i, there\\nis no causal eﬀect. Changing the dose will not change anyone’s outcome. The lower\\nplot shows the causal regression functionθ(x)=( C\\n1(x)+ C2(x)+ C3(x)+ C4(x))/4.\\nThe four dots represent the observed data points Y1 = C1(X1), Y2 = C2(X2),\\nY3 = C3(X3), Y4 = C4(X4). The dotted line represents the regression\\nr(x)= E(Y |X = x). There is no causal eﬀect since Ci(x) is constant for all i.\\nBut there is an association since the regression curve r(x) is not constant.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 274, 'page_label': '275'}, page_content='16.4 Simpson’s Paradox 259\\nIn particular, if r(x, z)= β0 + β1x + β2z is linear, then a consistent estimate\\nof θ(x) is\\nˆθ(x)= ˆβ0 + ˆβ1x + ˆβ2Zn (16.8)\\nwhere (ˆβ0, ˆβ1, ˆβ2) are the least squares estimators.\\n16.7 Remark. It is useful to compare equation (16.7) to E(Y |X = x) which\\ncan be written as E(Y |X = x)=\\n∫\\nE(Y |X = x, Z = z)dFZ|X(z|x).\\nEpidemiologists call (16.7) theadjusted treatment eﬀect. The process of\\ncomputing adjusted treatment eﬀects is called adjusting (or controlling)\\nfor confounding. The selection of what confounders Z to measure and con-\\ntrol for requires scientiﬁc insight. Even after adjusting for confounders, we\\ncannot be sure that there are not other confounding variables that we missed.\\nThis is why observational studies must be treated with healthy skepticism.\\nResults from observational studies start to become believable when: (i) the\\nresults are replicated in many studies, (ii) each of the studies controlled for\\nplausible confounding variables, (iii) there is a plausible scientiﬁc explanation\\nfor the existence of a causal relationship.\\nA good example is smoking and cancer. Numerous studies have shown a\\nrelationship between smoking and cancer even after adjusting for many con-\\nfounding variables. Moreover, in laboratory studies, smoking has been shown\\nto damage lung cells. Finally, a causal link between smoking and cancer has\\nbeen found in randomized animal studies. It is this collection of evidence\\nover many years that makes this a convincing case. One single observational\\nstudy is not, by itself, strong evidence. Remember that when you read the\\nnewspaper.\\n16.4 Simpson’s Paradox\\nSimpson’s paradox is a puzzling phenomenon that is discussed in most statis-\\ntics texts. Unfortunately, most explanations are confusing (and in some cases\\nincorrect). The reason is that it is nearly impossible to explain the paradox\\nwithout using counterfactuals (or directed acyclic graphs).\\nLet X be a binary treatment variable, Y a binary outcome, and Z a third\\nbinary variable such as gender. Suppose the joint distribution of X,Y,Z is'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 275, 'page_label': '276'}, page_content='260 16. Causal Inference\\nY =1 Y =0 Y =1 Y =0\\nX =1 .1500 .2250 .1000 .0250\\nX =0 .0375 .0875 .2625 .1125\\nZ = 1 (men) Z = 0 (women)\\nThe marginal distribution for (X,Y )i s\\nY =1 Y =0\\nX = 1 .25 .25 .50\\nX = 0 .30 .20 .50\\n.55 .45 1\\nFrom these tables we ﬁnd that,\\nP(Y =1 |X =1 ) − P(Y =1 |X =0 ) = −0.1\\nP(Y =1 |X =1 ,Z =1 ) − P(Y =1 |X =0 ,Z =1 ) = 0 .1\\nP(Y =1 |X =1 ,Z =0 ) − P(Y =1 |X =0 ,Z =0 ) = 0 .1.\\nTo summarize, we seem to have the following information:\\nMathematical Statement English Statement?\\nP(Y =1 |X =1 ) < P(Y =1 |X = 0) treatment is harmful\\nP(Y =1 |X =1 ,Z =1 ) > P(Y =1 |X =0 ,Z = 1) treatment is beneﬁcial to men\\nP(Y =1 |X =1 ,Z =0 ) > P(Y =1 |X =0 ,Z = 0) treatment is beneﬁcial to women\\nClearly, something is amiss. There can’t be a treatment which is good for\\nmen, good for women, but bad overall. This is nonsense. The problem is with\\nthe set of English statements in the table. Our translation from math into\\nEnglish is specious.\\nThe inequality P(Y =1 |X =1 ) < P(Y =1 |X =0 ) does not\\nmean that treatment is harmful.\\nThe phrase “treatment is harmful” should be written mathematically as\\nP(C\\n1 =1 ) < P(C0 = 1). The phrase “treatment is harmful for men” should\\nbe written P(C1 =1 |Z =1 ) < P(C0 =1 |Z = 1). The three mathematical\\nstatements in the table are not at all contradictory. It is only the translation\\ninto English that is wrong.\\nLet us now show that a real Simpson’s paradox cannot happen, that is,\\nthere cannot be a treatment that is beneﬁcial for men and women but harmful\\noverall. Suppose that treatment is beneﬁcial for both sexes. Then\\nP(C\\n1 =1 |Z = z) > P(C0 =1 |Z = z)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 276, 'page_label': '277'}, page_content='16.5 Bibliographic Remarks 261\\nfor all z. It then follows that\\nP(C1 =1 ) =\\n∑\\nz\\nP(C1 =1 |Z = z)P(Z = z)\\n>\\n∑\\nz\\nP(C0 =1 |Z = z)P(Z = z)\\n= P(C0 =1 ).\\nHence, P(C1 =1 ) > P(C0 = 1), so treatment is beneﬁcial overall. No paradox.\\n16.5 Bibliographic Remarks\\nThe use of potential outcomes to clarify causation is due mainly to Jerzy Ney-\\nman and Donald Rubin. Later developments are due to Jamie Robins, Paul\\nRosenbaum, and others. A parallel development took place in econometrics\\nby various people including James Heckman and Charles Manski. Texts on\\ncausation include Pearl (2000), Rosenbaum (2002), Spirtes et al. (2000), and\\nvan der Laan and Robins (2003).\\n16.6 Exercises\\n1. Create an example like Example 16.2 in which α> 0 and θ< 0.\\n2. Prove Theorem 16.4.\\n3. Suppose you are given data (X\\n1,Y1),..., (Xn,Yn) from an observational\\nstudy, where Xi ∈{ 0,1} and Yi ∈{ 0,1}. Although it is not possible\\nto estimate the causal eﬀect θ, it is possible to put bounds on θ. Find\\nupper and lower bounds on θ that can be consistently estimated from\\nthe data. Show that the bounds have width 1.\\nHint: Note that E(C1)= E(C1|X =1 )P(X =1 )+ E(C1|X =0 )P(X =\\n0).\\n4. Suppose that X ∈ R and that, for each subject i, Ci(x)= β1ix. Each\\nsubject has their own slopeβ1i. Construct a joint distribution on (β1,X )\\nsuch that P(β1 > 0) = 1 but E(Y |X = x) is a decreasing function of x,\\nwhere Y = C(X). Interpret.\\n5. Let X ∈{ 0,1} be a binary treatment variable and let ( C0,C1) denote\\nthe corresponding potential outcomes. LetY = CX denote the observed'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 277, 'page_label': '278'}, page_content='262 16. Causal Inference\\nresponse. Let F0 and F1 be the cumulative distribution functions for\\nC0 and C1. Assume that F0 and F1 are both continuous and strictly\\nincreasing. Let θ = m1 − m0 where m0 = F−1\\n0 (1/2) is the median of C0\\nand m1 = F−1\\n1 (1/2) is the median ofC1. Suppose that the treatmentX\\nis assigned randomly. Find an expression for θ involving only the joint\\ndistribution of X and Y .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 278, 'page_label': '279'}, page_content='17\\nDirected Graphs and Conditional\\nIndependence\\n17.1 Introduction\\nA directed graph consists of a set of nodes with arrows between some nodes.\\nAn example is shown in Figure 17.1.\\nGraphs are useful for representing independence relations between variables.\\nThey can also be used as an alternative to counterfactuals to represent causal\\nrelationships. Some people use the phrase Bayesian network to refer to a\\ndirected graph endowed with a probability distribution. This is a poor choice\\nof terminology. Statistical inference for directed graphs can be performed using\\nY\\nXZ\\nFIGURE 17.1. A directed graph with vertices V = {X,Y,Z } and edges\\nE = {(Y,X ), (Y,Z )}.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 279, 'page_label': '280'}, page_content='264 17. Directed Graphs and Conditional Independence\\nfrequentist or Bayesian methods, so it is misleading to call them Bayesian\\nnetworks.\\nBefore getting into details about directed acyclic graphs (DAGs), we need\\nto discuss conditional independence.\\n17.2 Conditional Independence\\n17.1 Deﬁnition. Let X, Y and Z be random variables. X and Y are\\nconditionally independent given Z, written X ⨿ Y | Z,i f\\nfX,Y |Z(x, y|z)= fX|Z(x|z)fY |Z(y|z). (17.1)\\nfor all x, y and z.\\nIntuitively, this means that, once you know Z, Y provides no extra infor-\\nmation about X. An equivalent deﬁnition is that\\nf(x|y,z )= f(x|z). (17.2)\\nThe conditional independence relation satisﬁes some basic properties.\\n17.2 Theorem. The following implications hold: 1\\nX ⨿ Y | Z =⇒ Y ⨿ X | Z\\nX ⨿ Y | Z and U = h(X)= ⇒ U ⨿ Y | Z\\nX ⨿ Y | Z and U = h(X)= ⇒ X ⨿ Y | (Z,U )\\nX ⨿ Y | Z and X ⨿ W|(Y,Z )= ⇒ X ⨿ (W, Y) | Z\\nX ⨿ Y | Z and X ⨿ Z | Y =⇒ X ⨿ (Y,Z ).\\n17.3 DAGs\\nA directed graph G consists of a set of vertices V and an edge set E of\\nordered pairs of vertices. For our purposes, each vertex will correspond to a\\nrandom variable. If (X,Y ) ∈ E then there is an arrow pointing from X to Y .\\nSee Figure 17.1.\\n1The last property requires the assumption that all events have positive probability; the ﬁrst\\nfour do not.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 280, 'page_label': '281'}, page_content='17.3 DAGs 265\\nheart disease cough\\noverweight smoking\\nFIGURE 17.2. DAG for Example 17.4.\\nIf an arrow connects two variables X and Y (in either direction) we say\\nthat X and Y are adjacent. If there is an arrow from X to Y then X is a\\nparent of Y and Y is a child of X. The set of all parents of X is denoted\\nby πX or π(X). A directed path between two variables is a set of arrows\\nall pointing in the same direction linking one variable to the other such as:\\nX\\n/Bullet/Bullet/Bullet\\nY\\nA sequence of adjacent vertices staring with X and ending with Y but\\nignoring the direction of the arrows is called an undirected path. The se-\\nquence {X,Y,Z } in Figure 17.1 is an undirected path. X is an ancestor of\\nY if there is a directed path from X to Y (or X = Y ). We also say that Y is\\na descendant of X.\\nA conﬁguration of the form:\\nX Y Z\\nis called a collider at Y . A conﬁguration not of that form is called a non-\\ncollider, for example,\\nX Y Z'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 281, 'page_label': '282'}, page_content='266 17. Directed Graphs and Conditional Independence\\nor\\nX Y Z\\nThe collider property is path dependent. In Figure 17.7, Y is a collider on\\nthe path {X,Y,Z } but it is a non-collider on the path {X,Y,W }. When the\\nvariables pointing into the collider are not adjacent, we say that the collider\\nis unshielded. A directed path that starts and ends at the same variable is\\ncalled a cycle. A directed graph is acyclic if it has no cycles. In this case we\\nsay that the graph is a directed acyclic graph or DAG. From now on, we\\nonly deal with acyclic graphs.\\n17.4 Probability and DAGs\\nLet G be a DAG with vertices V =( X1,...,X k).\\n17.3 Deﬁnition. If P is a distribution for V with probability function f,\\nwe say that P is Markov to G, or that G represents P,i f\\nf(v)=\\nk∏\\ni=1\\nf(xi | πi) (17.3)\\nwhere πi are the parents of Xi. The set of distributions represented by G\\nis denoted by M(G).\\n17.4 Example. Figure 17.2 shows a DAG with four variables. The probability\\nfunction for this example factors as\\nf(overweight,smoking,heart disease,cough)\\n= f(overweight)× f(smoking)\\n× f(heart disease |overweight,smoking)\\n× f(cough|smoking). ■\\n17.5 Example. For the DAG in Figure 17.3, P ∈ M(G) if and only if its\\nprobability function f has the form\\nf(x, y, z, w)= f(x)f(y)f(z | x, y)f(w | z). ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 282, 'page_label': '283'}, page_content='17.5 More Independence Relations 267\\nY\\nX\\nZW\\nFIGURE 17.3. Another DAG.\\nThe following theorem says that P ∈ M(G) if and only if the Markov\\nCondition holds. Roughly speaking, the Markov Condition means that every\\nvariable W is independent of the “past” given its parents.\\n17.6 Theorem. A distribution P ∈ M(G) if and only if the followingMarkov\\nCondition holds: for every variable W,\\nW ⨿ ˜W | πW (17.4)\\nwhere ˜W denotes all the other variables except the parents and descendants\\nof W.\\n17.7 Example. In Figure 17.3, the Markov Condition implies that\\nX ⨿ Y and W ⨿ {X,Y }| Z. ■\\n17.8 Example. Consider the DAG in Figure 17.4. In this case probability\\nfunction must factor like\\nf(a, b, c, d, e)= f(a)f(b|a)f(c|a)f(d|b, c)f(e|d).\\nThe Markov Condition implies the following independence relations:\\nD ⨿ A |{ B,C },E ⨿ {A, B, C}| D and B ⨿ C | A ■\\n17.5 More Independence Relations\\nThe Markov Condition allows us to list some independence relations implied\\nby a DAG. These relations might imply other independence relations. Con-'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 283, 'page_label': '284'}, page_content='268 17. Directed Graphs and Conditional Independence\\nA\\nC\\nB\\nDE\\nFIGURE 17.4. Yet another DAG.\\nsider the DAG in Figure 17.5. The Markov Condition implies:\\nX1 ⨿ X2,X 2 ⨿ {X1,X 4},X 3 ⨿ X4 |{ X1,X 2},\\nX4 ⨿ {X2,X 3}| X1,X 5 ⨿ {X1,X 2}|{ X3,X 4}\\nIt turns out (but it is not obvious) that these conditions imply that\\n{X4,X 5} ⨿ X2 |{ X1,X 3}.\\nHow do we ﬁnd these extra independence relations? The answer is “d-\\nseparation” which means “directed separation.” d-separation can be summa-\\nrized by three rules. Consider the four DAG’s in Figure 17.6 and the DAG in\\nFigure 17.7. The ﬁrst 3 DAG’s in Figure 17.6 have no colliders. The DAG in\\nthe lower right of Figure 17.6 has a collider. The DAG in Figure 17.7 has a\\ncollider with a descendant.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 284, 'page_label': '285'}, page_content='17.5 More Independence Relations 269\\nX1\\nX2\\nX3\\nX4\\nX5\\nFIGURE 17.5. And yet another DAG.\\nXY Z XY Z\\nXY Z XY Z\\nFIGURE 17.6. The ﬁrst three DAG’s have no colliders. The fourth DAG in the lower\\nright corner has a collider at Y .\\nXY Z\\nW\\nFIGURE 17.7. A collider with a descendant.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 285, 'page_label': '286'}, page_content='270 17. Directed Graphs and Conditional Independence\\nXUVWY\\nS1 S2\\nFIGURE 17.8. d-separation explained.\\nThe Rules of d-Separation\\nConsider the DAGs in Figures 17.6 and 17.7.\\n1. When Y is not a collider, X and Z are d-connected, but they are\\nd-separated given Y .\\n2. If X and Z collide at Y , then X and Z are d-separated, but they\\nare d-connected given Y .\\n3. Conditioning on the descendant of a collider has the same eﬀect as\\nconditioning on the collider. Thus in Figure 17.7, X and Z are\\nd-separated but they are d-connected given W.\\nHere is a more formal deﬁnition of d-separation. Let X and Y be distinct\\nvertices and let W be a set of vertices not containing X or Y . Then X and\\nY are d-separated given W if there exists no undirected path U between\\nX and Y such that (i) every collider on U has a descendant in W, and (ii)\\nno other vertex on U is in W.I f A, B, and W are distinct sets of vertices and\\nA and B are not empty, then A and B are d-separated given W if for every\\nX ∈ A and Y ∈ B, X and Y are d-separated given W. Sets of vertices that\\nare not d-separated are said to be d-connected.\\n17.9 Example. Consider the DAG in Figure 17.8. From the d-separation rules\\nwe conclude that:\\nX and Y are d-separated (given the empty set);\\nX and Y are d-connected given {S1,S 2};\\nX and Y are d-separated given {S1,S 2,V }.\\n17.10 Theorem. 2 Let A, B, andC be disjoint sets of vertices. ThenA⨿ B | C\\nif and only if A and B are d-separated byC.\\n2We implicitly assume thatP is faithful to G which means thatP has no extra independence\\nrelations other than those logically implied by the Markov Condition.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 286, 'page_label': '287'}, page_content='17.5 More Independence Relations 271\\nlate\\naliens watch\\nFIGURE 17.9. Jordan’s alien example (Example 17.11). Was your friend kidnapped\\nby aliens or did you forget to set your watch?\\n17.11 Example. The fact that conditioning on a collider creates dependence\\nmight not seem intuitive. Here is a whimsical example from Jordan (2004) that\\nmakes this idea more palatable. Your friend appears to be late for a meeting\\nwith you. There are two explanations: she was abducted by aliens or you forgot\\nto set your watch ahead one hour for daylight savings time. (See Figure 17.9.)\\nAliens and Watch are blocked by a collider which implies they are marginally\\nindependent. This seems reasonable since — before we know anything about\\nyour friend being late — we would expect these variables to be independent.\\nWe would also expect that P(Aliens = yes|Late = yes) > P(Aliens = yes);\\nlearning that your friend is late certainly increases the probability that she\\nwas abducted. But when we learn that you forgot to set your watch properly,\\nwe would lower the chance that your friend was abducted. Hence,P(Aliens =\\nyes|Late = yes) ̸= P(Aliens = yes|Late = yes,Watch = no). Thus, Aliens and\\nWatch are dependent given Late.\\n■\\n17.12 Example. Consider the DAG in Figure 17.2. In this example, over-\\nweight and smoking are marginally independent but they are dependent given\\nheart disease. ■\\nGraphs that look diﬀerent may actually imply the same independence re-\\nlations. If G i saD A G ,w el e tI(G) denote all the independence statements\\nimplied by G. Two DAGs G1 and G2 for the same variables V are Markov\\nequivalent if I(G1)= I(G2). Given a DAG G, let skeleton( G) denote the\\nundirected graph obtained by replacing the arrows with undirected edges.\\n17.13 Theorem. Two DAGs G1 and G2 are Markov equivalent if and only if\\n(i) skeleton(G1) = skeleton(G2) and (ii) G1 and G2 have the same unshielded\\ncolliders.\\n17.14 Example. The ﬁrst three DAGs in Figure 17.6 are Markov equivalent.\\nThe DAG in the lower right of the Figure is not Markov equivalent to the\\nothers.\\n■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 287, 'page_label': '288'}, page_content='272 17. Directed Graphs and Conditional Independence\\n17.6 Estimation for DAGs\\nTwo estimation questions arise in the context of DAGs. First, given a DAG\\nG and data V1,...,V n from a distribution f consistent with G, how do we\\nestimate f? Second, given data V1,...,V n how do we estimate G? The ﬁrst\\nquestion is pure estimation while the second involves model selection. These\\nare very involved topics and are beyond the scope of this book. We will just\\nbrieﬂy mention the main ideas.\\nTypically, one uses some parametric modelf(x|π\\nx;θx) for each conditional\\ndensity. The likelihood function is then\\nL(θ)=\\nn∏\\ni=1\\nf(Vi;θ)=\\nn∏\\ni=1\\nm∏\\nj=1\\nf(Xij|πj;θj),\\nwhere Xij is the value ofXj for theith data point andθj are the parameters for\\nthe jth conditional density. We can then estimate the parameters by maximum\\nlikelihood.\\nTo estimate the structure of the DAG itself, we could ﬁt every possible DAG\\nusing maximum likelihood and use AIC (or some other method) to choose a\\nDAG. However, there are many possible DAGs so you would need much data\\nfor such a method to be reliable. Also, searching through all possible DAGs\\nis a serious computational challenge. Producing a valid, accurate conﬁdence\\nset for the DAG structure would require astronomical sample sizes. If prior\\ninformation is available about part of the DAG structure, the computational\\nand statistical problems are at least partly ameliorated.\\n17.7 Bibliographic Remarks\\nThere are a number of texts on DAGs including Edwards (1995) and Jordan\\n(2004). The ﬁrst use of DAGs for representing causal relationships was by\\nWright (1934). Modern treatments are contained in Spirtes et al. (2000) and\\nPearl (2000). Robins et al. (2003) discuss the problems with estimating causal\\nstructure from data.\\n17.8 Appendix\\nCausation Revisited.We discussed causation in Chapter 16 using the idea\\nof counterfactual random variables. A diﬀerent approach to causation uses'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 288, 'page_label': '289'}, page_content='17.8 Appendix 273\\nXY Z\\nFIGURE 17.10. Conditioning versus intervening.\\nDAGs. The two approaches are mathematically equivalent though they appear\\nto be quite diﬀerent. In the DAG approach, the extra element is the idea of\\nintervention. Consider the DAG in Figure 17.10.\\nThe probability function for a distribution consistent with this DAG has\\nthe form f(x, y, z)= f(x)f(y|x)f(z|x, y). The following is pseudocode for\\ngenerating from this distribution.\\nFor i =1 ,...,n :\\nx\\ni <− pX(xi)\\nyi <− pY |X(yi|xi)\\nzi <− pZ|X,Y (zi|xi,y i)\\nSuppose we repeat this code many times, yielding data (x1,y 1,z 1), ..., (xn,y n,z n).\\nAmong all the times that we observeY = y, how often is Z = z? The answer\\nto this question is given by the conditional distribution of Z|Y . Speciﬁcally,\\nP(Z = z|Y = y)= P(Y = y,Z = z)\\nP(Y = y) = f(y,z )\\nf(y)\\n=\\n∑\\nx f(x, y, z)\\nf(y) =\\n∑\\nx f(x) f(y|x) f(z|x, y)\\nf(y)\\n=\\n∑\\nx\\nf(z|x, y)f(y|x) f(x)\\nf(y) =\\n∑\\nx\\nf(z|x, y)f(x, y)\\nf(y)\\n=\\n∑\\nx\\nf(z|x, y) f(x|y).\\nNow suppose weintervene by changing the computer code. Speciﬁcally, sup-\\npose we ﬁx Y at the value y. The code now looks like this:\\nset Y = y\\nfor i =1 ,...,n\\nxi <− pX(xi)\\nzi <− pZ|X,Y (zi|xi,y )'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 289, 'page_label': '290'}, page_content='274 17. Directed Graphs and Conditional Independence\\nHaving set Y = y, how often was Z = z? To answer, note that the inter-\\nvention has changed the joint probability to be\\nf∗(x, z)= f(x)f(z|x, y).\\nThe answer to our question is given by the marginal distribution\\nf∗(z)=\\n∑\\nx\\nf∗(x, z)=\\n∑\\nx\\nf(x)f(z|x, y).\\nWe shall denote this as P(Z = z|Y := y)o r f(z|Y := y). We call P(Z =\\nz|Y = y) conditioning by observation or passive conditioning. We call\\nP(Z = z|Y := y) conditioning by intervention or active conditioning.\\nPassive conditioning is used to answer a predictive question like:\\n“Given that Joe smokes, what is the probability he will get lung cancer?”\\nActive conditioning is used to answer a causal question like:\\n“If Joe quits smoking, what is the probability he will get lung cancer?”\\nConsider a pair ( G,P) where G is a DAG and P is a distribution for the\\nvariables V of the DAG. Let p denote the probability function for P. Con-\\nsider intervening and ﬁxing a variable X to be equal to x. We represent the\\nintervention by doing two things:\\n(1) Create a new DAG G\\n∗ by removing all arrows pointing into X;\\n(2) Create a new distribution f∗(v)= P(V = v|X := x) by removing the\\nterm f(x|πX) from f(v).\\nThe new pair (G∗,f ∗) represents the intervention “set X = x.”\\n17.15 Example. You may have noticed a correlation between rain and having\\na wet lawn, that is, the variable “Rain” is not independent of the variable “Wet\\nLawn” and hence p\\nR,W (r, w) ̸= pR(r)pW (w) where R denotes Rain and W\\ndenotes Wet Lawn. Consider the following two DAGs:\\nRain −→Wet Lawn Rain ←−Wet Lawn.\\nThe ﬁrst DAG implies that f(w,r )= f(r)f(w|r) while the second implies\\nthat f(w,r )= f(w)f(r|w) No matter what the joint distribution f(w,r ) is,\\nboth graphs are correct. Both imply thatR and W are not independent. But,\\nintuitively, if we want a graph to indicate causation, the ﬁrst graph is right\\nand the second is wrong. Throwing water on your lawn doesn’t cause rain.\\nThe reason we feel the ﬁrst is correct while the second is wrong is because the\\ninterventions implied by the ﬁrst graph are correct.\\nLook at the ﬁrst graph and form the intervention W = 1 where 1 denotes\\n“wet lawn.” Following the rules of intervention, we break the arrows into W'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 290, 'page_label': '291'}, page_content='17.8 Appendix 275\\nto get the modiﬁed graph:\\nRain set W e tL a w n= 1\\nwith distribution f∗(r)= f(r). Thus P(R = r | W := w)= P(R = r) tells us\\nthat “wet lawn” does not cause rain.\\nSuppose we (wrongly) assume that the second graph is the correct causal\\ngraph and form the intervention W = 1 on the second graph. There are no\\narrows into W that need to be broken so the intervention graph is the same\\nas the original graph. Thus f∗(r)= f(r|w) which would imply that changing\\n“wet” changes “rain.” Clearly, this is nonsense.\\nBoth are correct probability graphs but only the ﬁrst is correct causally.\\nWe know the correct causal graph by using background knowledge.\\n17.16 Remark. We could try to learn the correct causal graph from data but\\nthis is dangerous. In fact it is impossible with two variables. With more than\\ntwo variables there are methods that can ﬁnd the causal graph under certain\\nassumptions but they are large sample methods and, furthermore, there is no\\nway to ever know if the sample size you have is large enough to make the\\nmethods reliable.\\nWe can use DAGs to represent confounding variables. If X is a treatment\\nand Y is an outcome, a confounding variableZ is a variable with arrows into\\nboth X and Y ; see Figure 17.11. It is easy to check, using the formalism of\\ninterventions, that the following facts are true:\\nIn a randomized study, the arrow betweenZ and X is broken. In this case,\\neven with Z unobserved (represented by enclosing Z in a circle), the causal\\nrelationship between X and Y is estimable because it can be shown that\\nE(Y |X := x)= E(Y |X = x) which does not involve the unobserved Z.I n\\nan observational study, with all confounders observed, we getE(Y |X := x)=∫\\nE(Y |X = x, Z = z)dF\\nZ(z) as in formula (16.7). If Z is unobserved then we\\ncannot estimate the causal eﬀect because E(Y |X := x)=\\n∫\\nE(Y |X = x, Z =\\nz)dFZ(z) involves the unobservedZ. We can’t just useX and Y since in this\\ncase. P(Y = y|X = x) ̸= P(Y = y|X := x) which is just another way of saying\\nthat causation is not association.\\nIn fact, we can make a precise connection between DAGs and counterfac-\\ntuals as follows. Suppose that X and Y are binary. Deﬁne the confounding'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 291, 'page_label': '292'}, page_content='276 17. Directed Graphs and Conditional Independence\\nXY\\nZ\\nXY\\nZ\\nXY\\nZ\\nFIGURE 17.11. Randomized study; Observational study with measured con-\\nfounders; Observational study with unmeasured confounders. The circled variables\\nare unobserved.\\nvariable Z by\\nZ =\\n\\uf8f1\\n\\uf8f4\\uf8f4\\n\\uf8f2\\n\\uf8f4\\uf8f4\\n\\uf8f3\\n1i f ( C\\n0,C1)=( 0 ,0)\\n2i f ( C0,C1)=( 0 ,1)\\n3i f ( C0,C1)=( 1 ,0)\\n4i f ( C0,C1)=( 1 ,1).\\nFrom this, you can make the correspondence between the DAG approach and\\nthe counterfactual approach explicit. I leave this for the interested reader.\\n17.9 Exercises\\n1. Show that (17.1) and (17.2) are equivalent.\\n2. Prove Theorem 17.2.\\n3. Let X, Y and Z have the following joint distribution:\\nY =0 Y =1 Y =0 Y =1\\nX = 0 .405 .045 X = 0 .125 .125\\nX = 1 .045 .005 X = 1 .125 .125\\nZ =0 Z =1\\n(a) Find the conditional distribution of X and Y given Z = 0 and the\\nconditional distribution of X and Y given Z =1 .\\n(b) Show that X\\n⨿ Y |Z.\\n(c) Find the marginal distribution of X and Y .\\n(d) Show that X and Y are not marginally independent.\\n4. Consider the three DAGs in Figure 17.6 without a collider. Prove that\\nX ⨿ Z|Y .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 292, 'page_label': '293'}, page_content='17.9 Exercises 277\\nX Y1 Z1Y3Z3\\nY4\\nZ4\\nY2\\nZ2\\nFIGURE 17.12. DAG for exercise 7.\\n5. Consider the DAG in Figure 17.6 with a collider. Prove thatX ⨿ Z and\\nthat X and Z are dependent given Y .\\n6. Let X ∈{ 0,1}, Y ∈{ 0,1}, Z ∈{ 0,1,2}. Suppose the distribution of\\n(X,Y,Z ) is Markov to:\\nX −→Y −→Z\\nCreate a joint distribution f(x, y, z) that is Markov to this DAG. Gen-\\nerate 1000 random vectors from this distribution. Estimate the distribu-\\ntion from the data using maximum likelihood. Compare the estimated\\ndistribution to the true distribution. Letθ =( θ\\n000,θ 001,...,θ 112) where\\nθrst = P(X = r, Y = s, Z = t). Use the bootstrap to get standard errors\\nand 95 percent conﬁdence intervals for these 12 parameters.\\n7. Consider the DAG in Figure 17.12.\\n(a) Write down the factorization of the joint density.\\n(b) Prove that X\\n⨿ Zj.\\n8. Let V =( X,Y,Z ) have the following joint distribution\\nX ∼ Bernoulli\\n\\uf8f61\\n2\\n\\uf8f7'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 293, 'page_label': '294'}, page_content='278 17. Directed Graphs and Conditional Independence\\nY | X = x ∼ Bernoulli\\n\\uf8f6 e4x−2\\n1+ e4x−2\\n\\uf8f7\\nZ | X = x, Y = y ∼ Bernoulli\\n\\uf8f6 e2(x+y)−2\\n1+ e2(x+y)−2\\n\\uf8f7\\n.\\n(a) Find an expression for P(Z = z | Y = y). In particular, ﬁnd P(Z =\\n1 | Y = 1).\\n(b) Write a program to simulate the model. Conduct a simulation and\\ncompute P(Z =1 | Y = 1) empirically. Plot this as a function of\\nthe simulation size N. It should converge to the theoretical value you\\ncomputed in (a).\\n(c) (Refers to material in the appendix.) Write down an expression for\\nP(Z =1 | Y := y). In particular, ﬁnd P(Z =1 | Y := 1).\\n(d) (Refers to material in the appendix.) Modify your program to sim-\\nulate the intervention “set Y = 1.” Conduct a simulation and compute\\nP(Z =1 | Y := 1) empirically. Plot this as a function of the simulation\\nsize N. It should converge to the theoretical value you computed in (c).\\n9. This is a continuous, Gaussian version of the last question. Let V =\\n(X,Y,Z ) have the following joint distribution\\nX ∼ Normal (0,1)\\nY | X = x ∼ Normal (αx, 1)\\nZ | X = x, Y = y ∼ Normal (βy + γx, 1).\\nHere, α, β and γ are ﬁxed parameters. economists refer to models like\\nthis as structural equation models.\\n(a) Find an explicit expression for f(z | y) and E(Z | Y = y)=\\n∫\\nzf(z |\\ny)dz.\\n(b) (Refers to material in the appendix.) Find an explicit expression\\nfor f(z | Y := y) and then ﬁnd E(Z | Y := y) ≡\\n∫\\nzf(z | Y := y)dy.\\nCompare to (b).\\n(c) Find the joint distribution of (Y,Z ). Find the correlation ρ between\\nY and Z.\\n(d) (Refers to material in the appendix.) Suppose thatX is not observed\\nand we try to make causal conclusions from the marginal distribution of\\n(Y,Z ). (Think ofX as unobserved confounding variables.) In particular,'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 294, 'page_label': '295'}, page_content='17.9 Exercises 279\\nsuppose we declare thatY causes Z if ρ ̸= 0 and we declare thatY does\\nnot cause Z if ρ = 0. Show that this will lead to erroneous conclusions.\\n(e) (Refers to material in the appendix.) Suppose we conduct a ran-\\ndomized experiment in which Y is randomly assigned. To be concrete,\\nsuppose that\\nX ∼ Normal(0,1)\\nY ∼ Normal(α, 1)\\nZ | X = x, Y = y ∼ Normal(βy + γx, 1).\\nShow that the method in (d) now yields correct conclusions (i.e., ρ =0\\nif and only if f(z | Y := y) does not depend on y).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 295, 'page_label': '296'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 296, 'page_label': '297'}, page_content='18\\nUndirected Graphs\\nUndirected graphs are an alternative to directed graphs for representing in-\\ndependence relations. Since both directed and undirected graphs are used in\\npractice, it is a good idea to be facile with both. The main diﬀerence between\\nthe two is that the rules for reading independence relations from the graph\\nare diﬀerent.\\n18.1 Undirected Graphs\\nAn undirected graph G =( V,E ) has a ﬁnite setV of vertices (or nodes)\\nand a set E of edges (or arcs) consisting of pairs of vertices. The vertices\\ncorrespond to random variablesX,Y,Z,... and edges are written as unordered\\npairs. For example, (X,Y ) ∈ E means that X and Y are joined by an edge.\\nAn example of a graph is in Figure 18.1.\\nTwo vertices are adjacent, written X ∼ Y , if there is an edge between\\nthem. In Figure 18.1, X and Y are adjacent but X and Z are not adjacent. A\\nsequence X0,...,X n is called a path if Xi−1 ∼ Xi for each i. In Figure 18.1,\\nX,Y,Z is a path. A graph iscomplete if there is an edge between every pair\\nof vertices. A subset U ⊂ V of vertices together with their edges is called a\\nsubgraph.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 297, 'page_label': '298'}, page_content='282 18. Undirected Graphs\\n/Bullet\\n/Bullet\\n/BulletX\\nY\\nZ\\nFIGURE 18.1. A graph with vertices V = {X,Y,Z }. The edge set is\\nE = {(X,Y ), (Y,Z )}.\\n/Bullet\\n/Bullet\\n/Bullet\\n/Bullet\\nY\\nWX\\nZ\\nFIGURE 18.2. {Y,W } and {Z} are separated by{X}. Also, W and Z are separated\\nby {X,Y }.\\nIf A, B and C are three distinct subsets of V , we say that C separates\\nA and B if every path from a variable in A to a variable in B intersects a\\nvariable in C. In Figure 18.2 {Y,W } and {Z} are separated by {X}. Also, W\\nand Z are separated by {X,Y }.\\n18.2 Probability and Graphs\\nLet V be a set of random variables with distribution P. Construct a graph\\nwith one vertex for each random variable inV . Omit the edge between a pair\\nof variables if they are independent given the rest of the variables:\\nno edge between X and Y ⇐⇒ X ⨿ Y |rest'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 298, 'page_label': '299'}, page_content='18.2 Probability and Graphs 283\\n/Bullet\\n/Bullet\\n/BulletX\\nY\\nZ\\nFIGURE 18.3. X ⨿ Z|Y .\\n/Bullet\\n/Bullet\\n/BulletX\\nY\\nZ\\nFIGURE 18.4. No implied independence relations.\\nwhere “rest” refers to all the other variables besides X and Y . The resulting\\ngraph is called a pairwise Markov graph . Some examples are shown in\\nFigures 18.3, 18.4, 18.5, and 18.6.\\nThe graph encodes a set of pairwise conditional independence relations.\\nThese relations imply other conditional independence relations. How can we\\nﬁgure out what they are? Fortunately, we can read these other conditional\\nindependence relations directly from the graph as well, as is explained in the\\nnext theorem.\\n18.1 Theorem. Let G =( V,E ) be a pairwise Markov graph for a distribution\\nP.L e tA, B and C be distinct subsets of V such that C separates A and B.\\nThen A\\n⨿ B|C.\\n18.2 Remark. If A and B are not connected (i.e., there is no path from A to\\nB) then we may regard A and B as being separated by the empty set. Then\\nTheorem 18.1 implies that A ⨿ B.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 299, 'page_label': '300'}, page_content='284 18. Undirected Graphs\\n/Bullet\\n/Bullet\\n/Bullet\\n/Bullet\\nY\\nXW\\nZ\\nFIGURE 18.5. X ⨿ Z|{Y,W } and Y ⨿ W|{X,Z }.\\n/Bullet/Bullet/Bullet/Bullet\\nXY ZW\\nFIGURE 18.6. Pairwise independence implies that X ⨿ Z|{Y,W }. But is X ⨿ Z|Y ?\\nThe independence condition in Theorem 18.1 is called theglobal Markov\\nproperty. We thus see that the pairwise and global Markov properties are\\nequivalent. Let us state this more precisely. Given a graph G, let Mpair(G)\\nbe the set of distributions which satisfy the pairwise Markov property: thus\\nP ∈ M\\npair(G) if, under P, X ⨿ Y |rest if and only if there is no edge between\\nX and Y . Let Mglobal(G) be the set of distributions which satisfy the global\\nMarkov property: thus P ∈ Mpair(G) if, under P, A ⨿ B|C if and only if C\\nseparates A and B.\\n18.3 Theorem. Let G be a graph. Then, Mpair(G)= Mglobal(G).\\nTheorem 18.3 allows us to construct graphs using the simpler pairwise prop-\\nerty and then we can deduce other independence relations using the global\\nMarkov property. Think how hard this would be to do algebraically. Returning\\nto 18.6, we now see that X\\n⨿ Z|Y and Y ⨿ W|Z.\\n18.4 Example. Figure 18.7 implies that X ⨿ Y , X ⨿ Z and X ⨿ (Y,Z ). ■\\n18.5 Example. Figure 18.8 implies that X ⨿ W|(Y,Z ) and X ⨿ Z|Y . ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 300, 'page_label': '301'}, page_content='18.3 Cliques and Potentials 285\\n/Bullet\\n/Bullet\\n/BulletX\\nY\\nZ\\nFIGURE 18.7. X ⨿ Y , X ⨿ Z and X ⨿ (Y,Z ).\\n/Bullet\\n/Bullet\\n/Bullet\\n/Bullet\\nXY\\nZ\\nW\\nFIGURE 18.8. X ⨿ W|(Y,Z ) and X ⨿ Z|Y .\\n18.3 Cliques and Potentials\\nA clique is a set of variables in a graph that are all adjacent to each other. A\\nset of variables is a maximal clique if it is a clique and if it is not possible\\nto include another variable and still be a clique. A potential is any positive\\nfunction. Under certain conditions, it can be shown thatP is Markov G if and\\nonly if its probability function f can be written as\\nf(x)=\\n∏\\nC∈C ψC(xC)\\nZ (18.1)\\nwhere C is the set of maximal cliques and\\nZ =\\n∑\\nx\\n∏\\nC∈C\\nψC(xC).\\n18.6 Example. The maximal cliques for the graph in Figure 18.1 are C1 =\\n{X,Y } and C2 = {Y,Z }. Hence, if P is Markov to the graph, then its proba-\\nbility function can be written\\nf(x, y, z) ∝ ψ1(x, y)ψ2(y,z )\\nfor some positive functions ψ1 and ψ2. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 301, 'page_label': '302'}, page_content='286 18. Undirected Graphs\\n/Bullet/Bullet\\n/Bullet /Bullet\\n/Bullet/Bullet\\nX3 X5\\nX1\\nX2 X4\\nX6\\nFIGURE 18.9. The maximumly cliques of this graph are\\n{X1,X 2}, {X1,X 3}, {X2,X 4}, {X3,X 5}, {X2,X 5,X 6}.\\n18.7 Example. The maximal cliques for the graph in Figure 18.9 are\\n{X1,X 2},{X1,X 3},{X2,X 4},{X3,X 5},{X2,X 5,X 6}.\\nThus we can write the probability function as\\nf(x1,x2,x3,x4,x5,x6) ∝ ψ12(x1,x2)ψ13(x1,x3)ψ24(x2,x4)\\n×ψ35(x3,x5)ψ256(x2,x5,x6). ■\\n18.4 Fitting Graphs to Data\\nGiven a data set, how do we ﬁnd a graphical model that ﬁts the data? As\\nwith directed graphs, this is a big topic that we will not treat here. However,\\nin the discrete case, one way to ﬁt a graph to data is to use a log-linear\\nmodel, which is the subject of the next chapter.\\n18.5 Bibliographic Remarks\\nThorough treatments of undirected graphs can be found in Whittaker (1990)\\nand Lauritzen (1996). Some of the exercises below are from Whittaker (1990).\\n18.6 Exercises\\n1. Consider random variables (X1,X 2,X 3). In each of the following cases,\\ndraw a graph that has the given independence relations.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 302, 'page_label': '303'}, page_content='18.6 Exercises 287\\n/Bullet\\n/Bullet/Bullet/Bullet\\nX1 X2 X4\\nX3\\nFIGURE 18.10.\\n/Bullet/Bullet/Bullet/Bullet\\nX1 X2 X3 X4\\nFIGURE 18.11.\\n(a) X1 ⨿ X3 | X2.\\n(b) X1 ⨿ X2 | X3 and X1 ⨿ X3 | X2.\\n(c) X1 ⨿ X2 | X3 and X1 ⨿ X3 | X2 and X2 ⨿ X3 | X1.\\n2. Consider random variables ( X1,X 2,X 3,X 4). In each of the following\\ncases, draw a graph that has the given independence relations.\\n(a) X1 ⨿ X3 | X2,X 4 and X1 ⨿ X4 | X2,X 3 and X2 ⨿ X4 | X1,X 3.\\n(b) X1 ⨿ X2 | X3,X 4 and X1 ⨿ X3 | X2,X 4 and X2 ⨿ X3 | X1,X 4.\\n(c) X1 ⨿ X3 | X2,X 4 and X2 ⨿ X4 | X1,X 3.\\n3. A conditional independence between a pair of variables isminimal if it\\nis not possible to use the Separation Theorem to eliminate any variable\\nfrom the conditioning set, i.e. from the right hand side of the bar Whit-\\ntaker (1990). Write down the minimal conditional independencies from:\\n(a) Figure 18.10; (b) Figure 18.11; (c) Figure 18.12; (d) Figure 18.13.\\n4. Let X\\n1,X 2,X 3 be binary random variables. Construct the likelihood\\nratio test for\\nH0 : X1 ⨿ X2|X3 versus H1 : X1is not independent of X2|X3.\\n5. Here are breast cancer data from Morrison et al. (1973) on diagnostic\\ncenter (X1), nuclear grade (X2), and survival (X3):'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 303, 'page_label': '304'}, page_content='288 18. Undirected Graphs\\n/Bullet\\n/Bullet\\n/Bullet\\n/Bullet\\nX4\\nX3 X2\\nX1\\nFIGURE 18.12.\\n/Bullet\\n/Bullet\\n/Bullet\\n/Bullet/Bullet\\n/Bullet\\nX4\\nX2 X3\\nX1\\nX6X5\\nFIGURE 18.13.\\nX2 malignant malignant benign benign\\nX3 died survived died survived\\nX1 Boston 35 59 47 112\\nGlamorgan 42 77 26 76\\n(a) Treat this as a multinomial and ﬁnd the maximum likelihood esti-\\nmator.\\n(b) If someone has a tumor classiﬁed as benign at the Glamorgan clinic,\\nwhat is the estimated probability that they will die? Find the standard\\nerror for this estimate.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 304, 'page_label': '305'}, page_content='18.6 Exercises 289\\n(c) Test the following hypotheses:\\nX1 ⨿ X2|X3 versus X1 /gluonbelement/gluonelement/gluonelement/gluonelement/gluonelement/gluoneelementX2|X3\\nX1 ⨿ X3|X2 versus X1 /gluonbelement/gluonelement/gluonelement/gluonelement/gluonelement/gluoneelementX3|X2\\nX2 ⨿ X3|X1 versus X2 /gluonbelement/gluonelement/gluonelement/gluonelement/gluonelement/gluoneelementX3|X1\\nUse the test from question 4. Based on the results of your tests, draw\\nand interpret the resulting graph.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 305, 'page_label': '306'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 306, 'page_label': '307'}, page_content='19\\nLog-Linear Models\\nIn this chapter we study log-linear models which are useful for modeling\\nmultivariate discrete data. There is a strong connection between log-linear\\nmodels and undirected graphs.\\n19.1 The Log-Linear Model\\nLet X =( X1,...,X m) be a discrete random vector with probability function\\nf(x)= P(X = x)= P(X1 = x1,...,X m = xm)\\nwhere x =( x1,...,x m). Letrj be the number of values thatXj takes. Without\\nloss of generality, we can assume that Xj ∈{ 0,1,...,r j − 1}. Suppose now\\nthat we have n such random vectors. We can think of the data as a sample\\nfrom a Multinomial with N = r1 × r2 ×···× rm categories. The data can be\\nrepresented as counts in ar1 ×r2 ×···× rm table. Let p =( p1,...,p N ) denote\\nthe multinomial parameter.\\nLet S = {1,...,m }. Given a vector x =( x1,...,x m) and a subset A ⊂ S,\\nlet xA =( xj : j ∈ A). For example, if A = {1,3} then xA =( x1,x3).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 307, 'page_label': '308'}, page_content='292 19. Log-Linear Models\\n19.1 Theorem. The joint probability functionf(x) of a single random vector\\nX =( X1,...,X m) can be written as\\nlog f(x)=\\n∑\\nA⊂S\\nψA(x) (19.1)\\nwhere the sum is over all subsets A of S = {1,...,m } and the ψ’s satisfy the\\nfollowing conditions:\\n1. ψ∅(x) is a constant;\\n2. For every A ⊂ S, ψA(x) is only a function of xA and not the rest of the\\nx′\\njs.\\n3. If i ∈ A and xi =0 , then ψA(x)=0 .\\nThe formula in equation (19.1) is called the log-linear expansion of f.\\nEach ψA(x) may depend on some unknown parameters βA. Let β =( βA :\\nA ⊂ S) be the set of all these parameters. We will writef(x)= f(x;β) when\\nwe want to emphasize the dependence on the unknown parameters β.\\nIn terms of the multinomial, the parameter space is\\nP =\\n{\\np =( p1,...,p N ): pj ≥ 0,\\nN∑\\nj=1\\npj =1\\n}\\n.\\nThis is an N − 1 dimensional space. In the log-linear representation, the pa-\\nrameter space is\\nΘ=\\n{\\nβ =( β1,...,β N ): β = β(p),p ∈P\\n}\\nwhere β(p) is the set of β values associated with p.T h es e tΘi sa N − 1\\ndimensional surface in RN . We can always go back and forth between the two\\nparameterizations we can write β = β(p) and p = p(β).\\n19.2 Example. Let X ∼ Bernoulli(p) where 0 <p< 1. We can write the\\nprobability mass function for X as\\nf(x)= px(1 − p)1−x = px\\n1 p1−x\\n2\\nfor x =0 ,1, where p1 = p and p2 =1 − p. Hence,\\nlog f(x)= ψ∅(x)+ ψ1(x)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 308, 'page_label': '309'}, page_content='19.1 The Log-Linear Model 293\\nwhere\\nψ∅(x) = log( p2)\\nψ1(x)= xlog\\n\\uf8f6p1\\np2\\n\\uf8f7\\n.\\nNotice that ψ∅(x) is a constant (as a function ofx) and ψ1(x) = 0 whenx =0 .\\nThus the three conditions of Theorem 19.1 hold. The log-linear parameters\\nare\\nβ\\n0 = log(p2),β 1 = log\\n\\uf8f6p1\\np2\\n\\uf8f7\\n.\\nThe original, multinomial parameter space isP = {(p1,p 2): pj ≥ 0,p 1 +p2 =\\n1}. The log-linear parameter space is\\nΘ=\\n{\\n(β0,β1) ∈ R2 : eβ0+β1 + eβ0 =1 .\\n}\\nGiven (p1,p 2) we can solve for (β0,β1). Conversely, given (β0,β1) we can solve\\nfor (p1,p 2). ■\\n19.3 Example. Let X =( X1,X 2) where X1 ∈{ 0,1} and X2 ∈{ 0,1,2}. The\\njoint distribution ofn such random vectors is a multinomial with 6 categories.\\nThe multinomial parameters can be written as a 2-by-3 table as follows:\\nmultinomial x2 012\\nx1 0 p00 p01 p02\\n1 p10 p11 p12\\nThe n data vectors can be summarized as counts:\\ndata x2 012\\nx1 0 C00 C01 C02\\n1 C10 C11 C12\\nFor x =( x1,x2), the log-linear expansion takes the form\\nlog f(x)= ψ∅(x)+ ψ1(x)+ ψ2(x)+ ψ12(x)\\nwhere\\nψ∅(x) = log p00\\nψ1(x)= x1 log\\n\\uf8f6p10\\np00\\n\\uf8f7\\nψ2(x)= I(x2 = 1) log\\n\\uf8f6p01\\np00\\n\\uf8f7\\n+ I(x2 = 2) log\\n\\uf8f6p02\\np00\\n\\uf8f7\\nψ12(x)= I(x1 =1 ,x2 = 1) log\\n\\uf8f6p11p00\\np01p10\\n\\uf8f7\\n+ I(x1 =1 ,x2 = 2) log\\n\\uf8f6p12p00\\np02p10\\n\\uf8f7\\n.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 309, 'page_label': '310'}, page_content='294 19. Log-Linear Models\\nConvince yourself that the three conditions on the ψ’s of the theorem are\\nsatisﬁed. The six parameters of this model are:\\nβ1 = logp00 β2 = log\\n\\uf8f6\\np10\\np00\\n\\uf8f7\\nβ3 = log\\n\\uf8f6\\np01\\np00\\n\\uf8f7\\nβ4 = log\\n\\uf8f6\\np02\\np00\\n\\uf8f7\\nβ5 = log\\n\\uf8f6\\np11p00\\np01p10\\n\\uf8f7\\nβ6 = log\\n\\uf8f6\\np12p00\\np02p10\\n\\uf8f7\\n.\\n■\\nThe next theorem gives an easy way to check for conditional independence\\nin a log-linear model.\\n19.4 Theorem. Let (Xa,X b,X c) be a partition of a vectors (X1, ... , Xm).\\nThen Xb ⨿ Xc|Xa if and only if all the ψ-terms in the log-linear expansion\\nthat have at least one coordinate inb and one coordinate in c are 0.\\nTo prove this theorem, we will use the following lemma whose proof follows\\neasily from the deﬁnition of conditional independence.\\n19.5 Lemma. A partition (Xa,X b,X c) satisﬁes Xb ⨿ Xc|Xa if and only if\\nf(xa,xb,xc)= g(xa,xb)h(xa,xc) for some functions g and h\\nProof. (Theorem 19.4.) Suppose that ψt is 0 whenever t has coordinates\\nin b and c. Hence, ψt i s0i f t ̸⊂ a⋃ b or t ̸⊂ a⋃ c. Therefore\\nlog f(x)=\\n∑\\nt⊂a ⋃ b\\nψt(x)+\\n∑\\nt⊂a ⋃ c\\nψt(x) −\\n∑\\nt⊂a\\nψt(x).\\nExponentiating, we see that the joint density is of the formg(xa,xb)h(xa,xc).\\nBy Lemma 19.5,Xb ⨿ Xc|Xa. The converse follows by reversing the argument.\\n■\\n19.2 Graphical Log-Linear Models\\nA log-linear model is graphical if missing terms correspond only to condi-\\ntional independence constraints.\\n19.6 Deﬁnition. Let log f(x)= ∑\\nA⊂S ψA(x) be a log-linear model. Then\\nf is graphical if all ψ-terms are nonzero except for any pair of\\ncoordinates not in the edge set for some graphG. In other words,\\nψA(x)=0 if and only if {i, j}⊂ A and (i, j) is not an edge.\\nHere is a way to think about the deﬁnition above:'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 310, 'page_label': '311'}, page_content='19.2 Graphical Log-Linear Models 295\\n/Bullet/Bullet/Bullet\\n/Bullet/Bullet\\nX1 X2 X3\\nX5 X4\\nFIGURE 19.1. Graph for Example 19.7.\\nIf you can add a term to the model and the graph does not change,\\nthen the model is not graphical.\\n19.7 Example. Consider the graph in Figure 19.1.\\nThe graphical log-linear model that corresponds to this graph is\\nlog f(x)= ψ∅ + ψ1(x)+ ψ2(x)+ ψ3(x)+ ψ4(x)+ ψ5(x)\\n+ ψ12(x)+ ψ23(x)+ ψ25(x)+ ψ34(x)+ ψ35(x)+ ψ45(x)+ ψ235(x)+ ψ345(x).\\nLet’s see why this model is graphical. The edge (1,5) is missing in the graph.\\nHence any term containing that pair of indices is omitted from the model. For\\nexample,\\nψ\\n15,ψ 125,ψ 135,ψ 145,ψ 1235,ψ 1245,ψ 1345,ψ 12345\\nare all omitted. Similarly, the edge (2,4) is missing and hence\\nψ24,ψ 124,ψ 234,ψ 245,ψ 1234,ψ 1245,ψ 2345,ψ 12345\\nare all omitted. There are other missing edges as well. You can check that the\\nmodel omits all the corresponding ψ terms. Now consider the model\\nlog f(x)= ψ∅(x)+ ψ1(x)+ ψ2(x)+ ψ3(x)+ ψ4(x)+ ψ5(x)\\n+ ψ12(x)+ ψ23(x)+ ψ25(x)+ ψ34(x)+ ψ35(x)+ ψ45(x).\\nThis is the same model except that the three way interactions were removed.\\nIf we draw a graph for this model, we will get the same graph. For example,\\nno ψ terms contain (1,5) so we omit the edge betweenX\\n1 and X5. But this is\\nnot graphical since it has extra terms omitted. The independencies and graphs'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 311, 'page_label': '312'}, page_content='296 19. Log-Linear Models\\n/Bullet/Bullet/Bullet\\nX2 X1 X3\\nFIGURE 19.2. Graph for Example 19.10.\\nfor the two models are the same but the latter model has other constraints\\nbesides conditional independence constraints. This is not a bad thing. It just\\nmeans that if we are only concerned about presence or absence of conditional\\nindependences, then we need not consider such a model. The presence of the\\nthree-way interactionψ\\n235 means that the strength of association betweenX2\\nand X3 varies as a function of X5. Its absence indicates that this is not so. ■\\n19.3 Hierarchical Log-Linear Models\\nThere is a set of log-linear models that is larger than the set of graphical\\nmodels and that are used quite a bit. These are the hierarchical log-linear\\nmodels.\\n19.8 Deﬁnition. A log-linear model ishierarchical if ψA =0 and A ⊂ B\\nimplies that ψB =0 .\\n19.9 Lemma. A graphical model is hierarchical but the reverse need not be\\ntrue.\\n19.10 Example. Let\\nlog f(x)= ψ∅(x)+ ψ1(x)+ ψ2(x)+ ψ3(x)+ ψ12(x)+ ψ13(x).\\nThe model is hierarchical; its graph is given in Figure 19.2. The model is\\ngraphical because all terms involving (2,3) are omitted. It is also hierarchical.\\n■\\n19.11 Example. Let\\nlog f(x)= ψ∅(x)+ ψ1(x)+ ψ2(x)+ ψ3(x)+ ψ12(x)+ ψ13(x)+ ψ23(x).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 312, 'page_label': '313'}, page_content='19.4 Model Generators 297\\n/Bullet\\n/Bullet/Bullet\\nX3\\nX1 X2\\nFIGURE 19.3. The graph is complete. The model is hierarchical but not graphical.\\n/Bullet/Bullet/Bullet\\nX1 X2 X3\\nFIGURE 19.4. The model for this graph is not hierarchical.\\nThe model is hierarchical. It is not graphical. The graph corresponding to this\\nmodel is complete; see Figure 19.3. It is not graphical because ψ123(x)=0\\nwhich does not correspond to any pairwise conditional independence. ■\\n19.12 Example. Let\\nlog f(x)= ψ∅(x)+ ψ3(x)+ ψ12(x).\\nThe graph corresponding is in Figure 19.4. This model is not hierarchical since\\nψ2 = 0 but ψ12 is not. Since it is not hierarchical, it is not graphical either.■\\n19.4 Model Generators\\nHierarchical models can be written succinctly usinggenerators. This is most\\neasily explained by example. Suppose that X =( X1,X 2,X 3). Then, M =\\n1.2+1 .3 stands for\\nlog f = ψ∅ + ψ1 + ψ2 + ψ3 + ψ12 + ψ13.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 313, 'page_label': '314'}, page_content='298 19. Log-Linear Models\\nThe formulaM =1 .2+1.3 says: “includeψ12 and ψ13.” We have to also include\\nthe lower order terms or it won’t be hierarchical. The generatorM =1 .2.3i s\\nthe saturated model\\nlog f = ψ∅ + ψ1 + ψ2 + ψ3 + ψ12 + ψ13 + ψ23 + ψ123.\\nThe saturated models corresponds to ﬁtting an unconstrained multinomial.\\nConsider M =1+2+3 which means\\nlog f = ψ∅ + ψ1 + ψ2 + ψ3.\\nThis is the mutual independence model. Finally, consider M =1 .2 which has\\nlog-linear expansion\\nlog f = ψ∅ + ψ1 + ψ2 + ψ12.\\nThis model makes X3|X2 = x2,X 1 = x1 a uniform distribution.\\n19.5 Fitting Log-Linear Models to Data\\nLet β denote all the parameters in a log-linear model M. The loglikelihood\\nfor β is\\nℓ(β)=\\nn∑\\ni=1\\nlog f(Xi;β)\\nwhere f(Xi;β) is the probability function for the ith random vector Xi =\\n(Xi1,...,X im) as give by equation (19.1). The mle ˆβ generally has to be\\nfound numerically. The Fisher information matrix is also found numerically\\nand we can then get the estimated standard errors from the inverse Fisher\\ninformation matrix.\\nWhen ﬁtting log-linear models, one has to address the following model\\nselection problem: which ψ terms should we include in the model? This is\\nessentially the same as the model selection problem in linear regression.\\nOne approach is is to use AIC. LetM denote some log-linear model. Diﬀer-\\nent models correspond to setting diﬀerent ψ terms to 0. Now we choose the\\nmodel M which maximizes\\nAIC(M)= ˆℓ(M) −| M| (19.2)\\nwhere |M| is the number of parameters in model M and ˆℓ(M) is the value\\nof the log-likelihood evaluated at the mle for that model. Usually the model\\nsearch is restricted to hierarchical models. This reduces the search space. Some'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 314, 'page_label': '315'}, page_content='19.5 Fitting Log-Linear Models to Data 299\\nalso claim that we should only search through the hierarchical models because\\nother models are less interpretable.\\nA diﬀerent approach is based on hypothesis testing. The model that includes\\nall possible ψ-terms is called thesaturated model and we denote it byMsat.\\nNow for each M we test the hypothesis\\nH0 : the true model is M versus H1 : the true model is Msat.\\nThe likelihood ratio test for this hypothesis is called the deviance.\\n19.13 Deﬁnition. For any submodel M, deﬁne the deviance dev(M) by\\ndev(M)=2 ( ˆℓsat − ˆℓM )\\nwhere ˆℓsat is the log-likelihood of the saturated model evaluated at themle\\nand ˆℓM is the log-likelihood of the modelM evaluated at its mle.\\n19.14 Theorem. The deviance is the likelihood ratio test statistic for\\nH0 : the model is M versus H1 : the model is Msat.\\nUnder H0, dev(M)\\nd\\n→ χ2\\nν with ν degrees of freedom equal to the diﬀerence in\\nthe number of parameters between the saturated model andM.\\nOne way to ﬁnd a good model is to use the deviance to test every sub-model.\\nEvery model that is not rejected by this test is then considered a plausible\\nmodel. However, this is not a good strategy for two reasons. First, we will end\\nup doing many tests which means that there is ample opportunity for making\\nType I and Type II errors. Second, we will end up using models where we\\nfailed to reject H\\n0. But we might fail to reject H0 due to low power. The\\nresult is that we end up with a bad model just due to low power.\\nAfter ﬁnding a “best model” this way we can draw the corresponding graph.\\n19.15 Example. The following breast cancer data are from Morrison et al.\\n(1973). The data are on diagnostic center (X1), nuclear grade (X2), and sur-\\nvival (X3):\\nX2 malignant malignant benign benign\\nX3 died survived died survived\\nX1 Boston 35 59 47 112\\nGlamorgan 42 77 26 76\\nThe saturated log-linear model is:'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 315, 'page_label': '316'}, page_content='300 19. Log-Linear Models\\nCenter Grade Survival\\nFIGURE 19.5. The graph for Example 19.15.\\nVariable ˆβj ˆse Wj p-value\\n(Intercept) 3.56 0.17 21.03 0.00 ***\\ncenter 0.18 0.22 0.79 0.42\\ngrade 0.29 0.22 1.32 0.18\\nsurvival 0.52 0.21 2.44 0.01 *\\ncenter×grade -0.77 0.33 -2.31 0.02 *\\ncenter×survival 0.08 0.28 0.29 0.76\\ngrade×survival 0.34 0.27 1.25 0.20\\ncenter×grade×survival 0.12 0.40 0.29 0.76\\nThe best sub-model, selected using AIC and backward searching is:\\nVariable ˆβ\\nj ˆse Wj p-value\\n(Intercept) 3.52 0.13 25.62 < 0.00 ***\\ncenter 0.23 0.13 1.70 0.08\\ngrade 0.26 0.18 1.43 0.15\\nsurvival 0.56 0.14 3.98 6.65e-05 ***\\ncenter×grade -0.67 0.18 -3.62 0.00 ***\\ngrade×survival 0.37 0.19 1.90 0.05\\nThe graph for this model M is shown in Figure 19.5. To test the ﬁt of this\\nmodel, we compute the deviance of M which is 0.6. The appropriate χ\\n2 has\\n8 − 6 = 2 degrees of freedom. The p-value isP(χ2\\n2 >. 6) = .74. So we have no\\nevidence to suggest that the model is a poor ﬁt. ■\\n19.6 Bibliographic Remarks\\nFor this chapter, I drew heavily on Whittaker (1990) which is an excellent\\ntext on log-linear models and graphical models. Some of the exercises are from\\nWhittaker. A classic reference on log-linear models is Bishop et al. (1975).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 316, 'page_label': '317'}, page_content='19.7 Exercises 301\\n19.7 Exercises\\n1. Solve for the p′\\nijs in terms of the β’s in Example 19.3.\\n2. Prove Lemma 19.5.\\n3. Prove Lemma 19.9.\\n4. Consider random variables (X\\n1,X 2,X 3,X 4). Suppose the log-density is\\nlog f(x)= ψ∅(x)+ ψ12(x)+ ψ13(x)+ ψ24(x)+ ψ34(x).\\n(a) Draw the graph G for these variables.\\n(b) Write down all independence and conditional independence relations\\nimplied by the graph.\\n(c) Is this model graphical? Is it hierarchical?\\n5. Suppose that parameters p(x1,x2,x3) are proportional to the following\\nvalues:\\nx2 00 11\\nx3 01 01\\nx1 02 841 6\\n1 16 128 32 256\\nFind the ψ-terms for the log-linear expansion. Comment on the model.\\n6. Let X1,...,X 4 be binary. Draw the independence graphs correspond-\\ning to the following log-linear models. Also, identify whether each is\\ngraphical and/or hierarchical (or neither).\\n(a) log f =7+1 1 x\\n1 +2 x2 +1 .5x3 +1 7x4\\n(b) logf =7+1 1 x1 +2 x2 +1 .5x3 +1 7x4 +1 2x2x3 +7 8x2x4 +3 x3x4 +\\n32x2x3x4\\n(c) logf = 7+11x1 +2x2 +1.5x3 +17x4 +12x2x3 +3x3x4 +x1x4 +2x1x2\\n(d) log f = 7 + 5055x1x2x3x4'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 317, 'page_label': '318'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 318, 'page_label': '319'}, page_content='20\\nNonparametric Curve Estimation\\nIn this Chapter we discuss nonparametric estimation of probability density\\nfunctions and regression functions which we refer to ascurve estimation or\\nsmoothing.\\nIn Chapter 7 we saw that it is possible to consistently estimate a cumulative\\ndistribution function F without making any assumptions aboutF.I fw ew a n t\\nto estimate a probability density functionf(x) or a regression functionr(x)=\\nE(Y |X = x) the situation is diﬀerent. We cannot estimate these functions\\nconsistently without making some smoothness assumptions. Correspondingly,\\nwe need to perform some sort of smoothing operation on the data.\\nAn example of a density estimator is a histogram, which we discuss in\\ndetail in Section 20.2. To form a histogram estimator of a densityf, we divide\\nthe real line to disjoint sets calledbins. The histogram estimator is a piecewise\\nconstant function where the height of the function is proportional to number\\nof observations in each bin; see Figure 20.3. The number of bins is an example\\nof a smoothing parameter. If we smooth too much (large bins) we get a\\nhighly biased estimator while if we smooth too little (small bins) we get a\\nhighly variable estimator. Much of curve estimation is concerned with trying\\nto optimally balance variance and bias.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 319, 'page_label': '320'}, page_content='304 20. Nonparametric Curve Estimation\\nˆg(x)\\nThis is a function of the data This is the point at which we are\\nevaluating ˆg(·)\\nFIGURE 20.1. A curve estimate ˆg is random because it is a function of the data.\\nThe point x at which we evaluate ˆg is not a random variable.\\n20.1 The Bias-Variance Tradeoﬀ\\nLet g denote an unknown function such as a density function or a regression\\nfunction. Let ˆgn denote an estimator ofg. Bear in mind thatˆgn(x) is a random\\nfunction evaluated at a point x. The estimator is random because it depends\\non the data. See Figure 20.1.\\nAs a loss function, we will use the integrated squared error (ISE): 1\\nL(g, ˆgn)=\\n∫\\n(g(u) − ˆgn(u))2 du. (20.1)\\nThe risk or mean integrated squared error (MISE) with respect to\\nsquared error loss is\\nR(f, ˆf)= E\\n\\uf8f6\\nL(g, ˆg)\\n\\uf8f7\\n. (20.2)\\n20.1 Lemma. The risk can be written as\\nR(g, ˆgn)=\\n∫\\nb2(x) dx +\\n∫\\nv(x) dx (20.3)\\nwhere\\nb(x)= E(ˆgn(x)) − g(x) (20.4)\\nis the bias of ˆgn(x) at a ﬁxed x and\\nv(x)= V(ˆgn(x)) = E\\n\\uf8f6\\uf8f6\\nˆgn(x) − E\\n\\uf8f6\\nˆgn(x)\\n\\uf8f72\\uf8f7\\uf8f7\\n(20.5)\\nis the variance of ˆgn(x) at a ﬁxed x.\\n1We could use other loss functions. The results are similar but the analysis is much more\\ncomplicated.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 320, 'page_label': '321'}, page_content='20.2 Histograms 305\\n/Bullet\\n/Bullet\\nRisk\\nBias squared\\nVariance\\nOptimal\\nSmoothing\\nMore SmoothingLess Smoothing\\nFIGURE 20.2. The Bias-Variance trade-oﬀ. The bias increases and the variance de-\\ncreases with the amount of smoothing. The optimal amount of smoothing, indicated\\nby the vertical line, minimizes the risk = bias\\n2 + variance.\\nIn summary,\\nRISK = BIAS2 + VARIANCE. (20.6)\\nWhen the data are oversmoothed, the bias term is large and the variance\\nis small. When the data are undersmoothed the opposite is true; see Figure\\n20.2. This is called thebias-variance tradeoﬀ. Minimizing risk corresponds\\nto balancing bias and variance.\\n20.2 Histograms\\nLet X1,...,X n be iid on [0,1] with density f. The restriction to [0,1] is not\\ncrucial; we can always rescale the data to be on this interval. Let m be an'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 321, 'page_label': '322'}, page_content='306 20. Nonparametric Curve Estimation\\ninteger and deﬁne bins\\nB1 =\\n[\\n0, 1\\nm\\n\\uf8f7\\n,B2 =\\n[1\\nm, 2\\nm\\n\\uf8f7\\n, ..., B m =\\n[m − 1\\nm ,1\\n]\\n. (20.7)\\nDeﬁne the binwidth h =1 /m, let νj be the number of observations in Bj,\\nlet ˆpj = νj/n and let pj =\\n∫\\nBj\\nf(u)du.\\nThe histogram estimator is deﬁned by\\nˆfn(x)=\\n\\uf8f1\\n\\uf8f4\\uf8f4\\n\\uf8f4\\n\\uf8f2\\n\\uf8f4\\uf8f4\\n\\uf8f4\\n\\uf8f3\\nˆp\\n1/h x ∈ B1\\nˆp2/h x ∈ B2\\n..\\n. ..\\n.\\nˆp\\nm/h x ∈ Bm\\nwhich we can write more succinctly as\\nˆfn(x)=\\nn∑\\nj=1\\nˆpj\\nh I(x ∈ Bj). (20.8)\\nTo understand the motivation for this estimator, letpj =\\n∫\\nBj\\nf(u)du and note\\nthat, for x ∈ Bj and h small,\\nE( ˆfn(x)) = E(ˆpj)\\nh = pj\\nh =\\n∫\\nBj\\nf(u)du\\nh ≈ f(x)h\\nf(x) = f(x).\\n20.2 Example. Figure 20.3 shows three diﬀerent histograms based on n =\\n1,266 data points from an astronomical sky survey. Each data point repre-\\nsents the distance from us to a galaxy. The galaxies lie on a “pencilbeam”\\npointing directly from the Earth out into space. Because of the ﬁnite speed of\\nlight, looking at galaxies farther and fartheraway corresponds to looking back\\nin time. Choosing the right number of bins involves ﬁnding a good tradeoﬀ\\nbetween bias and variance. We shall see later that the top left histogram has\\ntoo few bins resulting in oversmoothing and too much bias. The bottom left\\nhistogram has too many bins resulting in undersmoothing and too few bins.\\nThe top right histogram is just right. The histogram reveals the presence of\\nclusters of galaxies. Seeing how the size and number of galaxy clusters varies\\nwith time, helps cosmologists understand the evolution of the universe.\\n■\\nThe mean and variance of ˆfn(x) are given in the following Theorem.\\n20.3 Theorem. Consider ﬁxedx and ﬁxedm, and letBj be the bin containing\\nx. Then,\\nE( ˆfn(x)) = pj\\nh and V( ˆfn(x)) = pj(1 − pj)\\nnh2 . (20.9)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 322, 'page_label': '323'}, page_content='20.2 Histograms 307\\nOversmoothed\\n0.00 0.05 0.10 0.15 0.20\\n02468 1 0 1 2 1 4\\nJust Right\\n0.00 0.05 0.10 0.15 0.20\\n0 1 02 03 04 05 06 0\\nUndersmoothed\\n0.00 0.05 0.10 0.15 0.20\\n02 0 4 0 6 0\\n0 200 400 600 800 1000\\n−14 −12 −10 −8 −6\\nnumber of bins\\ncross validation score\\nFIGURE 20.3. Three versions of a histogram for the astronomy data. The top left\\nhistogram has too few bins. The bottom left histogram has too many bins. The top\\nright histogram is just right. The lower, right plot shows the estimated risk versus\\nthe number of bins.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 323, 'page_label': '324'}, page_content='308 20. Nonparametric Curve Estimation\\nLet’s take a closer look at the bias-variance tradeoﬀ using equation (20.9).\\nConsider some x ∈ Bj. For any other u ∈ Bj,\\nf(u) ≈ f(x)+( u − x)f′(x)\\nand so\\npj =\\n∫\\nBj\\nf(u)du ≈\\n∫\\nBj\\n\\uf8f6\\nf(x)+( u − x)f′(x)\\n\\uf8f7\\ndu\\n= f(x)h + hf′(x)\\n\\uf8f6\\nh\\n\\uf8f6\\nj − 1\\n2\\n\\uf8f7\\n− x\\n\\uf8f7\\n.\\nTherefore, the bias b(x)i s\\nb(x)= E( ˆfn(x)) − f(x)= pj\\nh − f(x)\\n≈ f(x)h + hf′(x)\\n\\uf8f6\\nh\\n\\uf8f6\\nj − 1\\n2\\n\\uf8f7\\n− x\\n\\uf8f7\\nh − f(x)\\n= f′(x)\\n\\uf8f6\\nh\\n\\uf8f6\\nj − 1\\n2\\n\\uf8f7\\n− x\\n\\uf8f7\\n.\\nIf ˜xj is the center of the bin, then\\n∫\\nBj\\nb2(x) dx ≈\\n∫\\nBj\\n(f′(x))2\\n\\uf8f6\\nh\\n\\uf8f6\\nj − 1\\n2\\n\\uf8f7\\n− x\\n\\uf8f72\\ndx\\n≈ (f′(˜xj))2\\n∫\\nBj\\n\\uf8f6\\nh\\n\\uf8f6\\nj − 1\\n2\\n\\uf8f7\\n− x\\n\\uf8f72\\ndx\\n=( f′(˜xj))2 h3\\n12.\\nTherefore,\\n∫ 1\\n0\\nb2(x)dx =\\nm∑\\nj=1\\n∫\\nBj\\nb2(x)dx ≈\\nm∑\\nj=1\\n(f′(˜xj))2 h3\\n12\\n= h2\\n12\\nm∑\\nj=1\\nh (f′(˜xj))2 ≈ h2\\n12\\n∫ 1\\n0\\n(f′(x))2dx.\\nNote that this increases as a function of h. Now consider the variance. For h\\nsmall, 1 − pj ≈ 1, so\\nv(x) ≈ pj\\nnh2\\n= f(x)h + hf′(x)\\n\\uf8f6\\nh\\n\\uf8f6\\nj − 1\\n2\\n\\uf8f7\\n− x\\n\\uf8f7\\nnh2\\n≈ f(x)\\nnh'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 324, 'page_label': '325'}, page_content='20.2 Histograms 309\\nwhere we have kept only the dominant term. So,\\n∫ 1\\n0\\nv(x)dx ≈ 1\\nnh.\\nNote that this decreases with h. Putting all this together, we get:\\n20.4 Theorem. Suppose that\\n∫\\n(f′(u))2du < ∞. Then\\nR( ˆfn,f ) ≈ h2\\n12\\n∫\\n(f′(u))2du + 1\\nnh. (20.10)\\nThe value h∗ that minimizes (20.10) is\\nh∗ = 1\\nn1/3\\n\\uf8f6 6∫\\n(f′(u))2du\\n\\uf8f71/3\\n. (20.11)\\nWith this choice of binwidth,\\nR( ˆfn,f ) ≈ C\\nn2/3 (20.12)\\nwhere C =( 3/4)2/3\\n\\uf8f6∫\\n(f′(u))2du\\n\\uf8f71/3\\n.\\nTheorem 20.4 is quite revealing. We see that with an optimally chosen bin-\\nwidth, the MISE decreases to 0 at raten−2/3. By comparison, most parametric\\nestimators converge at rate n−1. The slower rate of convergence is the price\\nwe pay for being nonparametric. The formula for the optimal binwidth h∗ is\\nof theoretical interest but it is not useful in practice since it depends on the\\nunknown function f.\\nA practical way to choose the binwidth is to estimate the risk function\\nand minimize over h. Recall that the loss function, which we now write as a\\nfunction of h,i s\\nL(h)=\\n∫\\n( ˆf\\nn(x) − f(x))2 dx\\n=\\n∫\\nˆf 2\\nn (x) dx − 2\\n∫\\nˆfn(x)f(x)dx +\\n∫\\nf2(x) dx.\\nThe last term does not depend on the binwidth h so minimizing the risk is\\nequivalent to minimizing the expected value of\\nJ(h)=\\n∫\\nˆf 2\\nn (x) dx − 2\\n∫\\nˆfn(x)f(x)dx.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 325, 'page_label': '326'}, page_content='310 20. Nonparametric Curve Estimation\\nWe shall refer to E(J(h)) as the risk, although it diﬀers from the true risk by\\nthe constant term\\n∫\\nf2(x) dx.\\n20.5 Deﬁnition. The cross-validation estimator of risk is\\nˆJ(h)=\\n∫ \\uf8f6\\nˆfn(x)\\n\\uf8f72\\ndx − 2\\nn\\nn∑\\ni=1\\nˆf(−i)(Xi) (20.13)\\nwhere ˆf(−i) is the histogram estimator obtained after removing theith\\nobservation. We refer to ˆJ(h) as the cross-validation score or estimated\\nrisk.\\n20.6 Theorem. The cross-validation estimator is nearly unbiased:\\nE( ˆJ(x)) ≈ E(J(x)).\\nIn principle, we need to recompute the histogramn times to compute ˆJ(h).\\nMoreover, this has to be done for all values of h. Fortunately, there is a\\nshortcut formula.\\n20.7 Theorem. The following identity holds:\\nˆJ(h)= 2\\n(n − 1)h − n +1\\n(n − 1)\\nm∑\\nj=1\\nˆp2\\nj . (20.14)\\n20.8 Example. We used cross-validation in the astronomy example. The cross-\\nvalidation function is quite ﬂat near its minimum. Anym in the range of 73 to\\n310 is an approximate minimizer but the resulting histogram does not change\\nmuch over this range. The histogram in the top right plot in Figure 20.3 was\\nconstructed using m = 73 bins. The bottom right plot shows the estimated\\nrisk, or more precisely, ˆA, plotted versus the number of bins.\\n■\\nNext we want a conﬁdence set forf. Suppose ˆfn is a histogram withm bins\\nand binwidth h =1 /m. We cannot realistically make conﬁdence statements\\nabout the ﬁne details of the true densityf. Instead, we shall make conﬁdence\\nstatements about f at the resolution of the histogram. To this end, deﬁne\\nfn(x)= E( ˆfn(x)) = pj\\nh for x ∈ Bj (20.15)\\nwhere pj =\\n∫\\nBj\\nf(u)du. Think of f(x) as a “histogramized” version of f.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 326, 'page_label': '327'}, page_content='20.2 Histograms 311\\n20.9 Deﬁnition. A pair of functions (ℓn(x),u n(x)) is a 1 − α conﬁdence\\nband (or conﬁdence envelope) if\\nP\\n\\uf8f6\\nℓ(x) ≤ fn(x) ≤ u(x) for all x\\n\\uf8f7\\n≥ 1 − α. (20.16)\\n20.10 Theorem. Let m = m(n) be the number of bins in the histogram ˆfn.\\nAssume that m(n) →∞ and m(n) logn/n → 0 as n →∞ . Deﬁne\\nℓn(x)=\\n\\uf8f6\\nmax\\n{√\\nˆfn(x) − c,0\\n}\\uf8f72\\nun(x)=\\n\\uf8f6√\\nˆfn(x)+ c\\n\\uf8f72\\n(20.17)\\nwhere\\nc = zα/(2m)\\n2\\n√ m\\nn . (20.18)\\nThen, (ℓn(x),u n(x)) is an approximate 1 − α conﬁdence band.\\nProof. Here is an outline of the proof. From the central limit theorem,ˆpj ≈\\nN(pj,p j(1 − pj)/n). By the delta method,\\n√\\nˆpj ≈ N(√pj,1/(4n)). Moreover,\\nit can be shown that the\\n√\\nˆpj’s are approximately independent. Therefore,\\n2√n\\n\\uf8f6√\\nˆpj − √pj\\n\\uf8f7\\n≈ Zj (20.19)\\nwhere Z1,...,Z m ∼ N(0,1). Let\\nA =\\n{\\nℓn(x) ≤ fn(x) ≤ un(x) for all x\\n}\\n=\\n{\\nmax\\nx\\n⏐⏐\\n⏐\\n⏐\\n√\\nˆfn(x) −\\n√\\nf(x)\\n⏐⏐\\n⏐\\n⏐≤ c\\n}\\n.\\nThen,\\nP(A\\nc)= P\\n\\uf8f6\\nmax\\nx\\n⏐⏐\\n⏐\\n⏐\\n√\\nˆfn(x) −\\n√\\nf(x)\\n⏐⏐\\n⏐\\n⏐>c\\n\\uf8f7\\n= P\\n\\uf8f6\\nmax\\nj\\n⏐⏐\\n⏐\\n⏐\\n⏐\\n√\\nˆpj\\nh −\\n√ pj\\nh\\n⏐⏐\\n⏐\\n⏐\\n⏐>c\\n\\uf8f7\\n= P\\n\\uf8f6\\nmax\\nj\\n2√n\\n⏐⏐\\n⏐\\n√\\nˆpj − √pj\\n⏐⏐\\n⏐>z\\nα/(2m)\\n\\uf8f7\\n≈ P\\n\\uf8f6\\nmax\\nj\\n|Zj| >z α/(2m)\\n\\uf8f7\\n≤\\nm∑\\nj=1\\nP\\n\\uf8f6\\n|Zj| >z α/(2m)\\n\\uf8f7\\n=\\nm∑\\nj=1\\nα\\nm = α. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 327, 'page_label': '328'}, page_content='312 20. Nonparametric Curve Estimation\\n0.00 0.05 0.10 0.15 0.20\\n0 1 02 03 04 05 0\\nFIGURE 20.4. 95 percent conﬁdence envelope for astronomy data using m =7 3\\nbins.\\n20.11 Example. Figure 20.4 shows a 95 percent conﬁdence envelope for the\\nastronomy data. We see that even with over 1,000 data points, there is still\\nsubstantial uncertainty.\\n■\\n20.3 Kernel Density Estimation\\nHistograms are discontinuous.Kernel density estimatorsare smoother and\\nthey converge faster to the true density than histograms.\\nLet X1,...,X n denote the observed data, a sample from f. In this chap-\\nter, a kernel is deﬁned to be any smooth function K such that K(x) ≥ 0,∫\\nK(x) dx =1 ,\\n∫\\nxK(x)dx = 0 and σ2\\nK ≡\\n∫\\nx2K(x)dx > 0. Two examples of\\nkernels are the Epanechnikov kernel\\nK(x)=\\n{ 3\\n4(1 − x2/5)/\\n√\\n5 |x| <\\n√\\n5\\n0 otherwise (20.20)\\nand the Gaussian (Normal) kernel K(x)=( 2 π)−1/2e−x2/2.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 328, 'page_label': '329'}, page_content='20.3 Kernel Density Estimation 313\\n−10 −5 0 5 10\\nFIGURE 20.5. A kernel density estimator ˆf. At each point x, ˆf(x) is the average\\nof the kernels centered over the data points Xi. The data points are indicated by\\nshort vertical bars.\\n20.12 Deﬁnition. Given a kernel K and a positive number h, called the\\nbandwidth, the kernel density estimator is deﬁned to be\\nˆf(x)= 1\\nn\\nn∑\\ni=1\\n1\\nhK\\n\\uf8f6x − Xi\\nh\\n\\uf8f7\\n. (20.21)\\nAn example of a kernel density estimator is show in Figure 20.5. The kernel\\nestimator eﬀectively puts a smoothed-out lump of mass of size 1/n over each\\ndata point Xi. The bandwidth h controls the amount of smoothing. When h\\nis close to 0, ˆfn consists of a set of spikes, one at each data point. The height\\nof the spikes tends to inﬁnity as h → 0. When h →∞ , ˆfn tends to a uniform\\ndensity.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 329, 'page_label': '330'}, page_content='314 20. Nonparametric Curve Estimation\\n20.13 Example. Figure 20.6 shows kernel density estimators for the astron-\\nomy data using three diﬀerent bandwidths. In each case we used a Gaussian\\nkernel. The properly smoothed kernel density estimator in the top right panel\\nshows similar structure as the histogram. However, it is easier to see the clus-\\nters with the kernel estimator.\\n■\\nTo construct a kernel density estimator, we need to choose a kernelK and\\na bandwidth h. It can be shown theoretically and empirically that the choice\\nof K is not crucial. 2 However, the choice of bandwidth h is very important.\\nAs with the histogram, we can make a theoretical statement about how the\\nrisk of the estimator depends on the bandwidth.\\n20.14 Theorem. Under weak assumptions on f and K,\\nR(f, ˆf\\nn) ≈ 1\\n4σ4\\nKh4\\n∫\\n(f\\n′′\\n(x))2 +\\n∫\\nK2(x)dx\\nnh (20.22)\\nwhere σ2\\nK =\\n∫\\nx2K(x)dx. The optimal bandwidth is\\nh∗ = c−2/5\\n1 c1/5\\n2 c−1/5\\n3\\nn1/5 (20.23)\\nwhere c1 =\\n∫\\nx2K(x)dx, c2 =\\n∫\\nK(x)2dx and c3 =\\n∫\\n(f′′(x))2dx. With this\\nchoice of bandwidth,\\nR(f, ˆfn) ≈ c4\\nn4/5\\nfor some constant c4 > 0.\\nProof. WriteKh(x, X)= h−1K ((x − X)/h) and ˆfn(x)= n−1 ∑\\ni Kh(x, Xi).\\nThus, E[ ˆfn(x)] = E[Kh(x, X)] and V[ ˆfn(x)] = n−1V[Kh(x, X)]. Now,\\nE[Kh(x, X)] =\\n∫ 1\\nhK\\n\\uf8f6x − t\\nh\\n\\uf8f7\\nf(t) dt\\n=\\n∫\\nK(u)f(x − hu) du\\n=\\n∫\\nK(u)\\n[\\nf(x) − hf\\n′\\n(x)+ 1\\n2f\\n′′\\n(x)+ ···\\n]\\ndu\\n= f(x)+ 1\\n2h2f\\n′′\\n(x)\\n∫\\nu2K(u) du ···\\nsince\\n∫\\nK(x) dx = 1 and\\n∫\\nxK (x) dx = 0. The bias is\\nE[Kh(x, X)] − f(x) ≈ 1\\n2σ2\\nkh2f\\n′′\\n(x).\\n2It can be shown that the Epanechnikov kernel is optimal in the sense of giving smallest\\nasymptotic mean squared error, but it is really the choice of bandwidth which is crucial.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 330, 'page_label': '331'}, page_content='20.3 Kernel Density Estimation 315\\n0.0 0.1 0.2 0.0 0.1 0.2\\n0.0 0.1 0.2 0.002 0.004 0.006\\nFIGURE 20.6. Kernel density estimators and estimated risk for the astronomy data.\\nTop left: oversmoothed. Top right: just right (bandwidth chosen by cross-validation).\\nBottom left: undersmoothed. Bottom right: cross-validation curve as a function of\\nbandwidth h. The bandwidth was chosen to be the value of h where the curve is a\\nminimum.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 331, 'page_label': '332'}, page_content='316 20. Nonparametric Curve Estimation\\nBy a similar calculation,\\nV[ ˆfn(x)] ≈ f(x)\\n∫\\nK2(x) dx\\nnh n\\n.\\nThe result follows from integrating the squared bias plus the variance. ■\\nWe see that kernel estimators converge at raten−4/5 while histograms con-\\nverge at the slower raten−2/3. It can be shown that, under weak assumptions,\\nthere does not exist a nonparametric estimator that converges faster than\\nn\\n−4/5.\\nThe expression for h∗ depends on the unknown density f which makes\\nthe result of little practical use. As with the histograms, we shall use cross-\\nvalidation to ﬁnd a bandwidth. Thus, we estimate the risk (up to a constant)\\nby\\nˆJ(h)=\\n∫\\nˆf\\n2(x)dz − 2\\nn\\nn∑\\ni=1\\nˆf−i(Xi) (20.24)\\nwhere ˆf−i is the kernel density estimator after omitting the ith observation.\\n20.15 Theorem. For any h> 0,\\nE\\n[\\nˆJ(h)\\n]\\n= E [J(h)].\\nAlso,\\nˆJ(h) ≈ 1\\nhn2\\n∑\\ni\\n∑\\nj\\nK∗\\n\\uf8f6Xi − Xj\\nh\\n\\uf8f7\\n+ 2\\nnhK(0) (20.25)\\nwhere K∗(x)= K(2)(x) − 2K(x) and K(2)(z)=\\n∫\\nK(z − y)K(y)dy.I np a r -\\nticular, if K is a N(0,1) Gaussian kernel then K(2)(z) is the N(0,2) density.\\nWe then choose the bandwidthhn that minimizes ˆJ(h).3 A justiﬁcation for\\nthis method is given by the following remarkable theorem due to Stone.\\n20.16 Theorem (Stone’s Theorem). Suppose that f is bounded. Let ˆfh denote\\nthe kernel estimator with bandwidthh and let hn denote the bandwidth chosen\\nby cross-validation. Then,\\n∫\\uf8f6\\nf(x) − ˆfhn (x)\\n\\uf8f72\\ndx\\ninfh\\n∫\\uf8f6\\nf(x) − ˆfh(x)\\n\\uf8f72\\ndx\\nP\\n−→1. (20.26)\\n3For large data sets,ˆf and (20.25) can be computed quickly using the fast Fourier transform.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 332, 'page_label': '333'}, page_content='20.3 Kernel Density Estimation 317\\n20.17 Example. The top right panel of Figure 20.6 is based on cross-validation.\\nThese data are rounded which problems for cross-validation. Speciﬁcally, it\\ncauses the minimizer to be h = 0. To overcome this problem, we added a\\nsmall amount of random Normal noise to the data. The result is that ˆJ(h)i s\\nvery smooth with a well deﬁned minimum.\\n■\\n20.18 Remark. Do not assume that, if the estimator ˆf is wiggly, then cross-\\nvalidation has let you down. The eye is not a good judge of risk.\\nTo construct conﬁdence bands, we use something similar to histograms.\\nAgain, the conﬁdence band is for the smoothed version,\\nfn = E( ˆfn(x)) =\\n∫ 1\\nhK\\n\\uf8f6x − u\\nh\\n\\uf8f7\\nf(u) du,\\nof the true density f. 4 Assume the density is on an interval (a, b). The band\\nis\\nℓn(x)= ˆfn(x) − q se(x),u n(x)= ˆfn(x)+ q se(x) (20.27)\\nwhere\\nse(x)= s(x)√n ,\\ns2(x)= 1\\nn − 1\\nn∑\\ni=1\\n(Yi(x) − Y n(x))2,\\nYi(x)= 1\\nhK\\n\\uf8f6x − Xi\\nh\\n\\uf8f7\\n,\\nq =Φ −1\\n\\uf8f61+( 1 − α)1/m\\n2\\n\\uf8f7\\n,\\nm = b − a\\nω\\nwhere ω is the width of the kernel. In case the kernel does not have ﬁnite\\nwidth then we take ω to be the eﬀective width, that is, the range over which\\nthe kernel is non-negligible. In particular, we take ω =3 h for the Normal\\nkernel.\\n20.19 Example. Figure 20.7 shows approximate 95 percent conﬁdence bands\\nfor the astronomy data. ■\\n4This is a modiﬁed version of the band described in Chaudhuri and Marron (1999).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 333, 'page_label': '334'}, page_content='318 20. Nonparametric Curve Estimation\\n0.00 0.05 0.10 0.15 0.20\\n0 1 02 03 04 0\\nFIGURE 20.7. 95 percent conﬁdence bands for kernel density estimate for the as-\\ntronomy data.\\nSuppose now that the dataXi =( Xi1,...,X id) are d-dimensional. The ker-\\nnel estimator can easily be generalized to d dimensions. Let h =( h1,...,h d)\\nbe a vector of bandwidths and deﬁne\\nˆfn(x)= 1\\nn\\nn∑\\ni=1\\nKh(x − Xi) (20.28)\\nwhere\\nKh(x − Xi)= 1\\nnh1 ··· hd\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\nd∏\\nj=1\\nK\\n\\uf8f6xi − Xij\\nhj\\n\\uf8f7\\uf8fc\\n\\uf8fd\\n\\uf8fe (20.29)\\nwhere h1,...,h d are bandwidths. For simplicity, we might takehj = sjh where\\nsj is the standard deviation of the jth variable. There is now only a single\\nbandwidth h to choose. Using calculations like those in the one-dimensional\\ncase, the risk is given by\\nR(f, ˆfn) ≈ 1\\n4σ4\\nK\\n\\uf8ee\\n\\uf8f0\\nd∑\\nj=1\\nh4\\nj\\n∫\\nf2\\njj (x)dx +\\n∑\\nj̸=k\\nh2\\nj h2\\nk\\n∫\\nfjj fkkdx\\n\\uf8f9\\n\\uf8fb\\n+\\n\\uf8f6∫\\nK2(x)dx\\n\\uf8f7d\\nnh1 ··· hd\\nwhere fjj is the second partial derivative off. The optimal bandwidth satisﬁes\\nhi ≈ c1n−1/(4+d), leading to a risk of order n−4/(4+d). From this fact, we see'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 334, 'page_label': '335'}, page_content='20.4 Nonparametric Regression 319\\nthat the risk increases quickly with dimension, a problem usually called the\\ncurse of dimensionality . To get a sense of how serious this problem is,\\nconsider the following table from Silverman (1986) which shows the sample\\nsize required to ensure a relative mean squared error less than 0.1 at 0 when\\nthe density is multivariate normal and the optimal bandwidth is selected:\\nDimension Sample Size\\n14\\n21 9\\n36 7\\n4 223\\n5 768\\n6 2790\\n7 10,700\\n8 43,700\\n9 187,000\\n10 842,000\\nThis is bad news indeed. It says that having 842,000 observations in a ten-\\ndimensional problem is really like having 4 observations in a one-dimensional\\nproblem.\\n20.4 Nonparametric Regression\\nConsider pairs of points (x1,Y1),..., (xn,Yn) related by\\nYi = r(xi)+ ϵi (20.30)\\nwhere E(ϵi) = 0. We have written the xi’s in lower case since we will treat\\nthem as ﬁxed. We can do this since, in regression, it is only the mean of Y\\nconditional on x that we are interested in. We want to estimate the regression\\nfunction r(x)= E(Y |X = x).\\nThere are many nonparametric regression estimators. Most involve esti-\\nmating r(x) by taking some sort of weighted average of theYi’s, giving higher\\nweight to those points near x. A popular version is the Nadaraya-Watson\\nkernel estimator.\\n20.20 Deﬁnition. The Nadaraya-Watson kernel estimatoris deﬁned\\nby\\nˆr(x)=\\nn∑\\ni=1\\nwi(x)Yi (20.31)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 335, 'page_label': '336'}, page_content='320 20. Nonparametric Curve Estimation\\nwhere K is a kernel and the weights wi(x) are given by\\nwi(x)= K\\n\\uf8f6x−xi\\nh\\n\\uf8f7\\n∑ n\\nj=1 K\\n\\uf8f6\\nx−xj\\nh\\n\\uf8f7. (20.32)\\nThe form of this estimator comes from ﬁrst estimating the joint density\\nf(x, y) using kernel density estimation and then inserting the estimate into\\nthe formula,\\nr(x)= E(Y |X = x)=\\n∫\\nyf(y|x)dy =\\n∫\\nyf(x, y)dy∫\\nf(x, y)dy .\\n20.21 Theorem. Suppose that V(ϵi)= σ2. The risk of the Nadaraya-Watson\\nkernel estimator is\\nR(ˆrn,r ) ≈ h4\\n4\\n\\uf8f6∫\\nx2K2(x)dx\\n\\uf8f74 ∫ \\uf8f6\\nr′′(x)+2 r′(x)f′(x)\\nf(x)\\n\\uf8f72\\ndx\\n+\\n∫ σ2 ∫\\nK2(x)dx\\nnhf(x) dx. (20.33)\\nThe optimal bandwidth decreases at rate n−1/5 and with this choice the risk\\ndecreases at raten−4/5.\\nIn practice, to choose the bandwidth h we minimize the cross validation\\nscore\\nˆJ(h)=\\nn∑\\ni=1\\n(Yi − ˆr−i(xi))2 (20.34)\\nwhere ˆr−i is the estimator we get by omitting the ith variable. Fortunately,\\nthere is a shortcut formula for computing ˆJ.\\n20.22 Theorem. ˆJ can be written as\\nˆJ(h)=\\nn∑\\ni=1\\n(Yi − ˆr(xi))2 1\\n\\uf8f6\\n1 − K(0)\\n∑ n\\nj=1 K\\n(xi−xj\\nh\\n)\\n\\uf8f72 . (20.35)\\n20.23 Example. Figures 20.8 shows cosmic micr owave background (CMB)\\ndata from BOOMERaNG (Netterﬁeld et al. (2002)), Maxima (Lee et al.\\n(2001)), and DASI (Halverson et al. (2002))). The data consist of n pairs\\n(x\\n1,Y1), ... ,( xn,Yn) where xi is called the multipole moment and Yi is the'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 336, 'page_label': '337'}, page_content='20.4 Nonparametric Regression 321\\nestimated power spectrum of the temperature ﬂuctuations. What you are see-\\ning are sound waves in the cosmic microwave background radiation which is\\nthe heat, left over from the big bang. Ifr(x) denotes the true power spectrum,\\nthen\\nYi = r(xi)+ ϵi\\nwhere ϵi is a random error with mean 0. The location and size of peaks in\\nr(x) provides valuable clues about the behavior of the early universe. Figure\\n20.8 shows the ﬁt based on cross-validation as well as an undersmoothed and\\noversmoothed ﬁt. The cross-validation ﬁt shows the presence of three well-\\ndeﬁned peaks, as predicted by the physics of the big bang.\\n■\\nThe procedure for ﬁnding conﬁdence bands is similar to that for density\\nestimation. However, we ﬁrst need to estimate σ2. Suppose that the xi’s are\\nordered. Assuming r(x) is smooth, we have r(xi+1) − r(xi) ≈ 0 and hence\\nYi+1 − Yi =\\n[\\nr(xi+1)+ ϵi+1\\n]\\n−\\n[\\nr(xi)+ ϵi\\n]\\n≈ ϵi+1 − ϵi\\nand hence\\nV(Yi+1 − Yi) ≈ V(ϵi+1 − ϵi)= V(ϵi+1)+ V(ϵi)=2 σ2.\\nWe can thus use the average of then − 1 diﬀerences Yi+1 − Yi to estimate σ2.\\nHence, deﬁne\\nˆσ2 = 1\\n2(n − 1)\\nn−1∑\\ni=1\\n(Yi+1 − Yi)2. (20.36)\\nAs with density estimate, the conﬁdence band is for the smoothed version\\nrn(x)= E(ˆrn(x)) of the true regression function r.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 337, 'page_label': '338'}, page_content='322 20. Nonparametric Curve Estimation\\n200 400 600 800 1000\\n0 1000 2000 3000 4000 5000 6000\\nUndersmoothed\\n200 400 600 800 1000\\n0 1000 2000 3000 4000 5000 6000\\nOversmoothed\\n200 400 600 800 1000\\n0 1000 2000 3000 4000 5000 6000\\nJust Right (Using cross−valdiation)\\n20 40 60 80 100 120\\n3e+05 4e+05 5e+05 6e+05 7e+05 8e+05\\nbandwidth\\nestimated risk\\nFIGURE 20.8. Regression analysis of the CMB data. The ﬁrst ﬁt is undersmoothed,\\nthe second is oversmoothed, and the third is based on cross-validation. The last\\npanel shows the estimated risk versus the bandwidth of the smoother. The data are\\nfrom BOOMERaNG, Maxima, and DASI.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 338, 'page_label': '339'}, page_content='20.4 Nonparametric Regression 323\\nConﬁdence Bands for Kernel Regression\\nAn approximate 1 − α conﬁdence band for rn(x)i s\\nℓn(x)= ˆrn(x) − q ˆse(x),u n(x)= ˆrn(x)+ q ˆse(x) (20.37)\\nwhere\\nˆse(x)= ˆσ\\n\\ued6a\\ued6b\\ued6b\\n√\\nn∑\\ni=1\\nw2\\ni (x),\\nq =Φ −1\\n\\uf8f61+( 1 − α)1/m\\n2\\n\\uf8f7\\n,\\nm = b − a\\nω ,\\nˆσ is deﬁned in (20.36) and ω is the width of the kernel. In case the kernel\\ndoes not have ﬁnite width then we take ω to be the eﬀective width, that\\nis, the range over which the kernel is non-negligible. In particular, we take\\nω =3 h for the Normal kernel.\\n20.24 Example. Figure 20.9 shows a 95 percent conﬁdence envelope for the\\nCMB data. We see that we are highly conﬁdent of the existence and position\\nof the ﬁrst peak. We are more uncertain about the second and third peak.\\nAt the time of this writing, more accurate data are becoming available that\\napparently provide sharper estimates of the second and third peak.\\n■\\nThe extension to multiple regressors X =( X1,...,X p) is straightforward.\\nAs with kernel density estimation we just replace the kernel with a multivari-\\nate kernel. However, the same caveats about the curse of dimensionality apply.\\nIn some cases, we might consider putting some restrictions on the regression\\nfunction which will then reduce the curse of dimensionality. For example,\\nadditive regression is based on the model\\nY =\\np∑\\nj=1\\nrj(Xj)+ ϵ. (20.38)\\nNow we only need to ﬁt p one-dimensional functions. The model can be en-\\nriched by adding various interactions, for example,\\nY =\\np∑\\nj=1\\nrj(Xj)+\\n∑\\nj<k\\nrjk(XjXk)+ ϵ. (20.39)\\nAdditive models are usually ﬁt by an algorithm called backﬁtting.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 339, 'page_label': '340'}, page_content='324 20. Nonparametric Curve Estimation\\n200 400 600 800 1000\\n−1000 0 1000 2000 3000 4000 5000 6000\\nFIGURE 20.9. 95 percent conﬁdence envelope for the CMB data.\\nBackﬁtting\\n1. Initialize r1(x1) , ..., rp(xp).\\n2. For j =1 ,...,p :\\n(a) Let ϵi = Yi − ∑\\ns̸=j rs(xi).\\n(b) Let rj be the function estimate obtained by regressing the ϵi’s\\non the jth covariate.\\n3. If converged STOP. Else, go back to step 2.\\nAdditive models have the advantage that they avoid the curse of dimension-\\nality and they can be ﬁt quickly, but they have one disadvantage: the model\\nis not fully nonparametric. In other words, the true regression function r(x)\\nmay not be of the form (20.38).\\n20.5 Appendix\\nConfidence Sets and Bias. The conﬁdence bands we computed are not\\nfor the density function or regression function but rather for the smoothed'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 340, 'page_label': '341'}, page_content='20.6 Bibliographic Remarks 325\\nfunction. For example, the conﬁdence band for a kernel density estimate with\\nbandwidth h is a band for the function one gets by smoothing the true function\\nwith a kernel with the same bandwidth. Getting a conﬁdence set for the true\\nfunction is complicated for reasons we now explain.\\nLet ˆf\\nn(x) denote an estimate of the function f(x). Denote the mean and\\nstandard deviation of ˆfn(x)b y fn(x) and sn(x). Then,\\nˆfn(x) − f(x)\\nsn(x) =\\nˆfn(x) − fn(x)\\nsn(x) + fn(x) − f(x)\\nsn(x) .\\nTypically, the ﬁrst term converges to a standard Normal from which one de-\\nrives conﬁdence bands. The second term is the bias divided by the standard\\ndeviation. In parametric inference, the bias is usually smaller than the stan-\\ndard deviation of the estimator so this term goes to 0 as the sample size\\nincreases. In nonparametric inference, optimal smoothing leads us to balance\\nthe bias and the standard deviation. Thus the second term does not vanish\\neven with large sample sizes. This means that the conﬁdence interval will not\\nbe centered around the true function f.\\n20.6 Bibliographic Remarks\\nTwo very good books on density estimation are Scott (1992) and Silverman\\n(1986). The literature on nonparametric regression is very large. Two good\\nstarting points are Hardle (1990) and Loader (1999). The latter emphasizes a\\nclass of techniques called local likelihood methods.\\n20.7 Exercises\\n1. Let X1,...,X n ∼ f and let ˆfn be the kernel density estimator using the\\nboxcar kernel:\\nK(x)=\\n{\\n1 −1\\n2 <x< 1\\n2\\n0 otherwise .\\n(a) Show that\\nE( ˆf(x)) = 1\\nh\\n∫ x+(h/2)\\nx−(h/2)\\nf(y)dy\\nand\\nV( ˆf(x)) = 1\\nnh2\\n\\uf8ee\\n\\uf8f0\\n∫ x+(h/2)\\nx−(h/2)\\nf(y)dy −\\n\\uf8f6∫ x+(h/2)\\nx−(h/2)\\nf(y)dy\\n\\uf8f72\\uf8f9\\n\\uf8fb.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 341, 'page_label': '342'}, page_content='326 20. Nonparametric Curve Estimation\\n(b) Show that if h → 0 and nh →∞ as n →∞ , then ˆfn(x)\\nP\\n−→f(x).\\n2. Get the data on fragments of glass collected in forensic work from the\\nbook website. Estimate the density of the ﬁrst variable (refractive in-\\ndex) using a histogram and use a kernel density estimator. Use cross-\\nvalidation to choose the amount of smoothing. Experiment with diﬀerent\\nbinwidths and bandwidths. Comment on the similarities and diﬀerences.\\nConstruct 95 percent conﬁdence bands for your estimators.\\n3. Consider the data from question 2. Let Y be refractive index and let\\nx be aluminum content (the fourth variable). Perform a nonparametric\\nregression to ﬁt the modelY = f(x)+ϵ. Use cross-validation to estimate\\nthe bandwidth. Construct 95 percent conﬁdence bands for your estimate.\\n4. Prove Lemma 20.1.\\n5. Prove Theorem 20.3.\\n6. Prove Theorem 20.7.\\n7. Prove Theorem 20.15.\\n8. Consider regression data (x\\n1,Y1),..., (xn,Yn). Suppose that 0 ≤ xi ≤ 1\\nfor all i. Deﬁne bins Bj as in equation (20.7). For x ∈ Bj deﬁne\\nˆrn(x)= Y j\\nwhere Y j is the mean of all the Yi’s corresponding to those xi’s in Bj.\\nFind the approximate risk of this estimator. From this expression for\\nthe risk, ﬁnd the optimal bandwidth. At what rate does the risk go to\\nzero?\\n9. Show that with suitable smoothness assumptions onr(x), ˆσ\\n2 in equation\\n(20.36) is a consistent estimator of σ2.\\n10. Prove Theorem 20.22.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 342, 'page_label': '343'}, page_content='21\\nSmoothing Using Orthogonal Functions\\nIn this chapter we will study an approach to nonparametric curve estima-\\ntion based on orthogonal functions. We begin with a brief introduction to\\nthe theory of orthogonal functions, then we turn to density estimation and\\nregression.\\n21.1 Orthogonal Functions and L2 Spaces\\nLet v =( v1,v2,v3) denote a three-dimensional vector, that is, a list of three\\nreal numbers. Let V denote the set of all such vectors. If a is a scalar (a\\nnumber) and v is a vector, we deﬁne av =( av1,a v2,a v3). The sum of vectors\\nv and w is deﬁned byv+w =( v1 +w1,v2 +w2,v3 +w3). The inner product\\nbetween two vectors v and w is deﬁned by ⟨v,w ⟩ = ∑ 3\\ni=1 viwi. The norm\\n(or length) of a vector v is deﬁned by\\n||v|| =\\n√\\n⟨v,v ⟩ =\\n\\ued6a\\ued6b\\ued6b\\n√\\n3∑\\ni=1\\nv2\\ni . (21.1)\\nTwo vectors are orthogonal (or perpendicular) if ⟨v,w ⟩ = 0. A set of\\nvectors are orthogonal if each pair in the set is orthogonal. A vector isnormal\\nif ||v|| =1 .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 343, 'page_label': '344'}, page_content='328 21. Smoothing Using Orthogonal Functions\\nLet φ1 =( 1,0,0), φ2 =( 0,1,0), φ3 =( 0,0,1). These vectors are said to be\\nan orthonormal basis for V since they have the following properties:\\n(i) they are orthogonal;\\n(ii) they are normal;\\n(iii) they form a basis for V, which means that any v ∈V can be written as a\\nlinear combination of φ\\n1, φ2, φ3:\\nv =\\n3∑\\nj=1\\nβjφj where βj = ⟨φj,v ⟩. (21.2)\\nFor example, if v = (12,3,4) then v =1 2φ1 +3 φ2 +4 φ3. There are other\\northonormal bases for V, for example,\\nψ1 =\\n\\uf8f6 1√\\n3, 1√\\n3, 1√\\n3\\n\\uf8f7\\n,ψ 2 =\\n\\uf8f6 1√\\n2,− 1√\\n2,0\\n\\uf8f7\\n,ψ 3 =\\n\\uf8f6 1√\\n6, 1√\\n6,− 2√\\n6\\n\\uf8f7\\n.\\nYou can check that these three vectors also form an orthonormal basis forV.\\nAgain, if v is any vector then we can write\\nv =\\n3∑\\nj=1\\nβjψj where βj = ⟨ψj,v ⟩.\\nFor example, if v = (12,3,4) then\\nv =1 0.97ψ1 +6 .36ψ2 +2 .86ψ3.\\nNow we make the leap from vectors to functions. Basically, we just replace\\nvectors with functions and sums with integrals. Let L2(a, b) denote all func-\\ntions deﬁned on the interval [a, b] such that\\n∫b\\na f(x)2dx < ∞:\\nL2(a, b)=\\n{\\nf :[ a, b] → R,\\n∫ b\\na\\nf(x)2dx < ∞\\n}\\n. (21.3)\\nWe sometimes write L2 instead of L2(a, b). The inner product between two\\nfunctions f,g ∈ L2 is deﬁned by\\n∫\\nf(x)g(x)dx. The norm of f is\\n||f|| =\\n√ ∫\\nf(x)2dx. (21.4)\\nTwo functions are orthogonal if\\n∫\\nf(x)g(x)dx = 0. A function is normal if\\n||f|| =1 .\\nA sequence of functions φ1,φ2,φ3,... is orthonormal if\\n∫\\nφ2\\nj (x)dx = 1 for\\neach j and\\n∫\\nφi(x)φj(x)dx = 0 for i ̸= j. An orthonormal sequence is com-\\nplete if the only function that is orthogonal to each φj is the zero function.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 344, 'page_label': '345'}, page_content='21.1 Orthogonal Functions and L2 Spaces 329\\nIn this case, the functions φ1,φ2,φ3,... form in basis, meaning that if f ∈ L2\\nthen f can be written as1\\nf(x)=\\n∞∑\\nj=1\\nβjφj(x), where βj =\\n∫ b\\na\\nf(x)φj(x)dx. (21.5)\\nA useful result is Parseval’s relation which says that\\n||f||2 ≡\\n∫\\nf2(x) dx =\\n∞∑\\nj=1\\nβ2\\nj ≡| |β||2 (21.6)\\nwhere β =( β1,β2,... ).\\n21.1 Example. An example of an orthonormal basis forL2(0,1) is thecosine\\nbasis deﬁned as follows. Let φ0(x) = 1 and for j ≥ 1 deﬁne\\nφj(x)=\\n√\\n2 cos(jπx). (21.7)\\nThe ﬁrst six functions are plotted in Figure 21.1. ■\\n21.2 Example. Let\\nf(x)=\\n√\\nx(1 − x) sin\\n\\uf8f6 2.1π\\n(x + .05)\\n\\uf8f7\\nwhich is called the “doppler function.” Figure 21.2 shows f (top left) and its\\napproximation\\nfJ(x)=\\nJ∑\\nj=1\\nβjφj(x)\\nwith J equal to 5 (top right), 20 (bottom left), and 200 (bottom right).\\nAs J increases we see that fJ(x) gets closer to f(x). The coeﬃcients βj =∫1\\n0 f(x)φj(x)dx were computed numerically. ■\\n21.3 Example. The Legendre polynomials on [−1,1] are deﬁned by\\nPj(x)= 1\\n2jj!\\ndj\\ndxj (x2 − 1)j,j =0 ,1,2,... (21.8)\\nIt can be shown that these functions are complete and orthogonal and that\\n∫ 1\\n−1\\nP2\\nj (x)dx = 2\\n2j +1 . (21.9)\\n1The equality in the displayed equation means that\\n∫\\n(f(x)−fn(x))2dx → 0 where fn(x)=∑ n\\nj=1 βj φj (x).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 345, 'page_label': '346'}, page_content='330 21. Smoothing Using Orthogonal Functions\\nFIGURE 21.1. The ﬁrst six functions in the cosine basis.\\nFIGURE 21.2. Approximating the doppler function with its expansion\\nin the cosine basis. The function f (top left) and its approximation\\nfJ (x)= ∑ J\\nj=1 βj φj (x) with J equal to 5 (top right), 20 (bottom left),\\nand 200 (bottom right). The coeﬃcients βj =\\n∫1\\n0 f(x)φj (x)dx were\\ncomputed numerically.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 346, 'page_label': '347'}, page_content='21.2 Density Estimation 331\\nIt follows that the functions φj(x)=\\n√\\n(2j +1 )/2Pj(x), j =0 ,1,... form an\\northonormal basis for L2(−1,1). The ﬁrst few Legendre polynomials are:\\nP0(x)=1 ,\\nP1(x)= x,\\nP2(x)= 1\\n2\\n\\uf8f6\\n3x2 − 1\\n\\uf8f7\\n, and\\nP3(x)= 1\\n2\\n\\uf8f6\\n5x3 − 3x\\n\\uf8f7\\n.\\nThese polynomials may be constructed explicitly using the following recursive\\nrelation:\\nPj+1(x)= (2j +1 )xPj(x) − jPj−1(x)\\nj +1 . ■ (21.10)\\nThe coeﬃcients β1,β2,... are related to the smoothness of the function f.\\nTo see why, note that iff is smooth, then its derivatives will be ﬁnite. Thus we\\nexpect that, for some k,\\n∫1\\n0 (f(k)(x))2dx < ∞ where f(k) is the kth derivative\\nof f. Now consider the cosine basis (21.7) and letf(x)= ∑ ∞\\nj=0 βjφj(x). Then,\\n∫ 1\\n0\\n(f(k)(x))2dx =2\\n∞∑\\nj=1\\nβ2\\nj (πj)2k.\\nThe only way that ∑ ∞\\nj=1 β2\\nj (πj)2k can be ﬁnite is if the βj’s get small when\\nj gets large. To summarize:\\nIf the function f is smooth, then the coeﬃcients βj will be small\\nwhen j is large.\\nFor the rest of this chapter, assume we are using the cosine basis unless\\notherwise speciﬁed.\\n21.2 Density Estimation\\nLet X1,...,X n be iid observations from a distribution on [0,1] with density\\nf. Assuming f ∈ L2 we can write\\nf(x)=\\n∞∑\\nj=0\\nβjφj(x)\\nwhere φ1,φ2,... is an orthonormal basis. Deﬁne\\nˆβj = 1\\nn\\nn∑\\ni=1\\nφj(Xi). (21.11)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 347, 'page_label': '348'}, page_content='332 21. Smoothing Using Orthogonal Functions\\n21.4 Theorem. The mean and variance of ˆβj are\\nE\\n\\uf8f6\\nˆβj\\n\\uf8f7\\n= βj, V\\n\\uf8f6\\nˆβj\\n\\uf8f7\\n= σ2\\nj\\nn (21.12)\\nwhere\\nσ2\\nj = V(φj(Xi)) =\\n∫\\n(φj(x) − βj)2f(x)dx. (21.13)\\nProof. The mean is\\nE\\n\\uf8f6\\nˆβj\\n\\uf8f7\\n= 1\\nn\\nn∑\\ni=1\\nE (φj(Xi))\\n= E (φj(X1))\\n=\\n∫\\nφj(x)f(x)dx = βj.\\nThe calculation for the variance is similar. ■\\nHence, ˆβj is an unbiased estimate of βj. It is tempting to estimate f by∑ ∞\\nj=1\\nˆβjφj(x) but this turns out to have a very high variance. Instead, consider\\nthe estimator\\nˆf(x)=\\nJ∑\\nj=1\\nˆβjφj(x). (21.14)\\nThe number of terms J is a smoothing parameter. Increasing J will decrease\\nbias while increasing variance. For technical reasons, we restrict J to lie in\\nthe range\\n1 ≤ J ≤ p\\nwhere p = p(n)= √n. To emphasize the dependence of the risk function on\\nJ, we write the risk function as R(J).\\n21.5 Theorem. The risk of ˆf is\\nR(J)=\\nJ∑\\nj=1\\nσ2\\nj\\nn +\\n∞∑\\nj=J+1\\nβ2\\nj . (21.15)\\nAn estimate of the risk is\\nˆR(J)=\\nJ∑\\nj=1\\nˆσ2\\nj\\nn +\\np∑\\nj=J+1\\n\\uf8f6\\nˆβ2\\nj − ˆσ2\\nj\\nn\\n\\uf8f7\\n+\\n(21.16)\\nwhere a+ = max{a,0} and\\nˆσ2\\nj = 1\\nn − 1\\nn∑\\ni=1\\n\\uf8f6\\nφj(Xi) − ˆβj\\n\\uf8f72\\n. (21.17)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 348, 'page_label': '349'}, page_content='21.2 Density Estimation 333\\nTo motivate this estimator, note that ˆσ2\\nj is an unbiased estimate of σ2\\nj and\\nˆβ2\\nj − ˆσ2\\nj is an unbiased estimator ofβ2\\nj . We take the positive part of the latter\\nterm since we know thatβ2\\nj cannot be negative. We now choose 1≤ ˆJ ≤ p to\\nminimize ˆR( ˆf,f ). Here is a summary:\\nSummary of Orthogonal Function Density Estimation\\n1. Let\\nˆβj = 1\\nn\\nn∑\\ni=1\\nφj(Xi).\\n2. Choose ˆJ to minimize ˆR(J) over 1 ≤ J ≤ p = √n where ˆR is given in\\nequation (21.16).\\n3. Let\\nˆf(x)=\\nˆJ∑\\nj=1\\nˆβjφj(x).\\nThe estimator ˆfn can be negative. If we are interested in exploring the\\nshape of f, this is not a problem. However, if we need our estimate to be a\\nprobability density function, we can truncate the estimate and then normalize\\nit. That is, we take ˆf\\n∗ = max{ ˆfn(x),0}/\\n∫1\\n0 max{ ˆfn(u),0}du.\\nNow let us construct a conﬁdence band forf. Suppose we estimate f using\\nJ orthogonal functions. We are essentially estimating fJ(x)= ∑ J\\nj=1 βjφj(x)\\nnot the true density f(x)= ∑ ∞\\nj=1 βjφj(x). Thus, the conﬁdence band should\\nbe regarded as a band for fJ(x).\\n21.6 Theorem. An approximate 1 − α conﬁdence band for fJ is (ℓ(x),u (x))\\nwhere\\nℓ(x)= ˆfn(x) − c, u (x)= ˆfn(x)+ c (21.18)\\nwhere\\nc = K2\\n√\\nJχ2\\nJ,α\\nn (21.19)\\nand\\nK = max\\n1≤j≤J\\nmax\\nx\\n|φj(x)|.\\nFor the cosine basis,K =\\n√\\n2.\\nProof. Here is an outline of the proof. Let L = ∑ J\\nj=1(ˆβj − βj)2.B yt h e\\ncentral limit theorem, ˆβj ≈ N(βj,σ 2\\nj /n). Hence, ˆβj ≈ βj + σjϵj/√n where'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 349, 'page_label': '350'}, page_content='334 21. Smoothing Using Orthogonal Functions\\nϵj ∼ N(0,1), and therefore\\nL ≈ 1\\nn\\nJ∑\\nj=1\\nσ2\\nj ϵ2\\nj\\n≤ K2\\nn\\nJ∑\\nj=1\\nϵ2\\nj\\nd\\n= K2\\nn χ2\\nJ. (21.20)\\nThus we have, approximately, that\\nP\\n\\uf8f6\\nL> K2\\nn χ2\\nJ,α\\n\\uf8f7\\n≤ P\\n\\uf8f6K2\\nn χ2\\nJ > K2\\nn χ2\\nJ,α\\n\\uf8f7\\n= α.\\nAlso,\\nmax\\nx\\n| ˆfJ(x) − fJ(x)|≤ max\\nx\\nJ∑\\nj=1\\n|φj(x)|| ˆβj − βj|\\n≤ K\\nJ∑\\nj=1\\n|ˆβj − βj|\\n≤\\n√\\nJK\\n\\ued6a\\ued6b\\ued6b\\n√\\nJ∑\\nj=1\\n(ˆβj − βj)2\\n=\\n√\\nJK\\n√\\nL\\nwhere the third inequality is from the Cauchy-Schwartz inequality (Theorem\\n4.8). So,\\nP\\n\\uf8eb\\n\\uf8edmax\\nx\\n| ˆfJ(x) − fJ(x)| >K 2\\n√\\nJχ2\\nJ,α\\nn\\n\\uf8f6\\n\\uf8f8 ≤ P\\n\\uf8eb\\n\\uf8ed√\\nJK\\n√\\nL>K 2\\n√\\nJχ2\\nJ,α\\nn\\n\\uf8f6\\n\\uf8f8\\n= P\\n\\uf8eb\\n\\uf8ed√\\nL>K\\n√\\nχ2\\nJ,α\\nn\\n\\uf8f6\\n\\uf8f8\\n= P\\n\\uf8f6\\nL>\\nK2χ2\\nJ,α\\nn\\n\\uf8f7\\n≤ α. ■\\n21.7 Example. Let\\nf(x)= 5\\n6φ(x;0,1) + 1\\n6\\n5∑\\nj=1\\nφ(x;µj,.1)\\nwhere φ(x;µ, σ) denotes a Normal density with meanµ and standard deviation\\nσ, and (µ1,...,µ 5)=( −1,−1/2,0,1/2,1). Marron and Wand (1992) call this'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 350, 'page_label': '351'}, page_content='21.3 Regression 335\\n0.0 0.2 0.4 0.6 0.8 1.0\\n01234\\n0.0 0.2 0.4 0.6 0.8 1.0\\n01234\\nFIGURE 21.3. The top plot is the true density for the Bart Simpson distribution\\n(rescaled to have most of its mass between 0 and 1). The bottom plot is the orthog-\\nonal function density estimate and 95 percent conﬁdence band.\\n“the claw” although the “Bart Simpson” might be more appropriate. Figure\\n21.3 shows the true density as well as the estimated density based on n =\\n5,000 observations and a 95 percent conﬁdence band. The density has been\\nrescaled to have most of its mass between 0 and 1 using the transformation\\ny =( x +3 )/6.\\n■\\n21.3 Regression\\nConsider the regression model\\nYi = r(xi)+ ϵi,i =1 ,...,n (21.21)\\nwhere the ϵi are independent with mean 0 and variance σ2. We will initially\\nfocus on the special case where xi = i/n. We assume that r ∈ L2(0,1) and\\nhence we can write\\nr(x)=\\n∞∑\\nj=1\\nβjφj(x) where βj =\\n∫ 1\\n0\\nr(x)φj(x)dx (21.22)\\nwhere φ1,φ2,... where is an orthonormal basis for [0,1].'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 351, 'page_label': '352'}, page_content='336 21. Smoothing Using Orthogonal Functions\\nDeﬁne\\nˆβj = 1\\nn\\nn∑\\ni=1\\nYi φj(xi),j =1 ,2,... (21.23)\\nSince ˆβj is an average, the central limit theorem tells us that ˆβj will be\\napproximately Normally distributed.\\n21.8 Theorem.\\nˆβj ≈ N\\n\\uf8f6\\nβj, σ2\\nn\\n\\uf8f7\\n. (21.24)\\nProof. The mean of ˆβj is\\nE(ˆβj)= 1\\nn\\nn∑\\ni=1\\nE(Yi)φj(xi)= 1\\nn\\nn∑\\ni=1\\nr(xi)φj(xi)\\n≈\\n∫\\nr(x)φj(x)dx = βj\\nwhere the approximate equality follows from the deﬁnition of a Riemann in-\\ntegral: ∑\\ni ∆nh(xi) →\\n∫1\\n0 h(x)dx where ∆n =1 /n. The variance is\\nV(ˆβj)= 1\\nn2\\nn∑\\ni=1\\nV(Yi)φ2\\nj (xi)\\n= σ2\\nn2\\nn∑\\ni=1\\nφ2\\nj (xi)= σ2\\nn\\n1\\nn\\nn∑\\ni=1\\nφ2\\nj (xi)\\n≈ σ2\\nn\\n∫\\nφ2\\nj (x)dx = σ2\\nn\\nsince\\n∫\\nφ2\\nj (x)dx =1 . ■\\nLet\\nˆr(x)=\\nJ∑\\nj=1\\nˆβjφj(x),\\nand let\\nR(J)= E\\n∫\\n(r(x) − ˆr(x))2 dx\\nbe the risk of the estimator.\\n21.9 Theorem. The risk R(J) of the estimator ˆrn(x)= ∑ J\\nj=1\\nˆβjφj(x) is\\nR(J)= Jσ2\\nn +\\n∞∑\\nj=J+1\\nβ2\\nj . (21.25)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 352, 'page_label': '353'}, page_content='21.3 Regression 337\\nTo estimate for σ2 = V(ϵi)w eu s e\\nˆσ2 = n\\nk\\nn∑\\ni=n−k+1\\nˆβ2\\nj (21.26)\\nwhere k = n/4. To motivate this estimator, recall that if f is smooth, then\\nβj ≈ 0 for large j. So, for j ≥ k, ˆβj ≈ N(0,σ 2/n) and thus, ˆβj ≈ σZj/√n for\\nfor j ≥ k, where Zj ∼ N(0,1). Therefore,\\nˆσ2 = n\\nk\\nn∑\\ni=n−k+1\\nˆβ2\\nj ≈ n\\nk\\nn∑\\ni=n−k+1\\n\\uf8f6 σ√n\\nˆβj\\n\\uf8f72\\n= σ2\\nk\\nn∑\\ni=n−k+1\\nˆβ2\\nj = σ2\\nk χ2\\nk\\nsince a sum of k Normals has a χ2\\nk distribution. Now E(χ2\\nk)= k and hence\\nE(ˆσ2) ≈ σ2. Also, V(χ2\\nk)=2 k and hence V(ˆσ2) ≈ (σ4/k2)(2k)=( 2 σ4/k) → 0\\nas n →∞ . Thus we expect ˆσ2 to be a consistent estimator of σ2. There is\\nnothing special about the choice k = n/4. Any k that increases with n at an\\nappropriate rate will suﬃce.\\nWe estimate the risk with\\nˆR(J)= J ˆσ2\\nn +\\nn∑\\nj=J+1\\n\\uf8f6\\nˆβ2\\nj − ˆσ2\\nn\\n\\uf8f7\\n+\\n. (21.27)\\n21.10 Example. Figure 21.4 shows the doppler function f and n =2 ,048\\nobservations generated from the model\\nYi = r(xi)+ ϵi\\nwhere xi = i/n, ϵi ∼ N(0,(.1)2). The ﬁgure shows the data and the estimated\\nfunction. The estimate was based on ˆJ = 234 terms. ■\\nWe are now ready to give a complete description of the method.\\nOrthogonal Series Regression Estimator\\n1. Let\\nˆβj = 1\\nn\\nn∑\\ni=1\\nYiφj(xi),j =1 ,...,n .\\n2. Let\\nˆσ2 = n\\nk\\nn∑\\ni=n−k+1\\nˆβ2\\nj (21.28)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 353, 'page_label': '354'}, page_content='338 21. Smoothing Using Orthogonal Functions\\nFIGURE 21.4. Data from the doppler test function and the estimated function. See\\nExample 21.10.\\nwhere k ≈ n/4.\\n3. For 1 ≤ J ≤ n, compute the risk estimate\\nˆR(J)= J ˆσ2\\nn +\\nn∑\\nj=J+1\\n\\uf8f6\\nˆβ2\\nj − ˆσ2\\nn\\n\\uf8f7\\n+\\n.\\n4. Choose ˆJ ∈{ 1,...n } to minimize ˆR(J).\\n5. Let\\nˆr(x)=\\nˆJ∑\\nj=1\\nˆβjφj(x).\\nFinally, we turn to conﬁdence bands. As before, these bands are not really\\nfor the true function r(x) but rather for the smoothed version of the function\\nrJ(x)= ∑ ˆJ\\nj=1 βjφj(x).\\n21.11 Theorem. Suppose the estimate ˆr is based onJ terms and ˆσ is deﬁned\\nas in equation (21.28). Assume that J<n − k +1 . An approximate 1 − α\\nconﬁdence band for rJ is (ℓ, u) where\\nℓ(x)= ˆrn(x) − c, u (x)= ˆrn(x)+ c, (21.29)\\nwhere\\nc = a(x) ˆσχ J,α√n ,a (x)=\\n\\ued6a\\ued6b\\ued6b\\n√\\nJ∑\\nj=1\\nφ2\\nj (x),'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 354, 'page_label': '355'}, page_content='21.3 Regression 339\\nand ˆσ is given in equation (21.28).\\nProof. Let L = ∑ J\\nj=1(ˆβj − βj)2. By the central limit theorem, ˆβj ≈\\nN(βj,σ 2/n). Hence, ˆβj ≈ βj + σϵj/√n where ϵj ∼ N(0,1) and therefore\\nL ≈ σ2\\nn\\nJ∑\\nj=1\\nϵ2\\nj\\nd\\n= σ2\\nn χ2\\nJ.\\nThus,\\nP\\n\\uf8f6\\nL> σ2\\nn χ2\\nJ,α\\n\\uf8f7\\n= P\\n\\uf8f6σ2\\nn χ2\\nJ > σ2\\nn χ2\\nJ,α\\n\\uf8f7\\n= α.\\nAlso,\\n|ˆr(x) − rJ(x)|≤\\nJ∑\\nj=1\\n|φj(x)|| ˆβj − βj|\\n≤\\n\\ued6a\\ued6b\\ued6b\\n√\\nJ∑\\nj=1\\nφ2\\nj (x)\\n\\ued6a\\ued6b\\ued6b\\n√\\nJ∑\\nj=1\\n(ˆβj − β2\\nj )\\n≤ a(x)\\n√\\nL\\nby the Cauchy-Schwartz inequality (Theorem 4.8). So,\\nP\\n\\uf8f6\\nmax\\nx\\n| ˆfJ(x) − f(x)|\\na(x) > ˆσχJ,α√n\\n\\uf8f7\\n≤ P\\n\\uf8f6√\\nL> ˆσχJ,α√n\\n\\uf8f7\\n= α\\nand the result follows. ■\\n21.12 Example. Figure 21.5 shows the conﬁdence envelope for the doppler\\nsignal. The ﬁrst plot is based on J = 234 (the value of J that minimizes the\\nestimated risk). The second is based onJ =4 5 ≈ √n. Larger J yields a higher\\nresolution estimator at the cost of large conﬁdence bands. Smaller J yields a\\nlower resolution estimator but has tighter conﬁdence bands. ■\\nSo far, we have assumed that the xi’s are of the form {1/n, 2/ n ,...,1}.\\nIf the xi’s are on interval [a, b], then we can rescale them so that are in the\\ninterval [0,1]. If thexi’s are not equally spaced, the methods we have discussed\\nstill apply so long as thexi’s “ﬁll out” the interval [0,1] in such a way so as to\\nnot be too clumped together. If we want to treat the xi’s as random instead\\nof ﬁxed, then the method needs signiﬁcant modiﬁcations which we shall not\\ndeal with here.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 355, 'page_label': '356'}, page_content='340 21. Smoothing Using Orthogonal Functions\\nFIGURE 21.5. Estimates and conﬁdence bands for the doppler test function using\\nn =2 , 048 observations. First plot: J = 234 terms. Second plot: J = 45 terms.\\n21.4 Wavelets\\nSuppose there is a sharp jump in a regression function f at some point x\\nbut that f is otherwise very smooth. Such a function f is said to be spa-\\ntially inhomogeneous. The doppler function is an example of a spatially\\ninhomogeneous function; it is smooth for large x and unsmooth for small x.\\nIt is hard to estimate f using the methods we have discussed so far. If we\\nuse a cosine basis and only keep low order terms, we will miss the peak; if\\nwe allow higher order terms we will ﬁnd the peak but we will make the rest\\nof the curve very wiggly. Similar comments apply to kernel regression. If we\\nuse a large bandwidth, then we will smooth out the peak; if we use a small\\nbandwidth, then we will ﬁnd the peak but we will make the rest of the curve\\nvery wiggly.\\nOne way to estimate inhomogeneous functions is to use a more carefully\\nchosen basis that allows us to place a “blip” in some small region without\\nadding wiggles elsewhere. In this section, we describe a special class of bases\\ncalled wavelets, that are aimed at ﬁxing this problem. Statistical inference\\nusing wavelets is a large and active area. We will just discuss a few of the\\nmain ideas to get a ﬂavor of this approach.\\nWe start with a particular wavelet called the Haar wavelet. The Haar\\nfather wavelet or Haar scaling function is deﬁned by\\nφ(x)=\\n{\\n1i f 0 ≤ x< 1\\n0 otherwise . (21.30)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 356, 'page_label': '357'}, page_content='21.4 Wavelets 341\\nThe mother Haar wavelet is deﬁned by\\nψ(x)=\\n{\\n−1i f 0 ≤ x ≤ 1\\n2,\\n1i f 1\\n2 <x ≤ 1. (21.31)\\nFor any integers j and k deﬁne\\nψj,k(x)=2 j/2ψ(2jx − k). (21.32)\\nThe function ψj,k has the same shape asψ but it has been rescaled by a factor\\nof 2j/2 and shifted by a factor of k.\\nSee Figure 21.6 for some examples of Haar wavelets. Notice that for large\\nj, ψj,k is a very localized function. This makes it possible to add a blip to a\\nfunction in one place without adding wiggles elsewhere. Increasing j is like\\nlooking in a microscope at increasing degrees of resolution. In technical terms,\\nwe say that wavelets provide a multiresolution analysis of L\\n2(0,1).\\n-2\\n-1\\n0\\n1\\n2\\n-2\\n-1\\n0\\n1\\n2\\nFIGURE 21.6. Some Haar wavelets. Left: the mother wavelet ψ(x); Right: ψ2,2(x).\\nLet\\nWj = {ψjk,k =0 ,1,..., 2j − 1}\\nbe the set of rescaled and shifted mother wavelets at resolution j.\\n21.13 Theorem. The set of functions\\n{\\nφ, W0,W 1,W 2,...,\\n}\\nis an orthonormal basis for L2(0,1).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 357, 'page_label': '358'}, page_content='342 21. Smoothing Using Orthogonal Functions\\nIt follows from this theorem that we can expand any functionf ∈ L2(0,1) in\\nthis basis. Because eachWj is itself a set of functions, we write the expansion\\nas a double sum:\\nf(x)= αφ (x)+\\n∞∑\\nj=0\\n2j−1∑\\nk=0\\nβj,kψj,k(x) (21.33)\\nwhere\\nα =\\n∫ 1\\n0\\nf(x)φ(x) dx, β j,k =\\n∫ 1\\n0\\nf(x)ψj,k(x) dx.\\nWe call α the scaling coeﬃcient and the βj,k’s are called the detail\\ncoeﬃcients. We call the ﬁnite sum\\nfJ(x)= αφ(x)+\\nJ−1∑\\nj=0\\n2j−1∑\\nk=0\\nβj,kψj,k(x) (21.34)\\nthe resolution J approximation to f. The total number of terms in this sum\\nis\\n1+\\nJ−1∑\\nj=0\\n2j =1+2 J − 1=2 J.\\n21.14 Example. Figure 21.7 shows the doppler signal, and its reconstruction\\nusing J =3 ,5 and J =8 . ■\\nHaar wavelets are localized, meaning that they are zero outside an interval.\\nBut they are not smooth. This raises the question of whether there exist\\nsmooth, localized wavelets that from an orthonormal basis. In 1988, Ingrid\\nDaubechie showed that such wavelets do exist. These smooth wavelets are\\ndiﬃcult to describe. They can be constructed numerically but there is no\\nclosed form formula for the smootherwavelets. To keep things simple, we will\\ncontinue to use Haar wavelets.\\nConsider the regression model Y\\ni = r(xi)+ σϵi where ϵi ∼ N(0,1) and\\nxi = i/n. To simplify the discussion we assume that n =2 J for some J.\\nThere is one major diﬀerence between estimation using wavelets instead of\\na cosine (or polynomial) basis. With the cosine basis, we used all the terms\\n1 ≤ j ≤ J for someJ. The number of termsJ acted as a smoothing parameter.\\nWith wavelets, we control smoothing using a method called thresholding\\nwhere we keep a term in the function approximation if its coeﬃcient is large,'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 358, 'page_label': '359'}, page_content='21.4 Wavelets 343\\n0.0 0.2 0.4 0.6 0.8 1.0\\n−0.4 −0.2 0.0 0.2 0.4\\nx\\nf\\n0.0 0.2 0.4 0.6 0.8 1.0\\n−0.4 −0.2 0.0 0.2 0.4\\n0.0 0.2 0.4 0.6 0.8 1.0\\n−0.4 −0.2 0.0 0.2 0.4\\n0.0 0.2 0.4 0.6 0.8 1.0\\n−0.4 −0.2 0.0 0.2 0.4\\nFIGURE 21.7. The doppler signal and its reconstruction\\nfJ (x)= αφ(x)+ ∑ J−1\\nj=0\\n∑\\nk βj,k ψj,k (x) based on J =3 , J = 5, and J =8 .\\notherwise, we throw out that term. There are many versions of thresholding.\\nThe simplest is called hard, universal thresholding. LetJ = log2(n) and deﬁne\\nˆα = 1\\nn\\n∑\\ni\\nφk(xi)Yi and Dj,k = 1\\nn\\n∑\\ni\\nψj,k(xi)Yi (21.35)\\nfor 0 ≤ j ≤ J − 1.\\nHaar Wavelet Regression\\n1. Compute ˆα and Dj,k as in (21.35), for 0 ≤ j ≤ J − 1.\\n2. Estimate σ; see (21.37).\\n3. Apply universal thresholding:\\nˆβj,k =\\n{\\nDj,k if |Dj,k| > ˆσ\\n√\\n2 logn\\nn\\n0 otherwise .\\n}\\n(21.36)\\n4. Set ˆf(x)= ˆαφ(x)+ ∑ J−1\\nj=j0\\n∑ 2j−1\\nk=0\\nˆβj,kψj,k(x).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 359, 'page_label': '360'}, page_content='344 21. Smoothing Using Orthogonal Functions\\nIn practice, we do not compute Sk and Dj,k using (21.35). Instead, we use\\nthe discrete wavelet transform (DWT)which is very fast. The DWT for\\nHaar wavelets is described in the appendix. The estimate of σ is\\nˆσ = √n × median\\n\\uf8f6\\n|DJ−1,k| : k =0 ,..., 2J−1 − 1\\n\\uf8f7\\n0.6745 . (21.37)\\nThe estimate for σ may look strange. It is similar to the estimate we used\\nfor the cosine basis but it is designed to be insensitive to sharp peaks in the\\nfunction.\\nTo understand the intuition behind universal thresholding, consider what\\nhappens when there is no signal, that is, when β\\nj,k = 0 for all j and k.\\n21.15 Theorem. Suppose that βj,k =0 for all j and k and let ˆβj,k be the\\nuniversal threshold estimator. Then\\nP(ˆβj,k = 0 for all j, k) → 1\\nas n →∞ .\\nProof. To simplify the proof, assume that σ is known. Now Dj,k ≈\\nN(0,σ 2/n). We will need Mill’s inequality (Theorem 4.7): if Z ∼ N(0,1)\\nthen P(|Z| >t ) ≤ (c/t)e−t2/2 where c =\\n√\\n2/π is a constant. Thus,\\nP(max |Dj,k| >λ ) ≤\\n∑\\nj,k\\nP(|Dj,k| >λ )=\\n∑\\nj,k\\nP\\n\\uf8f6√n|Dj,k|\\nσ >\\n√nλ\\nσ\\n\\uf8f7\\n≤\\n∑\\nj,k\\ncσ\\nλ√n exp\\n{\\n−1\\n2\\nnλ2\\nσ2\\n}\\n= c√2 logn → 0. ■\\n21.16 Example. Consider Yi = r(xi)+ σϵi where f is the doppler signal,\\nσ = .1 and n =2 ,048. Figure 21.8 shows the data and the estimated function\\nusing universal thresholding. Of course, the estimate is not smooth since Haar\\nwavelets are not smooth. Nonetheless, the estimate is quite accurate.\\n■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 360, 'page_label': '361'}, page_content='21.5 Appendix 345\\n0.0 0.2 0.4 0.6 0.8 1.0\\n−0.5 0.0 0.5\\n0.0 0.2 0.4 0.6 0.8 1.0\\n−0.4 −0.2 0.0 0.2 0.4\\nFIGURE 21.8. Estimate of the Doppler function using Haar wavelets and universal\\nthresholding.\\n21.5 Appendix\\nThe DWT for Haar Wavelets. Let y be the vector of Yi’s (length n) and\\nlet J = log2(n). Create a list D with elements\\nD[[0]], ..., D [[J − 1]].\\nSet:\\ntemp ← y/√n.\\nThen do:\\nfor(ji n (J − 1 ):0 ){\\nm ← 2j\\nI ← (1 : m)\\nD[[j]] ←\\n\\uf8f6\\ntemp[2 ∗ I] − temp[(2 ∗ I) − 1]\\n\\uf8f7\\n/\\n√\\n2\\ntemp ←\\n\\uf8f6\\ntemp[2 ∗ I]+ temp[(2 ∗ I) − 1]\\n\\uf8f7\\n/\\n√\\n2\\n}'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 361, 'page_label': '362'}, page_content='346 21. Smoothing Using Orthogonal Functions\\n21.6 Bibliographic Remarks\\nEfromovich (1999) is a reference for orthogonal function methods. See also\\nBeran (2000) and Beran and D¨umbgen (1998). An introduction towavelets is\\ngiven in Ogden (1997). A more advanced treatment can be found in H¨ardle\\net al. (1998). The theory of statistical estimation using wavelets has been\\ndeveloped by many authors, especially David Donoho and Ian Johnstone. See\\nDonoho and Johnstone (1994), Donoho and Johnstone (1995), Donoho et al.\\n(1995), and Donoho and Johnstone (1998).\\n21.7 Exercises\\n1. Prove Theorem 21.5.\\n2. Prove Theorem 21.9.\\n3. Let\\nψ\\n1 =\\n\\uf8f6 1√\\n3, 1√\\n3, 1√\\n3\\n\\uf8f7\\n,ψ 2 =\\n\\uf8f6 1√\\n2,− 1√\\n2,0\\n\\uf8f7\\n,ψ 3 =\\n\\uf8f6 1√\\n6, 1√\\n6,− 2√\\n6\\n\\uf8f7\\n.\\nShow that these vectors have norm 1 and are orthogonal.\\n4. Prove Parseval’s relation equation (21.6).\\n5. Plot the ﬁrst ﬁve Legendre polynomials. Verify, numerically, that they\\nare orthonormal.\\n6. Expand the following functions in the cosine basis on [0 ,1]. For (a)\\nand (b), ﬁnd the coeﬃcients β\\nj analytically. For (c) and (d), ﬁnd the\\ncoeﬃcients βj numerically, i.e.\\nβj =\\n∫ 1\\n0\\nf(x)φj(x) ≈ 1\\nN\\nN∑\\nr=1\\nf\\n\\uf8f6r\\nN\\n\\uf8f7\\nφj\\n\\uf8f6r\\nN\\n\\uf8f7\\nfor some large integer N. Then plot the partial sum ∑ n\\nj=1 βjφj(x) for\\nincreasing values of n.\\n(a) f(x)=\\n√\\n2 cos(3πx).\\n(b) f(x) = sin(πx).\\n(c) f(x)= ∑ 11\\nj=1 hjK(x−tj) where K(t) = (1+sign(t))/2, sign(x)= −1\\nif x< 0, sign(x)=0i f x = 0, sign(x)=1i f x> 0,'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 362, 'page_label': '363'}, page_content='21.7 Exercises 347\\n(tj)=( .1,.13,.15,.23,.25,.40,.44,.65,.76,.78,.81),\\n(hj)=( 4 ,−5,3,−4,5,−4.2,2.1,4.3,−3.1,2.1,−4.2).\\n(d) f =\\n√\\nx(1 − x) sin\\n\\uf8f6\\n2.1π\\n(x+.05)\\n\\uf8f7\\n.\\n7. Consider the glass fragments data from the book’s website. Let Y be\\nrefractive index and let X be aluminum content (the fourth variable).\\n(a) Do a nonparametric regression to ﬁt the model Y = f(x)+ ϵ using\\nthe cosine basis method. The data are not on a regular grid. Ignore this\\nwhen estimating the function. (But do sort the data ﬁrst according to\\nx.) Provide a function estimate, an estimate of the risk, and a conﬁdence\\nband.\\n(b) Use the wavelet method to estimate f.\\n8. Show that the Haar wavelets are orthonormal.\\n9. Consider again the doppler signal:\\nf(x)=\\n√\\nx(1 − x) sin\\n\\uf8f6 2.1π\\nx +0 .05\\n\\uf8f7\\n.\\nLet n =1 ,024, σ =0 .1, and let ( x1,...,x n)=( 1 / n ,...,1). Generate\\ndata\\nYi = f(xi)+ σϵi\\nwhere ϵi ∼ N(0,1).\\n(a) Fit the curve using the cosine basis method. Plot the function esti-\\nmate and conﬁdence band for J =1 0,20,..., 100.\\n(b) Use Haar wavelets to ﬁt the curve.\\n10. (Haar density Estimation.) Let X1,...,X n ∼ f for some density f on\\n[0,1]. Let’s consider constructing a wavelet histogram. Let φ and ψ be\\nthe Haar father and mother wavelet. Write\\nf(x) ≈ φ(x)+\\nJ−1∑\\nj=0\\n2j−1∑\\nk=0\\nβj,kψj,k(x)\\nwhere J ≈ log2(n). Let\\nˆβj,k = 1\\nn\\nn∑\\ni=1\\nψj,k(Xi).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 363, 'page_label': '364'}, page_content='348 21. Smoothing Using Orthogonal Functions\\n(a) Show that ˆβj,k is an unbiased estimate of βj,k.\\n(b) Deﬁne the Haar histogram\\nˆf(x)= φ(x)+\\nB∑\\nj=0\\n2j−1∑\\nk=0\\nˆβj,kψj,k(x)\\nfor 0 ≤ B ≤ J − 1.\\n(c) Find an approximate expression for the MSE as a function of B.\\n(d) Generate n =1 ,000 observations from a Beta (15,4) density. Es-\\ntimate the density using the Haar histogram. Use leave-one-out cross\\nvalidation to choose B.\\n11. In this question, we will explore the motivation for equation (21.37). Let\\nX\\n1,...,X n ∼ N(0,σ 2). Let\\nˆσ = √n × median (|X1|,..., |Xn|)\\n0.6745 .\\n(a) Show that E(ˆσ)= σ.\\n(b) Simulate n = 100 observations from a N(0,1) distribution. Compute\\nˆσ as well as the usual estimate of σ. Repeat 1,000 times and compare\\nthe MSE.\\n(c) Repeat (b) but add some outliers to the data. To do this, simulate\\neach observation from a N(0,1) with probability .95 and simulate each\\nobservation from a N(0,10) with probability .95.\\n12. Repeat question 6 using the Haar basis.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 364, 'page_label': '365'}, page_content='22\\nClassiﬁcation\\n22.1 Introduction\\nThe problem of predicting a discrete random variableY from another random\\nvariable X is called classiﬁcation, supervised learning, discrimination,\\nor pattern recognition.\\nConsider iid data (X1,Y1),..., (Xn,Yn) where\\nXi =( Xi1,...,X id) ∈X⊂ Rd\\nis a d-dimensional vector and Yi takes values in some ﬁnite setY.A classiﬁ-\\ncation rule is a function h : X→Y . When we observe a new X, we predict\\nY to be h(X).\\n22.1 Example. Here is a an example with fake data. Figure 22.1 shows 100\\ndata points. The covariate X =( X1,X 2) is 2-dimensional and the outcome\\nY ∈Y = {0,1}. The Y values are indicated on the plot with the triangles\\nrepresenting Y = 1 and the squares representingY = 0. Also shown is a linear\\nclassiﬁcation rule represented by the solid line. This is a rule of the form\\nh(x)=\\n{ 1i f a + b1x1 + b2x2 > 0\\n0 otherwise .\\nEverything above the line is classiﬁed as a 0 and everything below the line is\\nclassiﬁed as a 1. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 365, 'page_label': '366'}, page_content='350 22. Classiﬁcation\\n/SolidTriangle/Triangle\\n/SolidTriangle/Triangle\\n/SolidTriangle/Triangle\\n/SolidTriangle/Triangle\\n/SolidTriangle/Triangle\\n/SolidTriangle/Triangle\\n/SolidSquare/Square\\n/SolidSquare/Square/SolidSquare/Square\\n/SolidSquare/Square /SolidSquare/Square\\n/SolidSquare/Square\\nx1\\nx2\\nFIGURE 22.1. Two covariates and a linear decision boundary. △ means Y =1 .\\n/Boxmeans Y = 0. These two groups are perfectly separated by the linear decision\\nboundary; you probably won’t see real data like this.\\n22.2 Example. Recall the the Coronary Risk-Factor Study (CORIS) data\\nfrom Example 13.17. There are 462 males between the ages of 15 and 64 from\\nthree rural areas in South Africa. The outcome Y is the presence (Y =1 )o r\\nabsence (Y = 0) of coronary heart disease and there are 9 covariates: systolic\\nblood pressure, cumulative tobacco (kg), ldl (low density lipoprotein choles-\\nterol), adiposity, famhist (family history of heart disease), typea (type-A be-\\nhavior), obesity, alcohol (current alcohol consumption), and age. I computed\\na linear decision boundary using the LDA method based on two of the co-\\nvariates, systolic blood pressure and tobacco consumption. The LDA method\\nwill be explained shortly. In this example, the groups are hard to tell apart.\\nIn fact, 141 of the 462 subjects are misclassiﬁed using this classiﬁcation rule.\\n■\\nAt this point, it is worth revisiting the Statistics/Data Mining dictionary:\\nStatistics Computer Science Meaning\\nclassiﬁcation supervised learning predicting a discrete Y from X\\ndata training sample ( X1,Y1),..., (Xn,Yn)\\ncovariates features the Xi’s\\nclassiﬁer hypothesis map h : X→Y\\nestimation learning ﬁnding a good classiﬁer\\n22.2 Error Rates and the Bayes Classiﬁer\\nOur goal is to ﬁnd a classiﬁcation ruleh that makes accurate predictions. We\\nstart with the following deﬁnitions:'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 366, 'page_label': '367'}, page_content='22.2 Error Rates and the Bayes Classiﬁer 351\\n22.3 Deﬁnition. The true error rate1of a classiﬁer h is\\nL(h)= P({h(X) ̸= Y }) (22.1)\\nand the empirical error rate or training error rate is\\nˆLn(h)= 1\\nn\\nn∑\\ni=1\\nI(h(Xi) ̸= Yi). (22.2)\\nFirst we consider the special case where Y = {0,1}. Let\\nr(x)= E(Y |X = x)= P(Y =1 |X = x)\\ndenote the regression function. From Bayes’ theorem we have that\\nr(x)= P(Y =1 |X = x)\\n= f(x|Y =1 )P(Y =1 )\\nf(x|Y =1 )P(Y =1 )+ f(x|Y =0 )P(Y =0 )\\n= πf1(x)\\nπf1(x)+( 1 − π)f0(x) (22.3)\\nwhere\\nf0(x)= f(x|Y =0 )\\nf1(x)= f(x|Y =1 )\\nπ = P(Y =1 ).\\n22.4 Deﬁnition. The Bayes classiﬁcation rule h∗ is\\nh∗(x)=\\n{\\n1i f r(x) > 1\\n2\\n0 otherwise . (22.4)\\nThe set D(h)= {x : P(Y =1 |X = x)= P(Y =0 |X = x)} is called the\\ndecision boundary.\\nWarning! The Bayes rule has nothing to do with Bayesian inference. We\\ncould estimate the Bayes rule using either frequentist or Bayesian methods.\\nThe Bayes rule may be written in several equivalent forms:\\n1One can use other loss functions. For simplicity we will use the error rate as our loss function.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 367, 'page_label': '368'}, page_content='352 22. Classiﬁcation\\nh∗(x)=\\n{\\n1i f P(Y =1 |X = x) > P(Y =0 |X = x)\\n0 otherwise (22.5)\\nand\\nh∗(x)=\\n{\\n1i f πf1(x) > (1 − π)f0(x)\\n0 otherwise . (22.6)\\n22.5 Theorem. The Bayes rule is optimal, that is, if h is any other classiﬁ-\\ncation rule then L(h∗) ≤ L(h).\\nThe Bayes rule depends on unknown quantities so we need to use the data\\nto ﬁnd some approximation to the Bayes rule. At the risk of oversimplifying,\\nthere are three main approaches:\\n1. Empirical Risk Minimization. Choose a set of classiﬁersH and ﬁnd ˆh ∈H\\nthat minimizes some estimate of L(h).\\n2. Regression. Find an estimate ˆr of the regression function r and deﬁne\\nˆh(x)=\\n{\\n1i f ˆr(x) >\\n1\\n2\\n0 otherwise .\\n3. Density Estimation. Estimate f0 from the Xi’s for whichYi = 0, estimate\\nf1 from the Xi’s for which Yi = 1 and let ˆπ = n−1 ∑ n\\ni=1 Yi. Deﬁne\\nˆr(x)= ˆP(Y =1 |X = x)= ˆπ ˆf1(x)\\nˆπ ˆf1(x)+( 1 − ˆπ) ˆf0(x)\\nand\\nˆh(x)=\\n{\\n1i f ˆr(x) > 1\\n2\\n0 otherwise .\\nNow let us generalize to the case where Y takes on more than two values\\nas follows.\\n22.6 Theorem. Suppose that Y ∈Y = {1,...,K }. The optimal rule is\\nh(x) = argmax k P(Y = k|X = x) (22.7)\\n= argmax kπk fk(x) (22.8)\\nwhere\\nP(Y = k|X = x)= fk(x)πk∑\\nr fr(x)πr\\n, (22.9)\\nπr = P(Y = r), fr(x)= f(x|Y = r) and argmaxk means “the value of k\\nthat maximizes that expression.”'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 368, 'page_label': '369'}, page_content='22.3 Gaussian and Linear Classiﬁers 353\\n22.3 Gaussian and Linear Classiﬁers\\nPerhaps the simplest approach to classiﬁcation is to use the density estima-\\ntion strategy and assume a parametric model for the densities. Suppose that\\nY = {0,1} and that f\\n0(x)= f(x|Y = 0) and f1(x)= f(x|Y = 1) are both\\nmultivariate Gaussians:\\nfk(x)= 1\\n(2π)d/2|Σk|1/2 exp\\n{\\n−1\\n2(x − µk)T Σ−1\\nk (x − µk)\\n}\\n,k =0 ,1.\\nThus, X|Y =0 ∼ N(µ0,Σ0) and X|Y =1 ∼ N(µ1,Σ1).\\n22.7 Theorem. If X|Y =0 ∼ N(µ0,Σ0) and X|Y =1 ∼ N(µ1,Σ1), then the\\nBayes rule is\\nh∗(x)=\\n{\\n1i f r2\\n1 <r 2\\n0 + 2 log\\n\\uf8f6\\nπ1\\nπ0\\n\\uf8f7\\n+ log\\n\\uf8f6\\n|Σ0|\\n|Σ1|\\n\\uf8f7\\n0 otherwise\\n(22.10)\\nwhere\\nr2\\ni =( x − µi)T Σ−1\\ni (x − µi),i =1 ,2 (22.11)\\nis the Manalahobis distance. An equivalent way of expressing the Bayes’\\nrule is\\nh∗(x) = argmaxkδk(x)\\nwhere\\nδk(x)= −1\\n2 log |Σk|− 1\\n2(x − µk)T Σ−1\\nk (x − µk) + logπk (22.12)\\nand |A| denotes the determinant of a matrix A.\\nThe decision boundary of the above classiﬁer is quadratic so this procedure\\nis called quadratic discriminant analysis (QDA) . In practice, we use\\nsample estimates of π,µ 1,µ2,Σ0,Σ1 in place of the true value, namely:\\nˆπ0 = 1\\nn\\nn∑\\ni=1\\n(1 − Yi), ˆπ1 = 1\\nn\\nn∑\\ni=1\\nYi\\nˆµ0 = 1\\nn0\\n∑\\ni: Yi=0\\nXi, ˆµ1 = 1\\nn1\\n∑\\ni: Yi=1\\nXi\\nS0 = 1\\nn0\\n∑\\ni: Yi=0\\n(Xi − ˆµ0)(Xi − ˆµ0)T ,S 1 = 1\\nn1\\n∑\\ni: Yi=1\\n(Xi − ˆµ1)(Xi − ˆµ1)T\\nwhere n0 = ∑\\ni(1 − Yi) and n1 = ∑\\ni Yi.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 369, 'page_label': '370'}, page_content='354 22. Classiﬁcation\\nA simpliﬁcation occurs if we assume that Σ 0 =Σ 0 = Σ. In that case, the\\nBayes rule is\\nh∗(x) = argmaxkδk(x) (22.13)\\nwhere now\\nδk(x)= xT Σ−1µk − 1\\n2µT\\nk Σ−1 + logπk. (22.14)\\nThe parameters are estimated as before, except that the mle o fΣi s\\nS = n0S0 + n1S1\\nn0 + n1\\n.\\nThe classiﬁcation rule is\\nh∗(x)=\\n{ 1i f δ1(x) >δ 0(x)\\n0 otherwise (22.15)\\nwhere\\nδj(x)= xT S−1ˆµj − 1\\n2 ˆµT\\nj S−1ˆµj + logˆπj\\nis called the discriminant function. The decision boundary {x : δ0(x)=\\nδ1(x)} is linear so this method is called linear discrimination analysis\\n(LDA).\\n22.8 Example. Let us return to the South African heart disease data. The\\ndecision rule in in Example 22.2 was obtained by linear discrimination. The\\noutcome was\\nclassiﬁed as 0 classiﬁed as 1\\ny = 0 277 25\\ny = 1 116 44\\nThe observed misclassiﬁcation rate is 141/462 = .31. Including all the covari-\\nates reduces the error rate to .27. The results from quadratic discrimination\\nare\\nclassiﬁed as 0 classiﬁed as 1\\ny = 0 272 30\\ny = 1 113 47\\nwhich has about the same error rate 143/462 = .31. Including all the covariates\\nreduces the error rate to .26. In this example, there is little advantage to QDA\\nover LDA.\\n■\\nNow we generalize to the case where Y takes on more than two values.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 370, 'page_label': '371'}, page_content='22.3 Gaussian and Linear Classiﬁers 355\\n22.9 Theorem. Suppose that Y ∈{ 1,...,K }.I f fk(x)= f(x|Y = k) is\\nGaussian, the Bayes rule is\\nh(x) = argmaxkδk(x)\\nwhere\\nδk(x)= −1\\n2 log |Σk|− 1\\n2(x − µk)T Σ−1\\nk (x − µk) + logπk. (22.16)\\nIf the variances of the Gaussians are equal, then\\nδk(x)= xT Σ−1µk − 1\\n2µT\\nk Σ−1 + logπk. (22.17)\\nWe estimate δk(x) by by inserting estimates of µk,Σ k and πk. There is\\nanother version of linear discriminant analysis due to Fisher. The idea is\\nto ﬁrst reduce the dimension of covariates to one dimension by projecting\\nthe data onto a line. Algebraically, this means replacing the covariate X =\\n(X\\n1,...,X d) with a linear combination U = wT X = ∑ d\\nj=1 wjXj. The goal is\\nto choose the vector w =( w1,...,w d) that “best separates the data.” Then\\nwe perform classiﬁcation with the one-dimensional covariate Z instead of X.\\nWe need deﬁne what we mean by separation of the groups. We would like\\nthe two groups to have means that are far apart relative to their spread. Let\\nµ\\nj denote the mean of X for Yj and let Σ be the variance matrix of X. Then\\nE(U|Y = j)= E(wT X|Y = j)= wT µj and V(U)= wT Σw. 2 Deﬁne the\\nseparation by\\nJ(w)= (E(U|Y =0 ) − E(U|Y = 1))2\\nwT Σw\\n= (wT µ0 − wT µ1)2\\nwT Σw\\n= wT (µ0 − µ1)(µ0 − µ1)T w\\nwT Σw .\\nWe estimate J as follows. Let nj = ∑ n\\ni=1 I(Yi = j) be the number of obser-\\nvations in group j, let Xj be the sample mean vector of the X’s for group j,\\nand let Sj be the sample covariance matrix in group j. Deﬁne\\nˆJ(w)= wT SBw\\nwT SW w (22.18)\\n2The quantity J arises in physics, where it is called the Rayleigh coeﬃcient.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 371, 'page_label': '372'}, page_content='356 22. Classiﬁcation\\nwhere\\nSB =( X0 − X1)(X0 − X1)T\\nSW = (n0 − 1)S0 +( n1 − 1)S1\\n(n0 − 1 )+(n1 − 1) .\\n22.10 Theorem. The vector\\nw = S−1\\nW (X0 − X1) (22.19)\\nis a minimizer of ˆJ(w).W ec a l l\\nU = wT X =( X0 − X1)T S−1\\nW X (22.20)\\nthe Fisher linear discriminant function. The midpointm between X0 and\\nX1 is\\nm = 1\\n2(X0 + X1)= 1\\n2(X0 − X1)T S−1\\nB (X0 + X1) (22.21)\\nFisher’s classiﬁcation rule is\\nh(x)=\\n{ 0i f wT X ≥ m\\n1i f wT X<m .\\nFisher’s rule is the same as the Bayes linear classiﬁer in equation (22.14)\\nwhen ˆπ =1 /2.\\n22.4 Linear Regression and Logistic Regression\\nA more direct approach to classiﬁcation is to estimate the regression function\\nr(x)= E(Y |X = x) without bothering to estimate the densities fk. For the\\nrest of this section, we will only consider the case where Y = {0,1}. Thus,\\nr(x)= P(Y =1 |X = x) and once we have an estimate ˆr, we will use the\\nclassiﬁcation rule\\nˆh(x)=\\n{\\n1i f ˆr(x) > 1\\n2\\n0 otherwise . (22.22)\\nThe simplest regression model is the linear regression model\\nY = r(x)+ ϵ = β0 +\\nd∑\\nj=1\\nβjXj + ϵ (22.23)\\nwhere E(ϵ) = 0. This model can’t be correct since it does not force Y =0o r\\n1. Nonetheless, it can sometimes lead to a decent classiﬁer.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 372, 'page_label': '373'}, page_content='22.4 Linear Regression and Logistic Regression 357\\nRecall that the least squares estimate of β =( β0,β1,...,β d)T minimizes\\nthe residual sums of squares\\nrss(β)=\\nn∑\\ni=1\\n\\uf8f6\\nYi − β0 −\\nd∑\\nj=1\\nXijβj\\n\\uf8f72\\n.\\nLet X denote the N × (d + 1) matrix of the form\\nX =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\n\\uf8ef\\uf8f0\\n1 X\\n11 ... X 1d\\n1 X21 ... X 2d\\n..\\n. ..\\n. ..\\n. ..\\n.\\n1 X\\nn1 ... X nd\\n\\uf8f9\\n\\uf8fa\\uf8fa\\n\\uf8fa\\uf8fb.\\nAlso let Y =( Y\\n1,...,Y n)T . Then,\\nRSS(β)=( Y − Xβ)T (Y − Xβ)\\nand the model can be written as\\nY = Xβ + ϵ\\nwhere ϵ =( ϵ1,...,ϵ n)T . From Theorem 13.13,\\nˆβ =( XT X)−1XT Y.\\nThe predicted values are\\nˆY = Xˆβ.\\nNow we use (22.22) to classify, where ˆr(x)= ˆβ0 + ∑\\nj\\nˆβjxj.\\nAn alternative is to use logistic regression which was also discussed in Chap-\\nter 13. The model is\\nr(x)= P(Y =1 |X = x)= eβ0+∑\\nj βjxj\\n1+ eβ0+∑\\nj βjxj\\n(22.24)\\nand the mle ˆβ is obtained numerically.\\n22.11 Example. Let us return to the heart disease data. The mle is given in\\nExample 13.17. The error rate, using this model for classiﬁcation, is .27. The\\nerror rate from a linear regression is .26.\\nWe can get a better classiﬁer by ﬁtting a richer model. For example, we\\ncould ﬁt\\nlogit P(Y =1 |X = x)= β\\n0 +\\n∑\\nj\\nβjxj +\\n∑\\nj,k\\nβjkxjxk. (22.25)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 373, 'page_label': '374'}, page_content='358 22. Classiﬁcation\\nMore generally, we could add terms of up to orderr for some integer r. Large\\nvalues of r give a more complicated model which should ﬁt the data better.\\nBut there is a bias–variance tradeoﬀ which we’ll discuss later.\\n22.12 Example. If we use model (22.25) for the heart disease data withr =2 ,\\nthe error rate is reduced to .22. ■\\n22.5 Relationship Between Logistic Regression and\\nLDA\\nLDA and logistic regression are almost the same thing. If we assume that each\\ngroup is Gaussian with the same covariance matrix, then we saw earlier that\\nlog\\n\\uf8f6P(Y =1 |X = x)\\nP(Y =0 |X = x)\\n\\uf8f7\\n= log\\n\\uf8f6π0\\nπ1\\n\\uf8f7\\n− 1\\n2(µ0 + µ1)T Σ−1(µ1 − µ0)\\n+ xT Σ−1(µ1 − µ0)\\n≡ α0 + αT x.\\nOn the other hand, the logistic model is, by assumption,\\nlog\\n\\uf8f6P(Y =1 |X = x)\\nP(Y =0 |X = x)\\n\\uf8f7\\n= β0 + βT x.\\nThese are the same model since they both lead to classiﬁcation rules that are\\nlinear in x. The diﬀerence is in how we estimate the parameters.\\nThe joint density of a single observation isf(x, y)= f(x|y)f(y)= f(y|x)f(x).\\nIn LDA we estimated the whole joint distribution by maximizing the likeli-\\nhood ∏\\ni\\nf(xi,y i)=\\n∏\\ni\\nf(xi|yi)\\n\\ued19 \\ued18\\ued17 \\ued1a\\nGaussian\\n∏\\ni\\nf(yi)\\n\\ued19 \\ued18\\ued17 \\ued1a\\nBernoulli\\n. (22.26)\\nIn logistic regression we maximized the conditional likelihood∏\\ni f(yi|xi) but\\nwe ignored the second term f(xi):\\n∏\\ni\\nf(xi,y i)=\\n∏\\ni\\nf(yi|xi)\\n\\ued19 \\ued18\\ued17 \\ued1a\\nlogistic\\n∏\\ni\\nf(xi)\\n\\ued19 \\ued18\\ued17 \\ued1a\\nignored\\n. (22.27)\\nSince classiﬁcation only requires knowing f(y|x), we don’t really need to es-\\ntimate the whole joint distribution. Logistic regression leaves the marginal'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 374, 'page_label': '375'}, page_content='22.6 Density Estimation and Naive Bayes 359\\ndistribution f(x) unspeciﬁed so it is more nonparametric than LDA. This is\\nan advantage of the logistic regression approach over LDA.\\nTo summarize: LDA and logistic regression both lead to a linear classi-\\nﬁcation rule. In LDA we estimate the entire joint distribution f(x, y)=\\nf(x|y)f(y). In logistic regression we only estimatef(y|x) and we don’t bother\\nestimating f(x).\\n22.6 Density Estimation and Naive Bayes\\nThe Bayes rule is h(x) = argmax k πk fk(x). If we can estimate πk and fk\\nthen we can estimate the Bayes classiﬁcation rule. Estimating πk is easy but\\nwhat about fk? We did this previously by assuming fk was Gaussian. An-\\nother strategy is to estimate fk with some nonparametric density estimator\\nˆfk such as a kernel estimator. But if x =( x1,...,x d) is high-dimensional,\\nnonparametric density estimation is not very reliable. This problem is amelio-\\nrated if we assume thatX\\n1,...,X d are independent, for then,fk(x1,...,x d)=∏d\\nj=1 fkj(xj). This reduces the problem to d one-dimensional density estima-\\ntion problems, within each of the k groups. The resulting classiﬁer is called\\nthe naive Bayes classiﬁer. The assumption that the components of X are\\nindependent is usually wrong yet the resulting classiﬁer might still be accu-\\nrate. Here is a summary of the steps in the naive Bayes classiﬁer:\\nThe Naive Bayes Classiﬁer\\n1. For each group k, compute an estimate ˆfkj of the density fkj for Xj,\\nusing the data for which Yi = k.\\n2. Let\\nˆfk(x)= ˆfk(x1,...,x d)=\\nd∏\\nj=1\\nˆfkj(xj).\\n3. Let\\nˆπk = 1\\nn\\nn∑\\ni=1\\nI(Yi = k)\\nwhere I(Yi = k)=1i f Yi = k and I(Yi = k)=0i f Yi ̸= k.\\n4. Let\\nh(x) = argmaxk ˆπk ˆfk(x).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 375, 'page_label': '376'}, page_content='360 22. Classiﬁcation\\n01\\nBlood Pressure 1\\nAge\\n< 100 ≥ 100\\n< 50 ≥ 50\\nFIGURE 22.2. A simple classiﬁcation tree.\\nThe naive Bayes classiﬁer is popular when x is high-dimensional and dis-\\ncrete. In that case, ˆfkj(xj) is especially simple.\\n22.7 Trees\\nTrees are classiﬁcation methods that partition the covariate space X into\\ndisjoint pieces and then classify the observations according to which partition\\nelement they fall in. As the name implies, the classiﬁer can be represented as\\na tree.\\nFor illustration, suppose there are two covariates,X\\n1 = age andX2 = blood\\npressure. Figure 22.2 shows a classiﬁcation tree using these variables.\\nThe tree is used in the following way. If a subject has Age ≥ 50 then we\\nclassify him as Y = 1. If a subject has Age < 50 then we check his blood\\npressure. If systolic blood pressure is < 100 then we classify him as Y =1 ,\\notherwise we classify him as Y = 0. Figure 22.3 shows the same classiﬁer as\\na partition of the covariate space.\\nHere is how a tree is constructed. First, suppose that y ∈Y = {0,1} and\\nthat there is only a single covariate X. We choose a split point t that divides\\nthe real line into two sets A1 =( −∞,t ] and A2 =( t, ∞). Let ˆps(j)b et h e\\nproportion of observations in As such that Yi = j:\\nˆps(j)=\\n∑ n\\ni=1 I(Yi = j, Xi ∈ As)∑ n\\ni=1 I(Xi ∈ As) (22.28)\\nfor s =1 ,2 and j =0 ,1. The impurity of the split t is deﬁned to be\\nI(t)=\\n2∑\\ns=1\\nγs (22.29)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 376, 'page_label': '377'}, page_content='22.7 Trees 361\\n1\\n0\\n1\\nAge\\nBlood Pressure\\n50\\n110\\nFIGURE 22.3. Partition representation of classiﬁcation tree.\\nwhere\\nγs =1 −\\n1∑\\nj=0\\nˆps(j)2. (22.30)\\nThis particular measure of impurity is known as theGini index. If a partition\\nelement As contains all 0’s or all 1’s, then γs = 0. Otherwise, γs > 0. We\\nchoose the split point t to minimize the impurity. (Other indices of impurity\\nbesides can be used besides the Gini index.)\\nWhen there are several covariates, we choose whichever covariate and split\\nthat leads to the lowest impurity. This process is continued until some stopping\\ncriterion is met. For example, we might stop when every partition element has\\nfewer than n\\n0 data points, where n0 is some ﬁxed number. The bottom nodes\\nof the tree are called the leaves. Each leaf is assigneda0o r1d e p ending on\\nwhether there are more data points with Y =0o r Y = 1 in that partition\\nelement.\\nThis procedure is easily generalized to the case where Y ∈{ 1,...,K }. We\\nsimply deﬁne the impurity by\\nγs =1 −\\nk∑\\nj=1\\nˆps(j)2 (22.31)\\nwhere ˆpi(j) is the proportion of observations in the partition element for which\\nY = j.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 377, 'page_label': '378'}, page_content='362 22. Classiﬁcation\\ntobacco\\n< 0.51 ≥ 0.51\\nage\\n< 31.5 ≥ 31.5\\nage\\n< 50.5 ≥ 50.5\\ntobacco\\n< 7.47 ≥ 7.47\\n000\\n01\\nFIGURE 22.4. A classiﬁcation tree for the heart disease data using two covariates.\\n22.13 Example. A classiﬁcation tree for the heart disease data yields a mis-\\nclassiﬁcation rate of .21. If we build a tree using only tobacco and age, the\\nmisclassiﬁcation rate is then .29. The tree is shown in Figure 22.4.\\n■\\nOur description of how to build trees is incomplete. If we keep splitting\\nuntil there are few cases in each leaf of the tree, we are likely to overﬁt the\\ndata. We should choose the complexity of the tree in such a way that the\\nestimated true error rate is low. In the next section, we discuss estimation of\\nthe error rate.\\n22.8 Assessing Error Rates and Choosing a Good\\nClassiﬁer\\nHow do we choose a good classiﬁer? We would like to have a classiﬁerh with\\na low true error rateL(h). Usually, we can’t use the training error rateˆLn(h)\\nas an estimate of the true error rate because it is biased downward.\\n22.14 Example. Consider the heart disease data again. Suppose we ﬁt a se-\\nquence of logistic regression models. In the ﬁrst model we include one co-\\nvariate. In the second model we include two covariates, and so on. The ninth\\nmodel includes all the covariates. We can go even further. Let’s also ﬁt a tenth\\nmodel that includes all nine covariates plus the ﬁrst covariate squared. Then'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 378, 'page_label': '379'}, page_content='22.8 Assessing Error Rates and Choosing a Good Classiﬁer 363\\nwe ﬁt an eleventh model that includes all nine covariates plus the ﬁrst covari-\\nate squared and the second covariate squared. Continuing this way we will get\\na sequence of 18 classiﬁers of increasing complexity. The solid line in Figure\\n22.5 shows the observed classiﬁcation error which steadily decreases as we\\nmake the model more complex. If we keep going, we can make a model with\\nzero observed classiﬁcation error. The dotted line shows the 10-fold cross-\\nvalidation estimate of the error rate (to be explained shortly) which is a\\nbetter estimate of the true error rate than the observed classiﬁcation error.\\nThe estimated error decreases for a while then increases. This is essentially\\nthe bias–variance tradeoﬀ phenomenon we have seen in Chapter 20.\\n■\\nnumber of terms in model\\nerror rate\\n0.26\\n0.30\\n0.34\\n51 5\\nFIGURE 22.5. The solid line is the observed error rate and dashed line is the\\ncross-validation estimate of true error rate.\\nThere are many ways to estimate the error rate. We’ll consider two:cross-\\nvalidation and probability inequalities.\\nCross-Validation. The basic idea of cross-validation, which we have al-\\nready encountered in curve estimation, is to leave out some of the data when\\nﬁtting a model. The simplest version of cross-validation involves randomly\\nsplitting the data into two pieces: the training set T and the validation\\nset V. Often, about 10 per cent of the data might be set aside as the validation\\nset. The classiﬁer h is constructed from the training set. We then estimate'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 379, 'page_label': '380'}, page_content='364 22. Classiﬁcation\\nTraining Data T Validation Data V\\n\\ued19 \\ued18\\ued17 \\ued1a\\nˆh\\n\\ued19 \\ued18\\ued17 \\ued1a\\nˆL\\nFIGURE 22.6. Cross-validation. The data are divided into two groups: the training\\ndata and the validation data. The training data are used to produce an estimated\\nclassiﬁer ˆh. Then, ˆh is applied to the validation data to obtain an estimateˆL of the\\nerror rate of ˆh.\\nthe error by\\nˆL(h)= 1\\nm\\n∑\\nXi∈V\\nI(h(Xi) ̸= YI). (22.32)\\nwhere m is the size of the validation set. See Figure 22.6.\\nAnother approach to cross-validation isK-fold cross-validation which is\\nobtained from the following algorithm.\\nK-fold cross-validation.\\n1. Randomly divide the data into K chunks of approximately equal size.\\nA common choice is K = 10.\\n2 . F o rk=1t oK ,d ot h efollowing:\\n(a) Delete chunk k from the data.\\n(b) Compute the classiﬁer ˆh(k) from the rest of the data.\\n(c) Use ˆh(k) to the predict the data in chunk k. Let ˆL(k) denote\\nthe observed error rate.\\n3. Let\\nˆL(h)= 1\\nK\\nK∑\\nk=1\\nˆL(k). (22.33)\\n22.15 Example. We applied 10-fold cross-validation to the heart disease data.\\nThe minimum cross-validation error as a function of the number of leaves\\noccurred at six. Figure 22.7 shows the tree with six leaves.\\n■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 380, 'page_label': '381'}, page_content='22.8 Assessing Error Rates and Choosing a Good Classiﬁer 365\\nage\\n< 31.5 ≥ 31.5\\nage\\n< 50.5 ≥ 50.5\\ntype A\\n< 68.5 ≥ 68.5\\nfamily history\\nno yes\\ntobacco\\n< 7.605 ≥ 7.605\\n0\\n01\\n01\\n1\\nFIGURE 22.7. Smaller classiﬁcation tree with size chosen by cross-validation.\\nProbability Inequalities. Another approach to estimating the error rate\\nis to ﬁnd a conﬁdence interval for ˆLn(h) using probability inequalities. This\\nmethod is useful in the context of empirical risk minimization.\\nLet H be a set of classiﬁers, for example, all linear classiﬁers. Empirical risk\\nminimization means choosing the classiﬁer ˆh ∈H to minimize the training\\nerror ˆLn(h), also called the empirical risk. Thus,\\nˆh = argminh∈H ˆLn(h) = argminh∈H\\n\\uf8f6\\n1\\nn\\n∑\\ni\\nI(h(Xi) ̸= Yi)\\n\\uf8f7\\n. (22.34)\\nTypically, ˆLn(ˆh) underestimates the true error rateL(ˆh) because ˆh was chosen\\nto make ˆLn(ˆh) small. Our goal is to assess how much underestimation is taking\\nplace. Our main tool for this analysis is Hoeﬀding’s inequality (Theorem\\n4.5). Recall that if X1,...,X n ∼ Bernoulli(p), then, for any ϵ> 0,\\nP (|ˆp − p| >ϵ ) ≤ 2e−2nϵ2\\n(22.35)\\nwhere ˆp = n−1 ∑ n\\ni=1 Xi.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 381, 'page_label': '382'}, page_content='366 22. Classiﬁcation\\nFirst, suppose that H = {h1,...,h m} consists of ﬁnitely many classiﬁers.\\nFor any ﬁxed h, ˆLn(h) converges in almost surely to L(h) by the law of large\\nnumbers. We will now establish a stronger result.\\n22.16 Theorem (Uniform Convergence). Assume H is ﬁnite and has m ele-\\nments. Then,\\nP\\n\\uf8f6\\nmax\\nh∈H\\n|ˆLn(h) − L(h)| >ϵ\\n\\uf8f7\\n≤ 2me−2nϵ2\\n.\\nProof. We will use Hoeﬀding’s inequality and we will also use the fact\\nthat if A1,...,A m is a set of events then P(⋃m\\ni=1 Ai) ≤ ∑ m\\ni=1 P(Ai). Now,\\nP\\n\\uf8f6\\nmax\\nh∈H\\n|ˆLn(h) − L(h)| >ϵ\\n\\uf8f7\\n= P\\n\\uf8f6⋃\\nh∈H\\n|ˆLn(h) − L(h)| >ϵ\\n\\uf8f7\\n≤\\n∑\\nH∈H\\nP\\n\\uf8f6\\n|ˆLn(h) − L(h)| >ϵ\\n\\uf8f7\\n≤\\n∑\\nH∈H\\n2e−2nϵ2\\n=2 me−2nϵ2\\n. ■\\n22.17 Theorem. Let\\nϵ =\\n√\\n2\\nn log\\n\\uf8f62m\\nα\\n\\uf8f7\\n.\\nThen ˆLn(ˆh) ± ϵ is a 1 − α conﬁdence interval for L(ˆh).\\nProof. This follows from the fact that\\nP(|ˆLn(ˆh) − L(ˆh)| >ϵ ) ≤ P\\n\\uf8f6\\nmax\\nh∈H\\n|ˆLn(ˆh) − L(ˆh)| >ϵ\\n\\uf8f7\\n≤ 2me−2nϵ2\\n= α. ■\\nWhen H is large the conﬁdence interval forL(ˆh) is large. The more functions\\nthere are in H the more likely it is we have “overﬁt” which we compensate\\nfor by having a larger conﬁdence interval.\\nIn practice we usually use sets H that are inﬁnite, such as the set of linear\\nclassiﬁers. To extend our analysis to these cases we want to be able to say\\nsomething like\\nP\\n\\uf8f6\\nsup\\nh∈H\\n|ˆLn(h) − L(h)| >ϵ\\n\\uf8f7\\n≤ something not too big.\\nOne way to develop such a generalization is by way of theVapnik-Chervonenkis\\nor VC dimension.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 382, 'page_label': '383'}, page_content='22.8 Assessing Error Rates and Choosing a Good Classiﬁer 367\\nLet A be a class of sets. Give a ﬁnite set F = {x1,...,x n} let\\nNA(F)=#\\n{\\nF\\n⋂\\nA : A ∈A\\n}\\n(22.36)\\nbe the number of subsets of F “picked out” by A. Here #( B) denotes the\\nnumber of elements of a set B. The shatter coeﬃcient is deﬁned by\\ns(A,n ) = max\\nF∈Fn\\nNA(F) (22.37)\\nwhere Fn consists of all ﬁnite sets of size n. Now let X1,...,X n ∼ P and let\\nPn(A)= 1\\nn\\n∑\\ni\\nI(Xi ∈ A)\\ndenote the empirical probability measure. The following remarkable the-\\norem bounds the distance between P and Pn.\\n22.18 Theorem (Vapnik and Chervonenkis (1971)). For any P, n and ϵ> 0,\\nP\\n{\\nsup\\nA∈A\\n|Pn(A) − P(A)| >ϵ\\n}\\n≤ 8s(A,n )e−nϵ2/32. (22.38)\\nThe proof, though very elegant, is long and we omit it. If H is a set of\\nclassiﬁers, deﬁne A to be the class of sets of the form {x : h(x)=1 }.W e\\nthen deﬁne s(H,n )= s(A,n ).\\n22.19 Theorem.\\nP\\n{\\nsup\\nh∈H\\n|ˆLn(h) − L(h)| >ϵ\\n}\\n≤ 8s(H,n )e−nϵ2/32.\\nA 1 − α conﬁdence interval for L(ˆh) is ˆLn(ˆh) ± ϵn where\\nϵ2\\nn = 32\\nn log\\n\\uf8f68s(H,n )\\nα\\n\\uf8f7\\n.\\nThese theorems are only useful if the shatter coeﬃcients do not grow too\\nquickly with n. This is where VC dimension enters.\\n22.20 Deﬁnition. The VC (Vapnik-Chervonenkis) dimension of a class of\\nsets A is deﬁned as follows. If s(A,n )=2 n for all n, set VC (A)= ∞.\\nOtherwise, deﬁne VC (A) to be the largest k for which s(A,n )=2 k.\\nThus, the VC-dimension is the size of the largest ﬁnite set F that can be\\nshattered by A meaning that A picks out each subset of F.I f H is a set of\\nclassiﬁers we deﬁne VC (H)= VC (A) where A is the class of sets of the form\\n{x : h(x)=1 } as h varies in H. The following theorem shows that if A has\\nﬁnite VC-dimension, then the shatter coeﬃcients grow as a polynomial in n.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 383, 'page_label': '384'}, page_content='368 22. Classiﬁcation\\n22.21 Theorem. If A has ﬁnite VC-dimension v, then\\ns(A,n ) ≤ nv +1 .\\n22.22 Example. Let A = {(−∞,a]; a ∈R }. The A shatters every 1-point\\nset {x} but it shatters no set of the form {x, y}. Therefore, VC (A)=1 . ■\\n22.23 Example. Let A be the set of closed intervals on the real line. Then\\nA shatters S = {x, y} but it cannot shatter sets with 3 points. Consider\\nS = {x, y, z} where x<y<z . One cannot ﬁnd an interval A such that\\nA ⋂ S = {x, z}. So, VC (A)=2 . ■\\n22.24 Example. Let A be all linear half-spaces on the plane. Any 3-point\\nset (not all on a line) can be shattered. No 4 point set can be shattered.\\nConsider, for example, 4 points forming a diamond. Let T be the left and\\nrightmost points. This can’t be picked out. Other conﬁgurations can also be\\nseen to be unshatterable. So VC (A) = 3. In general, halfspaces in R\\nd have\\nVC dimension d +1 . ■\\n22.25 Example. Let A be all rectangles on the plane with sides parallel to\\nthe axes. Any 4 point set can be shattered. Let S b ea5p o i n tset. There is\\none point that is not leftmost, rightmost, uppermost, or lowermost. LetT be\\nall points in S except this point. Then T can’t be picked out. So VC (A)=4 .\\n■\\n22.26 Theorem. Let x have dimension d and let H be th set of linear classi-\\nﬁers. The VC-dimension of H is d+1. Hence, a 1−α conﬁdence interval for\\nthe true error rate is ˆL(ˆh) ± ϵ where\\nϵ2\\nn = 32\\nn log\\n\\uf8f68(nd+1 +1 )\\nα\\n\\uf8f7\\n.\\n22.9 Support Vector Machines\\nIn this section we consider a class of linear classiﬁers called support vector\\nmachines. Throughout this section, we assume that Y is binary. It will be\\nconvenient to label the outcomes as −1 and +1 instead of 0 and 1. A linear\\nclassiﬁer can then be written as\\nh(x) = sign\\n\\uf8f6\\nH(x)\\n\\uf8f7'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 384, 'page_label': '385'}, page_content='22.9 Support Vector Machines 369\\nwhere x =( x1,...,x d),\\nH(x)= a0 +\\nd∑\\ni=1\\naixi\\nand\\nsign(z)=\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n−1i f z< 0\\n0i f z =0\\n1i f z> 0.\\nFirst, suppose that the data are linearly separable, that is, there exists\\na hyperplane that perfectly separates the two classes.\\n22.27 Lemma. The data can be separated by some hyperplane if and only if\\nthere exists a hyperplane H(x)= a0 + ∑ d\\ni=1 aixi such that\\nYiH(xi) ≥ 1,i =1 ,...,n . (22.39)\\nProof. Suppose the data can be separated by a hyperplane W(x)= b0 +∑ d\\ni=1 bixi. It follows that there exists some constantc such thatYi = 1 implies\\nW(Xi) ≥ c and Yi = −1 implies W(Xi) ≤− c. Therefore, YiW(Xi) ≥ c for\\nall i. Let H(x)= a0 + ∑ d\\ni=1 aixi where aj = bj/c. Then YiH(Xi) ≥ 1 for all\\ni. The reverse direction is straightforward. ■\\nIn the separable case, there will be many separating hyperplanes. How\\nshould we choose one? Intuitively, it seems reasonable to choose the hyper-\\nplane “furthest” from the data in the sense that it separates the +1s and -1s\\nand maximizes the distance to the closest point. This hyperplane is called the\\nmaximum margin hyperplane. The margin is the distance to from the\\nhyperplane to the nearest point. Points on the boundary of the margin are\\ncalled support vectors. See Figure 22.8.\\n22.28 Theorem. The hyperplane ˆH(x)= ˆa\\n0 + ∑ d\\ni=1 ˆaixi that separates the\\ndata and maximizes the margin is given by minimizing (1/2) ∑ d\\nj=1 a2\\nj subject\\nto (22.39).\\nIt turns out that this problem can be recast as a quadratic programming\\nproblem. Let ⟨Xi,X k⟩ = XT\\ni Xk denote the inner product of Xi and Xk.\\n22.29 Theorem. Let ˆH(x)= ˆa0 +∑ d\\ni=1 ˆaixi denote the optimal (largest mar-\\ngin) hyperplane. Then, for j =1 ,...,d ,\\nˆaj =\\nn∑\\ni=1\\nˆαiYiXj(i)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 385, 'page_label': '386'}, page_content='370 22. Classiﬁcation\\n/Bullet/Circle\\n/Bullet/Circle\\n/Bullet/Circle\\n/Bullet/Circle\\n/Bullet/Circle\\n/Bullet/Circle\\n/Bullet/Circle\\n/Bullet/Circle\\n/Bullet/Circle\\n/Bullet/Circle\\n/Bullet/Circle\\n/Bullet/Circle\\n/Bullet/Circle\\n/Bullet/Circle\\nH(x)= a0 + aT x =0\\nFIGURE 22.8. The hyperplane H(x) has the largest margin of all hyperplanes that\\nseparate the two classes.\\nwhere Xj(i) is the value of the covariate Xj for the ith data point, and ˆα =\\n(ˆα1,..., ˆαn) is the vector that maximizes\\nn∑\\ni=1\\nαi − 1\\n2\\nn∑\\ni=1\\nn∑\\nk=1\\nαiαkYiYk⟨Xi,X k⟩ (22.40)\\nsubject to\\nαi ≥ 0\\nand\\n0=\\n∑\\ni\\nαiYi.\\nThe points Xi for which ˆα ̸=0 are called support vectors. ˆa0 can be found\\nby solving\\nˆαi\\n\\uf8f6\\nYi(XT\\ni ˆa + ˆβ0\\n\\uf8f7\\n=0\\nfor any support point Xi. ˆH may be written as\\nˆH(x)= ˆα0 +\\nn∑\\ni=1\\nˆαiYi⟨x, Xi⟩.\\nThere are many software packages that will solve this problem quickly. If\\nthere is no perfect linear classiﬁer, then one allows overlap between the groups'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 386, 'page_label': '387'}, page_content='22.10 Kernelization 371\\nby replacing the condition (22.39) with\\nYiH(xi) ≥ 1 − ξi,ξ i ≥ 0,i =1 ,...,n . (22.41)\\nThe variables ξ1,...,ξ n are called slack variables.\\nWe now maximize (22.40) subject to\\n0 ≤ ξi ≤ c, i =1 ,...,n\\nand n∑\\ni=1\\nαiYi =0 .\\nThe constant c is a tuning parameter that controls the amount of overlap.\\n22.10 Kernelization\\nThere is a trick calledkernelization for improving a computationally simple\\nclassiﬁer h. The idea is to map the covariateX — which takes values inX —\\ninto a higher dimensional space Z and apply the classiﬁer in the bigger space\\nZ. This can yield a more ﬂexible classiﬁer while retaining computationally\\nsimplicity.\\nThe standard example of this idea is illustrated in Figure 22.9. The covariate\\nx =( x1,x2). The Yis can be separated into two groups using an ellipse. Deﬁne\\na mapping φ by\\nz =( z1,z 2,z 3)= φ(x)=( x2\\n1,\\n√\\n2x1x2,x2\\n2).\\nThus, φ maps X = R2 into Z = R3. In the higher-dimensional space Z, the\\nYi’s are separable by a linear decision boundary. In other words,\\na linear classiﬁer in a higher-dimensional space corresponds to a non-\\nlinear classiﬁer in the original space.\\nThe point is that to get a richer set of classiﬁers we do not need to give up the\\nconvenience of linear classiﬁers. We simply map the covariates to a higher-\\ndimensional space. This is akin to making linear regression more ﬂexible by\\nusing polynomials.\\nThere is a potential drawback. If we signiﬁcantly expand the dimension\\nof the problem, we might increase the computational burden. For example,\\nif x has dimension d = 256 and we wanted to use all fourth-order terms,\\nthen z = φ(x) has dimension 183,181,376. We are spared this computational'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 387, 'page_label': '388'}, page_content='372 22. Classiﬁcation\\nx1\\nx2\\n+\\n+\\n+\\n+\\n+\\n+\\n+ +\\n+\\n+\\n++\\n+\\n+ +\\nz1\\nz2\\nz3\\n+\\n+\\n+\\n+\\n+\\n+\\n+\\n+\\nφ\\nFIGURE 22.9. Kernelization. Mapping the covariates into a higher-dimensional\\nspace can make a complicated decision boundary into a simpler decision bound-\\nary.\\nnightmare by the following two facts. First, many classiﬁers do not require\\nthat we know the values of the individual points but, rather, just the inner\\nproduct between pairs of points. Second, notice in our example that the inner\\nproduct in Z can be written\\n⟨z, ˜z⟩ = ⟨φ(x),φ(˜x)⟩\\n= x\\n2\\n1˜x2\\n1 +2 x1˜x1x2˜x2 + x2\\n2˜x2\\n2\\n=( ⟨x, ˜x⟩)2 ≡ K(x, ˜x).\\nThus, we can compute ⟨z, ˜z⟩ without ever computing Zi = φ(Xi).\\nTo summarize, kernelization involves ﬁnding a mapping φ : X→Z and a\\nclassiﬁer such that:\\n1. Z has higher dimension than X and so leads a richer set of classiﬁers.\\n2. The classiﬁer only requires computing inner products.\\n3. There is a function K, called a kernel, such that⟨φ(x),φ(˜x)⟩ = K(x, ˜x).\\n4. Everywhere the term ⟨x, ˜x⟩ appears in the algorithm, replace it with\\nK(x, ˜x).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 388, 'page_label': '389'}, page_content='22.10 Kernelization 373\\nIn fact, we never need to construct the mapping φ at all. We only need\\nto specify a kernel K(x, ˜x) that corresponds to ⟨φ(x),φ(˜x)⟩ for some φ. This\\nraises an interesting question: given a function of two variablesK(x, y), does\\nthere exist a function φ(x) such that K(x, y)= ⟨φ(x),φ(y)⟩? The answer is\\nprovided by Mercer’s theorem which says, roughly, that if K is positive\\ndeﬁnite — meaning that\\n∫∫\\nK(x, y)f(x)f(y)dxdy ≥ 0\\nfor square integrable functions f — then such a φ exists. Examples of com-\\nmonly used kernels are:\\npolynomial K(x, ˜x)=\\n\\uf8f6\\n⟨x, ˜x⟩ + a\\n\\uf8f7r\\nsigmoid K(x, ˜x) = tanh( a⟨x, ˜x⟩ + b)\\nGaussian K(x, ˜x) = exp\\n\\uf8f6\\n−||x − ˜x||2/(2σ2)\\n\\uf8f7\\nLet us now see how we can use this trick in LDA and in support vector\\nmachines.\\nRecall that the Fisher linear discriminant method replaces X with U =\\nwT X where w is chosen to maximize the Rayleigh coeﬃcient\\nJ(w)= wT SBw\\nwT SW w,\\nSB =( X0 − X1)(X0 − X1)T\\nand\\nSW =\\n\\uf8f6 (n0 − 1)S0\\n(n0 − 1 )+(n1 − 1)\\n\\uf8f7\\n+\\n\\uf8f6 (n1 − 1)S1\\n(n0 − 1 )+(n1 − 1)\\n\\uf8f7\\n.\\nIn the kernelized version, we replace Xi with Zi = φ(Xi) and we ﬁnd w to\\nmaximize\\nJ(w)= wT ˜SBw\\nwT ˜SW w\\n(22.42)\\nwhere\\n˜SB =( Z0 − Z1)(Z0 − Z1)T\\nand\\nSW =\\n\\uf8f6\\n(n0 − 1)˜S0\\n(n0 − 1 )+(n1 − 1)\\n\\uf8f7\\n+\\n\\uf8f6\\n(n1 − 1)˜S1\\n(n0 − 1 )+(n1 − 1)\\n\\uf8f7\\n.\\nHere, ˜Sj is the sample of covariance of the Zi’s for which Y = j. However, to\\ntake advantage of kernelization, we need to re-express this in terms of inner\\nproducts and then replace the inner products with kernels.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 389, 'page_label': '390'}, page_content='374 22. Classiﬁcation\\nIt can be shown that the maximizing vector w is a linear combination of\\nthe Zi’s. Hence we can write\\nw =\\nn∑\\ni=1\\nαiZi.\\nAlso,\\nZj = 1\\nnj\\nn∑\\ni=1\\nφ(Xi)I(Yi = j).\\nTherefore,\\nwT Zj =\\n\\uf8f6 n∑\\ni=1\\nαiZi\\n\\uf8f7T \\uf8f6 1\\nnj\\nn∑\\ni=1\\nφ(Xi)I(Yi = j)\\n\\uf8f7\\n= 1\\nnj\\nn∑\\ni=1\\nn∑\\ns=1\\nαiI(Ys = j)ZT\\ni φ(Xs)\\n= 1\\nnj\\nn∑\\ni=1\\nαi\\nn∑\\ns=1\\nI(Ys = j)φ(Xi)T φ(Xs)\\n= 1\\nnj\\nn∑\\ni=1\\nαi\\nn∑\\ns=1\\nI(Ys = j)K(Xi,X s)\\n= αT Mj\\nwhere Mj is a vector whose ith component is\\nMj(i)= 1\\nnj\\nn∑\\ns=1\\nK(Xi,X s)I(Yi = j).\\nIt follows that\\nwT ˜SBw = αT Mα\\nwhere M =( M0 − M1)(M0 − M1)T . By similar calculations, we can write\\nwT ˜SW w = αT Nα\\nwhere\\nN = K0\\n\\uf8f6\\nI − 1\\nn0\\n1\\n\\uf8f7\\nKT\\n0 + K1\\n\\uf8f6\\nI − 1\\nn1\\n1\\n\\uf8f7\\nKT\\n1 ,\\nI is the identity matrix, 1 is a matrix of all one’s, and Kj is the n × nj\\nmatrix with entries (Kj)rs = K(xr,xs) with xs varying over the observations\\nin group j. Hence, we now ﬁnd α to maximize\\nJ(α)= αT Mα\\nαT Nα .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 390, 'page_label': '391'}, page_content='22.11 Other Classiﬁers 375\\nAll the quantities are expressed in terms of the kernel. Formally, the solution\\nis α = N−1(M0 − M1). However, N might be non-invertible. In this case one\\nreplaces N by N + bI, for some constant b. Finally, the projection onto the\\nnew subspace can be written as\\nU = wT φ(x)=\\nn∑\\ni=1\\nαiK(xi,x).\\nThe support vector machine can similarly be kernelized. We simply replace\\n⟨Xi,X j⟩ with K(Xi,X j). For example, instead of maximizing (22.40), we now\\nmaximize\\nn∑\\ni=1\\nαi − 1\\n2\\nn∑\\ni=1\\nn∑\\nk=1\\nαiαkYiYkK(Xi,X j). (22.43)\\nThe hyperplane can be written as ˆH(x)= ˆa0 + ∑ n\\ni=1 ˆαiYiK(X,X i).\\n22.11 Other Classiﬁers\\nThere are many other classiﬁers and space precludes a full discussion of all of\\nthem. Let us brieﬂy mention a few.\\nThe k-nearest-neighbors classiﬁer is very simple. Given a point x, ﬁnd\\nthe k data points closest to x. Classify x using the majority vote of these k\\nneighbors. Ties can be broken randomly. The parameter k can be chosen by\\ncross-validation.\\nBagging is a method for reducing the variability of a classiﬁer. It is most\\nhelpful for highly nonlinear classiﬁers such as trees. We draw B bootstrap\\nsamples from the data. The bth bootstrap sample yields a classiﬁer hb. The\\nﬁnal classiﬁer is\\nˆh(x)=\\n{\\n1i f 1\\nB\\n∑ B\\nb=1 hb(x) ≥ 1\\n2\\n0 otherwise .\\nBoosting is a method for starting with a simple classiﬁer and gradually\\nimproving it by reﬁtting the data giving higher weight to misclassiﬁed samples.\\nSuppose that H is a collection of classiﬁers, for example, trees with only\\none split. Assume that Y\\ni ∈{ −1,1} and that each h is such that h(x) ∈\\n{−1,1}. We usually give equal weight to all data points in the methods we\\nhave discussed. But one can incorporate unequal weights quite easily in most\\nalgorithms. For example, in constructing a tree, we could replace the impurity\\nmeasure with a weighted impurity measure. The original version of boosting,\\ncalled AdaBoost, is as follows.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 391, 'page_label': '392'}, page_content='376 22. Classiﬁcation\\n1. Set the weights wi =1 /n, i =1 ,...,n .\\n2. For j =1 ,...,J , do the following steps:\\n(a) Constructing a classiﬁer hj from the data using the weightsw1,...,w n.\\n(b) Compute the weighted error estimate:\\nˆLj =\\n∑ n\\ni=1 wiI(Yi ̸= hj(Xi))∑ n\\ni=1 wi\\n.\\n(c) Let αj = log((1 − ˆLj)/ˆLj).\\n(d) Update the weights:\\nwi ←−wieαjI(Yi̸=hj(Xi))\\n3. The ﬁnal classiﬁer is\\nˆh(x) = sign\\n\\uf8f6 J∑\\nj=1\\nαjhj(x)\\n\\uf8f7\\n.\\nThere is now an enormous literature trying to explain and improve on\\nboosting. Whereas bagging is a variance reduction technique, boosting can\\nbe thought of as a bias reduction technique. We starting with a simple —\\nand hence highly-biased — classiﬁer, and we gradually reduce the bias. The\\ndisadvantage of boosting is that the ﬁnal classiﬁer is quite complicated.\\nNeural Networks are regression models of the form\\n3\\nY = β0 +\\np∑\\nj=1\\nβjσ(α0 + αT X)\\nwhere σ is a smooth function, often taken to be σ(v)= ev/(1 + ev). This\\nis really nothing more than a nonlinear regression model. Neural nets were\\nfashionable for some time but they pose great computational diﬃculties. In\\nparticular, one often encounters multiple minima when trying to ﬁnd the least\\nsquares estimates of the parameters. Also, the number of termsp is essentially\\na smoothing parameter and there is the usual problem of trying to choose p\\nto ﬁnd a good balance between bias and variance.\\n3This is the simplest version of a neural net. There are more complex versions of the model.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 392, 'page_label': '393'}, page_content='22.12 Bibliographic Remarks 377\\n22.12 Bibliographic Remarks\\nThe literature on classiﬁcation is vast and is growing quickly. An excellent\\nreference is Hastie et al. (2001). For more on the theory, see Devroye et al.\\n(1996) and Vapnik (1998). Two recent books on kernels are Scholkopf and\\nSmola (2002) and Herbich (2002).\\n22.13 Exercises\\n1. Prove Theorem 22.5.\\n2. Prove Theorem 22.7.\\n3. Download the spam data from:\\nhttp://www-stat.stanford.edu/∼tibs/ElemStatLearn/index.html\\nThe data ﬁle can also be found on the course web page. The data con-\\ntain 57 covariates relating to email messages. Each email message was\\nclassiﬁed as spam (Y=1) or not spam (Y=0). The outcome Y is the last\\ncolumn in the ﬁle. The goal is to predict whether an email is spam or\\nnot.\\n(a) Construct classiﬁcation rules using (i) LDA, (ii) QDA, (iii) logistic\\nregression, and (iv) a classiﬁcation tree. For each, report the observed\\nmisclassiﬁcation error rate and construct a 2-by-2 table of the form\\nˆh(x)=0 ˆh(x)=1\\nY =0 ?? ??\\nY =1 ?? ??\\n(b) Use 5-fold cross-validation to estimate the prediction accuracy of\\nLDA and logistic regression.\\n(c) Sometimes it helps to reduce the number of covariates. One strategy\\nis to compare Xi for the spam and email group. For each of the 57\\ncovariates, test whether the mean of the covariate is the same or diﬀerent\\nbetween the two groups. Keep the 10 covariates with the smallest p-\\nvalues. Try LDA and logistic regression using only these 10 variables.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 393, 'page_label': '394'}, page_content='378 22. Classiﬁcation\\n4. Let A be the set of two-dimensional spheres. That is, A ∈A if A =\\n{(x, y): ( x−a)2+(y−b)2 ≤ c2} for some a, b, c. Find the VC-dimension\\nof A.\\n5. Classify the spam data using support vector machines. Free software for\\nthe support vector machine is at http://svmlight.joachims.org/\\n6. Use VC theory to get a conﬁdence interval on the true error rate of the\\nLDA classiﬁer for the iris data (from the book web site).\\n7. Suppose that Xi ∈ R and that Yi = 1 whenever |Xi|≤ 1 and Yi =0\\nwhenever |Xi| > 1. Show that no linear classiﬁer can perfectly classify\\nthese data. Show that the kernelized dataZi =( Xi,X 2\\ni ) can be linearly\\nseparated.\\n8. Repeat question 5 using the kernel K(x, ˜x)=( 1+ xT ˜x)p. Choose p by\\ncross-validation.\\n9. Apply the k nearest neighbors classiﬁer to the “iris data.” Choose k by\\ncross-validation.\\n10. (Curse of Dimensionality.) Suppose that X has a uniform distribution\\non the d-dimensional cube [−1/2,1/2]d. Let R be the distance from the\\norigin to the closest neighbor. Show that the median of R is\\n\\uf8eb\\n\\uf8ed\\n\\uf8f6\\n1 −\\n\\uf8f61\\n2\\n\\uf8f71/n\\uf8f7\\nvd(1)\\n\\uf8f6\\n\\uf8f8\\n1/d\\nwhere\\nvd(r)= rd πd/2\\nΓ((d/2 )+1 )\\nis the volume of a sphere of radius r. For what dimension d does the\\nmedian of R exceed the edge of the cube when n = 100, n =1 ,000,\\nn =1 0,000? (Hastie et al. (2001), p. 22–27.)\\n11. Fit a tree to the data in question 3. Now apply bagging and report your\\nresults.\\n12. Fit a tree that uses only one split on one variable to the data in question\\n3. Now apply boosting.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 394, 'page_label': '395'}, page_content='22.13 Exercises 379\\n13. Let r(x)= P(Y =1 |X = x) and letˆr(x) be an estimate ofr(x). Consider\\nthe classiﬁer\\nh(x)=\\n{\\n1i f ˆr(x) ≥ 1/2\\n0 otherwise .\\nAssume that ˆr(x) ≈ N(r(x),σ 2(x)) for some functions r(x) and σ2(x).\\nShow that, for ﬁxed x,\\nP(Y ̸= h(x)) ≈ P(Y ̸= h∗(x))\\n+\\n⏐⏐\\n⏐\\n⏐\\n⏐2r(x) − 1\\n⏐⏐\\n⏐\\n⏐\\n⏐×\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8f01 − Φ\\n\\uf8eb\\n\\uf8ec\\uf8ec\\uf8ed\\nsign\\n\\uf8f6\\nr(x) − (1/2)\\n\\uf8f7\\n(\\nr(x) − (1/2))\\nσ(x)\\n\\uf8f6\\n\\uf8f7\\uf8f7\\uf8f8\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fb\\nwhere Φ is the standard Normal cdf and h∗ is the Bayes rule. Regard\\nsign\\n\\uf8f6\\n(r(x) − (1/2))(r(x) − (1/2))\\n\\uf8f7\\nas a type of bias term. Explain the\\nimplications for the bias–variance tradeoﬀ in classiﬁcation (Friedman\\n(1997)).\\nHint: ﬁrst show that\\nP(Y ̸= h(x)) = |2r(x) − 1|P(h(x) ̸= h∗(x)) +P(Y ̸= h∗(x)).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 395, 'page_label': '396'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 396, 'page_label': '397'}, page_content='23\\nProbability Redux: Stochastic Processes\\n23.1 Introduction\\nMost of this book has focused on iid sequences of random variables. Now we\\nconsider sequences of dependent random variables. For example, daily tem-\\nperatures will form a sequence of time-ordered random variables and clearly\\nthe temperature on one day is not independent of the temperature on the\\nprevious day.\\nA stochastic process {X\\nt : t ∈ T} is a collection of random variables.\\nWe shall sometimes writeX(t) instead of Xt. The variables Xt take values in\\nsome set X called the state space. The set T is called the index set and\\nfor our purposes can be thought of as time. The index set can be discrete\\nT = {0,1,2,... } or continuous T =[ 0,∞) depending on the application.\\n23.1 Example (iid observations). A sequence of iid random variables can be\\nwritten as {X\\nt : t ∈ T} where T = {1,2,3,..., }. Thus, a sequence of iid\\nrandom variables is an example of a stochastic process. ■\\n23.2 Example (The Weather). Let X = {sunny,cloudy}. A typical sequence\\n(depending on where you live) might be\\nsunny,sunny,cloudy,sunny,cloudy,cloudy,···\\nThis process has a discrete state space and a discrete index set. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 397, 'page_label': '398'}, page_content='382 23. Probability Redux: Stochastic Processes\\ntime\\nprice\\nFIGURE 23.1. Stock price over ten week period.\\n23.3 Example (Stock Prices). Figure 23.1 shows the price of a ﬁctitious stock\\nover time. The price is monitored continuously so the index setT is continuous.\\nPrice is discrete but for all practical purposes we can treat it as a continuous\\nvariable.\\n■\\n23.4 Example (Empirical Distribution Function). Let X1,...,X n ∼ F where\\nF is some cdf on [0,1]. Let\\nˆFn(t)= 1\\nn\\nn∑\\ni=1\\nI(Xi ≤ t)\\nbe the empirical cdf. For any ﬁxed value t, ˆFn(t) is a random variable. But\\nthe whole empirical cdf\\n{\\nˆFn(t): t ∈ [0,1]\\n}\\nis a stochastic process with a continuous state space and a continuous index\\nset. ■\\nWe end this section by recalling a basic fact. If X1,...,X n are random\\nvariables, then we can write the joint density as\\nf(x1,...,x n)= f(x1)f(x2|x1) ··· f(xn|x1,...,x n−1)\\n=\\nn∏\\ni=1\\nf(xi|pasti) (23.1)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 398, 'page_label': '399'}, page_content='23.2 Markov Chains 383\\nwhere pasti =( X1,...,X i−1).\\n23.2 Markov Chains\\nA Markov chain is a stochastic process for which the distribution of Xt de-\\npends only on Xt−1. In this section we assume that the state space is dis-\\ncrete, either X = {1,...,N } or X = {1,2,..., } and that the index set is\\nT = {0,1,2,... }. Typically, most authors write Xn instead of Xt when dis-\\ncussing Markov chains and I will do so as well.\\n23.5 Deﬁnition. The process {Xn : n ∈ T} is a Markov chain if\\nP(Xn = x | X0,...,X n−1)= P(Xn = x | Xn−1) (23.2)\\nfor all n and for all x ∈X .\\nFor a Markov chain, equation (23.1) simpliﬁes to\\nf(x1,...,x n)= f(x1)f(x2|x1)f(x3|x2) ··· f(xn|xn−1).\\nA Markov chain can be represented by the following DAG:\\nX0 X1 X2 ··· Xn ···\\nEach variable has a single parent, namely, the previous observation.\\nThe theory of Markov chains is a very rich and complex. We have to get\\nthrough many deﬁnitions before we can do anything interesting. Our goal is\\nto answer the following questions:\\n1. When does a Markov chain “settle down” into some sort of equilibrium?\\n2. How do we estimate the parameters of a Markov chain?\\n3. How can we construct Markov chains that converge to a given equilib-\\nrium distribution and why would we want to do that?\\nWe will answer questions 1 and 2 in this chapter. We will answer question\\n3 in the next chapter. To understand question 1, look at the two chains in\\nFigure 23.2. The ﬁrst chain oscillates all over the place and will continue to\\ndo so forever. The second chain eventually settles into an equilibrium. If we\\nconstructed a histogram of the ﬁrst process, it would keep changing as we got'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 399, 'page_label': '400'}, page_content='384 23. Probability Redux: Stochastic Processes\\nmore and more observations. But a histogram from the second chain would\\neventually converge to some ﬁxed distribution.\\ntime time\\nFIGURE 23.2. Two Markov chains. The ﬁrst chain does not settle down into an\\nequilibrium. The second does.\\nTransition Probabilities.The key quantities of a Markov chain are the\\nprobabilities of jumping from one state into another state. A Markov chain is\\nhomogeneous if P(X\\nn+1 = j|Xn = i) does not change with time. Thus, for\\na homogeneous Markov chain, P(Xn+1 = j|Xn = i)= P(X1 = j|X0 = i). We\\nshall only deal with homogeneous Markov chains.\\n23.6 Deﬁnition. We call\\npij ≡ P(Xn+1 = j|Xn = i) (23.3)\\nthe transition probabilities. The matrix P whose (i, j) element is pij\\nis called the transition matrix.\\nWe will only consider homogeneous chains. Notice that P has two proper-\\nties: (i) pij ≥ 0 and (ii) ∑\\ni pij = 1. Each row can be regarded as a probability\\nmass function.\\n23.7 Example (Random Walk With Absorbing Barriers). Let X = {1,...,N }.\\nSuppose you are standing at one of these points. Flip a coin withP(Heads) = p\\nand P(Tails) = q =1 − p. If it is heads, take one step to the right. If it is\\ntails, take one step to the left. If you hit one of the endpoints, stay there. The'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 400, 'page_label': '401'}, page_content='23.2 Markov Chains 385\\ntransition matrix is\\nP =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\uf8f0\\n1000 ··· 00\\nq 0 p 0 ··· 00\\n0 q 0 p ··· 00\\n··· ··· ··· ··· ··· ··· ···\\n0000 q 0 p\\n0000001\\n\\uf8f9\\n\\uf8fa\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\uf8fb\\n.\\n■\\n23.8 Example. Suppose the state space is X = {sunny,cloudy}. Then X1,\\nX2, ... represents the weather for a sequence of days. The weather today\\nclearly depends on yesterday’s weather. It might also depend on the weather\\ntwo days ago but as a ﬁrst approximation we might assume that the depen-\\ndence is only one day back. In that case the weather is a Markov chain and a\\ntypical transition matrix might be\\nSunny Cloudy\\nSunny 0.4 0.6\\nCloudy 0.8 0.2\\nFor example, if it is sunny today, there is a 60 per cent chance it will be cloudy\\ntomorrow.\\n■\\nLet\\npij(n)= P(Xm+n = j|Xm = i) (23.4)\\nbe the probability of of going from state i to state j inn steps. Let Pn be the\\nmatrix whose (i, j) element is pij(n). These are called the n-step transition\\nprobabilities.\\n23.9 Theorem (The Chapman-Kolmogorov equations). The n-step probabilities\\nsatisfy\\npij(m + n)=\\n∑\\nk\\npik(m)pkj(n). (23.5)\\nProof. Recall that, in general,\\nP(X = x, Y = y)= P(X = x)P(Y = y|X = x).\\nThis fact is true in the more general form\\nP(X = x, Y = y|Z = z)= P(X = x|Z = z)P(Y = y|X = x, Z = z).\\nAlso, recall the law of total probability:\\nP(X = x)=\\n∑\\ny\\nP(X = x, Y = y).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 401, 'page_label': '402'}, page_content='386 23. Probability Redux: Stochastic Processes\\nUsing these facts and the Markov property we have\\npij(m + n)= P(Xm+n = j|X0 = i)\\n=\\n∑\\nk\\nP(Xm+n = j, Xm = k|X0 = i)\\n=\\n∑\\nk\\nP(Xm+n = j|Xm = k,X 0 = i)P(Xm = k|X0 = i)\\n=\\n∑\\nk\\nP(Xm+n = j|Xm = k)P(Xm = k|X0 = i)\\n=\\n∑\\nk\\npik(m)pkj(n). ■\\nLook closely at equation (23.5). This is nothing more than the equation for\\nmatrix multiplication. Hence we have shown that\\nPm+n = PmPn. (23.6)\\nBy deﬁnition, P1 = P. Using the above theorem, P2 = P1+1 = P1P1 =\\nPP = P2. Continuing this way, we see that\\nPn = Pn ≡ P × P ×···× P\\ued19 \\ued18\\ued17 \\ued1a\\nmultiply the matrix n times\\n. (23.7)\\nLet µn =( µn(1),...,µ n(N)) be a row vector where\\nµn(i)= P(Xn = i) (23.8)\\nis the marginal probability that the chain is in statei at time n. In particular,\\nµ0 is called the initial distribution. To simulate a Markov chain, all you\\nneed to know is µ0 and P. The simulation would look like this:\\nStep 1: Draw X0 ∼ µ0. Thus, P(X0 = i)= µ0(i).\\nStep 2: Denote the outcome of step 1 by i. Draw X1 ∼ P. In other words,\\nP(X1 = j|X0 = i)= pij.\\nStep 3: Suppose the outcome of step 2 is j. Draw X2 ∼ P. In other words,\\nP(X2 = k|X1 = j)= pjk.\\nAnd so on.\\nIt might be diﬃcult to understand the meaning of µn. Imagine simulating\\nthe chain many times. Collect all the outcomes at timen from all the chains.\\nThis histogram would look approximately like µn. A consequence of theorem\\n23.9 is the following:'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 402, 'page_label': '403'}, page_content='23.2 Markov Chains 387\\n23.10 Lemma. The marginal probabilities are given by\\nµn = µ0Pn.\\nProof.\\nµn(j)= P(Xn = j)\\n=\\n∑\\ni\\nP(Xn = j|X0 = i)P(X0 = i)\\n=\\n∑\\ni\\nµ0(i)pij(n)= µ0Pn. ■\\nSummary of Terminology\\n1. Transition matrix: P(i, j)= P(Xn+1 = j|Xn = i)= pij.\\n2. n-step matrix: Pn(i, j)= P(Xn+m = j|Xm = i).\\n3. Pn = Pn.\\n4. Marginal: µn(i)= P(Xn = i).\\n5. µn = µ0Pn.\\nStates. The states of a Markov chain can be classiﬁed according to various\\nproperties.\\n23.11 Deﬁnition. We say that i reaches j (or j is accessible from i)i f\\npij(n) > 0 for some n, and we write i → j.I f i → j and j → i then we\\nwrite i ↔ j and we say that i and j communicate.\\n23.12 Theorem. The communication relation satisﬁes the following proper-\\nties:\\n1. i ↔ i.\\n2. If i ↔ j then j ↔ i.\\n3. If i ↔ j and j ↔ k then i ↔ k.\\n4. The set of states X can be written as a disjoint union of classes X =\\nX1\\n⋃ X2\\n⋃ ··· where two states i and j communicate with each other if\\nand only if they are in the same class.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 403, 'page_label': '404'}, page_content='388 23. Probability Redux: Stochastic Processes\\nIf all states communicate with each other, then the chain is called irre-\\nducible. A set of states is closed if, once you enter that set of states you\\nnever leave. A closed set consisting of a single state is called an absorbing\\nstate.\\n23.13 Example. Let X = {1,2,3,4} and\\nP =\\n\\uf8eb\\n\\uf8ec\\uf8ec\\n\\uf8ec\\n\\uf8ec\\uf8ed\\n1\\n3\\n2\\n3 00\\n2\\n3\\n1\\n3 00\\n1\\n4\\n1\\n4\\n1\\n4\\n1\\n4\\n0001\\n\\uf8f6\\n\\uf8f7\\uf8f7\\n\\uf8f7\\n\\uf8f7\\uf8f8\\nThe classes are {1,2},{3} and {4}. State 4 is an absorbing state.\\n■\\nSuppose we start a chain in state i. Will the chain ever return to state i?\\nIf so, that state is called persistent or recurrent.\\n23.14 Deﬁnition. State i is recurrent or persistent if\\nP(Xn = i for some n ≥ 1 | X0 = i)=1 .\\nOtherwise, state i is transient.\\n23.15 Theorem. A state i is recurrent if and only if\\n∑\\nn\\npii(n)= ∞. (23.9)\\nA state i is transient if and only if\\n∑\\nn\\npii(n) < ∞. (23.10)\\nProof. Deﬁne\\nIn =\\n{ 1i f Xn = i\\n0i f Xn ̸= i.\\nThe number of times that the chain is in state i is Y = ∑ ∞\\nn=0 In. The mean\\nof Y , given that the chain starts in state i,i s\\nE(Y |X0 = i)=\\n∞∑\\nn=0\\nE(In|X0 = i)=\\n∞∑\\nn=0\\nP(Xn = i|X0 = i)=\\n∞∑\\nn=0\\npii(n).\\nDeﬁne ai = P(Xn = i for some n ≥ 1 | X0 = i). If i is recurrent, ai = 1. Thus,\\nthe chain will eventually return toi. Once it does return to i, we argue again'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 404, 'page_label': '405'}, page_content='23.2 Markov Chains 389\\nthat since ai = 1, the chain will return to state i again. By repeating this\\nargument, we conclude that E(Y |X0 = i)= ∞.I f i is transient, then ai < 1.\\nWhen the chain is in statei, there is a probability 1−ai > 0 that it will never\\nreturn to state i. Thus, the probability that the chain is in state i exactly n\\ntimes is an−1\\ni (1 − ai). This is a geometric distribution which has ﬁnite mean.\\n■\\n23.16 Theorem. Facts about recurrence.\\n1. If state i is recurrent and i ↔ j, then j is recurrent.\\n2. If state i is transient and i ↔ j, then j is transient.\\n3. A ﬁnite Markov chain must have at least one recurrent state.\\n4. The states of a ﬁnite, irreducible Markov chain are all recurrent.\\n23.17 Theorem (Decomposition Theorem). The state space X can be written\\nas the disjoint union\\nX = X\\nT\\n⋃\\nX1\\n⋃\\nX2 ···\\nwhere XT are the transient states and each Xi is a closed, irreducible set of\\nrecurrent states.\\n23.18 Example (Random Walk). Let X = {..., −2,−1,0,1,2,..., } and sup-\\npose that pi,i+1 = p, pi,i−1 = q =1 − p. All states communicate, hence either\\nall the states are recurrent or all are transient. To see which, suppose we start\\nat X\\n0 = 0. Note that\\np00(2n)=\\n\\uf8f62n\\nn\\n\\uf8f7\\npnqn (23.11)\\nsince the only way to get back to 0 is to haven heads (steps to the right) and\\nn tails (steps to the left). We can approximate this expression using Stirling’s\\nformula which says that\\nn! ∼ nn√ne−n√\\n2π.\\nInserting this approximation into (23.11) shows that\\np00(2n) ∼ (4pq)n\\n√nπ .\\nIt is easy to check that ∑\\nn p00(n) < ∞ if and only if ∑\\nn p00(2n) < ∞.\\nMoreover, ∑\\nn p00(2n)= ∞ if and only if p = q =1 /2. By Theorem (23.15),\\nthe chain is recurrent if p =1 /2 otherwise it is transient. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 405, 'page_label': '406'}, page_content='390 23. Probability Redux: Stochastic Processes\\nConvergence of Markov Chains.To discuss the convergence of chains,\\nwe need a few more deﬁnitions. Suppose thatX0 = i. Deﬁne the recurrence\\ntime\\nTij = min{n> 0: Xn = j} (23.12)\\nassuming Xn ever returns to state i, otherwise deﬁne Tij = ∞. The mean\\nrecurrence time of a recurrent state i is\\nmi = E(Tii)=\\n∑\\nn\\nnfii(n) (23.13)\\nwhere\\nfij(n)= P(X1 ̸= j, X2 ̸= j ,...,X n−1 ̸= j, Xn = j|X0 = i).\\nA recurrent state is null if mi = ∞ otherwise it is called non-null or posi-\\ntive.\\n23.19 Lemma. If a state is null and recurrent, then pn\\nii → 0.\\n23.20 Lemma. In a ﬁnite state Markov chain, all recurrent states are positive.\\nConsider a three-state chain with transition matrix\\n\\uf8ee\\n\\uf8f0\\n010\\n001\\n100\\n\\uf8f9\\n\\uf8fb.\\nSuppose we start the chain in state 1. Then we will be in state 3 at times 3, 6,\\n9 ,.... This is an example of a periodic chain. Formally, theperiod of state i\\nis d if p\\nii(n) = 0 whenever n is not divisible by d and d is the largest integer\\nwith this property. Thus, d = gcd{n : pii(n) > 0} where gcd means “greater\\ncommon divisor.” State i is periodic if d(i) > 1 and aperiodic if d(i)=1 .\\nA state with period 1 is called aperiodic.\\n23.21 Lemma. If state i has period d and i ↔ j then j has period d.\\n23.22 Deﬁnition. A state is ergodic if it is recurrent, non-null and\\naperiodic. A chain is ergodic if all its states are ergodic.\\nLet π =( πi : i ∈X ) be a vector of non-negative numbers that sum to one.\\nThus π can be thought of as a probability mass function.\\n23.23 Deﬁnition. We say that π is a stationary (or invariant)\\ndistribution if π = πP.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 406, 'page_label': '407'}, page_content='23.2 Markov Chains 391\\nHere is the intuition. Draw X0 from distribution π and suppose that π is a\\nstationary distribution. Now draw X1 according to the transition probability\\nof the chain. The distribution of X1 is then µ1 = µ0P = πP = π. The\\ndistribution of X2 is πP2 =( πP)P = πP = π. Continuing this way, we see\\nthat the distribution of Xn is πPn = π. In other words:\\nIf at any time the chain has distribution π, then it will continue to\\nhave distribution π forever.\\n23.24 Deﬁnition. We say that a chain has limiting distribution if\\nPn →\\n\\uf8ee\\n\\uf8ef\\uf8ef\\n\\uf8ef\\uf8f0\\nπ\\nπ\\n..\\n.\\nπ\\n\\uf8f9\\n\\uf8fa\\uf8fa\\n\\uf8fa\\uf8fb\\nfor some π, that is, π\\nj = limn→∞ Pn\\nij exists and is independent of i.\\nHere is the main theorem about convergence. The theorem says that an\\nergodic chain converges to its stationary distribution. Also, sample averages\\nconverge to their theoretical expectations under the stationary distribution.\\n23.25 Theorem. An irreducible, ergodic Markov chain has a unique\\nstationary distribution π. The limiting distribution exists and is equal to\\nπ.I f g is any bounded function, then, with probability 1,\\nlim\\nN→∞\\n1\\nN\\nN∑\\nn=1\\ng(Xn) → Eπ(g) ≡\\n∑\\nj\\ng(j)πj. (23.14)\\nFinally, there is another deﬁnition that will be useful later. We say that π\\nsatisﬁes detailed balance if\\nπipij = pjiπj. (23.15)\\nDetailed balance guarantees that π is a stationary distribution.\\n23.26 Theorem. If π satisﬁes detailed balance, then π is a stationary distri-\\nbution.\\nProof. We need to show thatπP = π. The jth element ofπP is ∑\\ni πipij =∑\\ni πjpji = πj\\n∑\\ni pji = πj. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 407, 'page_label': '408'}, page_content='392 23. Probability Redux: Stochastic Processes\\nThe importance of detailed balance will become clear when we discuss\\nMarkov chain Monte Carlo methods in Chapter 24.\\nWarning!Just because a chain has a stationary distribution does not mean\\nit converges.\\n23.27 Example. Let\\nP =\\n\\uf8ee\\n\\uf8f0\\n010\\n001\\n100\\n\\uf8f9\\n\\uf8fb.\\nLet π =( 1/3,1/3,1/3). Then πP = π so π is a stationary distribution. If\\nthe chain is started with the distribution π it will stay in that distribution.\\nImagine simulating many chains and checking the marginal distribution at\\neach time n. It will always be the uniform distributionπ. But this chain does\\nnot have a limit. It continues to cycle around forever.\\n■\\nExamples of Markov Chains.\\n23.28 Example. Let X = {1,2,3,4,5,6}. Let\\nP =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\uf8f0\\n1\\n2\\n1\\n2 0000\\n1\\n4\\n3\\n4 0000\\n1\\n4\\n1\\n4\\n1\\n4\\n1\\n4 00\\n1\\n4 0 1\\n4\\n1\\n4 0 1\\n4\\n0000 1\\n2\\n1\\n2\\n0000 1\\n2\\n1\\n2\\n\\uf8f9\\n\\uf8fa\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\uf8fb\\nThen C\\n1 = {1,2} and C2 = {5,6} are irreducible closed sets. States 3 and\\n4 are transient because of the path 3 → 4 → 6 and once you hit state 6\\nyou cannot return to 3 or 4. Since pii(1) > 0, all the states are aperiodic. In\\nsummary, 3 and 4 are transient while 1, 2, 5, and 6 are ergodic. ■\\n23.29 Example (Hardy-Weinberg). Here is a famous example from genetics.\\nSuppose a gene can be typeA or typea. There are three types of people (called\\ngenotypes): AA, Aa, and aa. Let (p, q, r) denote the fraction of people of each\\ngenotype. We assume that everyone contributes one of their two copies of the\\ngene at random to their children. We also assume that mates are selected at\\nrandom. The latter is not realistic however, it is often reasonable to assume\\nthat you do not choose your mate based on whether they are AA, Aa, or\\naa. (This would be false if the gene was for eye color and if people chose\\nmates based on eye color.) Imagine if we pooled everyone’s genes together.\\nThe proportion of A genes is P = p +( q/2) and the proportion of a genes is'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 408, 'page_label': '409'}, page_content='23.2 Markov Chains 393\\nQ = r +( q/2). A child is AA with probability P2, aA with probability 2PQ,\\nand aa with probability Q2. Thus, the fraction of A genes in this generation\\nis\\nP2 + PQ =\\n\\uf8f6\\np + q\\n2\\n\\uf8f72\\n+\\n\\uf8f6\\np + q\\n2\\n\\uf8f7\\uf8f6\\nr + q\\n2\\n\\uf8f7\\n.\\nHowever, r =1 − p − q. Substitute this in the above equation and you get\\nP2 + PQ = P. A similar calculation shows that the fraction of “a” genes is\\nQ. We have shown that the proportion of type A and type a isP and Q and\\nthis remains stable after the ﬁrst generation. The proportion of people of type\\nAA, Aa, aa is thus (P\\n2,2PQ,Q 2) from the second generation and on. This is\\ncalled the Hardy-Weinberg law.\\nAssume everyone has exactly one child. Now consider a ﬁxed person and\\nlet Xn be the genotype of their nth descendant. This is a Markov chain with\\nstate space X = {AA, Aa, aa}. Some basic calculations will show you that the\\ntransition matrix is \\uf8ee\\n\\uf8f0\\nPQ 0\\nP\\n2\\nP+Q\\n2\\nQ\\n2\\n0 PQ\\n\\uf8f9\\n\\uf8fb.\\nThe stationary distribution is π =( P2,2PQ,Q 2). ■\\n23.30 Example (Markov chain Monte Carlo). In Chapter 24 we will present a\\nsimulation method called Markov chain Monte Carlo (MCMC). Here is a brief\\ndescription of the idea. Let f(x) be a probability density on the real line and\\nsuppose that f(x)= cg(x) where g(x) is a known function and c> 0i s\\nunknown. In principle, we can compute c since\\n∫\\nf(x)dx = 1 implies that\\nc =1 /\\n∫\\ng(x)dx. However, it may not be feasible to perform this integral, nor\\nis it necessary to know c in the following algorithm. Let X\\n0 be an arbitrary\\nstarting value. Given X0, ..., X i, draw Xi+1 as follows. First, draw W ∼\\nN(Xi,b 2) where b> 0 is some ﬁxed constant. Let\\nr = min\\n{g(W)\\ng(Xi), 1\\n}\\n.\\nDraw U ∼ Uniform(0,1) and set\\nXi+1 =\\n{ W if U<r\\nXi if U ≥ r.\\nWe will see in Chapter 24 that, under weak conditions, X0,X 1,..., is an\\nergodic Markov chain with stationary distribution f. Hence, we can regard\\nthe draws as a sample from f. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 409, 'page_label': '410'}, page_content='394 23. Probability Redux: Stochastic Processes\\nInference for Markov Chains.Consider a chain with ﬁnite state space\\nX = {1,2,...,N }. Suppose we observe n observations X1,...,X n from this\\nchain. The unknown parameters of a Markov chain are the initial probabilities\\nµ\\n0 =( µ0(1),µ0(2),..., ) and the elements of the transition matrix P. Each\\nrow of P is a multinomial distribution. So we are essentially estimating N\\ndistributions (plus the initial probabilities). Let nij be the observed number\\nof transitions from state i to state j. The likelihood function is\\nL(µ0,P)= µ0(x0)\\nn∏\\nr=1\\npXr−1,Xr = µ0(x0)\\nN∏\\ni=1\\nN∏\\nj=1\\npnij\\nij .\\nThere is only one observation on µ0 so we can’t estimate that. Rather, we\\nfocus on estimating P. The mle is obtained by maximizing L(µ0,P) subject\\nto the constraint that the elements are non-negative and the rows sum to 1.\\nThe solution is\\nˆp\\nij = nij\\nni\\nwhere ni = ∑ N\\nj=1 nij. Here we are assuming that ni > 0. If not, then we set\\nˆpij = 0 by convention.\\n23.31 Theorem (Consistency and Asymptotic Normality of the mle). Assume that\\nthe chain is ergodic. Let ˆpij(n) denote the mle after n observations. Then\\nˆpij(n)\\nP\\n−→pij. Also,\\n[√\\nNi(n)(ˆpij − pij)\\n]\\n⇝ N(0,Σ)\\nwhere the left-hand side is a matrix, Ni(n)= ∑ n\\nr=1 I(Xr = i) and\\nΣij,kℓ =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\npij(1 − pij)( i, j)=( k,ℓ )\\n−pijpiℓ i = k,j ̸= ℓ\\n0 otherwise .\\n23.3 Poisson Processes\\nThe Poisson process arises when we count occurrences of events over time, for\\nexample, traﬃc accidents, radioactive decay, arrival of email messages, etc.\\nAs the name suggests, the Poisson process is intimately related to the Poisson\\ndistribution. Let’s ﬁrst review the Poisson distribution.\\nRecall that X has a Poisson distribution with parameterλ — written X ∼\\nPoisson(λ)—i f\\nP(X = x) ≡ p(x; λ)= e\\n−λλx\\nx! ,x =0 ,1,2,...'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 410, 'page_label': '411'}, page_content='23.3 Poisson Processes 395\\nAlso recall that E(X)= λ and V(X)= λ.I f X ∼ Poisson(λ), Y ∼ Poisson(ν)\\nand X⨿ Y , thenX+Y ∼ Poisson(λ+ν). Finally, ifN ∼ Poisson(λ) andY |N =\\nn ∼ Binomial(n, p), then the marginal distribution of Y is Y ∼ Poisson(λp).\\nNow we describe the Poisson process. Imagine that you are at your com-\\nputer. Each time a new email message arrives you record the time. LetXt be\\nthe number of messages you have received up to and including time t. Then,\\n{Xt : t ∈ [0,∞)} is a stochastic process with state space X = {0,1,2,... }.\\nA process of this form is called a counting process. A Poisson process is\\na counting process that satisﬁes certain conditions. In what follows, we will\\nsometimes write X(t) instead of X\\nt. Also, we need the following notation.\\nWrite f(h)= o(h)i f f(h)/h → 0a s h → 0. This means that f(h) is smaller\\nthan h when h is close to 0. For example, h2 = o(h).\\n23.32 Deﬁnition. A Poisson process is a stochastic process\\n{Xt : t ∈ [0,∞)} with state space X = {0,1,2,... } such that\\n1. X( 0 )=0.\\n2. For any 0= t0 <t 1 <t 2 < ··· <t n, the increments\\nX(t1) − X(t0),X (t2) − X(t1), ··· ,X (tn) − X(tn−1)\\nare independent.\\n3. There is a function λ(t) such that\\nP(X(t + h) − X(t)=1 ) = λ(t)h + o(h) (23.16)\\nP(X(t + h) − X(t) ≥ 2) = o(h). (23.17)\\nWe call λ(t) the intensity function.\\nThe last condition means that the probability of an event in [ t, t+ h]i s\\napproximately hλ(t) while the probability of more than one event is small.\\n23.33 Theorem. If Xt is a Poisson process with intensity functionλ(t), then\\nX(s + t) − X(s) ∼ Poisson(m(s + t) − m(s))\\nwhere\\nm(t)=\\n∫ t\\n0\\nλ(s) ds.\\nIn particular, X(t) ∼ Poisson(m(t)). Hence, E(X(t)) = m(t) and V(X(t)) =\\nm(t).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 411, 'page_label': '412'}, page_content='396 23. Probability Redux: Stochastic Processes\\n23.34 Deﬁnition. A Poisson process with intensity function λ(t) ≡ λ for\\nsome λ> 0 is called a homogeneous Poisson process with rate λ.I n\\nthis case,\\nX(t) ∼ Poisson(λt).\\nLet X(t) be a homogeneous Poisson process with rate λ. Let Wn be the\\ntime at which the nth event occurs and set W0 = 0. The random variables\\nW0,W 1,..., are calledwaiting times. LetSn = Wn+1−Wn. ThenS0,S 1,...,\\nare called sojourn times or interarrival times.\\n23.35 Theorem. The sojourn timesS0,S 1,... are iid random variables. Their\\ndistribution is exponential with mean 1/λ, that is, they have density\\nf(s)= λe−λs,s ≥ 0.\\nThe waiting time Wn ∼ Gamma(n, 1/λ) i.e., it has density\\nf(w)= 1\\nΓ(n)λnwn−1e−λt.\\nHence, E(Wn)= n/λ and V(Wn)= n/λ2.\\nProof. First, we have\\nP(S1 >t )= P(X(t)=0 )= e−λt\\nwith shows that thecdf for S1 is 1−e−λt. This shows the result forS1.N o w ,\\nP(S2 >t |S1 = s)= P(no events in (s, s+ t]|S1 = s)\\n= P(no events in (s, s+ t]) (increments are independent)\\n= e−λt.\\nHence, S2 has an exponential distribution and is independent ofS1. The result\\nfollows by repeating the argument. The result for Wn follows since a sum of\\nexponentials has a Gamma distribution. ■\\n23.36 Example. Figure 23.3 shows requests to a WWW server in Calgary. 1\\nAssuming that this is a homogeneous Poisson process,N ≡ X(T) ∼ Poisson(λT).\\nThe likelihood is\\nL(λ) ∝ e−λT (λT)N\\n1See http://ita.ee.lbl.gov/html/contrib/Calgary-HTTP.html for more information.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 412, 'page_label': '413'}, page_content='23.4 Bibliographic Remarks 397\\n0 400 800 1200 time\\nFIGURE 23.3. Hits on a web server. Each vertical line represents one event.\\nwhich is maximized at\\nˆλ = N\\nT =4 8.0077\\nin units per minute. Let’s now test the assumption that the data follow a ho-\\nmogeneous Poisson process using a goodness-of-ﬁt test. We divide the interval\\n[0,T ] into 4 equal length intervalsI\\n1,I2,I3,I4. If the process is a homogeneous\\nPoisson process then, given the total number of events, the probability that an\\nevent falls into any of these intervals must be equal. Letp\\ni be the probability\\nof a point being in Ii. The null hypothesis is that p1 = p2 = p3 = p4 =1 /4.\\nWe can test this hypothesis using either a likelihood ratio test or a χ2 test.\\nThe latter is\\n4∑\\ni=1\\n(Oi − Ei)2\\nEi\\nwhere Oi is the number of observations in Ii and Ei = n/4 is the expected\\nnumber under the null. This yields χ2 = 252 with a p-value near 0. This is\\nstrong evidence against the null so we reject the hypothesis that the data are\\nfrom a homogeneous Poisson process. This is hardly surprising since we would\\nexpect the intensity to vary as a function of time.\\n■\\n23.4 Bibliographic Remarks\\nThis is standard material and there are many good references including Grim-\\nmett and Stirzaker (1982), Taylor and Karlin (1994), Guttorp (1995), and\\nRoss (2002). The following exercises are from those texts.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 413, 'page_label': '414'}, page_content='398 23. Probability Redux: Stochastic Processes\\n23.5 Exercises\\n1. Let X0,X 1,... be a Markov chain with states {0,1,2} and transition\\nmatrix\\nP =\\n\\uf8ee\\n\\uf8f0\\n0.10 .20 .7\\n0.90 .10 .0\\n0.10 .80 .1\\n\\uf8f9\\n\\uf8fb\\nAssume that µ0 =( 0.3,0.4,0.3). Find P(X0 =0 ,X 1 =1 ,X 2 = 2) and\\nP(X0 =0 ,X 1 =1 ,X 2 = 1).\\n2. Let Y1,Y2,... be a sequence of iid observations such that P(Y =0 )=\\n0.1, P(Y =1 )=0 .3, P(Y =2 )=0 .2, P(Y =3 )=0 .4. Let X0 = 0 and\\nlet\\nXn = max{Y1,...,Y n}.\\nShow that X0,X 1,... is a Markov chain and ﬁnd the transition matrix.\\n3. Consider a two-state Markov chain with statesX = {1,2} and transition\\nmatrix\\nP =\\n[ 1 − aa\\nb 1 − b\\n]\\nwhere 0 <a< 1 and 0 <b< 1. Prove that\\nlim\\nn→∞\\nPn =\\n[ b\\na+b\\na\\na+b\\nb\\na+b\\na\\na+b\\n]\\n.\\n4. Consider the chain from question 3 and set a = .1 and b = .3. Simulate\\nthe chain. Let\\nˆpn(1) = 1\\nn\\nn∑\\ni=1\\nI(Xi =1 )\\nˆpn(2) = 1\\nn\\nn∑\\ni=1\\nI(Xi =2 )\\nbe the proportion of times the chain is in state 1 and state 2. Plotˆpn(1)\\nand ˆpn(2) versus n and verify that they converge to the values predicted\\nfrom the answer in the previous question.\\n5. An important Markov chain is thebranching process which is used in\\nbiology, genetics, nuclear physics, and many other ﬁelds. Suppose that\\nan animal has Y children. Let p\\nk = P(Y = k). Hence, pk ≥ 0 for all\\nk and ∑ ∞\\nk=0 pk = 1. Assume each animal has the same lifespan and'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 414, 'page_label': '415'}, page_content='23.5 Exercises 399\\nthat they produce oﬀspring according to the distributionpk. Let Xn be\\nthe number of animals in the nth generation. Let Y (n)\\n1 ,...,Y (n)\\nXn be the\\noﬀspring produced in the nth generation. Note that\\nXn+1 = Y (n)\\n1 + ··· + Y (n)\\nXn .\\nLet µ = E(Y ) and σ2 = V(Y ). Assume throughout this question that\\nX0 = 1. Let M(n)= E(Xn) and V (n)= V(Xn).\\n(a) Show that M(n +1 )= µM(n) and V (n +1 )= σ2M(n)+ µ2V (n).\\n(b) Show that M(n)= µn and that V (n)= σ2µn−1(1+ µ+··· +µn−1).\\n(c) What happens to the variance if µ> 1? What happens to the vari-\\nance if µ = 1? What happens to the variance if µ< 1?\\n(d) The population goes extinct ifXn = 0 for somen. Let us thus deﬁne\\nthe extinction time N by\\nN = min{n : Xn =0 }.\\nLet F(n)= P(N ≤ n)b et h ecdf of the random variable N. Show that\\nF(n)=\\n∞∑\\nk=0\\npk(F(n − 1))k,n =1 ,2,...\\nHint: Note that the event {N ≤ n} is the same as event {Xn =0 }.\\nThus, P({N ≤ n})= P({Xn =0 }). Let k be the number of oﬀspring\\nof the original parent. The population becomes extinct at time n if and\\nonly if each of thek sub-populations generated from thek oﬀspring goes\\nextinct in n − 1 generations.\\n(e) Suppose that p0 =1 /4, p1 =1 /2, p2 =1 /4. Use the formula from\\n(5d) to compute the cdf F(n).\\n6. Let\\nP =\\n\\uf8ee\\n\\uf8f0\\n0.40 0 .50 0 .10\\n0.05 0 .70 0 .25\\n0.05 0 .50 0 .45\\n\\uf8f9\\n\\uf8fb\\nFind the stationary distribution π.\\n7. Show that if i is a recurrent state andi ↔ j, then j is a recurrent state.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 415, 'page_label': '416'}, page_content='400 23. Probability Redux: Stochastic Processes\\n8. Let\\nP =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\n\\uf8ef\\uf8f0\\n1\\n3 0 1\\n3 00 1\\n31\\n2\\n1\\n4\\n1\\n4 000\\n000010\\n1\\n4\\n1\\n4\\n1\\n4 00 1\\n4\\n001000\\n000001\\n\\uf8f9\\n\\uf8fa\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\n\\uf8fa\\uf8fb\\nWhich states are transient? Which states are recurrent?\\n9. Let\\nP =\\n[ 01\\n10\\n]\\nShow that π =( 1/2,1/2) is a stationary distribution. Does this chain\\nconverge? Why/why not?\\n10. Let 0 <p< 1 and q =1 − p. Let\\nP =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\n\\uf8ef\\n\\uf8ef\\uf8f0\\nqp 000\\nq 0 p 00\\nq 00 p 0\\nq 000 p\\n10000\\n\\uf8f9\\n\\uf8fa\\uf8fa\\n\\uf8fa\\n\\uf8fa\\uf8fb\\nFind the limiting distribution of the chain.\\n11. Let X(t) be an inhomogeneous Poisson process with intensity function\\nλ(t) > 0. Let Λ(t)=\\n∫\\nt\\n0 λ(u)du. Deﬁne Y (s)= X(t) where s =Λ (t).\\nShow that Y (s) is a homogeneous Poisson process with intensityλ =1 .\\n12. Let X(t) be a Poisson process with intensity λ. Find the conditional\\ndistribution of X(t) given that X(t + s)= n.\\n13. Let X(t) be a Poisson process with intensity λ. Find the probability\\nthat X(t) is odd, i.e. P(X(t)=1 ,3,5,... ).\\n14. Suppose that people logging in to the University computer system is\\ndescribed by a Poisson process X(t) with intensity λ. Assume that a\\nperson stays logged in for some random time withcdf G. Assume these\\ntimes are all independent. Let Y (t) be the number of people on the\\nsystem at time t. Find the distribution of Y (t).\\n15. Let X(t) be a Poisson process with intensity λ. Let W1,W 2,..., be the\\nwaiting times. Let f be an arbitrary function. Show that\\nE\\n\\uf8eb\\n\\uf8ed\\nX(t)∑\\ni=1\\nf(Wi)\\n\\uf8f6\\n\\uf8f8 = λ\\n∫ t\\n0\\nf(w)dw.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 416, 'page_label': '417'}, page_content='23.5 Exercises 401\\n16. A two-dimensional Poisson point process is a process of random points\\non the plane such that (i) for any set A, the number of points falling\\nin A is Poisson with mean λµ(A) where µ(A) is the area of A, (ii) the\\nnumber of events in non-overlapping regions is independent. Consider\\nan arbitrary point x\\n0 in the plane. Let X denote the distance from x0\\nto the nearest random point. Show that\\nP(X>t )= e−λπt2\\nand\\nE(X)= 1\\n2\\n√\\nλ\\n.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 417, 'page_label': '418'}, page_content=''),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 418, 'page_label': '419'}, page_content='24\\nSimulation Methods\\nIn this chapter we will show how simulation can be used to approximate inte-\\ngrals. Our leading example is the problem of computing integrals in Bayesian\\ninference but the techniques are widely applicable. We will look at three inte-\\ngration methods: (i) basic Monte Carlo integration, (ii) importance sampling,\\nand (iii) Markov chain Monte Carlo (MCMC).\\n24.1 Bayesian Inference Revisited\\nSimulation methods are especially useful in Bayesian inference so let us brieﬂy\\nreview the main ideas in Bayesian inference. See Chapter 11 for more details.\\nGiven a prior f(θ) and data X\\nn =( X1,...,X n) the posterior density is\\nf(θ|Xn)= L(θ)f(θ)\\nc\\nwhere L(θ) is the likelihood function and\\nc =\\n∫\\nL(θ)f(θ) dθ\\nis the normalizing constant. The posterior mean is\\nθ =\\n∫\\nθf(θ|Xn)dθ =\\n∫\\nθL(θ)f(θ)dθ\\nc .'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 419, 'page_label': '420'}, page_content='404 24. Simulation Methods\\nIf θ =( θ1,...,θ k) is multidimensional, then we might be interested in the\\nposterior for one of the components, θ1, say. This marginal posterior density\\nis\\nf(θ1|Xn)=\\n∫∫\\n···\\n∫\\nf(θ1,...,θ k|Xn)dθ2 ··· dθk\\nwhich involves high-dimensional integration.\\nWhen θ is high-dimensional, it may not be feasible to calculate these inte-\\ngrals analytically. Simulation methods will often be helpful.\\n24.2 Basic Monte Carlo Integration\\nSuppose we want to evaluate the integral\\nI =\\n∫ b\\na\\nh(x) dx\\nfor some function h.I f h is an “easy” function like a polynomial or trigono-\\nmetric function, then we can do the integral in closed form. Ifh is complicated\\nthere may be no known closed form expression forI. There are many numer-\\nical techniques for evaluating I such as Simpson’s rule, the trapezoidal rule\\nand Gaussian quadrature. Monte Carlo integration is another approach for\\napproximating I which is notable for its simplicity, generality and scalability.\\nLet us begin by writing\\nI =\\n∫\\nb\\na\\nh(x)dx =\\n∫ b\\na\\nw(x)f(x)dx (24.1)\\nwhere w(x)= h(x)(b−a) andf(x)=1 /(b−a). Notice thatf is the probability\\ndensity for a uniform random variable over (a, b). Hence,\\nI = Ef (w(X))\\nwhere X ∼ Unif(a, b). If we generate X1,...,X N ∼ Unif(a, b), then by the\\nlaw of large numbers\\nˆI ≡ 1\\nN\\nN∑\\ni=1\\nw(Xi)\\nP\\n−→E(w(X)) = I. (24.2)\\nThis is the basic Monte Carlo integration method. We can also compute\\nthe standard error of the estimate\\nˆse = s√\\nN'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 420, 'page_label': '421'}, page_content='24.2 Basic Monte Carlo Integration 405\\nwhere\\ns2 =\\n∑ N\\ni=1(Yi − ˆI)2\\nN − 1\\nwhere Yi = w(Xi). A 1−α conﬁdence interval forI is ˆI ±zα/2 ˆse. We can take\\nN as large as we want and hence make the length of the conﬁdence interval\\nvery small.\\n24.1 Example. Let h(x)= x3. Then, I =\\n∫1\\n0 x3dx =1 /4. Based on N =\\n10,000 observations from a Uniform(0 ,1) we get ˆI = .248 with a standard\\nerror of .0028. ■\\nA generalization of the basic method is to consider integrals of the form\\nI =\\n∫\\nh(x)f(x)dx (24.3)\\nwhere f(x) is a probability density function. Taking f to be a Uniform (a,b)\\ngives us the special case above. Now we draw X1,...,X N ∼ f and take\\nˆI ≡ 1\\nN\\nN∑\\ni=1\\nh(Xi)\\nas before.\\n24.2 Example. Let\\nf(x)= 1√\\n2πe−x2/2\\nbe the standard Normal pdf. Suppose we want to compute the cdf at some\\npoint x:\\nI =\\n∫ x\\n−∞\\nf(s)ds =Φ (x).\\nWrite\\nI =\\n∫\\nh(s)f(s)ds\\nwhere\\nh(s)=\\n{ 1 s<x\\n0 s ≥ x.\\nNow we generate X1,...,X N ∼ N(0,1) and set\\nˆI = 1\\nN\\n∑\\ni\\nh(Xi)= number of observations ≤ x\\nN .\\nFor example, with x = 2, the true answer is Φ(2) = .9772 and the Monte\\nCarlo estimate with N =1 0,000 yields .9751. Using N = 100,000 we get\\n.9771. ■'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 421, 'page_label': '422'}, page_content='406 24. Simulation Methods\\n24.3 Example (Bayesian Inference for Two Binomials). Let X ∼ Binomial(n, p1)\\nand Y ∼ Binomial(m, p2). We would like to estimate δ = p2 − p1. The mle\\nis ˆδ = ˆp2 − ˆp1 =( Y/m) − (X/n). We can get the standard error ˆse using the\\ndelta method which yields\\nˆse =\\n√\\nˆp1(1 − ˆp1)\\nn + ˆp2(1 − ˆp2)\\nm\\nand then construct a 95 percent conﬁdence interval ˆδ ± 2 ˆse. Now consider a\\nBayesian analysis. Suppose we use the prior f(p1,p 2)= f(p1)f(p2) = 1, that\\nis, a ﬂat prior on (p1,p 2). The posterior is\\nf(p1,p 2|X,Y ) ∝ pX\\n1 (1 − p1)n−X pY\\n2 (1 − p2)m−Y .\\nThe posterior mean of δ is\\nδ =\\n∫ 1\\n0\\n∫ 1\\n0\\nδ(p1,p 2)f(p1,p 2|X,Y )=\\n∫ 1\\n0\\n∫ 1\\n0\\n(p2 − p1)f(p1,p 2|X,Y ).\\nIf we want the posterior density of δ we can ﬁrst get the posterior cdf\\nF(c|X,Y )= P(δ ≤ c|X,Y )=\\n∫\\nA\\nf(p1,p 2|X,Y )\\nwhere A = {(p1,p 2): p2 − p1 ≤ c}. The density can then be obtained by\\ndiﬀerentiating F.\\nTo avoid all these integrals, let’s use simulation. Note thatf(p1,p 2|X,Y )=\\nf(p1|X)f(p2|Y ) which implies that p1 and p2 are independent under the pos-\\nterior distribution. Also, we see thatp1|X ∼ Beta(X+1,n −X+1) and p2|Y ∼\\nBeta(Y +1,m −Y +1). Hence, we can simulate (P(1)\\n1 ,P (1)\\n2 ),..., (P(N)\\n1 ,P (N)\\n2 )\\nfrom the posterior by drawing\\nP(i)\\n1 ∼ Beta(X +1 ,n − X +1 )\\nP(i)\\n2 ∼ Beta(Y +1 ,m − Y +1 )\\nfor i =1 ,...,N . Now let δ(i) = P(i)\\n2 − P(i)\\n1 . Then,\\nδ ≈ 1\\nN\\n∑\\ni\\nδ(i).\\nWe can also get a 95 percent posterior interval forδ by sorting the simulated\\nvalues, and ﬁnding the.025 and .975 quantile. The posterior densityf(δ|X,Y )\\ncan be obtained by applying density estimation techniques to δ(1),...,δ (N)\\nor, simply by plotting a histogram. For example, suppose that n = m = 10,'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 422, 'page_label': '423'}, page_content='24.2 Basic Monte Carlo Integration 407\\n−0.6 0.0 0.6\\nFIGURE 24.1. Posterior of δ from simulation.\\nX = 8 and Y = 6. From a posterior sample of size 1000 we get a 95 percent\\nposterior interval of (-0.52,0.20). The posterior density can be estimated from\\na histogram of the simulated values as shown in Figure 24.1.\\n■\\n24.4 Example (Bayesian Inference for Dose Response). Suppose we conduct an\\nexperiment by giving rats one of ten possible doses of a drug, denoted by\\nx\\n1 <x 2 < ... < x 10. For each dose level xi we use n rats and we observe\\nYi, the number that survive. Thus we have ten independent binomials Yi ∼\\nBinomial(n, pi). Suppose we know from biological considerations that higher\\ndoses should have higher probability of death. Thus,p1 ≤ p2 ≤···≤ p10.W e\\nwant to estimate the dose at which the animals have a 50 percent chance of\\ndying. This is called the LD50. Formally,δ = x\\nj where\\nj = min{i : pi ≥ .50}.\\nNotice that δ is implicitly a (complicated) function of p1,...,p 10 so we can\\nwrite δ = g(p1,...,p 10) for someg. This just means that if we know (p1,...,p 10)\\nthen we can ﬁnd δ. The posterior mean of δ is\\n∫∫\\n···\\n∫\\nA\\ng(p1,...,p 10)f(p1,...,p 10|Y1,...,Y 10)dp1dp2 ...d p 10.\\nThe integral is over the region\\nA = {(p1,...,p 10): p1 ≤···≤ p10}.\\nThe posterior cdf of δ is\\nF(c|Y1,...,Y 10)= P(δ ≤ c|Y1,...,Y 10)\\n=\\n∫∫\\n···\\n∫\\nB\\nf(p1,...,p 10|Y1,...,Y 10)dp1dp2 ...d p 10'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 423, 'page_label': '424'}, page_content='408 24. Simulation Methods\\nwhere\\nB = A\\n⋂ {\\n(p1,...,p 10): g(p1,...,p 10) ≤ c\\n}\\n.\\nWe need to do a 10-dimensional integral over a restricted region A. Instead,\\nwe will use simulation. Let us take a ﬂat prior truncated over A. Except for\\nthe truncation, each Pi has once again a Beta distribution. To draw from the\\nposterior we do the following steps:\\n(1) Draw Pi ∼ Beta(Yi +1 ,n − Yi +1 ),i =1 ,..., 10.\\n(2) If P1 ≤ P2 ≤ ··· ≤ P10 keep this draw. Otherwise, throw it away and\\ndraw again until you get one you can keep.\\n(3) Let δ = xj where\\nj = min{i : Pi >. 50}.\\nWe repeat this N times to get δ(1),...,δ (N) and take\\nE(δ|Y1,...,Y 10) ≈ 1\\nN\\n∑\\ni\\nδ(i).\\nδ is a discrete variable. We can estimate its probability mass function by\\nP(δ = xj|Y1,...,Y 10) ≈ 1\\nN\\nN∑\\ni=1\\nI(δ(i) = j).\\nFor example, consider the following data:\\nDose 123456789 1 0\\nNumber of animals ni 15 15 15 15 15 15 15 15 15 15\\nNumber of survivors Yi 00228 1 0 1 2 1 4 1 5 1 4\\nThe posterior draws for p1,...,p 10 are shown in the second panel in the\\nﬁgure. We ﬁnd that that δ =4 .04 with a 95 percent interval of (3,5). ■\\n24.3 Importance Sampling\\nConsider again the integralI =\\n∫\\nh(x)f(x)dx where f is a probability density.\\nThe basic Monte Carlo method involves sampling from f. However, there\\nare cases where we may not know how to sample from f. For example, in\\nBayesian inference, the posterior density density is is obtained by multiplying\\nthe likelihood L(θ) times the prior f(θ). There is no guarantee that f(θ|x)\\nwill be a known distribution like a Normal or Gamma or whatever.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 424, 'page_label': '425'}, page_content='24.3 Importance Sampling 409\\nImportance sampling is a generalization of basic Monte Carlo which over-\\ncomes this problem. Let g be a probability density that we know how to\\nsimulate from. Then\\nI =\\n∫\\nh(x)f(x)dx =\\n∫ h(x)f(x)\\ng(x) g(x)dx = Eg(Y ) (24.4)\\nwhere Y = h(X)f(X)/g(X) and the expectation Eg(Y ) is with respect to g.\\nWe can simulate X1,...,X N ∼ g and estimate I by\\nˆI = 1\\nN\\n∑\\ni\\nYi = 1\\nN\\n∑\\ni\\nh(Xi)f(Xi)\\ng(Xi) . (24.5)\\nThis is called importance sampling. By the law of large numbers, ˆI\\nP\\n−→I.\\nHowever, there is a catch. It’s possible thatˆI might have an inﬁnite standard\\nerror. To see why, recall that I is the mean of w(x)= h(x)f(x)/g(x). The\\nsecond moment of this quantity is\\nEg(w2(X)) =\\n∫ \\uf8f6h(x)f(x)\\ng(x)\\n\\uf8f72\\ng(x)dx =\\n∫ h2(x)f2(x)\\ng(x) dx. (24.6)\\nIf g has thinner tails thanf, then this integral might be inﬁnite. To avoid this,\\na basic rule in importance sampling is to sample from a densityg with thicker\\ntails than f. Also, suppose that g(x) is small over some set A where f(x)i s\\nlarge. Again, the ratio of f/g could be large leading to a large variance. This\\nimplies that we should choose g to be similar in shape to f. In summary, a\\ngood choice for an importance sampling density g should be similar to f but\\nwith thicker tails. In fact, we can say what the optimal choice of g is.\\n24.5 Theorem. The choice of g that minimizes the variance of ˆI is\\ng∗(x)= |h(x)|f(x)∫\\n|h(s)|f(s)ds.\\nProof. The variance of w = fh/g is\\nEg(w2) − (E(w2))2 =\\n∫\\nw2(x)g(x)dx −\\n\\uf8f6∫\\nw(x)g(x)dx\\n\\uf8f72\\n=\\n∫ h2(x)f2(x)\\ng2(x) g(x)dx −\\n\\uf8f6∫ h(x)f(x)\\ng(x) g(x)dx\\n\\uf8f72\\n=\\n∫ h2(x)f2(x)\\ng2(x) g(x)dx −\\n\\uf8f6∫\\nh(x)f(x)dx\\n\\uf8f72\\n.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 425, 'page_label': '426'}, page_content='410 24. Simulation Methods\\nThe second integral does not depend on g, so we only need to minimize the\\nﬁrst integral. From Jensen’s inequality (Theorem 4.9) we have\\nEg(W2) ≥ (Eg(|W|))2 =\\n\\uf8f6∫\\n|h(x)|f(x)dx\\n\\uf8f72\\n.\\nThis establishes a lower bound on Eg(W2). However, Eg∗ (W2) equals this\\nlower bound which proves the claim. ■\\nThis theorem is interesting but it is only of theoretical interest. If we did\\nnot know how to sample fromf then it is unlikely that we could sample from\\n|h(x)|f(x)/\\n∫\\n|h(s)|f(s)ds. In practice, we simply try to ﬁnd a thick-tailed\\ndistribution g which is similar to f|h|.\\n24.6 Example (Tail Probability). Let’s estimate I = P(Z> 3) = .0013 where\\nZ ∼ N(0,1). Write I =\\n∫\\nh(x)f(x)dx where f(x) is the standard Normal\\ndensity and h(x)=1i f x> 3, and 0 otherwise. The basic Monte Carlo\\nestimator is ˆI = N−1 ∑\\ni h(Xi) where X1,...,X N ∼ N(0,1). Using N = 100\\nwe ﬁnd (from simulating many times) that E(ˆI)= .0015 and V(ˆI)= .0039.\\nNotice that most observations are wasted in the sense that most are not near\\nthe right tail. Now we will estimate this with importance sampling taking g\\nto be a Normal(4,1) density. We draw values fromg and the estimate is now\\nˆI = N\\n−1 ∑\\ni f(Xi)h(Xi)/g(Xi). In this case we ﬁnd that E(ˆI)= .0011 and\\nV(ˆI)= .0002. We have reduced the standard deviation by a factor of 20.■\\n24.7 Example (Measurement Model With Outliers). Suppose we have measure-\\nments X1,...,X n of some physical quantity θ. A reasonable model is\\nXi = θ + ϵi.\\nIf we assume that ϵi ∼ N(0,1) then Xi ∼ N(θi,1). However, when taking\\nmeasurements, it is often the case that we get the occasional wild observation,\\nor outlier. This suggests that a Normal might be a poor model since Normals\\nhave thin tails which implies that extreme observations are rare. One way to\\nimprove the model is to use a density for ϵ\\ni with a thicker tail, for example,\\na t-distribution with ν degrees of freedom which has the form\\nt(x)= Γ\\n\\uf8f6ν+1\\n2\\n\\uf8f7\\nΓ\\n\\uf8f6ν\\n2\\n\\uf8f7 1\\nνπ\\n\\uf8f6\\n1+ x2\\nν\\n\\uf8f7−(ν+1)/2\\n.\\nSmaller values of ν correspond to thicker tails. For the sake of illustration we\\nwill take ν = 3. Suppose we observe nX i = θ + ϵi, i =1 ,...,n where ϵi has'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 426, 'page_label': '427'}, page_content='24.4 MCMC Part I: The Metropolis–Hastings Algorithm 411\\na t distribution with ν = 3. We will take a ﬂat prior on θ. The likelihood is\\nL(θ)= ∏n\\ni=1 t(Xi − θ) and the posterior mean of θ is\\nθ =\\n∫\\nθL(θ)dθ∫\\nL(θ)dθ .\\nWe can estimate the top and bottom integral using importance sampling. We\\ndraw θ1,...,θ N ∼ g and then\\nθ ≈\\n1\\nN\\n∑ N\\nj=1\\nθjL(θj)\\ng(θj)\\n1\\nN\\n∑ N\\nj=1\\nL(θj)\\ng(θj)\\n.\\nTo illustrate the idea, we drewn = 2 observations. The posterior mean (com-\\nputed numerically) is -0.54. Using a Normal importance sampler g yields an\\nestimate of -0.74. Using a Cauchy (t-distribution with 1 degree of freedom)\\nimportance sampler yields an estimate of -0.53.\\n■\\n24.4 MCMC Part I: The Metropolis–Hastings\\nAlgorithm\\nConsider once more the problem of estimating the integralI =\\n∫\\nh(x)f(x)dx.\\nNow we introduce Markov chain Monte Carlo (MCMC) methods. The idea is\\nto construct a Markov chain X\\n1,X 2,..., whose stationary distribution is f.\\nUnder certain conditions it will then follow that\\n1\\nN\\nN∑\\ni=1\\nh(Xi)\\nP\\n−→Ef (h(X)) = I.\\nThis works because there is a law of large numbers for Markov chains; see\\nTheorem 23.25.\\nThe Metropolis–Hastings algorithm is a speciﬁc MCMC method that\\nworks as follows. Let q(y|x) be an arbitrary, friendly distribution (i.e., we\\nknow how to sample from q(y|x)). The conditional density q(y|x) is called\\nthe proposal distribution. The Metropolis–Hastings algorithm creates a\\nsequence of observations X0,X 1,..., as follows.\\nMetropolis–Hastings Algorithm\\nChoose X0 arbitrarily. Suppose we have generated X0,X 1,...,X i.T o\\ngenerate Xi+1 do the following:\\n(1) Generate a proposal or candidate value Y ∼ q(y|Xi).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 427, 'page_label': '428'}, page_content='412 24. Simulation Methods\\n(2) Evaluate r ≡ r(Xi,Y ) where\\nr(x, y) = min\\n{f(y)\\nf(x)\\nq(x|y)\\nq(y|x), 1\\n}\\n.\\n(3) Set\\nXi+1 =\\n{\\nY with probability r\\nXi with probability 1 − r.\\n24.8 Remark. A simple way to execute step (3) is to generate U ∼ (0,1). If\\nU<r set Xi+1 = Y otherwise set Xi+1 = Xi.\\n24.9 Remark. A common choice for q(y|x)i s N(x, b2) for some b> 0. This\\nmeans that the proposal is draw from a Normal, centered at the current\\nvalue. In this case, the proposal density q is symmetric, q(y|x)= q(x|y), and\\nr simpliﬁes to\\nr = min\\n{ f(Y )\\nf(Xi), 1\\n}\\n.\\nBy construction, X0,X 1,... is a Markov chain. But why does this Markov\\nchain have f as its stationary distribution? Before we explain why, let us ﬁrst\\ndo an example.\\n24.10 Example. The Cauchy distribution has density\\nf(x)= 1\\nπ\\n1\\n1+ x2 .\\nOur goal is to simulate a Markov chain whose stationary distribution is f.\\nAs suggested in the remark above, we takeq(y|x)t ob ea N(x, b2). So in this\\ncase,\\nr(x, y) = min\\n{f(y)\\nf(x), 1\\n}\\n= min\\n{1+ x2\\n1+ y2 , 1\\n}\\n.\\nSo the algorithm is to draw Y ∼ N(Xi,b 2) and set\\nXi+1 =\\n{ Y with probability r(Xi,Y )\\nXi with probability 1 − r(Xi,Y ).\\nThe simulator requires a choice of b. Figure 24.2 shows three chains of length\\nN =1 ,000 using b = .1, b = 1 and b = 10. Setting b = .1 forces the chain\\nto take small steps. As a result, the chain doesn’t “explore” much of the\\nsample space. The histogram from the sample does not approximate the true\\ndensity very well. Setting b = 10 causes the proposals to often be far in the'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 428, 'page_label': '429'}, page_content='24.4 MCMC Part I: The Metropolis–Hastings Algorithm 413\\nFIGURE 24.2. Three Metropolis chains corresponding to b = .1, b =1 , b = 10.\\ntails, making r small and hence we reject the proposal and keep the chain\\nat its current position. The result is that the chain “gets stuck” at the same\\nplace quite often. Again, this means that the histogram from the sample does\\nnot approximate the true density very well. The middle choice avoids these\\nextremes and results in a Markov chain sample that better represents the\\ndensity sooner. In summary, there are tuning parameters and the eﬃciency\\nof the chain depends on these parameters. We’ll discuss this in more detail\\nlater.\\n■\\nIf the sample from the Markov chain starts to “look like” the target distri-\\nbution f quickly, then we say that the chain is “mixing well.” Constructing a\\nchain that mixes well is somewhat of an art.\\nWhy It Works. Recall from Chapter 23 that a distribution π satisﬁes\\ndetailed balance for a Markov chain if\\npijπi = pjiπj.\\nWe showed that if π satisﬁes detailed balance, then it is a stationary distri-\\nbution for the chain.\\nBecause we are now dealing with continuous state Markov chains, we will\\nchange notation a little and write p(x, y) for the probability of making a\\ntransition from x to y. Also, let’s use f(x) instead of π for a distribution. In'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 429, 'page_label': '430'}, page_content='414 24. Simulation Methods\\nthis new notation, f is a stationary distribution iff(x)=\\n∫\\nf(y)p(y,x )dy and\\ndetailed balance holds for f if\\nf(x)p(x, y)= f(y)p(y,x ). (24.7)\\nDetailed balance implies that f is a stationary distribution since, if detailed\\nbalance holds, then\\n∫\\nf(y)p(y,x )dy =\\n∫\\nf(x)p(x, y)dy = f(x)\\n∫\\np(x, y)dy = f(x)\\nwhich shows thatf(x)=\\n∫\\nf(y)p(y,x )dy as required. Our goal is to show that\\nf satisﬁes detailed balance which will imply thatf is a stationary distribution\\nfor the chain.\\nConsider two points x and y. Either\\nf(x)q(y|x) <f (y)q(x|y)o r f(x)q(y|x) >f (y)q(x|y).\\nWe will ignore ties (which occur with probability zero for continuous distribu-\\ntions). Without loss of generality, assume that f(x)q(y|x) >f (y)q(x|y). This\\nimplies that\\nr(x, y)= f(y)\\nf(x)\\nq(x|y)\\nq(y|x)\\nand that r(y,x )=1 .N o w p(x, y) is the probability of jumping from x to y.\\nThis requires two things: (i) the proposal distribution must generate y, and\\n(ii) you must accept y. Thus,\\np(x, y)= q(y|x)r(x, y)= q(y|x)f(y)\\nf(x)\\nq(x|y)\\nq(y|x) = f(y)\\nf(x)q(x|y).\\nTherefore,\\nf(x)p(x, y)= f(y)q(x|y). (24.8)\\nOn the other hand, p(y,x ) is the probability of jumping from y to x. This\\nrequires two things: (i) the proposal distribution must generatex, and (ii) you\\nmust accept x. This occurs with probability p(y,x )= q(x|y)r(y,x )= q(x|y).\\nHence,\\nf(y)p(y,x )= f(y)q(x|y). (24.9)\\nComparing (24.8) and (24.9), we see that we have shown that detailed balance\\nholds.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 430, 'page_label': '431'}, page_content='24.5 MCMC Part II: Diﬀerent Flavors 415\\n24.5 MCMC Part II: Diﬀerent Flavors\\nThere are diﬀerent types of MCMC algorithm. Here we will consider a few of\\nthe most popular versions.\\nRandom-Walk-Metropolis–Hastings. In the previous section we con-\\nsidered drawing a proposal Y of the form\\nY = Xi + ϵi\\nwhere ϵi comes from some distribution with densityg. In other words,q(y|x)=\\ng(y − x). We saw that in this case,\\nr(x, y) = min\\n{\\n1, f(y)\\nf(x)\\n}\\n.\\nThis is called a random-walk-Metropolis–Hastings method. The reason\\nfor the name is that, if we did not do the accept–reject step, we would be\\nsimulating a random walk. The most common choice for g is a N(0,b\\n2). The\\nhard part is choosing b so that the chain mixes well. A good rule of thumb is:\\nchoose b so that you accept the proposals about 50 percent of the time.\\nWarning! This method doesn’t make sense unless X takes values on the\\nwhole real line. If X is restricted to some interval then it is best to transform\\nX. For example, if X ∈ (0,∞) then you might take Y = log X and then\\nsimulate the distribution for Y instead of X.\\nIndependence-Metropolis–Hastings. This is an importance-sampling\\nversion of MCMC. We draw the proposal from a ﬁxed distribution g. Gen-\\nerally, g is chosen to be an approximation to f. The acceptance probability\\nbecomes\\nr(x, y) = min\\n{\\n1, f(y)\\nf(x)\\ng(x)\\ng(y)\\n}\\n.\\nGibbs Sampling. The two previous methods can be easily adapted, in\\nprinciple, to work in higher dimensions. In practice, tuning the chains to make\\nthem mix well is hard. Gibbs sampling is a way to turn a high-dimensional\\nproblem into several one-dimensional problems.\\nHere’s how it works for a bivariate problem. Suppose that (X,Y ) has den-\\nsity f\\nX,Y (x, y). First, suppose that it is possible to simulate from the condi-\\ntional distributions fX|Y (x|y) and fY |X(y|x). Let (X0,Y0) be starting values.\\nAssume we have drawn (X0,Y0),..., (Xn,Yn). Then the Gibbs sampling al-\\ngorithm for getting (Xn+1,Yn+1) is:'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 431, 'page_label': '432'}, page_content='416 24. Simulation Methods\\nGibbs Sampling\\nXn+1 ∼ fX|Y (x|Yn)\\nYn+1 ∼ fY |X(y|Xn+1)\\nrepeat\\nThis generalizes in the obvious way to higher dimensions.\\n24.11 Example (Normal Hierarchical Model). Gibbs sampling is very useful\\nfor a class of models called hierarchical models. Here is a simple case.\\nSuppose we draw a sample of k cities. From each city we drawni people and\\nobserve how many people Yi have a disease. Thus, Yi ∼ Binomial(ni,p i). We\\nare allowing for diﬀerent disease rates in diﬀerent cities. We can also think of\\nthe p\\n′\\nis as random draws from some distribution F. We can write this model\\nin the following way:\\nPi ∼ F\\nYi|Pi = pi ∼ Binomial(ni,p i).\\nWe are interested in estimating thep′\\nis and the overall disease rate\\n∫\\npd F(p).\\nTo proceed, it will simplify matters if we make some transformations that\\nallow us to use some Normal approximations. Let ˆpi = Yi/ni. Recall that\\nˆpi ≈ N(pi,si) where si =\\n√\\nˆpi(1 − ˆpi)/ni. Let ψi = log( pi/(1 − pi)) and\\ndeﬁne Zi ≡ ˆψi = log(ˆpi/(1 − ˆpi)). By the delta method,\\nˆψi ≈ N(ψi,σ 2\\ni )\\nwhere σ2\\ni =1 /(nˆpi(1−ˆpi)). Experience shows that the Normal approximation\\nfor ψ is more accurate than the Normal approximation forp so we shall work\\nwith ψ. We shall treatσi as known. Furthermore, we shall take the distribution\\nof the ψ′\\nis to be Normal. The hierarchical model is now\\nψi ∼ N(µ, τ2)\\nZi|ψi ∼ N(ψi,σ 2\\ni ).\\nAs yet another simpliﬁcation we take τ = 1. The unknown parameter are\\nθ =( µ, ψ1,...,ψ k). The likelihood function is\\nL(θ) ∝\\n∏\\ni\\nf(ψi|µ)\\n∏\\ni\\nf(Zi|ψ)\\n∝\\n∏\\ni\\nexp\\n{\\n−1\\n2(ψi − µ)2\\n}\\nexp\\n{\\n− 1\\n2σ2\\ni\\n(Zi − ψi)2\\n}\\n.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 432, 'page_label': '433'}, page_content='24.5 MCMC Part II: Diﬀerent Flavors 417\\nIf we use the priorf(µ) ∝ 1 then the posterior is proportional to the likelihood.\\nTo use Gibbs sampling, we need to ﬁnd the conditional distribution of each\\nparameter conditional on all the others. Let us begin by ﬁnding f(µ|rest)\\nwhere “rest” refers to all the other variables. We can throw away any terms\\nthat don’t involve µ. Thus,\\nf(µ|rest) ∝\\n∏\\ni\\nexp\\n{\\n−1\\n2(ψi − µ)2\\n}\\n∝ exp\\n{\\n−k\\n2(µ − b)2\\n}\\nwhere\\nb = 1\\nk\\n∑\\ni\\nψi.\\nHence we see that µ|rest ∼ N(b, 1/k). Next we will ﬁnd f(ψ|rest). Again, we\\ncan throw away any terms not involving ψi leaving us with\\nf(ψi|rest) ∝ exp\\n{\\n−1\\n2(ψi − µ)2\\n}\\nexp\\n{\\n− 1\\n2σ2\\ni\\n(Zi − ψi)2\\n}\\n∝ exp\\n{\\n− 1\\n2d2\\ni\\n(ψi − ei)2\\n}\\nwhere\\nei =\\nZi\\nσ2\\ni\\n+ µ\\n1+ 1\\nσ2\\ni\\nand d2\\ni = 1\\n1+ 1\\nσ2\\ni\\nand so ψi|rest ∼ N(ei,d 2\\ni ). The Gibbs sampling algorithm then involves iter-\\nating the following steps N times:\\ndraw µ ∼ N(b, v2)\\ndraw ψ1 ∼ N(e1,d 2\\n1)\\n..\\n. ..\\n.\\ndraw ψ\\nk ∼ N(ek,d 2\\nk).\\nIt is understood that at each step, the most recently drawn version of each\\nvariable is used.\\nWe generated a numerical example with k = 20 cities and n = 20 people\\nfrom each city. After running the chain, we can convert each ψi back into pi\\nby way of pi = eψi /(1 +eψi ). The raw proportions are shown in Figure 24.4.\\nFigure 24.3 shows “trace plots” of the Markov chain for p1 and µ. Figure\\n24.4 shows the posterior for µ based on the simulated values. The second'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 433, 'page_label': '434'}, page_content='418 24. Simulation Methods\\npanel of Figure 24.4 shows the raw proportions and the Bayes estimates. Note\\nthat the Bayes estimates are “shrunk” together. The parameter τ controls\\nthe amount of shrinkage. We set τ = 1 but, in practice, we should treat τ as\\nanother unknown parameter and let the data determine how much shrinkage\\nis needed.\\n■\\n0 500 1000\\n0.0 0.5 1.0\\n0 500 1000\\n−0.5 0.0 0.5\\nFIGURE 24.3. Posterior simulation for Example 24.11. The top panel shows simu-\\nlated values of p1. The top panel shows simulated values of µ.\\nSo far we assumed that we know how to draw samples from the conditionals\\nfX|Y (x|y) and fY |X(y|x). If we don’t know how, we can still use the Gibbs\\nsampling algorithm by drawing each observation using a Metropolis–Hastings\\nstep. Let q be a proposal distribution forx and let ˜q be a proposal distribution\\nfor y. When we do a Metropolis step for X, we treat Y as ﬁxed. Similarly,\\nwhen we do a Metropolis step for Y , we treat X as ﬁxed. Here are the steps:'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 434, 'page_label': '435'}, page_content='24.5 MCMC Part II: Diﬀerent Flavors 419\\nMetropolis within Gibbs\\n(1a) Draw a proposal Z ∼ q(z|Xn).\\n(1b) Evaluate\\nr = min\\n{ f(Z,Y n)\\nf(Xn,Yn)\\nq(Xn|Z)\\nq(Z|Xn), 1\\n}\\n.\\n(1c) Set\\nXn+1 =\\n{\\nZ with probability r\\nXn with probability 1 − r.\\n(2a) Draw a proposal Z ∼ ˜q(z|Yn).\\n(2b) Evaluate\\nr = min\\n{ f(Xn+1,Z )\\nf(Xn+1,Yn)\\n˜q(Yn|Z)\\n˜q(Z|Yn), 1\\n}\\n.\\n(2c) Set\\nYn+1 =\\n{ Z with probability r\\nYn with probability 1 − r.\\nAgain, this generalizes to more than two dimensions.\\n−0.6 0.0 0.6\\n0.0 0.5 1.0\\nFIGURE 24.4. Example 24.11. Top panel: posterior histogram of µ. Lower panel:\\nraw proportions and the Bayes posterior estimates. The Bayes estimates have been\\nshrunk closer together than the raw proportions.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 435, 'page_label': '436'}, page_content='420 24. Simulation Methods\\n24.6 Bibliographic Remarks\\nMCMC methods go back to the eﬀort to build the atomic bomb in World War\\nII. They were used in various places after that, especially in spatial statistics.\\nThere was a new surge of interest in the 1990s that still continues. My main\\nreference for this chapter was Robert and Casella (1999). See also Gelman\\net al. (1995) and Gilks et al. (1998).\\n24.7 Exercises\\n1. Let\\nI =\\n∫ 2\\n1\\ne−x2/2\\n√\\n2π dx.\\n(a) Estimate I using the basic Monte Carlo method. Use N = 100,000.\\nAlso, ﬁnd the estimated standard error.\\n(b) Find an (analytical) expression for the standard error of your esti-\\nmate in (a). Compare to the estimated standard error.\\n(c) Estimate I using importance sampling. Takeg to be N(1.5,v 2) with\\nv = .1, v = 1 and v = 10. Compute the (true) standard errors in each\\ncase. Also, plot a histogram of the values you are averaging to see if\\nthere are any extreme values.\\n(d) Find the optimal importance sampling function g\\n∗. What is the\\nstandard error using g∗?\\n2. Here is a way to use importance sampling to estimate a marginal density.\\nLet fX,Y (x, y) be a bivariate density and let (X1,X 2),..., (XN ,YN ) ∼\\nfX,Y .\\n(a) Let w(x) be an arbitrary probability density function. Let\\nˆfX(x)= 1\\nN\\nN∑\\ni=1\\nfX,Y (x, Yi)w(Xi)\\nfX,Y (Xi,Yi) .\\nShow that, for each x,\\nˆfX(x)\\np\\n→ fX(x).\\nFind an expression for the variance of this estimator.\\n(b) Let Y ∼ N(0,1) and X|Y = y ∼ N(y, 1+ y2). Use the method in\\n(a) to estimate fX(x).'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 436, 'page_label': '437'}, page_content='24.7 Exercises 421\\n3. Here is a method called accept–reject sampling for drawing observa-\\ntions from a distribution.\\n(a) Suppose that f is some probability density function. Let g be any\\nother density and suppose that f(x) ≤ Mg(x) for all x, where M is a\\nknown constant. Consider the following algorithm:\\n(step 1): Draw X ∼ g and U ∼ Unif(0,1);\\n(step 2): If U ≤ f(X)/(Mg(X)) set Y = X, otherwise go back to step\\n1. (Keep repeating until you ﬁnally get an observation.)\\nShow that the distribution of Y is f.\\n(b) Let f be a standard Normal density and let g(x)=1 /(1 + x2)b e\\nthe Cauchy density. Apply the method in (a) to draw 1,000 observations\\nfrom the Normal distribution. Draw a histogram of the sample to verify\\nthat the sample appears to be Normal.\\n4. A random variable Z has a inverse Gaussian distribution if it has\\ndensity\\nf(z) ∝ z\\n−3/2 exp\\n{\\n−θ1z − θ2\\nz +2\\n√\\nθ1θ2 + log\\n\\uf8f6√\\n2θ2\\n\\uf8f7}\\n,z > 0\\nwhere θ1 > 0 and θ2 > 0 are parameters. It can be shown that\\nE(Z)=\\n√\\nθ2\\nθ1\\nand E\\n\\uf8f61\\nZ\\n\\uf8f7\\n=\\n√\\nθ1\\nθ2\\n+ 1\\n2θ2\\n.\\n(a) Let θ1 =1 .5 and θ2 = 2. Draw a sample of size 1,000 using the\\nindependence-Metropolis–Hastings method. Use a Gamma distribution\\nas the proposal density. To assess the accuracy, compare the mean ofZ\\nand 1/Z from the sample to the theoretical means Try diﬀerent Gamma\\ndistributions to see if you can get an accurate sample.\\n(b) Draw a sample of size 1,000 using the random-walk-Metropolis–\\nHastings method. Since z> 0 we cannot just use a Normal density.\\nOne strategy is this. Let W = log Z. Find the density of W. Use the\\nrandom-walk-Metropolis–Hastings method to get a sampleW\\n1,...,W N\\nand let Zi = eWi . Assess the accuracy of the simulation as in part (a).\\n5. Get the heart disease data from the book web site. Consider a Bayesian\\nanalysis of the logistic regression model\\nP(Y =1 |X = x)= eβ0+∑ k\\nj=1 βjxj\\n1+ eβ0+∑ k\\nj=1 βjxj\\n.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 437, 'page_label': '438'}, page_content='422 24. Simulation Methods\\nUse the ﬂat priorf(β0,...,β k) ∝ 1. Use the Gibbs–Metropolis algorithm\\nto draw a sample of size 10,000 from the posterior f(β0,β1|data). Plot\\nhistograms of the posteriors for the βj’s. Get the posterior mean and a\\n95 percent posterior interval for each βj.\\n(b) Compare your analysis to a frequentist approach using maximum\\nlikelihood.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 438, 'page_label': '439'}, page_content='Bibliography\\nAgresti, A. (1990). Categorical Data Analysis. Wiley.\\nAkaike, H. (1973). Information theory and an extension of the maximum\\nlikelihood principle. Second International Symposium on Information The-\\nory 267–281.\\nAnderson, T. W.(1984). An Introduction to Multivariate Statistical Anal-\\nysis (Second Edition). Wiley.\\nBarron, A., Schervish, M. J. and Wasserman, L. (1999). The consis-\\ntency of posterior distributions in nonparametric problems. The Annals of\\nStatistics 27 536–561.\\nBeecher, H. (1959). Measurement of Subjective Responses. Oxford Univer-\\nsity Press.\\nBenjamini, Y. and Hochberg, Y. (1995). Controlling the false discovery\\nrate: A practical and powerful approach to multiple testing.Journal of the\\nRoyal Statistical Society, Series B, Methodological57 289–300.\\nBeran, R. (2000). REACT scatterplot smoothers: Supereﬃciency through\\nbasis economy.Journal of the American Statistical Association95 155–171.\\nBeran, R. and D¨umbgen, L. (1998). Modulation of estimators and conﬁ-\\ndence sets. The Annals of Statistics 26 1826–1856.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 439, 'page_label': '440'}, page_content='424 Bibliography\\nBerger, J. and Wolpert, R. (1984). The Likelihood Principle. Institute\\nof Mathematical Statistics.\\nBerger, J. O. (1985). Statistical Decision Theory and Bayesian Analysis\\n(Second Edition). Springer-Verlag.\\nBerger, J. O.and Delampady, M.(1987). Testing precise hypotheses (c/r:\\nP335-352). Statistical Science 2 317–335.\\nBerliner, L. M.(1983). Improving on inadmissible estimators in the control\\nproblem. The Annals of Statistics 11 814–826.\\nBickel, P. J. and Doksum, K. A. (2000). Mathematical Statistics: Basic\\nIdeas and Selected Topics, Vol. I (Second Edition). Prentice Hall.\\nBillingsley, P. (1979). Probability and Measure. Wiley.\\nBishop, Y. M. M., Fienberg, S. E.and Holland, P. W.(1975). Discrete\\nMultivariate Analyses: Theory and Practice. MIT Press.\\nBreiman, L. (1992). Probability. Society for Industrial and Applied Mathe-\\nmatics.\\nBrinegar, C. S. (1963). Mark Twain and the Quintus Curtius Snodgrass\\nletters: A statistical test of authorship. Journal of the American Statistical\\nAssociation 58 85–96.\\nCarlin, B. P.and Louis, T. A.(1996). Bayes and Empirical Bayes Methods\\nfor Data Analysis. Chapman & Hall.\\nCasella, G. and Berger, R. L. (2002). Statistical Inference. Duxbury\\nPress.\\nChaudhuri, P.and Marron, J. S.(1999). Sizer for exploration of structures\\nin curves. Journal of the American Statistical Association 94 807–823.\\nCox, D. and Lewis, P. (1966). The Statistical Analysis of Series of Events.\\nChapman & Hall.\\nCox, D. D. (1993). An analysis of Bayesian inference for nonparametric\\nregression. The Annals of Statistics 21 903–923.\\nCox, D. R.and Hinkley, D. V.(2000). Theoretical statistics. Chapman &\\nHall.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 440, 'page_label': '441'}, page_content='425\\nDavison, A. C.and Hinkley, D. V.(1997). Bootstrap Methods and Their\\nApplication. Cambridge University Press.\\nDeGroot, M. and Schervish, M.(2002). Probability and Statistics (Third\\nEdition). Addison-Wesley.\\nDevroye, L., Gy¨orfi, L. and Lugosi, G. (1996). A Probabilistic Theory\\nof Pattern Recognition. Springer-Verlag.\\nDiaconis, P. and Freedman, D. (1986). On inconsistent Bayes estimates\\nof location. The Annals of Statistics 14 68–87.\\nDobson, A. J.(2001). An introduction to generalized linear models. Chap-\\nman & Hall.\\nDonoho, D. L.and Johnstone, I. M.(1994). Ideal spatial adaptation by\\nwavelet shrinkage. Biometrika 81 425–455.\\nDonoho, D. L. and Johnstone, I. M. (1995). Adapting to unknown\\nsmoothness via wavelet shrinkage. Journal of the American Statistical As-\\nsociation 90 1200–1224.\\nDonoho, D. L. and Johnstone, I. M. (1998). Minimax estimation via\\nwavelet shrinkage. The Annals of Statistics 26 879–921.\\nDonoho, D. L., Johnstone, I. M., Kerkyacharian, G.and Picard, D.\\n(1995). Wavelet shrinkage: Asymptopia? (Disc: p 337–369). Journal of the\\nRoyal Statistical Society, Series B, Methodological57 301–337.\\nDunsmore, I., D a l y ,F .e ta l .(1987). M345 Statistical Methods, Unit 9:\\nCategorical Data. The Open University.\\nEdwards, D.(1995). Introduction to graphical modelling. Springer-Verlag.\\nEfromovich, S.(1999). Nonparametric Curve Estimation: Methods, Theory\\nand Applications. Springer-Verlag.\\nEfron, B. (1979). Bootstrap methods: Another look at the jackknife. The\\nAnnals of Statistics 7 1–26.\\nEfron, B., Tibshirani, R., Storey, J. D. and Tusher, V. (2001). Em-\\npirical Bayes analysis of a microarray experiment.Journal of the American\\nStatistical Association 96 1151–1160.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 441, 'page_label': '442'}, page_content='426 Bibliography\\nEfron, B.and Tibshirani, R. J.(1993). An Introduction to the Bootstrap.\\nChapman & Hall.\\nFerguson, T. (1967). Mathematical Statistics:aD e cision Theoretic Ap-\\nproach. Academic Press.\\nFisher, R. (1921). On the probable error of a coeﬃcient of correlation de-\\nduced from a small sample. Metron 1 1–32.\\nFreedman, D. (1999). Wald lecture: On the Bernstein-von Mises theorem\\nwith inﬁnite-dimensional parameters. The Annals of Statistics 27 1119–\\n1141.\\nFriedman, J. H. (1997). On bias, variance, 0/1-loss, and the curse-of-\\ndimensionality. Data Mining and Knowledge Discovery 1 55–77.\\nGelman, A., Carlin, J. B., Stern, H. S. and Rubin, D. B. (1995).\\nBayesian Data Analysis. Chapman & Hall.\\nGhosal, S., Ghosh, J. K. and Van Der Vaart, A. W.(2000). Conver-\\ngence rates of posterior distributions. The Annals of Statistics 28 500–531.\\nGilks, W. R., Richardson, S.and Spiegelhalter, D. J.(1998). Markov\\nChain Monte Carlo in Practice. Chapman & Hall.\\nGrimmett, G. and Stirzaker, D. (1982). Probability and Random Pro-\\ncesses. Oxford University Press.\\nGuttorp, P. (1995). Stochastic Modeling of Scientiﬁc Data. Chapman &\\nHall.\\nHall, P. (1992). The Bootstrap and Edgeworth Expansion. Springer-Verlag.\\nHalverson, N., Leitch, E., Pryke, C., Kovac, J., Carlstrom, J.,\\nHolzapfel, W., Dragovan, M., Cartwright, J., Mason, B., Padin,\\nS., Pearson, T., Shepherd, M. and Readhead, A. (2002). DASI ﬁrst\\nresults: A measurement of the cosmic microwave background angular power\\nspectrum. Astrophysics Journal 568 38–45.\\nHardle, W. (1990). Applied nonparametric regression. Cambridge Univer-\\nsity Press.\\nH¨ardle, W., Kerkyacharian, G., Picard, D.and Tsybakov, A.(1998).\\nWavelets, Approximation, and Statistical Applications. Springer-Verlag.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 442, 'page_label': '443'}, page_content='427\\nHastie, T., Tibshirani, R. and Friedman, J. H. (2001). The Elements\\nof Statistical Learning: Data Mining, Inference, and Prediction. Springer-\\nVerlag.\\nHerbich, R. (2002). Learning Kernel Classiﬁers: Theory and Algorithms .\\nMIT Press.\\nJohnson, R. A.and Wichern, D. W.(1982). Applied Multivariate Statis-\\ntical Analysis. Prentice-Hall.\\nJohnson, S. and Johnson, R. (1972). New England Journal of Medicine\\n287 1122–1125.\\nJordan, M. (2004). Graphical models. In Preparation.\\nKarr, A. (1993). Probability. Springer-Verlag.\\nKass, R. E. and Raftery, A. E. (1995). Bayes factors. Journal of the\\nAmerican Statistical Association 90 773–795.\\nKass, R. E.and Wasserman, L.(1996). The selection of prior distributions\\nby formal rules (corr: 1998 v93 p 412). Journal of the American Statistical\\nAssociation 91 1343–1370.\\nLarsen, R. J. and Marx, M. L. (1986). An Introduction to Mathematical\\nStatistics and Its Applications (Second Edition). Prentice Hall.\\nLauritzen, S. L.(1996). Graphical Models. Oxford University Press.\\nLee, A. T. et al.(2001). A high spatial resolution analysis of the maxima-1\\ncosmic microwave background anisotropy data. Astrophys. J. 561 L1–L6.\\nLee, P. M.(1997). Bayesian Statistics: An Introduction. Edward Arnold.\\nLehmann, E. L. (1986). Testing Statistical Hypotheses (Second Edition) .\\nWiley.\\nLehmann, E. L. and Casella, G. (1998). Theory of Point Estimation.\\nSpringer-Verlag.\\nLoader, C. (1999). Local regression and likelihood. Springer-Verlag.\\nMarron, J. S. and Wand, M. P.(1992). Exact mean integrated squared\\nerror. The Annals of Statistics 20 712–736.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 443, 'page_label': '444'}, page_content='428 Bibliography\\nMorrison, A., Black, M., Lowe, C., Macmahon, B. and Yusa, S.\\n(1973). Some international diﬀerences in histology and survival in breast\\ncancer. International Journal of Cancer 11 261–267.\\nNetterfield, C. B. et al.(2002). A measurement by boomerang of mul-\\ntiple peaks in the angular power spectrum of the cosmic micr owave back-\\nground. Astrophys. J. 571 604–614.\\nOgden, R. T. (1997). Essential Wavelets for Statistical Applications and\\nData Analysis. Birkh¨auser.\\nPearl, J. (2000). Casuality: models, reasoning, and inference. Cambridge\\nUniversity Press.\\nPhillips, D. and King, E. (1988). Death takes a holiday: Mortality sur-\\nrounding major social occasions. Lancet 2 728–732.\\nPhillips, D. and Smith, D. (1990). Postponement of death until symbol-\\nically meaningful occasions. Journal of the American Medical Association\\n263 1947–1961.\\nQuenouille, M. (1949). Approximate tests of correlation in time series.\\nJournal of the Royal Statistical Society B 11 18–84.\\nRice, J. A.(1995). Mathematical Statistics and Data Analysis (Second Edi-\\ntion). Duxbury Press.\\nRobert, C. P.(1994). The Bayesian Choice: A Decision-theoretic Motiva-\\ntion. Springer-Verlag.\\nRobert, C. P.and Casella, G. (1999). Monte Carlo Statistical Methods.\\nSpringer-Verlag.\\nRobins, J., Scheines, R., Spirtes, P.and Wasserman, L.(2003). Uniform\\nconvergence in causal inference. Biometrika (to appear).\\nRobins, J. M.and Ritov, Y. (1997). Toward a curse of dimensionality ap-\\npropriate (CODA) asymptotic theory for semi-parametric models.Statistics\\nin Medicine 16 285–319.\\nRosenbaum, P. (2002). Observational Studies. Springer-Verlag.\\nRoss, S. (2002). Probability Models for Computer Science. Academic Press.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 444, 'page_label': '445'}, page_content='429\\nRousseauw, J., du Plessis, J., Benade, A., Jordaan, P., Kotze, J.,\\nJooste, P. and Ferreira, J. (1983). Coronary risk factor screening in\\nthree rural communities. South African Medical Journal 64 430–436.\\nSchervish, M. J.(1995). Theory of Statistics. Springer-Verlag.\\nScholkopf, B. and Smola, A. (2002). Learning with Kernels: Support\\nVector Machines, Regularization, Optimization, and Beyond. MIT Press.\\nSchwarz, G. (1978). Estimating the dimension of a model. The Annals of\\nStatistics 6 461–464.\\nScott, D., Gotto, A., Cole, J. and Gorry, G. (1978). Plasma lipids as\\ncollateral risk factors in coronary artery disease: a study of 371 males with\\nchest pain. Journal of Chronic Diseases 31 337–345.\\nScott, D. W. (1992). Multivariate Density Estimation: Theory, Practice,\\nand Visualization. Wiley.\\nShao, J. and Tu, D. (1995). The Jackknife and Bootstrap (German) .\\nSpringer-Verlag.\\nShen, X. and Wasserman, L. (2001). Rates of convergence of posterior\\ndistributions. The Annals of Statistics 29 687–714.\\nShorack, G. R. and Wellner, J. A. (1986). Empirical Processes With\\nApplications to Statistics. Wiley.\\nSilverman, B. W.(1986). Density Estimation for Statistics and Data Anal-\\nysis. Chapman & Hall.\\nSpirtes, P., Glymour, C. N.and Scheines, R.(2000). Causation, predic-\\ntion, and search. MIT Press.\\nTaylor, H. M.and Karlin, S. (1994). An Introduction to Stochastic Mod-\\neling. Academic Press.\\nvan der Laan, M.and Robins, J. (2003). Uniﬁed Methods for Censored\\nLongitudinal Data and Causality. Springer Verlag.\\nvan der Vaart, A. W.(1998). Asymptotic Statistics. Cambridge University\\nPress.\\nvan der Vaart, A. W.and Wellner, J. A. (1996). Weak Convergence\\nand Empirical Processes: With Applications to Statistics. Springer-Verlag.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 445, 'page_label': '446'}, page_content='430 Bibliography\\nVapnik, V. N.(1998). Statistical Learning Theory. Wiley.\\nWeisberg, S. (1985). Applied Linear Regression. Wiley.\\nWhittaker, J. (1990). Graphical Models in Applied Multivariate Statistics.\\nWiley.\\nWright, S. (1934). The method of path coeﬃcients. The Annals of Mathe-\\nmatical Statistics 5 161–215.\\nZhao, L. H.(2000). Bayesian aspects of some nonparametric problems. The\\nAnnals of Statistics 28 532–552.\\nZheng, X. and Loh, W.-Y. (1995). Consistent variable selection in linear\\nmodels. Journal of the American Statistical Association 90 151–156.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 446, 'page_label': '447'}, page_content='List of Symbols\\nGeneral Symbols\\nR real numbers\\ninfx∈A f(x) inﬁmum: the largest number y such that\\ny ≤ f(x) for all x ∈ A\\nthink of this as the minimum of f\\nsupx∈A f(x) supremum: the smallest number y such that\\ny ≥ f(x) for all x ∈ A\\nthink of this as the maximum of f\\nn! n × (n − 1) × (n − 2) ×···× 3 × 2 × 1\\uf8f6n\\nk\\n\\uf8f7 n!\\nk!(n−k)!\\nΓ(α) Gamma function\\n∫∞\\n0 yα−1e−ydy\\nΩ sample space (set of outcomes)\\nω outcome, element, point\\nA event (subset of Ω)\\nIA(ω) indicator function; 1 if ω ∈ A and 0 otherwise\\n|A| number of points in set A\\nProbability Symbols\\nP(A) probability of event A\\nA ⨿ BA and B are independent\\nA /gluonbelement/gluonelement/gluonelement/gluonelement/gluonelement/gluoneelementBA and B are dependent\\nFX cumulative distribution function\\nF\\nX(x)= P(X ≤ x)\\nfX probability density (or mass) function\\nX ∼ FX has distribution F\\nX ∼ fX has density f\\nX\\nd\\n= YX and Y have the same distribution\\niid independent and identically distributed\\nX1,...,X n ∼ F iid sample of size n from F\\nφ standard Normal probability density\\nΦ standard Normal distribution function\\nz\\nα upper α quantile of N(0,1): zα =Φ −1(1 − α)\\nE(X)=\\n∫\\nxd F(x) expected value (mean) of random variable X\\nE(r(X)) =\\n∫\\nr(x)dF(x) expected value (mean) of r(X)\\nV(X) variance of random variable X\\nCov(X,Y ) covariance between X and Y\\nX1,...,X n data\\nn sample size'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 447, 'page_label': '448'}, page_content='432 List of Symbols\\nConvergence Symbols\\nP\\n−→ convergence in probability\\n⇝ convergence in distribution\\nqm\\n−→ convergence in quadratic mean\\nXn ≈ N(µ, σ2\\nn)( Xn − µ)/σn ⇝ N(0,1)\\nxn = o(an) xn/an → 0\\nxn = O(an) |xn/an| is bounded for large n\\nXn = oP (an) Xn/an\\nP\\n−→0\\nXn = OP (an) |Xn/an| is bounded in probability for large n\\nStatistical Models\\nF statistical model; a set of distribution functions,\\ndensity functions or regression functions\\nθ parameter\\nˆθ estimate of parameter\\nT(F) statistical functional (the mean, for example)\\nLn(θ) likelihood function\\nUseful Math Facts\\nex = ∑ ∞\\nk=0\\nxk\\nk! =1+ x + x2\\n2! + ···\\n∑ ∞\\nj=k rj = rk\\n1−r for 0 <r< 1\\nlimn→∞\\n\\uf8f6\\n1+ a\\nn\\n\\uf8f7n\\n= ea\\nStirling’s approximation: n! ≈ nne−n√\\n2πn\\nThe Gamma function. The Gamma function is deﬁned by\\nΓ(α)=\\n∫ ∞\\n0\\nyα−1e−ydy\\nfor α ≥ 0. If α> 1 then Γ(α)=( α−1)Γ(α−1). If n is a positive integer then\\nΓ(n)=( n − 1)!. Some special values are: Γ(1) = 1 and Γ(1/2) = √π.'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 448, 'page_label': '449'}, page_content='Table of Distributions\\nList of Symbols 433\\nDistribution\\n pdf or probability function\\n mean\\n variance\\n mgf\\nPoint mass ata\\n I(x = a)\\n a\\n 0\\n eat\\nBernoulli(p)\\n px(1 − p)1−x\\n p\\n p(1 − p)\\n pet +( 1− p)\\nBinomial(n, p)\\n(n\\nx\\n)\\npx(1 − p)n−x\\n np\\n np(1 − p)\\n (pet +( 1− p))n\\nGeometric(p)\\n p(1 − p)x−1I(x ≥ 1)\\n 1/p\\n 1−p\\np2\\npet\\n1−(1−p)et\\n(\\nt< −log(1 − p)\\n)\\nPoisson(λ)\\n λxe−λ\\nx!\\n λ\\n λ\\n eλ(et−1)\\nUniform(a, b)\\n I(a<x<b )/(b − a)\\n a+b\\n2\\n(b−a)2\\n12\\nebt−eat\\n(b−a)t\\nNormal(µ, σ2)\\n 1\\nσ\\n√\\n2π e−(x−µ)2/(2σ2)\\n µ\\n σ2\\n exp\\n{\\nµt + σ2t2\\n2\\n}\\nExponential(β)\\n e−x/β\\nβ\\n β\\n β2\\n 1\\n1−βt\\n(\\nt< 1/β\\n)\\nGamma(α, β)\\n xα−1e−x/β\\nΓ(α)βα\\n αβ\\n αβ2\\n(\\n1\\n1−βt\\n)α\\n(t< 1/β)\\nBeta(α, β)\\n Γ(α+β)\\nΓ(α)Γ(β)xα−1(1 − x)β−1\\n α\\nα+β\\nαβ\\n(α+β)2(α+β+1)\\n 1+ ∑ ∞\\nk=1\\n(∏ k−1\\nr=0\\nα+r\\nα+β+r\\n)\\ntk\\nk!\\ntν\\nΓ(ν+1\\n2 )\\nΓ(ν\\n2 )\\n1\\n(\\n1+x2\\nν\\n)(ν+1)/2 .\\n 0( i fν> 1)\\n ν\\nν−2 (if ν> 2)\\n does not exist\\nχ2\\np\\n1\\nΓ(p/2)2p/2 x(p/2)−1e−x/2\\n p\\n 2p\\n(\\n1\\n1−2t\\n)p/2 (\\nt< 1/2\\n)'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 449, 'page_label': '450'}, page_content='Index\\nχ2 distribution, 30\\naccept-reject sampling, 421\\naccessible, 387\\nactions, 193\\nacyclic, 266\\nadditive regression, 323\\nadjacent, 281\\nadjusted treatment eﬀect, 259\\nadmissibility\\nBayes rules, 202\\nadmissible, 202\\nAIC (Akaike Information Criterion),\\n220\\nAliens, 271\\nalternative hypothesis, 95, 149\\nancestor, 265\\naperiodic, 390\\narcs, 281\\nassociated, 239\\nassociation, 253\\nassociation is not causation, 16.1,\\n253\\nassume, 8\\nasymptotic Normality, 128\\nasymptotic theory, 71\\nasymptotically Normal, 92\\n, 126\\nasymptotically optimal, 126\\nasymptotically uniformly integrable,\\n81\\naverage causal eﬀect, 252\\naverage treatment eﬀect, 252\\nAxiom 1, 5\\nAxiom 2, 5\\nAxiom 3, 5\\naxioms of probability, 5\\nbackﬁtting, 324\\nbagging, 375\\nbandwidth, 313\\nBayes classiﬁcation rule, 351\\nBayes Estimators, 197\\nBayes risk, 195'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 450, 'page_label': '451'}, page_content='Index 435\\nBayes rules, 197\\nadmissibility, 202\\nBayes’ Theorem, 12, 1.17,1 2\\nBayesian inference, 89, 175\\nstrengths and weaknesses, 185\\nBayesian network, 263\\nBayesian philosophy, 175\\nBayesian testing, 184\\nBenjamini and Hochberg,10.26, 167\\nBenjamini-Hochberg (BH) method,\\n167\\nBernoulli distribution, 26\\n,2 9\\nBeta distribution, 30\\nbias-variance tradeoﬀ, 305\\nBibliographic Remarks, 13\\nBinomial distribution, 26\\nbins, 303, 306\\nbinwidth, 306\\nbivariate distribution, 31\\nBonferroni method, 166\\nboosting, 375\\nbootstrap, 107\\nparametric, 134\\nBootstrap Conﬁdence Intervals, 110\\nbootstrap percentile interval, 111\\nbootstrap pivotal conﬁdence, 111\\nBootstrap variance estimation, 109\\nbranching process, 398\\ncandidate, 411\\nCauchy distribution, 30\\nCauchy-Schwartz inequality,4.8,6 6\\ncausal odds ratio, 252\\ncausal regression function, 256\\ncausal relative risk, 253\\nCentral Limit Theorem (CLT),5.8,\\n77\\nChapman-Kolmogorov equations,23.9,\\n385\\nChebyshev’s inequality, 4.2,6 4\\nchecking assumptions, 135\\nchild, 265\\nclasses, 387\\nclassiﬁcation, 349\\nclassiﬁcation rule, 349\\nclassiﬁcation trees, 360\\nclassiﬁer\\nassessing error rate, 362\\nclique, 285\\nclosed, 388\\nCLT, 77\\ncollider, 265\\ncomparing risk functions, 194\\ncomplete, 281, 328\\ncomposite hypothesis, 151\\nComputer Experiment, 16, 17\\nconcave, 66\\nconditional causal eﬀect, 255\\nconditional distribution, 36\\nconditional expectation, 54\\nconditional independence, 264\\nminimal, 287\\nconditional likelihood, 213\\nConditional Probability, 10\\nconditional probability, 10, 10\\nconditional probability density func-\\ntion, 37\\nconditional probability mass func-\\ntion, 36\\nconditioning by intervention, 274\\nconditioning by observation, 274\\nconﬁdence band, 99\\nconﬁdence bands, 323\\nconﬁdence interval, 65, 92\\nconﬁdence set, 92\\nconfounding variables, 257\\nconjugate, 179'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 451, 'page_label': '452'}, page_content='436 Index\\nconsistency relationship, 252\\nconsistent, 90, 126\\ncontinuity of probabilities, 1.8,7\\ncontinuous, 23\\nconverges in distribution, 72\\nconverges in probability, 72\\nconvex, 66\\ncorrelation, 52\\nconﬁdence interval, 234\\ncosine basis, 329\\ncounterfactual, 251, 252\\ncounting process, 395\\ncovariance, 52\\ncovariance matrix, 232\\ncovariate, 209\\ncoverage, 92\\ncritical value, 150\\ncross-validation, 363\\ncross-validation estimator of risk,\\n310\\ncumulative distribution function, 20\\ncurse of dimensionality, 319\\ncurve estimation, 89, 303\\nd-connected, 270\\nd-separated, 270\\nDAG, 266\\ndata mining, vii\\ndecision rule, 193\\ndecision theory, 193\\ndecomposition theorem, 23.17, 389\\ndelta method, 5.13, 79, 131\\ndensity estimation, 312\\nkernel approach, 312\\northogonal function approach,\\n331\\ndependent, 34\\n, 239\\ndependent variable, 89\\nderive, 8\\ndescendant, 265\\ndetail coeﬃcients, 342\\ndetailed balance, 391, 413\\ndeviance, 299\\ndirected acyclic graph, 266\\ndirected graph, 264\\ndirected path, 265\\ndiscrete, 22\\ndiscrete uniform distribution, 26\\ndiscrete wavelet transform (DWT),\\n344\\ndiscriminant function, 354\\ndiscrimination, 349\\ndisjoint, 5\\ndistribution\\nχ\\n2,3 0\\nBernoulli, 26,2 9\\nBeta, 30\\nBinomial, 26\\nCauchy, 30\\nconditional, 36\\ndiscrete uniform, 26\\nGaussian, 28\\nGeometric, 26\\nMultinomial, 39\\nmultivariate Normal, 39\\nNormal, 28\\npoint mass, 26\\nPoisson, 27\\nt, 30\\nUniform, 27\\nDvoretzky-Kiefer-Wolfowitz (DKW)\\ninequality, 7.5,9 8\\nedges, 281\\neﬃcient, 126, 131\\nelements, 3\\nEM algorithm, 144\\nempirical distribution function, 97'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 452, 'page_label': '453'}, page_content='Index 437\\nempirical error rate, 351\\nempirical probability measure, 367\\nempirical risk minimization, 352, 365\\nEpanechnikov kernel, 312\\nequal in distribution, 25\\nequivariant, 126\\nergodic, 390\\nEvents, 3\\nevents, 3\\nevidence, 157\\nExercises, 13\\nexpectation, 47\\nconditional, 54\\nexpected value, 47\\nexponential families, 140\\nfaithful, 270\\nfalse discovery proportion, 166\\nfalse discovery rate, 166\\nFDP, 166\\nFDR, 166\\nfeature, 89, 209\\nﬁrst moment, 47\\nﬁrst quartile, 25\\nFisher information, 128\\nFisher information matrix, 133\\nFisher linear discriminant function,\\n356\\nﬁtted line, 210\\nﬁtted values, 210\\nfrequentist (or classical), 175\\nfrequentist inference, 89\\nGamma function, 29\\nGaussian classiﬁer, 353\\nGaussian distribution, 28\\nGeometric distribution, 26\\nGibbs sampling, 416\\nGini index, 361\\nGlivenko-Cantelli theorem, 7.4,9 8\\ngoodness-of-ﬁt tests, 168\\ngraphical, 294\\ngraphical log-linear models, 294\\nHaar father wavelet, 340\\nHaar scaling function, 340\\nHaar wavelet regression, 343\\nhierarchical log-linear model, 296\\nhierarchical model, 56\\nhierarchical models, 416\\nhistogram, 303, 305\\nhistogram estimator, 306\\nHoeﬀding’s inequality, 4.4, 64, 365\\nhomogeneous, 384\\nhomogeneous Poisson process, 396\\nHorwitz-Thompson, 188\\nhypothesis testing, 94\\nidentiﬁable, 126\\nimportance sampling, 408\\nimpurity, 360\\ninadmissible, 202\\nindependent, 8, 8,3 4\\nIndependent Events, 8\\nindependent random variables, 34\\nindependent variable, 89\\nindex set, 381\\nindicator function, 5\\ninequalities, 63\\ninner product, 327\\nintegrated squared error (ISE), 304\\nintensity function, 395\\ninterarrival times, 396\\nintervene, 273\\nintervention, 273\\nIntroduction, 3\\ninvariant, 390\\ninverse Gaussian distribution, 421'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 453, 'page_label': '454'}, page_content='438 Index\\nirreducible, 388\\niterated expectations, 3.24,5 5\\njackknife, 115\\nJames-Stein estimator, 204\\nJeﬀreys-Lindley paradox, 192\\nJensen’s inequality, 4.9,6 6\\njoint mass function, 31\\nK-fold cross-validation, 364\\nk-nearest-neighbors, 375\\nkernel, 312\\nkernel density estimator, 312,313\\nkernelization, 371\\nKolmogorov-Smirnov test, 245\\nKullback-Leibler distance, 126\\nLaplace transform, 56\\nlarge sample theory, 71\\nlaw of large numbers, 72\\nlaw of total probability, 1.16,1 2\\nlazy, 3.6,4 8\\nleast favorable prior, 198\\nleast squares estimates, 211\\nleave-one-out cross-validation, 220\\nleaves, 361\\nLegendre polynomials, 329\\nlength, 327\\nlevel, 150\\nlikelihood function, 122\\nlikelihood ratio statistic, 164\\nlikelihood ratio test, 164\\nlimit theory, 71\\nlimiting distribution, 391\\nlinear algebra notation, 231\\nlinear classiﬁer, 353\\nlinearly separable, 369\\nlog odds ratio, 240\\nlog-likelihood function, 122\\nlog-linear expansion, 292\\nlog-linear model, 286\\nlog-linear models, 291\\nlogistic regression, 223\\nloss function, 193\\nmachine learning, vii\\nManalahobis distance, 353\\nmarginal Distribution, 33\\nmarginal distribution, 197\\nMarkov chain, 383, 383\\nMarkov condition, 267\\nMarkov equivalent, 271\\nMarkov’s inequality,4.1,6 3\\nmaximal clique, 285\\nmaximum likelihood, 122\\nmaximum likelihood estimates\\ncomputing, 142\\nmaximum likelihood estimator\\nconsistent, 126\\nmaximum risk, 195\\nmean, 47\\nmean integrated squared error (MISE),\\n304\\nmean recurrence time, 390\\nmean squared error, 91\\nmeasurable, 13, 43\\nmedian, 25\\nbootstrap, 109\\nMercer’s theorem, 373\\nmethod of moments estimator, 121\\nMetropolis within Gibbs, 419\\nMetropolis–Hastings algorithm, 411\\nMill’s inequality, 4.7,6 5\\nminimal conditional independence,\\n287\\nminimal suﬃcient, 138\\nminimax rule, 197, 198\\nmissing data, 187'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 454, 'page_label': '455'}, page_content='Index 439\\nmixture of Normals, 143\\nmodel generator, 297\\nmodel selection, 218\\nmoment generating function, 56\\nmoments, 49\\nmonotone decreasing, 5\\nmonotone increasing, 5\\nMonte Carlo integration, 404\\nMonte Carlo integration method,\\n404\\nMonty Hall, 14\\nmost powerful, 152\\nmother Haar wavelet, 341\\nMSE, 91\\nMultinomial, 235\\nMultinomial distribution, 39\\nmultiparameter models, 133\\nmultiple regression, 216\\nmultiple testing, 165\\nmultiresolution analysis, 341\\nMultivariate central limit theorem,\\n5.12,7 8\\nMultivariate Delta Method, 5.15,\\n79\\nmultivariate Normal, 234\\nmultivariate Normal distribution, 39\\nmutually exclusive, 5\\nNadaraya-Watson kernel estimator,\\n319\\nnaive Bayes classiﬁer, 359\\nnatural parameter, 141\\nnatural suﬃcient statistic, 140\\nneural networks, 376\\nNewton-Raphson, 143\\nNeyman-Pearson, 10.30, 170\\nnodes, 281\\nnon-collider, 265\\nnon-null, 390\\nnonparametric model, 88\\nnonparametric regression, 319\\nkernel approach, 319\\northogonal function approach,\\n337\\nnorm, 327\\nnormal, 327\\nNormal distribution, 28\\nNormal-based conﬁdence interval,\\n6.16,9 4\\nnormalizing constant, 177, 403\\nnot, 10\\nnuisance parameter, 120\\nnuisance parameters, 88\\nnull, 390\\nnull hypothesis, 94, 149\\nobservational studies, 257\\nodds ratio, 240\\nolive statistics, i\\none-parameter exponential family,\\n140\\none-sided test, 151\\noptimality, 130\\northogonal, 327\\northogonal functions, 327\\northonormal, 328\\northonormal basis, 328\\noutcome, 89\\noverﬁtting, 218\\np-value, 156, 157\\npairwise Markov graph, 283\\nparameter of interest, 120\\nparameter space, 88\\nparameters, 26\\nparametric bootstrap, 134\\nparametric model, 87\\nparent, 265'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 455, 'page_label': '456'}, page_content='440 Index\\nParseval’s relation, 329\\npartition, 5\\npath, 281\\nPearson’s χ\\n2 test, 241\\nperiod, 390\\nperiodic, 390\\npermutation distribution, 162\\npermutation test, 161\\npermutation test:algorithm, 163\\nperpendicular, 327\\npersistent, 388\\npivot, 110\\nplug-in estimator, 99\\npoint estimation, 90\\npoint mass distribution, 26\\npointwise asymptotic, 95\\nPoisson distribution, 27\\nPoisson process, 394, 395\\npositive deﬁnite, 231\\nposterior, 176\\nlarge sample properties, 181\\nposterior risk, 197\\npotential, 285\\npotential outcomes, 251\\npower function, 150\\nprecision matrix, 232\\npredicted values, 210\\nprediction, 89, 215\\nprediction interval, 13.11, 215\\nprediction risk, 219\\npredictor, 89\\npredictor variable, 209\\nprior distribution, 176\\nProbability, 5\\nprobability, 5\\nprobability distribution, 5, 5\\nprobability function, 22\\nprobability inequalities, 63\\nprobability mass function, 22\\nprobability measure, 5, 5\\nProbability on Finite Sample Spaces,\\n7\\nproposal, 411\\nquadratic discriminant analysis (QDA),\\n353\\nquantile function, 25\\nquantiles, 102\\nrandom variable, 19\\nindependent, 34\\nrandom vector, 38, 232\\nrandom walk, 59\\nrandom-walk-Metropolis-Hastings,\\n415\\nrealizations, 3\\nrecurrence time, 390\\nrecurrent, 388\\nregression, 89, 209, 335\\nnonparametric, 319\\nregression function, 89, 209, 351\\nregression through the origin, 226\\nregressor, 89\\nrejection region, 150\\nrelative risk, 248\\nrepresents, 266\\nresidual sums of squares, 211\\nresiduals, 210\\nresponse variable, 89, 209\\nreweighted least squares, 224\\nrisk, 194\\n, 304\\nrule of the lazy statistician,3.6,4 8\\nRules of d-separation, 270\\nsample correlation, 102\\nsample mean, 51\\nsample outcomes, 3'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 456, 'page_label': '457'}, page_content='Index 441\\nsample quantile, 102\\nsample space, 3\\nSample Spaces and Events, 3\\nsample variance, 51\\nsampling distribution, 90\\nsaturated model, 298, 299\\nscaling coeﬃcient, 342\\nscore function, 128\\nse, 90\\nshatter coeﬃcient, 367\\nshattered, 367\\nsimple hypothesis, 151\\nsimple linear regression, 210\\nSimpson’s paradox, 259\\nsimulation, 108, 180\\nsize, 150\\nslack variables, 371\\nSlutzky’s theorem, 75\\nsmoothing, 303\\nsmoothing parameter, 303\\nSobolev space, 88\\nsojourn times, 396\\nspatially inhomogeneous, 340\\nstandard deviation, 51\\nstandard error, 90\\nstandard Normal distribution, 28\\nstate space, 381\\nstationary, 390\\nstatistic, 61, 107, 137\\nstatistical functional, 89, 99\\nstatistical model, 87\\nStein’s paradox, 204\\nstochastic process, 381\\nStone’s theorem, 20.16, 316\\nstrong law of large numbers, 5.18,\\n81\\nstrongly inadmissible, 204\\nsubjectivism, 181\\nsuﬃciency, 137\\nsuﬃcient statistic, 137\\nSummary of Terminology, 4\\nsupervised learning, 349\\nsupport vector machines, 368\\nsupport vectors, 370\\nt distribution, 30\\nt-test, 170\\ntest statistic, 150\\nthird quartile, 25\\nthresholding, 342\\ntraining error, 219\\ntraining error rate, 351\\ntraining set, 363\\ntransformations of random variables,\\n41\\ntransient, 388\\ntrue error rate, 351\\ntwo-sided test, 151\\ntype I error, 150\\ntype II error, 150\\ntypes of convergence, 72\\nunbiased, 90\\nunderﬁtting, 218\\nundirected graph, 281\\nuniform asymptotic, 95\\nUniform distribution, 27\\nunshielded collider, 266\\nvalidation set, 363\\nVapnik-Chervonenkis, 366\\nvariance, 51\\nconditional, 55\\nvariance-covariance matrix, 53\\nvertices, 281\\nwaiting times, 396\\nWald test, 153'),\n",
       " Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 457, 'page_label': '458'}, page_content='442 Index\\nwavelets, 340\\nweak law of large numbers (WLLN),\\n5.6,7 6\\nZheng-Loh method, 222')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcf28c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89316188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 838\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "print(f\"Number of documents: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0bd61a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page': 0, 'page_label': '1'}, page_content='To Isa')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07f582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01805581897497177,\n",
       " 0.00474091200158,\n",
       " -0.04882135987281799,\n",
       " -0.024462424218654633,\n",
       " -0.005917029920965433]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model='models/text-embedding-004')\n",
    "\n",
    "vector = embeddings.embed_query('hello')\n",
    "vector[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "598e0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51ce089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type='similarity',search_kwargs={\"k\": 10})\n",
    "\n",
    "retrieved_docs = retriever.get_relevant_documents(\"Summarize the content of these documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18777f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bc5d042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1f170c0f-03e7-4cff-8988-53c52be16157', metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creationdate': '2005-08-15T22:23:50-04:00', 'creator': 'A-PDF Merger(Infix)', 'page_label': '17', 'total_pages': 458, 'moddate': 'D:20080525100447', 'source': 'all-of-statistics.pdf', 'page': 16}, page_content='Part I\\nProbability'),\n",
       " Document(id='1943c8ca-f264-4508-a266-bc2d92035446', metadata={'total_pages': 458, 'page_label': '1', 'source': 'all-of-statistics.pdf', 'page': 0, 'moddate': 'D:20080525100447', 'creationdate': '2005-08-15T22:23:50-04:00', 'creator': 'A-PDF Merger(Infix)', 'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)'}, page_content='To Isa'),\n",
       " Document(id='d038731e-8d7f-4f00-9038-2da1ec97c7f0', metadata={'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'total_pages': 458, 'source': 'all-of-statistics.pdf', 'page': 222, 'moddate': 'D:20080525100447', 'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'page_label': '223'}, page_content='Part III\\nStatistical Models and\\nMethods'),\n",
       " Document(id='21b015df-cb5a-4c88-8b8d-2e696fdb257c', metadata={'source': 'all-of-statistics.pdf', 'total_pages': 458, 'page_label': '101', 'creationdate': '2005-08-15T22:23:50-04:00', 'page': 100, 'moddate': 'D:20080525100447', 'creator': 'A-PDF Merger(Infix)', 'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)'}, page_content='Part II\\nStatistical Inference'),\n",
       " Document(id='fb7c2f25-5967-4210-a980-15f250cc5c4e', metadata={'total_pages': 458, 'creationdate': '2005-08-15T22:23:50-04:00', 'source': 'all-of-statistics.pdf', 'moddate': 'D:20080525100447', 'page': 186, 'page_label': '187', 'creator': 'A-PDF Merger(Infix)', 'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)'}, page_content='interval for the diﬀerence of means. What do you conclude?\\n(b) Now use a permutation test to avoid the use of large sample methods.\\nWhat is your conclusion? (Brinegar (1963)).'),\n",
       " Document(id='2707e811-25ad-4517-b677-4fb0a444a49f', metadata={'moddate': 'D:20080525100447', 'creationdate': '2005-08-15T22:23:50-04:00', 'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'source': 'all-of-statistics.pdf', 'creator': 'A-PDF Merger(Infix)', 'total_pages': 458, 'page': 119, 'page_label': '120'}, page_content='website for this book. Estimate the cdf F(x). Compute and plot a 95\\npercent conﬁdence envelope for F (as described in the appendix). Find\\nan approximate 95 percent conﬁdence interval for F(4.9) − F(4.3).'),\n",
       " Document(id='10d0a753-7ffa-4230-9383-beeb639d1754', metadata={'source': 'all-of-statistics.pdf', 'creator': 'A-PDF Merger(Infix)', 'creationdate': '2005-08-15T22:23:50-04:00', 'page_label': '96', 'total_pages': 458, 'moddate': 'D:20080525100447', 'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'page': 95}, page_content='tails, see Grimmett and Stirzaker (1982), Karr (1993), and Billingsley (1979).\\nAdvanced convergence theory is explained in great detail in van der Vaart\\nand Wellner (1996) and and van der Vaart (1998).'),\n",
       " Document(id='adcf437b-78b5-40f5-82eb-2c48bb2f1a18', metadata={'creator': 'A-PDF Merger(Infix)', 'page': 8, 'creationdate': '2005-08-15T22:23:50-04:00', 'source': 'all-of-statistics.pdf', 'total_pages': 458, 'moddate': 'D:20080525100447', 'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'page_label': '9'}, page_content='2.5 Bivariate Distributions ....................... 3 1\\n2.6 Marginal Distributions ....................... 3 3\\n2.7 Independent Random Variables .................. 3 4\\n2.8 Conditional Distributions ..................... 3 6'),\n",
       " Document(id='4b342480-e42f-4846-bff3-a5d040a22265', metadata={'creator': 'A-PDF Merger(Infix)', 'page': 5, 'moddate': 'D:20080525100447', 'total_pages': 458, 'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'source': 'all-of-statistics.pdf', 'creationdate': '2005-08-15T22:23:50-04:00', 'page_label': '6'}, page_content='up. Some I remembered from my education. Some I borrowed from other\\nbooks. I hope I do not oﬀend anyone if I have used a problem from their book\\nand failed to give proper credit. As my colleague Mark Schervish wrote in his\\nbook (Schervish (1995)),\\n“ ...t h ep r o b l e m sa tt h ee n d so fe a c hc h a p t e rh a v ec o m ef r o mm a n y\\ns o u r c e s . ...T h e s e p r o b l e m s , i n t u r n , c a m e f r o m v a r i o u s s o u r c e s\\nu n k n o w nt om e...I fIh a v eu s e dap r o b l e mw i t h o u tg i v i n gp r o pe r\\ncredit, please take it as a compliment.”\\nI am indebted to many people without whose help I could not have written\\nthis book. First and foremost, the many students who used earlier versions\\nof this text and provided much feedback. In particular, Liz Prather and Jen-\\nnifer Bakal read the book carefully. Rob Reeder valiantly read through the\\nentire book in excruciating detail and gave me countless suggestions for im-'),\n",
       " Document(id='418c3c3f-f3e7-42a0-91eb-c36ad83e9d04', metadata={'producer': 'A-PDF Merger 3.0.4 (http://www.a-pdf.com)', 'creator': 'A-PDF Merger(Infix)', 'moddate': 'D:20080525100447', 'total_pages': 458, 'creationdate': '2005-08-15T22:23:50-04:00', 'page_label': '254', 'page': 253, 'source': 'all-of-statistics.pdf'}, page_content='conﬁdence interval for ρ. Use two methods: the bootstrap and Fisher’s\\nmethod. Compare.\\n6. ( Computer Experiment.) Repeat the previous exercise 1000 times. Com-\\npare the coverage of the two conﬁdence intervals forρ.')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68a5f072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "website for this book. Estimate the cdf F(x). Compute and plot a 95\n",
      "percent conﬁdence envelope for F (as described in the appendix). Find\n",
      "an approximate 95 percent conﬁdence interval for F(4.9) − F(4.3).\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[5].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "465a21db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.3, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "44daf60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\"\"\"You are a helpful AI assistant that helps people find information about courses from the provided context.\n",
    "If you don't know the answer, just say that you don't know. DO NOT try to make up an answer.\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "{context}  \n",
    "Answer the question truthfully and as best as you can and keep it concise.\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56b29706",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answering_chain = create_stuff_documents_chain(\n",
    "    llm,\n",
    "    prompt,   \n",
    ")\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever, question_answering_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3273c2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The documents appear to be excerpts from a textbook or course material covering topics in probability and statistics. The content is divided into three main parts: \"Probability,\" \"Statistical Inference,\" and \"Statistical Models and Methods.\"\n",
      "\n",
      "Key topics discussed include:\n",
      "*   **Probability:** Bivariate, Marginal, Independent, and Conditional Distributions.\n",
      "*   **Statistical Inference:** Confidence intervals (for differences of means, CDFs, and correlation coefficients ρ), permutation tests, bootstrap methods, Fisher's method, large sample methods, and confidence envelopes.\n",
      "*   **References:** Mentions various authors and their works related to advanced convergence theory and problems.\n",
      "\n",
      "The text also includes acknowledgments to students and colleagues for their feedback and contributions to the book.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\":\"What is Chebyshev's inequality?\"})\n",
    "print(response['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
